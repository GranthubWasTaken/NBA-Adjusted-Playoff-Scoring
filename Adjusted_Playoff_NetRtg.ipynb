{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KA1adZNvGkBH"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "pd.set_option('display.colheader_justify', 'center')\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "\n",
        "import scipy.stats\n",
        "from scipy import stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "\n",
        "from inspect import signature\n",
        "\n",
        "def someMethod(self, arg1, kwarg1=None):\n",
        "    pass\n",
        "\n",
        "nba_possession_data_seasons = np.arange(1974, 2024, 1)\n",
        "play_by_play_data_seasons = np.arange(1997, 2024, 1)\n",
        "nba_pre_possession_data_seasons = np.arange(1952, 1974, 1)\n",
        "aba_possession_data_seasons = np.arange(1974, 1977, 1)\n",
        "aba_pre_possession_data_seasons = np.arange(1968, 1974, 1)\n",
        "\n",
        "all_nba_seasons = np.arange(1952, 2024, 1)\n",
        "all_aba_seasons = np.arange(1968, 1977, 1)\n",
        "\n",
        "# plot\n",
        "import seaborn as sns\n",
        "import ast\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.pyplot import *\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as font_manager\n",
        "sns.set_style('darkgrid')        # darkgrid, white grid, dark, white and ticks\n",
        "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=14)     # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=13)    # legend fontsize\n",
        "plt.rc('font', size=13)          # controls default text sizes\n",
        "\n",
        "def label_point(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "      #if i % 2 == 0:\n",
        "      ax.text(point['x']+0.12, point['y']+.25, str(point['val']))\n",
        "      #else:\n",
        "      #ax.text(point['x']+0.30, point['y'], str(point['val']))\n",
        "      #ax.text(point['x']+0.05, point['y'], str(point['val']))\n",
        "\n",
        "def label_point_year(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "      #if i % 2 == 0:\n",
        "      ax.text(point['x']+0.12, point['y'], int(point['val']))\n",
        "      #else:\n",
        "      #ax.text(point['x']+0.30, point['y'], str(point['val']))\n",
        "      #ax.text(point['x']+0.05, point['y'], str(point['val']))\n",
        "\n",
        "plot_colors_set_list = [\"#FF0000\", \"#D3A6D6\", \"#916613\", \"#00A4A0\", \"#FF7F00\", \"#ABFFD2\", \"#610077\", \"#173E4C\", \"#00A54C\", \"#FF00A1\", \"#FFFE00\", \"#0B1ADD\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cn6OcXIY66Fb"
      },
      "outputs": [],
      "source": [
        "#@title Import Selenium\n",
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install chromium chromium-driver\n",
        "\n",
        "# Install selenium\n",
        "pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jozq2eJRHQHc"
      },
      "outputs": [],
      "source": [
        "#@title Start Webdriver and VirtualDisplay\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "\n",
        "service = Service(executable_path=r'/usr/bin/chromedriver')\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome(service=service, options=options)\n",
        "\n",
        "#options = Options()\n",
        "#options.add_argument(\"--headless\")\n",
        "#options.add_argument(\"--no-sandbox\")\n",
        "#options.headless = True\n",
        "\n",
        "#wd = webdriver.Chrome(\"/usr/bin/chromedriver\", options=options)\n",
        "\n",
        "!pip install pyvirtualdisplay\n",
        "!apt-get install xvfb\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(800, 800))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Determine Opponents' DefRtg+\n",
        "teams = pd.read_csv('/content/Nash_Series.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "specific_team = \"LEBRON\"\n",
        "\n",
        "specific_team_series = teams[(teams['Team'] == specific_team)]\n",
        "specific_team_series = specific_team_series[(specific_team_series['Year'] >= 2008)]\n",
        "specific_team_series = specific_team_series[(specific_team_series['Year'] <= 2018)]\n",
        "\n",
        "total_defrtg = 0\n",
        "stat = 'DefRtg+'\n",
        "\n",
        "total_opponents_df = pd.DataFrame(columns=[f'{stat}', 'MP'])\n",
        "\n",
        "team_finished = []\n",
        "\n",
        "for idx, row in specific_team_series.iterrows():\n",
        "\n",
        "  opp = row['Opp']\n",
        "  year = row['Year']\n",
        "  opp_playoffs = teams[(teams['Team'] == opp) & (teams['Year'] == year)]\n",
        "  opp_playoffs = opp_playoffs[opp_playoffs['Opp'] != specific_team]\n",
        "\n",
        "  if not opp_playoffs.empty:\n",
        "    team_was = str(row['Opp']) + str(row['Year'])\n",
        "    if team_was not in team_finished:\n",
        "      mp = int(opp_playoffs['MP'].sum())\n",
        "      opp_playoffs[f'{stat}_Portion'] = opp_playoffs[f'{stat}'] * (opp_playoffs['MP'] / mp)\n",
        "      rtg = opp_playoffs[f'{stat}_Portion'].sum().round(1)\n",
        "      total_opponents_df.loc[len(total_opponents_df.index)] = [rtg, mp]\n",
        "      print(opp_playoffs)\n",
        "      team_finished.append(team_was)\n",
        "\n",
        "\n",
        "mp = int(total_opponents_df['MP'].sum())\n",
        "total_opponents_df['Portion'] = total_opponents_df[f'{stat}'] = total_opponents_df[f'{stat}'] * (total_opponents_df['MP'] / mp)\n",
        "rtg = total_opponents_df[f'Portion'].sum().round(1)\n",
        "print(rtg)\n",
        "print(mp)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kg9mujcM52-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Determine Opponents' OffRtg+\n",
        "teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1957_2023_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "specific_team = \"SAS\"\n",
        "min_year = 2001\n",
        "max_year = 2008\n",
        "\n",
        "specific_team_series = teams[(teams['Team'] == specific_team)]\n",
        "specific_team_series = specific_team_series[(specific_team_series['Year'] >= min_year)]\n",
        "specific_team_series = specific_team_series[(specific_team_series['Year'] <= max_year)]\n",
        "\n",
        "total_defrtg = 0\n",
        "stat = 'OffRtg+'\n",
        "\n",
        "total_opponents_df = pd.DataFrame(columns=[f'{stat}', 'MP'])\n",
        "\n",
        "team_finished = []\n",
        "\n",
        "for idx, row in specific_team_series.iterrows():\n",
        "\n",
        "  opp = row['Opp']\n",
        "  year = row['Year']\n",
        "  opp_playoffs = teams[(teams['Team'] == opp) & (teams['Year'] == year)]\n",
        "  opp_playoffs = opp_playoffs[opp_playoffs['Opp'] != specific_team]\n",
        "\n",
        "  if not opp_playoffs.empty:\n",
        "    team_was = str(row['Opp']) + str(row['Year'])\n",
        "    if team_was not in team_finished:\n",
        "      mp = int(opp_playoffs['MP'].sum())\n",
        "      opp_playoffs[f'{stat}_Portion'] = opp_playoffs[f'{stat}'] * (opp_playoffs['MP'] / mp)\n",
        "      rtg = opp_playoffs[f'{stat}_Portion'].sum().round(1)\n",
        "      total_opponents_df.loc[len(total_opponents_df.index)] = [rtg, mp]\n",
        "      print(opp_playoffs)\n",
        "      tmp_sum = opp_playoffs[f'{stat}_Portion'].sum().round(1)\n",
        "      team_finished.append(team_was)\n",
        "      print(tmp_sum)\n",
        "\n",
        "\n",
        "mp = int(total_opponents_df['MP'].sum())\n",
        "total_opponents_df['Portion'] = total_opponents_df[f'{stat}'] = total_opponents_df[f'{stat}'] * (total_opponents_df['MP'] / mp)\n",
        "rtg = total_opponents_df[f'Portion'].sum().round(1)\n",
        "print(rtg)\n",
        "print(mp)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LLu6ci71Z9Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Print OffRtg or DefRtg over a stretch for a team\n",
        "def print_rtg_over_stretch(stat, team, first_year, second_year):\n",
        "  teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_1957_2023_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  if stat == \"d\":\n",
        "    stat = \"DefRtg+\"\n",
        "  elif stat == \"o\":\n",
        "    stat = \"OffRtg+\"\n",
        "  elif stat == \"n\":\n",
        "    stat = \"NetRtg+\"\n",
        "  specific_team = teams[(teams['Year'] >= first_year)]\n",
        "  specific_team = specific_team[(specific_team['Year'] <= second_year)]\n",
        "  specific_team = specific_team[(specific_team['Team'] == team)]\n",
        "  mp = specific_team['MP'].sum()\n",
        "  print(\"MP: \", mp)\n",
        "\n",
        "  specific_team[f'{stat}_Portion'] = specific_team[f'{stat}'] * (specific_team['MP'] / mp)\n",
        "  peak = specific_team[f'{stat}_Portion'].sum().round(1)\n",
        "\n",
        "  print(f\"{stat}: \", peak)"
      ],
      "metadata": {
        "id": "ltZkHsrL6Yx1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_rtg_over_stretch(\"d\", \"DET\", 2000, 2003)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvN-w__ZKkjL",
        "outputId": "bd815752-d3a2-47e5-dd2a-2486eb97243c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MP:  1450\n",
            "DefRtg+:  103.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Scrape Playoff Teams' OffRtg+ and rDefRtg+\n",
        "def scrape_playoff_rOffRtg_rDefRtg(origal_team_df):\n",
        "\n",
        "\n",
        "  teams_defense = pd.read_csv('/content/nba_Team_DefRtg_Allowed_74-23_df.csv', index_col=False, encoding='utf8')\n",
        "  teams_offense = pd.read_csv('/content/nba_Team_OffRtg_74-23_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  fiftytwo_seventythree_off_def_rtgs = pd.read_csv('/content/nba_Team_Estimated_Pace_52-73_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  missing_pistons_lakers_60_62 = pd.read_csv('/content/missing_fga_60_62.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "\n",
        "  team_df = pd.DataFrame(columns = ['Year', 'Team', 'OffRtg+', 'DefRtg+', 'MP'])\n",
        "  total_series_df = pd.DataFrame(columns = ['Year', 'Team', 'Opp', 'OffRtg+', 'DefRtg+', 'MP'])\n",
        "\n",
        "  for idx, row in origal_team_df.iterrows():\n",
        "\n",
        "    use_different_pace_formula = 0\n",
        "    dont_estimate_pace = 0\n",
        "\n",
        "    original_team = str(row['Team'])\n",
        "    series_df = pd.DataFrame(columns = ['Year', 'Team', 'Opp', 'OffRtg+', 'DefRtg+', 'MP'])\n",
        "\n",
        "    team_url = \"https://www.basketball-reference.com/teams/\" + row['Team'] + \"/\" + str(row['Year']) + \".html\"\n",
        "\n",
        "    html = urlopen(team_url)\n",
        "    soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "    for first_div in soup.find_all('div', attrs={'id': 'info'}):\n",
        "      second_div = first_div.find('div', attrs={'id': 'meta'})\n",
        "      second_div = str(second_div)\n",
        "      ref_urls = re.findall(r'/\\w+\\/\\d+[0-9abcdefghijklmnopqrstuvwxyz-]+', second_div)\n",
        "      urls = []\n",
        "      for ref_url in ref_urls:\n",
        "        if \"eastern\" in ref_url or \"western\" in ref_url or \"finals\" in ref_url:\n",
        "          ref_url = \"https://www.basketball-reference.com\" + ref_url + \".html\"\n",
        "          urls.append(ref_url)\n",
        "    for series_url in urls:\n",
        "\n",
        "      time.sleep(6)\n",
        "      html = urlopen(series_url)\n",
        "      soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_four_factors'})\n",
        "\n",
        "      second_div = str(second_div)\n",
        "\n",
        "      teams = re.findall(r'/\\w+\\/\\d+', second_div)\n",
        "      count = 0\n",
        "      for team in teams:\n",
        "        if count == 0:\n",
        "          if str(row['Team']) in team:\n",
        "            team_in = 0\n",
        "          else:\n",
        "            team_in = 1\n",
        "            other_team = team\n",
        "        else:\n",
        "          if str(row['Team']) not in team:\n",
        "            other_team = team\n",
        "        count = count + 1\n",
        "      year = row['Year']\n",
        "      other_team = other_team.replace(f'{year}', '')\n",
        "      other_team = other_team.replace(f'/', '')\n",
        "\n",
        "      rtgs_untrimmed = re.findall(r'off_rtg\" >\\d+.\\d+', second_div)\n",
        "\n",
        "      # no OffRtg's. Need to estimate them given boxscore.\n",
        "      if not rtgs_untrimmed:\n",
        "        if year >= 1971:\n",
        "          ORB_percent = 0.319\n",
        "        else:\n",
        "          ORB_percent = 0.303\n",
        "\n",
        "        # most likely have TOV data\n",
        "        if year >= 1974:\n",
        "\n",
        "          # team data to estimate pace\n",
        "\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{original_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{original_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "            mp_untrimmed = re.findall(r\"data-stat=[\\\"]mp\\\" >\\d+\", second_div_str)\n",
        "            mp_untrimmed = mp_untrimmed[-1]\n",
        "            mp = mp_untrimmed.replace(f'data-stat=\"mp\" >', '')\n",
        "            mp = int(mp) // 5\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            tov_untrimmed = re.findall(r\"data-stat=[\\\"]tov\\\" >\\d+\", second_div_str)\n",
        "            tov_untrimmed = tov_untrimmed[-1]\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            if tov:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              else:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "              TOV_percent = tov / poss\n",
        "            else:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                use_different_pace_formula = 1\n",
        "              else:\n",
        "                TOV_percent = 0.158\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            mp = int(series_data['MP'])\n",
        "            mp = int(mp // 5)\n",
        "\n",
        "            fga = int(series_data['FGA'])\n",
        "\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            try:\n",
        "              tov = int(series_data['TOV'])\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              except:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "                TOV_percent = tov / poss\n",
        "            except:\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                use_different_pace_formula = 1\n",
        "              except:\n",
        "                TOV_percent = 0.158\n",
        "\n",
        "          if dont_estimate_pace == 1:\n",
        "            OffRtg = pts / poss * 100\n",
        "          elif use_different_pace_formula == 0:\n",
        "            original_team_possessions = fga + (0.4 * fta) - ORB_percent * (fga - fg) + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            OffRtg = pts / original_team_possessions * 100\n",
        "          else:\n",
        "            original_team_possessions = fga + (0.4 * fta) - orb + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            OffRtg = pts / original_team_possessions * 100\n",
        "\n",
        "          # opponent data to estimate opponent pace\n",
        "\n",
        "          use_different_pace_formula = 0\n",
        "          dont_estimate_pace = 0\n",
        "\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{other_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{other_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            tov_untrimmed = re.findall(r\"data-stat=[\\\"]tov\\\" >\\d+\", second_div_str)\n",
        "            tov_untrimmed = tov_untrimmed[-1]\n",
        "            tov = tov_untrimmed.replace(f'data-stat=\"tov\" >', '')\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            if tov:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              else:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "              TOV_percent = tov / poss\n",
        "            else:\n",
        "              orb_untrimmed = re.findall(r\"data-stat=[\\\"]orb\\\" >\\d+\", second_div_str)\n",
        "              if orb_untrimmed:\n",
        "                orb_untrimmed = orb_untrimmed[-1]\n",
        "                orb = orb_untrimmed.replace(f'data-stat=\"orb\" >', '')\n",
        "                use_different_pace_formula = 1\n",
        "              else:\n",
        "                  TOV_percent = 0.158\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            fga = int(series_data['FGA'])\n",
        "\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            try:\n",
        "              tov = int(series_data['TOV'])\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                poss = fga + ft_trips + tov - orb\n",
        "                dont_estimate_pace = 1\n",
        "              except:\n",
        "                poss = fga + ft_trips + tov - (ORB_percent * (fga - fg))\n",
        "                TOV_percent = tov / poss\n",
        "            except:\n",
        "              try:\n",
        "                orb = int(series_data['ORB'])\n",
        "                use_different_pace_formula = 1\n",
        "              except:\n",
        "                TOV_percent = 0.158\n",
        "\n",
        "          if dont_estimate_pace == 1:\n",
        "            DefRtg = pts / poss * 100\n",
        "          elif use_different_pace_formula == 0:\n",
        "            opponent_team_possessions = fga + (0.4 * fta) - ORB_percent * (fga - fg) + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            DefRtg = pts / opponent_team_possessions * 100\n",
        "          else:\n",
        "            opponent_team_possessions = fga + (0.4 * fta) - orb + (-TOV_percent * (fga + 0.44 * fta) / (TOV_percent - 1))\n",
        "            DefRtg = pts / opponent_team_possessions * 100\n",
        "\n",
        "          other_team_defrtg = teams_defense[(teams_defense['Year'] == year) & (teams_defense['Team'] == other_team)]\n",
        "          other_team_offrtg = teams_offense[(teams_offense['Year'] == year) & (teams_offense['Team'] == other_team)]\n",
        "\n",
        "          r_OffRtg = float(OffRtg) / float(other_team_defrtg['DefRtg']) * 100\n",
        "          r_DefRtg = float(other_team_offrtg['OffRtg']) / float(DefRtg) * 100\n",
        "\n",
        "          r_OffRtg = round(r_OffRtg, 1)\n",
        "          r_DefRtg = round(r_DefRtg, 1)\n",
        "\n",
        "        # will not have TOV data\n",
        "        else:\n",
        "          if year >= 1971:\n",
        "            TOV_percent = 0.158\n",
        "          else:\n",
        "            TOV_percent = 0.161\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{original_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{original_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "            mp_untrimmed = re.findall(r\"data-stat=[\\\"]mp\\\" >\\d+\", second_div_str)\n",
        "            mp_untrimmed = mp_untrimmed[-1]\n",
        "            mp = mp_untrimmed.replace(f'data-stat=\"mp\" >', '')\n",
        "            mp = int(mp) // 5\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "            pts = int(pts)\n",
        "\n",
        "\n",
        "            total_fga = fga\n",
        "            total_fg = fg\n",
        "            total_fta = fta\n",
        "            total_pts = pts\n",
        "\n",
        "            original_pts = pts\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            mp = int(series_data['MP'])\n",
        "            mp = int(mp // 5)\n",
        "\n",
        "            try:\n",
        "              fga = int(series_data['FGA'])\n",
        "            except:\n",
        "              fga = missing_pistons_lakers_60_62[(missing_pistons_lakers_60_62['Team'] == original_team) & (missing_pistons_lakers_60_62['Year'] == year)]\n",
        "              fga = fga['FGA']\n",
        "              fga = int(fga)\n",
        "\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "\n",
        "            total_fga = fga\n",
        "            total_fg = fg\n",
        "            total_fta = fta\n",
        "            total_pts = pts\n",
        "\n",
        "            original_pts = pts\n",
        "\n",
        "          # opponent data to estimate opponent pace\n",
        "\n",
        "          first_div = soup.find('div', attrs={'id': 'content'})\n",
        "          second_div = first_div.find('div', attrs={'id': f'all_{other_team}'})\n",
        "          first_table = second_div.find('table', attrs={'id': f'{other_team}'})\n",
        "          if first_table == None:\n",
        "            second_div_str = str(second_div)\n",
        "\n",
        "            fga_untrimmed = re.findall(r\"data-stat=[\\\"]fga\\\" >\\d+\", second_div_str)\n",
        "            fga_untrimmed = fga_untrimmed[-1]\n",
        "            fga = fga_untrimmed.replace(f'data-stat=\"fga\" >', '')\n",
        "\n",
        "            fg_untrimmed = re.findall(r\"data-stat=[\\\"]fg\\\" >\\d+\", second_div_str)\n",
        "            fg_untrimmed = fg_untrimmed[-1]\n",
        "            fg = fg_untrimmed.replace(f'data-stat=\"fg\" >', '')\n",
        "\n",
        "            fta_untrimmed = re.findall(r\"data-stat=[\\\"]fta\\\" >\\d+\", second_div_str)\n",
        "            fta_untrimmed = fta_untrimmed[-1]\n",
        "            fta = fta_untrimmed.replace(f'data-stat=\"fta\" >', '')\n",
        "\n",
        "            pts_untrimmed = re.findall(r\"data-stat=[\\\"]pts\\\" >\\d+\", second_div_str)\n",
        "            pts_untrimmed = pts_untrimmed[-1]\n",
        "            pts = pts_untrimmed.replace(f'data-stat=\"pts\" >', '')\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "            pts = int(pts)\n",
        "\n",
        "            total_fga = total_fga + fga\n",
        "            total_fg = total_fg + fg\n",
        "            total_fta = total_fta + fta\n",
        "            total_pts = total_pts + pts\n",
        "\n",
        "          else:\n",
        "            header = first_table.find('thead')\n",
        "            foot = first_table.find('tfoot')\n",
        "\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            rows = foot.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "            #create df\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            pts_count = 0\n",
        "            mp_count = 0\n",
        "            cols = []\n",
        "            for column in series_data.columns:\n",
        "              if column == 'MP':\n",
        "                if mp_count == 1:\n",
        "                  cols.append(f'MPG')\n",
        "                else:\n",
        "                  cols.append(f'MP')\n",
        "                mp_count+=1\n",
        "                continue\n",
        "              if column == 'PTS':\n",
        "                if pts_count == 1:\n",
        "                  cols.append(f'PTS/G')\n",
        "                else:\n",
        "                  cols.append(f'PTS')\n",
        "                pts_count+=1\n",
        "                continue\n",
        "              cols.append(column)\n",
        "            series_data.columns = cols\n",
        "\n",
        "            try:\n",
        "              fga = int(series_data['FGA'])\n",
        "            except:\n",
        "              fga = missing_pistons_lakers_60_62[(missing_pistons_lakers_60_62['Team'] == original_team) & (missing_pistons_lakers_60_62['Year'] == year)]\n",
        "              fga = fga['FGA']\n",
        "              fga = int(fga)\n",
        "\n",
        "            fg = int(series_data['FG'])\n",
        "\n",
        "            fta = int(series_data['FTA'])\n",
        "            ft_trips = fta * .44\n",
        "\n",
        "            pts = int(series_data['PTS'])\n",
        "\n",
        "            fta = int(fta)\n",
        "            fga = int(fga)\n",
        "            fg = int(fg)\n",
        "\n",
        "            total_fga = total_fga + fga\n",
        "            total_fg = total_fg + fg\n",
        "            total_fta = total_fta + fta\n",
        "            total_pts = total_pts + pts\n",
        "\n",
        "          possessions = (total_fga + (0.4 * total_fta) - ORB_percent * (total_fga - total_fg) + (-TOV_percent * (total_fga + 0.44 * total_fta) / (TOV_percent - 1))) / 2\n",
        "          DefRtg = pts / possessions * 100\n",
        "          OffRtg = original_pts / possessions * 100\n",
        "\n",
        "          other_team_defrtg_ortg = fiftytwo_seventythree_off_def_rtgs[(fiftytwo_seventythree_off_def_rtgs['Year'] == year) & (fiftytwo_seventythree_off_def_rtgs['Team'] == other_team)]\n",
        "          r_OffRtg = float(OffRtg) / float(other_team_defrtg_ortg['DefRtg']) * 100\n",
        "          r_DefRtg = float(other_team_defrtg_ortg['OffRtg']) / float(DefRtg) * 100\n",
        "\n",
        "          r_OffRtg = round(r_OffRtg, 1)\n",
        "          r_DefRtg = round(r_DefRtg, 1)\n",
        "\n",
        "      # have OffRtg's, can use them\n",
        "      else:\n",
        "        count = 0\n",
        "        for rtg in rtgs_untrimmed:\n",
        "          rtg = rtg.replace('off_rtg\" >', '')\n",
        "          if count == 0 and team_in == 0:\n",
        "            off_rtg = rtg\n",
        "          elif count == 1 and team_in == 0:\n",
        "            def_rtg = rtg\n",
        "          elif count == 0 and team_in == 1:\n",
        "            def_rtg = rtg\n",
        "          elif count == 1 and team_in == 1:\n",
        "            off_rtg = rtg\n",
        "          count = count + 1\n",
        "\n",
        "        other_team_defrtg = teams_defense[(teams_defense['Year'] == year) & (teams_defense['Team'] == other_team)]\n",
        "\n",
        "        other_team_offrtg = teams_offense[(teams_offense['Year'] == year) & (teams_offense['Team'] == other_team)]\n",
        "\n",
        "        r_OffRtg = float(off_rtg) / float(other_team_defrtg['DefRtg']) * 100\n",
        "        r_DefRtg = float(other_team_offrtg['OffRtg']) / float(def_rtg)* 100\n",
        "\n",
        "        r_OffRtg = round(r_OffRtg, 1)\n",
        "        r_DefRtg = round(r_DefRtg, 1)\n",
        "\n",
        "\n",
        "        first_div = soup.find('div', attrs={'id': 'content'})\n",
        "        second_div = first_div.find('div', attrs={'id': f'all_{original_team}'})\n",
        "        first_table = second_div.find('table', attrs={'id': f'{original_team}'})\n",
        "        if first_table == None:\n",
        "          second_div_str = str(second_div)\n",
        "          mp_untrimmed = re.findall(r\"data-stat=[\\\"]mp\\\" >\\d+\", second_div_str)\n",
        "          mp_untrimmed = mp_untrimmed[-1]\n",
        "          mp = mp_untrimmed.replace(f'data-stat=\"mp\" >', '')\n",
        "          mp = int(mp) // 5\n",
        "        else:\n",
        "          header = first_table.find('thead')\n",
        "          foot = first_table.find('tfoot')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "          rows = foot.findAll('tr')[0:]\n",
        "          series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "          # remove empty rows\n",
        "          series_stats = [e for e in series_stats if e != []]\n",
        "          series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "          #create df\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          pts_count = 0\n",
        "          mp_count = 0\n",
        "          cols = []\n",
        "          for column in series_data.columns:\n",
        "            if column == 'MP':\n",
        "              if mp_count == 1:\n",
        "                cols.append(f'MPG')\n",
        "              else:\n",
        "                cols.append(f'MP')\n",
        "              mp_count+=1\n",
        "              continue\n",
        "            if column == 'PTS':\n",
        "              if pts_count == 1:\n",
        "                cols.append(f'PTS/G')\n",
        "              else:\n",
        "                cols.append(f'PTS')\n",
        "              pts_count+=1\n",
        "              continue\n",
        "            cols.append(column)\n",
        "          series_data.columns = cols\n",
        "\n",
        "          mp = int(series_data['MP'])\n",
        "          mp = int(mp // 5)\n",
        "\n",
        "      new_row = pd.DataFrame(np.array([[year, original_team, other_team, r_OffRtg, r_DefRtg, mp]]), columns=['Year', 'Team', 'Opp', 'OffRtg+', 'DefRtg+', 'MP'])\n",
        "      series_df = pd.concat([series_df, new_row], ignore_index=True)\n",
        "      total_series_df = pd.concat([total_series_df, new_row], ignore_index=True)\n",
        "      series_df['MP'] = series_df['MP'].astype(int)\n",
        "      total_series_df['MP'] = total_series_df['MP'].astype(int)\n",
        "\n",
        "    mp = int(series_df['MP'].sum())\n",
        "    print(series_df)\n",
        "\n",
        "    for idx, row in series_df.iterrows():\n",
        "\n",
        "      series_df.loc[idx, 'OffRtg+_Portion'] = float(series_df.loc[idx, 'OffRtg+']) * float((series_df.loc[idx, 'MP'] / mp))\n",
        "      series_df.loc[idx, 'DefRtg+_Portion'] = float(series_df.loc[idx, 'DefRtg+']) * float((series_df.loc[idx, 'MP'] / mp))\n",
        "    rOffRtg_avg = series_df[f'OffRtg+_Portion'].sum().round(1)\n",
        "    rDefRtg_avg = series_df[f'DefRtg+_Portion'].sum().round(1)\n",
        "\n",
        "    new_row = pd.DataFrame(np.array([[year, original_team, rOffRtg_avg, rDefRtg_avg, mp]]), columns=['Year', 'Team', 'OffRtg+', 'DefRtg+', 'MP'])\n",
        "    team_df = pd.concat([team_df, new_row], ignore_index=True)\n",
        "\n",
        "    total_series_df.to_csv('nba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1957_2023_df.csv', index=False)\n",
        "    team_df.to_csv('nba_Playoff_rOffRtg_rDefRtg_1957_2023_df.csv', index=False)\n",
        "    print(team_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Xrnh4EJm1fyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teams = pd.read_csv('/content/nba_playoff_teams_1952_2023_df.csv', index_col=False, encoding='utf8')\n",
        "scrape_playoff_rOffRtg_rDefRtg(teams)"
      ],
      "metadata": {
        "id": "ZTFTBTFwYI_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teams = pd.read_csv('/content/nba_Playoff_rOffRtg_rDefRtg_Series_By_Series_1957_2023_df.csv', index_col=False, encoding='utf8')\n",
        "finished = []\n",
        "count = 0\n",
        "for idx, row in teams.iterrows():\n",
        "  if row['Team'] not in finished:\n",
        "    print(row['Team'])\n",
        "    specific_team = teams[(teams['Team'] == row['Team'])]\n",
        "    specific_team.to_csv(f\"{row['Team']}_Adjusted_Playoff_NetRtg_Series_By_Series.csv\", index=False)\n",
        "    finished.append(row['Team'])"
      ],
      "metadata": {
        "id": "l31nUBczL0LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1000-5000 MP OffRtg+ Peaks\n",
        "team_data = pd.read_csv('/content/nash_peaks.csv', encoding='utf8', index_col=False)\n",
        "team_data['OffRtg+'] = team_data['OffRtg+'].round(1)\n",
        "\n",
        "team = \"LEBRON\"\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 1000]\n",
        "team_data = team_data[team_data['MP'] <= 1999]\n",
        "\n",
        "team_data = team_data.sort_values('OffRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['OffRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['OffRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "team_data.to_csv('1000_MP_Team_Peaks.csv',index=False)\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/nash_peaks.csv', encoding='utf8', index_col=False)\n",
        "team_data['OffRtg+'] = team_data['OffRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 2000]\n",
        "team_data = team_data[team_data['MP'] <= 2999]\n",
        "\n",
        "team_data = team_data.sort_values('OffRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['OffRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['OffRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "team_data.to_csv('2000_MP_Team_Peaks.csv',index=False)\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/nash_peaks.csv', encoding='utf8', index_col=False)\n",
        "team_data['OffRtg+'] = team_data['OffRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 3000]\n",
        "team_data = team_data[team_data['MP'] <= 3999]\n",
        "\n",
        "team_data = team_data.sort_values('OffRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['OffRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['OffRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "team_data.to_csv('3000_MP_Team_Peaks.csv',index=False)\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/nash_peaks.csv', encoding='utf8', index_col=False)\n",
        "team_data['OffRtg+'] = team_data['OffRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 4000]\n",
        "team_data = team_data[team_data['MP'] <= 4999]\n",
        "\n",
        "team_data = team_data.sort_values('OffRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['OffRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['OffRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "team_data.to_csv('4000_MP_Team_Peaks.csv',index=False)\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/nash_peaks.csv', encoding='utf8', index_col=False)\n",
        "team_data['OffRtg+'] = team_data['OffRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 5000]\n",
        "team_data = team_data[team_data['MP'] <= 5999]\n",
        "\n",
        "team_data = team_data.sort_values('OffRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "team_data.to_csv('5000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['OffRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['OffRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/nash_peaks.csv', encoding='utf8', index_col=False)\n",
        "team_data['OffRtg+'] = team_data['OffRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 6000]\n",
        "team_data = team_data[team_data['MP'] <= 6999]\n",
        "\n",
        "team_data = team_data.sort_values('OffRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "team_data.to_csv('5000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['OffRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['OffRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/nash_peaks.csv', encoding='utf8', index_col=False)\n",
        "team_data['OffRtg+'] = team_data['OffRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 7000]\n",
        "team_data = team_data[team_data['MP'] <= 7999]\n",
        "\n",
        "team_data = team_data.sort_values('OffRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "team_data.to_csv('5000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['OffRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['OffRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/nash_peaks.csv', encoding='utf8', index_col=False)\n",
        "team_data['OffRtg+'] = team_data['OffRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 8000]\n",
        "team_data = team_data[team_data['MP'] <= 8999]\n",
        "\n",
        "team_data = team_data.sort_values('OffRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "team_data.to_csv('5000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['OffRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['OffRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/nash_peaks.csv', encoding='utf8', index_col=False)\n",
        "team_data['OffRtg+'] = team_data['OffRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 9000]\n",
        "team_data = team_data[team_data['MP'] <= 9999]\n",
        "\n",
        "team_data = team_data.sort_values('OffRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "team_data.to_csv('5000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['OffRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['OffRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\")"
      ],
      "metadata": {
        "id": "mnslwxzuvMuA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1000-5000 MP DefRtg+ Peaks\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data['DefRtg+'] = team_data['DefRtg+'].round(1)\n",
        "\n",
        "team = \"CHI\"\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 1000]\n",
        "team_data = team_data[team_data['MP'] <= 1999]\n",
        "\n",
        "team_data = team_data.sort_values('DefRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "team_data.to_csv('1000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['DefRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['DefRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data['DefRtg+'] = team_data['DefRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 2000]\n",
        "team_data = team_data[team_data['MP'] <= 2999]\n",
        "\n",
        "team_data = team_data.sort_values('DefRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "team_data.to_csv('2000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['DefRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['DefRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data['DefRtg+'] = team_data['DefRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 3000]\n",
        "team_data = team_data[team_data['MP'] <= 3999]\n",
        "\n",
        "team_data = team_data.sort_values('DefRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "team_data.to_csv('3000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['DefRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['DefRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data['DefRtg+'] = team_data['DefRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 4000]\n",
        "team_data = team_data[team_data['MP'] <= 4999]\n",
        "\n",
        "team_data = team_data.sort_values('DefRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "team_data.to_csv('4000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['DefRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['DefRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "team_data = pd.read_csv('/content/all_peaks_and_single_playoffs_relative_team_data.csv', encoding='utf8', index_col=False)\n",
        "team_data['DefRtg+'] = team_data['DefRtg+'].round(1)\n",
        "\n",
        "team_data = team_data[team_data['MP'] >= 5000]\n",
        "team_data = team_data[team_data['MP'] <= 5999]\n",
        "\n",
        "team_data = team_data.sort_values('DefRtg+', ascending=False)\n",
        "team_data = team_data.reset_index(drop=True)\n",
        "team_data.to_csv('5000_MP_Team_Peaks.csv',index=False)\n",
        "\n",
        "\n",
        "only_team = team_data[(team_data['Team'] == team)]\n",
        "only_team = only_team.drop_duplicates('Team', keep='first')\n",
        "print(only_team)\n",
        "\n",
        "top_off = float(only_team['DefRtg+'])\n",
        "\n",
        "team_data = team_data[(team_data['DefRtg+'] == top_off)]\n",
        "\n",
        "print(team_data)\n",
        "\n",
        "print(\"\\n\\n\\n\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1dEohH_1WzNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEAM PEAK FUNCTIONS**"
      ],
      "metadata": {
        "id": "A2EJRvOmuS3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title X Year Peaks Functions (Team)\n",
        "\n",
        "# returns if all values in a column are unique.\n",
        "\n",
        "\n",
        "# def x_yearpeak(source_df, valuestring, number_of_seasons_peak):\n",
        "# returns a dataframe containing x year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts x year stretches of 'valuestring' AND the listed years from each x year stretch + minutes played across the 2 seasons.\n",
        "def x_yearpeak(source_df, valuestring, valuestring_2, valuestring_3, number_of_seasons_peak):\n",
        "  x_year_peak = pd.DataFrame(columns = ['Years', 'Team', f'{valuestring}', f'{valuestring_2}', f'{valuestring_3}', 'MP'])\n",
        "\n",
        "  team_finished = []\n",
        "\n",
        "  for idx, team in source_df.iterrows():\n",
        "\n",
        "    # if player has not already been through function call\n",
        "    if team['Team'] not in team_finished:\n",
        "      single_team_df = source_df[(source_df['Team'] == team['Team'])]\n",
        "      single_team_df = single_team_df.reset_index(drop=True)\n",
        "      number_of_total_team_seasons = len(single_team_df.index)\n",
        "\n",
        "      for season_index in range(0, number_of_total_team_seasons - (number_of_seasons_peak - 1)):\n",
        "\n",
        "        years = ''\n",
        "        non_consecutive_years = 0\n",
        "\n",
        "        stretch_of_peak_seasons = single_team_df.iloc[season_index: season_index+number_of_seasons_peak].copy()\n",
        "        stretch_of_peak_seasons = stretch_of_peak_seasons.reset_index(drop=True)\n",
        "        mp = int(stretch_of_peak_seasons['MP'].sum())\n",
        "        stretch_of_peak_seasons[f'{valuestring}_Portion'] = stretch_of_peak_seasons[f'{valuestring}'] * (stretch_of_peak_seasons['MP'] / mp)\n",
        "        stretch_of_peak_seasons[f'{valuestring_2}_Portion'] = stretch_of_peak_seasons[f'{valuestring_2}'] * (stretch_of_peak_seasons['MP'] / mp)\n",
        "        stretch_of_peak_seasons[f'{valuestring_3}_Portion'] = stretch_of_peak_seasons[f'{valuestring_3}'] * (stretch_of_peak_seasons['MP'] / mp)\n",
        "        valuestring_peak = stretch_of_peak_seasons[f'{valuestring}_Portion'].sum().round(2)\n",
        "        valuestring_peak_2 = stretch_of_peak_seasons[f'{valuestring_2}_Portion'].sum().round(2)\n",
        "        valuestring_peak_3 = stretch_of_peak_seasons[f'{valuestring_3}_Portion'].sum().round(2)\n",
        "\n",
        "        prev_year = stretch_of_peak_seasons.iloc[0]['Year']\n",
        "        for year in stretch_of_peak_seasons['Year']:\n",
        "          if year - prev_year != 1 and year - prev_year != 0:\n",
        "            stretch_of_peak_seasons[\"Year\"] = stretch_of_peak_seasons[\"Year\"].astype(str)\n",
        "            years = ', '.join(stretch_of_peak_seasons[\"Year\"])\n",
        "            non_consecutive_years = 1\n",
        "            break\n",
        "          prev_year = year\n",
        "        if non_consecutive_years == 0:\n",
        "          years = f\"{stretch_of_peak_seasons.iloc[0]['Year']} - {stretch_of_peak_seasons.iloc[number_of_seasons_peak-1]['Year']}\"\n",
        "\n",
        "        cols = ['Years', 'Team', f'{valuestring}', f'{valuestring_2}', f'{valuestring_3}', 'MP']\n",
        "        df_temp = pd.DataFrame([[years, stretch_of_peak_seasons.iloc[0]['Team'], valuestring_peak, valuestring_peak_2, valuestring_peak_3, mp]], columns=cols)\n",
        "        x_year_peak = pd.concat([x_year_peak, df_temp], ignore_index=False)\n",
        "        outfile = f\"{number_of_seasons_peak}_year_peak_relative_team_data.csv\"\n",
        "        x_year_peak.to_csv(outfile, index=False)\n",
        "      team_finished.append(stretch_of_peak_seasons.iloc[0]['Team'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gARDbX_YAWZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run 2-13 Year Team Data Peaks\n",
        "team_data = pd.read_csv('/content/Nash_Lebron.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "all_peaks = pd.DataFrame()\n",
        "\n",
        "years = 13\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = year8.replace(',', '')\n",
        "    year8 = int(year8)\n",
        "\n",
        "    year9 = peak_years.split()[8]\n",
        "    year9 = year9.replace(',', '')\n",
        "    year9 = int(year9)\n",
        "\n",
        "    year10 = peak_years.split()[9]\n",
        "    year10 = year10.replace(',', '')\n",
        "    year10 = int(year10)\n",
        "\n",
        "    year11 = peak_years.split()[10]\n",
        "    year11 = year11.replace(',', '')\n",
        "    year11 = int(year11)\n",
        "\n",
        "    year12 = peak_years.split()[11]\n",
        "    year12 = year12.replace(',', '')\n",
        "    year12 = int(year12)\n",
        "\n",
        "    year13 = peak_years.split()[12]\n",
        "    year13 = int(year13)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    elif year9 - year8 >= 5:\n",
        "      continue\n",
        "    elif year10 - year9 >= 5:\n",
        "      continue\n",
        "    elif year11 - year10 >= 5:\n",
        "      continue\n",
        "    elif year12 - year11 >= 5:\n",
        "      continue\n",
        "    elif year13 - year12 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 12\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = year8.replace(',', '')\n",
        "    year8 = int(year8)\n",
        "\n",
        "    year9 = peak_years.split()[8]\n",
        "    year9 = year9.replace(',', '')\n",
        "    year9 = int(year9)\n",
        "\n",
        "    year10 = peak_years.split()[9]\n",
        "    year10 = year10.replace(',', '')\n",
        "    year10 = int(year10)\n",
        "\n",
        "    year11 = peak_years.split()[10]\n",
        "    year11 = year11.replace(',', '')\n",
        "    year11 = int(year11)\n",
        "\n",
        "    year12 = peak_years.split()[11]\n",
        "    year12 = int(year12)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    elif year9 - year8 >= 5:\n",
        "      continue\n",
        "    elif year10 - year9 >= 5:\n",
        "      continue\n",
        "    elif year11 - year10 >= 5:\n",
        "      continue\n",
        "    elif year12 - year11 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 11\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = year8.replace(',', '')\n",
        "    year8 = int(year8)\n",
        "\n",
        "    year9 = peak_years.split()[8]\n",
        "    year9 = year9.replace(',', '')\n",
        "    year9 = int(year9)\n",
        "\n",
        "    year10 = peak_years.split()[9]\n",
        "    year10 = year10.replace(',', '')\n",
        "    year10 = int(year10)\n",
        "\n",
        "    year11 = peak_years.split()[10]\n",
        "    year11 = int(year11)\n",
        "\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    elif year9 - year8 >= 5:\n",
        "      continue\n",
        "    elif year10 - year9 >= 5:\n",
        "      continue\n",
        "    elif year11 - year10 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 10\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = year8.replace(',', '')\n",
        "    year8 = int(year8)\n",
        "\n",
        "    year9 = peak_years.split()[8]\n",
        "    year9 = year9.replace(',', '')\n",
        "    year9 = int(year9)\n",
        "\n",
        "    year10 = peak_years.split()[9]\n",
        "    year10 = int(year10)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    elif year9 - year8 >= 5:\n",
        "      continue\n",
        "    elif year10 - year9 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 9\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = year8.replace(',', '')\n",
        "    year8 = int(year8)\n",
        "\n",
        "    year9 = peak_years.split()[8]\n",
        "    year9 = int(year9)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    elif year9 - year8 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 8\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = year7.replace(',', '')\n",
        "    year7 = int(year7)\n",
        "\n",
        "    year8 = peak_years.split()[7]\n",
        "    year8 = int(year8)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    elif year8 - year7 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 7\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = year6.replace(',', '')\n",
        "    year6 = int(year6)\n",
        "\n",
        "    year7 = peak_years.split()[6]\n",
        "    year7 = int(year7)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    elif year7 - year6 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 6\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = year5.replace(',', '')\n",
        "    year5 = int(year5)\n",
        "\n",
        "    year6 = peak_years.split()[5]\n",
        "    year6 = int(year6)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    elif year6 - year5 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 5\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = year4.replace(',', '')\n",
        "    year4 = int(year4)\n",
        "\n",
        "    year5 = peak_years.split()[4]\n",
        "    year5 = int(year5)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    elif year5 - year4 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 4\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = year3.replace(',', '')\n",
        "    year3 = int(year3)\n",
        "\n",
        "    year4 = peak_years.split()[3]\n",
        "    year4 = int(year4)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "    elif year4 - year3 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 3\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = year2.replace(',', '')\n",
        "    year2 = int(year2)\n",
        "\n",
        "    year3 = peak_years.split()[2]\n",
        "    year3 = int(year3)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    elif year3 - year2 >= 5:\n",
        "      continue\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "\n",
        "years = 2\n",
        "stat = 'OffRtg+'\n",
        "stat_2 = 'DefRtg+'\n",
        "stat_3 = 'Relative NetRtg'\n",
        "x_yearpeak(team_data, stat, stat_2, stat_3, years)\n",
        "import_team_data = pd.read_csv(f\"{years}_year_peak_relative_team_data.csv\", encoding='utf8')\n",
        "copy = import_team_data.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for idx, row in copy.iterrows():\n",
        "  peak_years = row['Years']\n",
        "  dash_substring = '-'\n",
        "  if dash_substring in peak_years:\n",
        "    listed_row = [copy.iloc[idx]]\n",
        "    tmp_df = pd.DataFrame(listed_row)\n",
        "    new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "  else:\n",
        "    year1 = peak_years.split()[0]\n",
        "    year1 = year1.replace(',', '')\n",
        "    year1 = int(year1)\n",
        "\n",
        "    year2 = peak_years.split()[1]\n",
        "    year2 = int(year2)\n",
        "\n",
        "    if year2 - year1 >= 5:\n",
        "      continue\n",
        "    else:\n",
        "      listed_row = [copy.iloc[idx]]\n",
        "      tmp_df = pd.DataFrame(listed_row)\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=False)\n",
        "new_df.to_csv(f\"{years}_year_peak_relative_team_data.csv\", index=False)\n",
        "print(new_df)\n",
        "all_peaks = pd.concat([all_peaks, new_df], ignore_index=False)\n",
        "all_peaks.to_csv(f\"all_peaks_relative_team_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "eAVu5nK5Hs9h",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}