{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "KA1adZNvGkBH"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "pd.set_option('display.colheader_justify', 'center')\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "\n",
        "import scipy.stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "\n",
        "from inspect import signature\n",
        "\n",
        "def someMethod(self, arg1, kwarg1=None):\n",
        "    pass\n",
        "\n",
        "all_the_years = np.arange(1974, 2023, 1)\n",
        "some_of_the_years = np.arange(1997, 2023, 1)\n",
        "\n",
        "# plot\n",
        "import seaborn as sns\n",
        "import ast\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.pyplot import *\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as font_manager\n",
        "sns.set_style('darkgrid')        # darkgrid, white grid, dark, white and ticks\n",
        "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=14)     # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=13)    # legend fontsize\n",
        "plt.rc('font', size=13)          # controls default text sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "EqvRpXTQxtV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c993eeb-d87e-4810-f17e-67b01dd69be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.6.1-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 5.6 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[K     |████████████████████████████████| 384 kB 13.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.7/dist-packages (from selenium) (2022.9.24)\n",
            "Collecting urllib3[socks]~=1.26\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 42.7 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting exceptiongroup>=1.0.0rc9\n",
            "  Downloading exceptiongroup-1.0.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, exceptiongroup, async-generator, wsproto, urllib3, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.13 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 exceptiongroup-1.0.4 h11-0.14.0 outcome-1.2.0 selenium-4.6.1 sniffio-1.3.0 trio-0.22.0 trio-websocket-0.9.2 urllib3-1.26.13 wsproto-1.2.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,071 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,563 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,262 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [1,038 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,338 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,303 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,497 kB]\n",
            "Get:21 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [38.5 kB]\n",
            "Fetched 14.4 MB in 7s (2,092 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 95.1 MB of archives.\n",
            "After this operation, 319 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 107.0.5304.87-0ubuntu11.18.04.1 [1,158 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 107.0.5304.87-0ubuntu11.18.04.1 [83.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 107.0.5304.87-0ubuntu11.18.04.1 [5,260 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 107.0.5304.87-0ubuntu11.18.04.1 [5,570 kB]\n",
            "Fetched 95.1 MB in 5s (20.8 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 123991 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_107.0.5304.87-0ubuntu11.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_107.0.5304.87-0ubuntu11.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_107.0.5304.87-0ubuntu11.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_107.0.5304.87-0ubuntu11.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Setting up chromium-browser (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (107.0.5304.87-0ubuntu11.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  xserver-common\n",
            "Recommended packages:\n",
            "  xfonts-base\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "The following packages will be upgraded:\n",
            "  xserver-common\n",
            "1 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 812 kB of archives.\n",
            "After this operation, 2,271 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 xserver-common all 2:1.19.6-1ubuntu4.12 [27.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.12 [785 kB]\n",
            "Fetched 812 kB in 1s (974 kB/s)\n",
            "(Reading database ... 124114 files and directories currently installed.)\n",
            "Preparing to unpack .../xserver-common_2%3a1.19.6-1ubuntu4.12_all.deb ...\n",
            "Unpacking xserver-common (2:1.19.6-1ubuntu4.12) over (2:1.19.6-1ubuntu4.11) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.12_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.12) ...\n",
            "Setting up xserver-common (2:1.19.6-1ubuntu4.12) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.12) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: use options instead of chrome_options\n"
          ]
        }
      ],
      "source": [
        "#@title Import Selenium\n",
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "!pip install pyvirtualdisplay\n",
        "!apt-get install xvfb\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(800, 800))  \n",
        "display.start()\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('start-maximized')\n",
        "options.add_argument('enable-automation')\n",
        "options.add_argument('--disable-infobars')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--disable-browser-side-navigation')\n",
        "options.add_argument(\"--remote-debugging-port=9222\")\n",
        "# options.add_argument(\"--headless\")\n",
        "options.add_argument('--disable-gpu')\n",
        "options.add_argument(\"--log-level=3\")\n",
        "wd = webdriver.Chrome(chrome_options=options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NncsPba_zEg"
      },
      "source": [
        "**IMPORT RAW DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "u6CkVfCOGD-g"
      },
      "outputs": [],
      "source": [
        "#@title Manually add team abbrev, and teamcolors\n",
        "\n",
        "league_avg_df = pd.DataFrame(columns=['Year','TS%'])\n",
        "\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2022\",\n",
        "     \"TS%\":  .566, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2021\",\n",
        "     \"TS%\":  .572, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2020\",\n",
        "     \"TS%\":  .565, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2019\",\n",
        "     \"TS%\":  .560, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2018\",\n",
        "     \"TS%\":  .556, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2017\",\n",
        "     \"TS%\":  .552, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2016\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2015\",\n",
        "     \"TS%\":  .534, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2014\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2013\",\n",
        "     \"TS%\":  .535, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2012\",\n",
        "     \"TS%\":  .527, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2011\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2010\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2009\",\n",
        "     \"TS%\":  .544, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2008\",\n",
        "     \"TS%\":  .540, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2007\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2006\",\n",
        "     \"TS%\":  .536, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({  \n",
        "     \"Year\": \"2005\",\n",
        "     \"TS%\":  .529, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2004\",\n",
        "     \"TS%\":  .516, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2003\",\n",
        "     \"TS%\":  .519, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2002\",\n",
        "     \"TS%\":  .520, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2001\",\n",
        "     \"TS%\":  .518, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2000\",\n",
        "     \"TS%\":  .523, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1999\",\n",
        "     \"TS%\":  .511, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1998\",\n",
        "     \"TS%\":  .524, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1997\",\n",
        "     \"TS%\":  .536, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1996\",\n",
        "     \"TS%\":  .542, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1995\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1994\",\n",
        "     \"TS%\":  .528, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "      \"Year\": \"1993\",\n",
        "     \"TS%\":  .536, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1992\",\n",
        "     \"TS%\":  .531, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1991\",\n",
        "     \"TS%\":  .534, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1990\",\n",
        "     \"TS%\":  .537, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1989\",\n",
        "     \"TS%\":  .537, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1988\",\n",
        "     \"TS%\":  .538, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1987\",\n",
        "     \"TS%\":  .538, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1986\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1985\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)   \n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1984\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1983\",\n",
        "     \"TS%\":  .531, }, ignore_index=True) \n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1982\",\n",
        "     \"TS%\":  .539, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1981\",\n",
        "     \"TS%\":  .534, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "    \"Year\": \"1980\",\n",
        "     \"TS%\":  .531, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1979\",\n",
        "     \"TS%\":  .530, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1978\",\n",
        "     \"TS%\":  .515, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1977\",\n",
        "     \"TS%\":  .511, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1976\",\n",
        "     \"TS%\":  .504, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1975\",\n",
        "     \"TS%\":  .502, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1974\",\n",
        "     \"TS%\":  .503, }, ignore_index=True)\n",
        "\n",
        "team_colors = {\"ATL\": \"#E03A3E\", \"BOS\": \"#007A33\", \"BRK\": \"#000000\", \"BUF\": \"#ff6314\", \"CAP\": \"#E31837\", \"CHA\": \"#00788C\", \n",
        "               \"CHI\": \"#CE1141\", \"CHO\": \"#f26631\", \"CLE\": \"#860038\", \"DAL\": \"#00538C\", \"DEN\": \"#0E2240\", \"DET\": \"#1D42BA\",\n",
        "               \"GSW\": \"#FFC72C\", \"HOU\": \"#CE1141\", \"IND\": \"#002D62\", \"KCO\": \"#5A2D81\", \"KCK\": \"#5A2D81\", \"LAC\": \"#C8102E\", \n",
        "               \"LAL\": \"#552583\", \"MEM\": \"#5D76A9\", \"MIA\": \"#98002E\", \"MIL\": \"#00471B\", \"MIN\": \"#78BE20\", \"NOH\": \"#008fc5\", \n",
        "               \"NOP\": \"#85714D\", \"NOJ\": \"#00471B\", \"NJN\": \"#00275d\", \"NYK\": \"#006BB6\", \"OKC\": \"#007AC1\", \"ORL\": \"#0077C0\", \n",
        "               \"PHI\": \"#006BB6\", \"PHO\": \"#1D1160\", \"POR\": \"#E03A3E\", \"SAC\": \"#5A2D81\", \"SAS\": \"#C4CED4\", \"SEA\": \"#00653A\", \n",
        "               \"TOR\": \"#CE1141\", \"TOT\": \"pink\", \"UTA\": \"#00471B\", \"WAS\": \"#E31837\", \"WSB\": \"#E31837\"}\n",
        "\n",
        "team_abbrev = {\"Atlanta Hawks\" : \"ATL\",       \"Boston Celtics\": \"BOS\",        \"Brooklyn Nets\": \"BRK\",         \"Charlotte Bobcats\": \"CHA\", \n",
        "               \"Chicago Bulls\": \"CHI\",      \"Charlotte Hornets\": \"CHO\",      \"Cleveland Cavaliers\": \"CLE\",     \"Dallas Mavericks\": \"DAL\",\n",
        "               \"Denver Nuggets\": \"DEN\",     \"Detroit Pistons\": \"DET\",       \"Golden State Warriors\": \"GSW\",     \"Houston Rockets\": \"HOU\",\n",
        "               \"Indiana Pacers\": \"IND\",     \"Los Angeles Clippers\": \"LAC\",  \"Los Angeles Lakers\": \"LAL\",      \"Memphis Grizzlies\": \"MEM\",\n",
        "               \"Miami Heat\": \"MIA\",         \"Milwaukee Bucks\": \"MIL\",     \"Minnesota Timberwolves\": \"MIN\",  \"New Orleans Hornets\": \"NOH\",\n",
        "               \"New Orleans Pelicans\": \"NOP\", \"New Jersey Nets\": \"NJN\",     \"New York Knicks\": \"NYK\",     \"Oklahoma City Thunder\": \"OKC\", \n",
        "               \"Orlando Magic\": \"ORL\",     \"Philadelphia 76ers\": \"PHI\",      \"Phoenix Suns\": \"PHO\",       \"Portland Trail Blazers\": \"POR\",\n",
        "               \"Sacramento Kings\": \"SAC\",    \"San Antonio Spurs\": \"SAS\",       \"Toronto Raptors\": \"TOR\",               \"Utah Jazz\": \"UTA\", \n",
        "               \"Washington Wizards\": \"WAS\", \"Capital Bullets\": \"CAP\", \"Buffalo Braves\": \"BUF\", \"Seattle SuperSonics\": \"SEA\", \"Washington Bullets\": \"WSB\",\n",
        "               \"Kansas City-Omaha Kings\": \"KCO\", \"Kansas City Kings\": \"KCK\", \"Charlotte Hornets\": \"CHH\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "xTVOqjCkD24f"
      },
      "outputs": [],
      "source": [
        "#@title Import data and add team colors for advanced, play-by-play, per 100, and league avg data\n",
        "\n",
        "# per 100 posssessions\n",
        "import_player_since74_per100_df = pd.read_csv('nba_player_since74_per100_data.csv')\n",
        "\n",
        "# add team color for per 100 posssessions\n",
        "import_player_since74_per100_df['TeamColor'] = import_player_since74_per100_df['Tm'].map(team_colors)\n",
        "\n",
        "# per 100 playoff posssessions\n",
        "import_player_since74playoffs_per100_df = pd.read_csv('nba_player_since74playoffs_per100_data.csv')\n",
        "\n",
        "# add team color for playoff per 100 posssessions\n",
        "import_player_since74playoffs_per100_df['TeamColor'] = import_player_since74playoffs_per100_df['Tm'].map(team_colors)\n",
        "\n",
        "\n",
        "\n",
        "# advanced\n",
        "import_player_since74_advanced_df = pd.read_csv('nba_player_since74_advanced_data.csv', encoding='utf8')\n",
        "\n",
        "# advanced playoffs\n",
        "import_player_since74playoffs_advanced_df = pd.read_csv('nba_player_since74playoffs_advanced_data.csv', encoding='utf8')\n",
        "\n",
        "\n",
        "\n",
        "# play-by-play\n",
        "import_player_regular_playbyplay_df = pd.read_csv('nba_player_regular_playbyplay_data.csv', encoding='utf8')\n",
        "\n",
        "# add team color for play-by-play\n",
        "import_player_regular_playbyplay_df['TeamColor'] = import_player_regular_playbyplay_df['Tm'].map(team_colors)\n",
        "\n",
        "# play-by-play playoffs\n",
        "import_player_since74playoffs_playbyplay_df = pd.read_csv('nba_player_playoff_playbyplay_data.csv', encoding='utf8')\n",
        "\n",
        "# add team color for playoff play-by-play\n",
        "import_player_since74playoffs_playbyplay_df['TeamColor'] = import_player_since74playoffs_playbyplay_df['Tm'].map(team_colors)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# import league avg data\n",
        "\n",
        "# league avg\n",
        "import_leagueavgsince74_df = pd.read_csv('nba_leaguestats_data.csv')\n",
        "\n",
        "# drop NBA seasons from inception of league until 1973 (final year without per possession data)\n",
        "import_leagueavgsince74_df.drop(import_leagueavgsince74_df.tail(26).index,inplace=True)\n",
        "\n",
        "# change from '2020-21' to '2021' and '2019-20' to '2020'... and so on\n",
        "for i, trial in import_leagueavgsince74_df.iterrows():\n",
        "   import_leagueavgsince74_df.loc[i, \"Season\"] = 2022-i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "b0yr4pEL4W7l"
      },
      "outputs": [],
      "source": [
        "#@title Import per 75 data (can be used in place of 'Calculate per 75' cells with necessitated imported data')\n",
        "\n",
        "# per 75 posssessions\n",
        "import_player_since74_per75_df = pd.read_csv('nba_player_since74_per75_data.csv')\n",
        "\n",
        "# add team color for per 75 posssessions\n",
        "import_player_since74_per75_df['TeamColor'] = import_player_since74_per75_df['Tm'].map(team_colors)\n",
        "\n",
        "# per 75 playoff posssessions\n",
        "import_player_since74playoffs_per75_df = pd.read_csv('nba_player_since74playoffs_per75_data.csv')\n",
        "\n",
        "# add team color for playoff per 75 posssessions\n",
        "import_player_since74playoffs_per75_df['TeamColor'] = import_player_since74playoffs_per75_df['Tm'].map(team_colors)\n",
        "\n",
        "# per 75 adjusted ts playoff posssessions\n",
        "adjusted_playoff_per_75_df = pd.read_csv('/content/since74_adj_ts_playoffs_per75_data.csv')\n",
        "\n",
        "# add team color for playoff per 75 adjusted posssessions\n",
        "adjusted_playoff_per_75_df['TeamColor'] = adjusted_playoff_per_75_df['Tm'].map(team_colors)\n",
        "\n",
        "# era/opponent adjusted scoring\n",
        "\n",
        "era_adj_reg_per_75_df = pd.read_csv('/content/era_adjusted_reg_per75_data.csv')\n",
        "era_opponent_adj_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "f4veohWtxhJh"
      },
      "outputs": [],
      "source": [
        "#@title Create Coefficients\n",
        "\n",
        "# era-adjust per game data\n",
        "per_game_coeff = pd.read_csv('/content/Avg_Reg_PTS_G.csv', index_col=False, encoding='utf8')\n",
        "per_game_coeff['Coefficient'] = per_game_coeff['Average PTS_G'].max() / per_game_coeff['Average PTS_G'] \n",
        "\n",
        "# era-adjust per 75 data\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "bpm_coeff = pd.read_csv('/content/Avg_Reg_BPM.csv', index_col=False, encoding='utf8')\n",
        "bpm_coeff['Average BPM'] = bpm_coeff['Average BPM'] +  1\n",
        "bpm_coeff['Average OBPM'] = bpm_coeff['Average OBPM'] + 1\n",
        "bpm_coeff['BPM_Coefficient'] = bpm_coeff['Average BPM'].max() / bpm_coeff['Average BPM']\n",
        "bpm_coeff['OBPM_Coefficient'] = bpm_coeff['Average OBPM'].max() / bpm_coeff['Average OBPM']\n",
        "\n",
        "try:\n",
        "  opponent_adj_pts_coeff = pd.DataFrame(columns = ['Year', 'Team', 'PTS_coeff'])\n",
        "\n",
        "  team_def_rtg = pd.read_csv('NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "  league_avg_def_rtg = pd.read_csv('Avg_Def_Rtg.csv', index_col=False, encoding='utf8')\n",
        "  for idx, row in team_def_rtg.iterrows():\n",
        "          match_df = league_avg_def_rtg[(league_avg_def_rtg['Year'] == row['Year'])]\n",
        "          avg = match_df['Avg DefRtg']\n",
        "          avg = float(avg)\n",
        "          coeff = avg / row['DefRtg']\n",
        "\n",
        "          new_row = {'Year':row['Year'], 'Team':row['Team'], 'PTS_coeff':coeff}\n",
        "          opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "          opponent_adj_pts_coeff = opponent_adj_pts_coeff.append(new_row, ignore_index=True)\n",
        "\n",
        "  outfile = f\"opponent_adj_pts_coeff.csv\"\n",
        "  opponent_adj_pts_coeff.to_csv(outfile, index=False)\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kd = era_opponent_adj_playoff_per_75_df[(era_opponent_adj_playoff_per_75_df['Player'] == 'Kevin Durant')]\n",
        "kd = kd[(kd['Tm'] != 'GSW')]\n",
        "print(kd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu5DF4JsFBvH",
        "outputId": "2817206f-7c20-41d6-cff0-729d67ac8c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Year   TS%+  TeamColor     Player    Pos   Age  Tm     G    GS    MP    \\\n",
            "2455  2010   95.66   #007AC1  Kevin Durant  SF  21.0  OKC   6.0   6.0  231.0   \n",
            "2456  2011  107.79   #007AC1  Kevin Durant  SF  22.0  OKC  17.0  17.0  722.0   \n",
            "2457  2012  122.51   #007AC1  Kevin Durant  SF  23.0  OKC  20.0  20.0  837.0   \n",
            "2458  2013  108.30   #007AC1  Kevin Durant  SF  24.0  OKC  11.0  11.0  485.0   \n",
            "2459  2014  107.88   #007AC1  Kevin Durant  SF  25.0  OKC  19.0  19.0  815.0   \n",
            "2460  2016  104.55   #007AC1  Kevin Durant  SF  27.0  OKC  18.0  18.0  726.0   \n",
            "2464  2021  110.87   #000000  Kevin Durant  PF  32.0  BRK  12.0  12.0  485.0   \n",
            "2465  2022   97.90   #000000  Kevin Durant  PF  33.0  BRK   4.0   4.0  176.0   \n",
            "\n",
            "      ...   DRB   TRB  AST  STL  BLK  TOV  PF      PTS     ORtg   DRtg   \n",
            "2455  ...   8.7  10.6  3.2  0.7  1.8  5.0  3.9  27.948279   98.0  106.0  \n",
            "2456  ...   8.9  10.2  3.5  1.2  1.4  3.1  3.8  28.315567  119.0  107.0  \n",
            "2457  ...   8.5   9.4  4.7  1.8  1.5  4.0  3.2  29.576460  119.0  107.0  \n",
            "2458  ...   9.8  10.6  7.4  1.5  1.3  4.6  2.8  29.508797  112.0  102.0  \n",
            "2459  ...   9.3  10.8  4.8  1.2  1.6  4.6  2.6  29.088224  110.0  108.0  \n",
            "2460  ...   8.0   8.9  4.2  1.3  1.3  4.5  2.6  29.047729  107.0  107.0  \n",
            "2464  ...  10.9  11.4  5.5  1.9  2.0  4.3  3.2  31.869893  118.0  105.0  \n",
            "2465  ...   6.1   6.7  7.3  1.2  0.3  6.1  4.4  24.018577  102.0  124.0  \n",
            "\n",
            "[8 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ylkdaUS_rxK"
      },
      "source": [
        "**SCRAPE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "28WIXVx2GuiM"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA regular season per 100\n",
        "def scrape_nba_player_per100_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = final_players_per100_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"nba_player_since74_per100_data.csv\", index=False)\n",
        "scrape_nba_player_per100_data(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RfjSMXQvyh3o"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA playoffs per 100\n",
        "def scrape_nba_player_per100_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = final_players_per100_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"nba_player_since74playoffs_per100_data.csv\", index=False)\n",
        "scrape_nba_player_per100_data(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t7uOwPzEGrt8"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA regular season advanced\n",
        "def scrape_nba_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP'\n",
        "                                                        ])\n",
        "    for year in years:\n",
        "        player_advanced_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_advanced_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_advanced_stats = [e for e in player_advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_advanced_stats)):\n",
        "             player_advanced_stats[i].insert(0, year)\n",
        "             player_advanced_stats[i].insert(5, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(5, \"TeamColor\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_advanced_df = final_players_advanced_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "        #final_players_advanced_df['Player'] = final_players_advanced_df['Player'].apply(ast.literal_eval).str.decode(\"utf-8\")\n",
        "        #final_players_advanced_df['Player'] = unidecode(final_players_advanced_df['Player'])\n",
        "        final_players_advanced_df['Player'].apply(unidecode)\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"nba_player_since74_advanced_data.csv\", index=False)\n",
        "scrape_nba_advanced_data(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KtOiviORysCl"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA playoffs advanced\n",
        "def scrape_nba_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP'\n",
        "                                                        ])\n",
        "    for year in years:\n",
        "        player_advanced_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_advanced_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_advanced_stats = [e for e in player_advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_advanced_stats)):\n",
        "             player_advanced_stats[i].insert(0, year)\n",
        "             player_advanced_stats[i].insert(5, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(5, \"TeamColor\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_advanced_df = final_players_advanced_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "        #final_players_advanced_df['Player'] = final_players_advanced_df['Player'].apply(ast.literal_eval).str.decode(\"utf-8\")\n",
        "        #final_players_advanced_df['Player'] = unidecode(final_players_advanced_df['Player'])\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"nba_player_since74playoffs_advanced_data.csv\", index=False)\n",
        "scrape_nba_advanced_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oN_b0khEoM4z"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA regular season play-by-play\n",
        "\n",
        "# import needed libraries\n",
        "def scrape_nba_playbyplay_data(years):\n",
        " \n",
        "    final_players_playbyplay_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age',\n",
        "                                                          'Tm', 'G', 'MP','OnCourt', 'On-Off', 'BadPass', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1'\n",
        "                                                         ])\n",
        "    \n",
        "    for year in years:\n",
        "        player_playbyplay_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        html = urlopen(player_playbyplay_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        # grab tr[1], as tr[0] is populated with categorical headers. Not headers for each columns of data (which are in tr[1])\n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"Blkd\")+1]\n",
        "\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_playbyplay_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_playbyplay_stats = [e for e in player_playbyplay_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_playbyplay_stats)):\n",
        "             player_playbyplay_stats[i].insert(0, year)   \n",
        "        headers.insert(0, \"Year\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_playbyplay_stats, columns = headers)\n",
        "\n",
        "        #rename some columns for less ambiguity\n",
        "        each_year.columns=['Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'MP','PG%', 'SG%', 'SF%', 'PF%', 'C%',\n",
        "                            'OnCourt', 'On-Off', 'BadPass', 'LostBall', 'ShootCommit', 'OffCommit', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1', 'Blkd']\n",
        "        # drop irrelevant columns\n",
        "        each_year = each_year.drop(['PG%', 'SG%', 'SF%', 'PF%', 'C%', 'LostBall', 'ShootCommit', 'OffCommit', 'Blkd'], axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_playbyplay_df['Player'] = final_players_playbyplay_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_playbyplay_df.info)\n",
        "    final_players_playbyplay_df.to_csv(\"nba_player_regular_playbyplay_data.csv\", index=False)\n",
        "scrape_nba_playbyplay_data(some_of_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bz-X57MTbCTd"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA playoffs play-by-play\n",
        "# import needed libraries\n",
        "def scrape_nba_playbyplay_data(years):\n",
        " \n",
        "    final_players_playbyplay_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age',\n",
        "                                                          'Tm', 'G', 'MP','OnCourt', 'On-Off', 'BadPass', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1'\n",
        "                                                         ])\n",
        "    \n",
        "    for year in years:\n",
        "        player_playbyplay_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        html = urlopen(player_playbyplay_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        # grab tr[1], as tr[0] is populated with categorical headers. Not headers for each columns of data (which are in tr[1])\n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"Blkd\")+1]\n",
        "\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_playbyplay_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_playbyplay_stats = [e for e in player_playbyplay_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_playbyplay_stats)):\n",
        "             player_playbyplay_stats[i].insert(0, year)   \n",
        "        headers.insert(0, \"Year\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_playbyplay_stats, columns = headers)\n",
        "\n",
        "        #rename some columns for less ambiguity\n",
        "        each_year.columns=['Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'MP','PG%', 'SG%', 'SF%', 'PF%', 'C%',\n",
        "                            'OnCourt', 'On-Off', 'BadPass', 'LostBall', 'ShootCommit', 'OffCommit', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1', 'Blkd']\n",
        "        # drop irrelevant columns\n",
        "        each_year = each_year.drop(['PG%', 'SG%', 'SF%', 'PF%', 'C%', 'LostBall', 'ShootCommit', 'OffCommit', 'Blkd'], axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_playbyplay_df['Player'] = final_players_playbyplay_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_playbyplay_df.info)\n",
        "    final_players_playbyplay_df.to_csv(\"nba_player_playoff_playbyplay_data.csv\", index=False)\n",
        "scrape_nba_playbyplay_data(some_of_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EpNv19zh29sk"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA regular season per game\n",
        "def scrape_nba_player_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = final_players_pergame_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"nba_player_since74_pergame_data.csv\", index=False)\n",
        "scrape_nba_player_pergame_data(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9iMSjRJAC-a0"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA playoff per game\n",
        "def scrape_nba_player_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = final_players_pergame_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"playoff_pergame_data.csv\", index=False)\n",
        "scrape_nba_player_pergame_data(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "C0kF_pU8wazB"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA regular season league average\n",
        "def scrape_nba_leaguestats_data():\n",
        "\n",
        "        final_leaguestats_df = pd.DataFrame(columns = ['Year',\t'Lg',\t'Age',\t'Ht',\t'Wt',\t'G',\t'MP',\t'FG',\t'FGA',\t'3P',\n",
        "                                                      '3PA',\t'FT',\t'FTA',\t'ORB',\t'DRB',\t'TRB',\t'AST',\t'STL',\t'BLK',\t'TOV',\n",
        "                                                      'PF',\t'PTS',\t'FG%',\t'3P%',\t'FT%',\t'Pace',\t'eFG%',\t'TOV%',\t'ORB%',\n",
        "                                                      'FT/FGA',\t'ORtg', 'TS%'])\n",
        "        \n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_stats_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"ORtg\")+1]\n",
        "        headers.insert(32, \"TS%\")\n",
        "        print(headers)\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        #rows = soup.findAll('tr', class=None)[1:]\n",
        "        rows = soup.findAll('tr', class_=None)[1:]\n",
        "\n",
        "\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "          player_base_stats[i].insert(32, 0)\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        final_leaguestats_df = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        final_leaguestats_df = final_leaguestats_df.drop(['Lg'], axis=1)\n",
        "\n",
        "        final_leaguestats_df = final_leaguestats_df.iloc[1: , :]\n",
        "\n",
        "        final_leaguestats_df.drop(final_leaguestats_df.index[20])\n",
        "        final_leaguestats_df.drop(final_leaguestats_df.index[21])\n",
        "        \n",
        "        # print final_df\n",
        "        print(final_leaguestats_df.info)\n",
        "        final_leaguestats_df.to_csv(\"nba_leaguestats_data.csv\", index=False)\n",
        "scrape_nba_leaguestats_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qnboLs8Jc6LW"
      },
      "outputs": [],
      "source": [
        "#@title Scrape Reg Avg Per 100 Scoring\n",
        "def scrape_nba_player_reg_avg_per_100(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PP75'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = (each_year['PTS'].astype(float) * .75) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        new_row = {'Year':year, 'Average PP75':running_pts_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_Reg_PP75.csv\", index=False)\n",
        "scrape_nba_player_reg_avg_per_100(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YBiRp3G4SMCR"
      },
      "outputs": [],
      "source": [
        "#@title Scrape Playoff Avg Per 100 Scoring\n",
        "def scrape_nba_player_playoff_avg_per_100(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PP75'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = (each_year['PTS'].astype(float) * .75) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        year = year.astype(int)\n",
        "        new_row = {'Year':year, 'Average PP75':running_pts_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_Playoff_PP75.csv\", index=False)\n",
        "scrape_nba_player_playoff_avg_per_100(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DusUMcoSwNEa"
      },
      "outputs": [],
      "source": [
        "#@title Scrape Reg Avg Per Game Scoring\n",
        "def scrape_nba_player_reg_avg_per_game(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PTS_G'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = each_year['PTS'].astype(float) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        new_row = {'Year':year, 'Average PTS_G':running_pts_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        final_df['Year'] = final_df['Year'].astype(int)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_Reg_PTS_G.csv\", index=False)\n",
        "scrape_nba_player_reg_avg_per_game(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Agd-o25LdpJJ"
      },
      "outputs": [],
      "source": [
        "#@title Scrape Reg Avg BPM\n",
        "def scrape_nba_player_reg_bpm_avg(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average BPM', 'Average OBPM'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_bpm_avg = 0\n",
        "        running_obpm_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['BPM'] = each_year['BPM'].astype(float)\n",
        "        each_year['OBPM'] = each_year['OBPM'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['adjBPM'] = each_year['BPM'].astype(float) * (each_year['MP'].astype(float) / total_mp)\n",
        "        each_year['adjOBPM'] = each_year['OBPM'].astype(float) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_bpm_avg = each_year['adjBPM'].sum()\n",
        "        running_obpm_avg = each_year['adjOBPM'].sum()\n",
        "\n",
        "        running_bpm_avg = running_bpm_avg + 1\n",
        "        running_obpm_avg = running_obpm_avg + 1\n",
        "\n",
        "\n",
        "        new_row = {'Year':year, 'Average BPM':running_bpm_avg, 'Average OBPM':running_obpm_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        final_df['Year'] = final_df['Year'].astype(int)\n",
        "        \n",
        "    # print final_df\n",
        "    final_df.to_csv(\"Avg_Reg_BPM.csv\", index=False)\n",
        "scrape_nba_player_reg_bpm_avg(all_the_years)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xD45xeb_1zE"
      },
      "source": [
        "**PEAK FUNCTION DEFINITIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WKanZbn6ABM9"
      },
      "outputs": [],
      "source": [
        "#@title 2 year peaks function\n",
        "\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '777' '15'\n",
        "def twoyearpeak(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = 0\n",
        "    prev_min = 0\n",
        "    prev_g = 0\n",
        "    prevYearTeam = 0\n",
        "    prevyear = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + prev_g\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back * (prev_min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prev_back = 0\n",
        "            prev_min = 0\n",
        "            prev_g = 0\n",
        "            prevYearTeam = 0\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 2 consecutive seasons\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear , present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+2 and len(indexlist) >=2:\n",
        "            two_seasons_count = player['Year']\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back = inner_row[valuestring]\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prev_min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "            prev_g = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            prev_back = inner_row[valuestring]\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prev_min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "            prev_g = inner_row['G']\n",
        "\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 2:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and prevYearTeam == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_two_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_two_year_peak_val, running_min, games]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "            outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "            two_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XTmZzNX7_UBG"
      },
      "outputs": [],
      "source": [
        "#@title 3 year peaks function\n",
        "\n",
        "# def threeyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 3 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 3 year stretches of 'valuestring' AND the listed years from each 3 year stretch + minutes played across the 3 seasons.\n",
        "# EX: threeyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-20', 'Kris Middleton', 'MIL' '23.32', '712' '22'\n",
        "def threeyearpeak(df, valuestring):\n",
        "  three_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 3 year peaks); begin as 0's\n",
        "    for i in range(0, 2):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    three_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_three_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_three_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[1]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 2):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons\n",
        "          if present_year >= original_year+2 and len(indexlist) >=3:\n",
        "            if (prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[1] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}'.format(prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if three_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            three_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 1\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 1\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          three_seasons_count = three_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 3:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_three_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_three_year_peak_val, running_min, games]], columns=cols)\n",
        "            three_year_peak = three_year_peak.append(df_temp)\n",
        "            outfile = f\"three_year_peak_{valuestring}_data.csv\"\n",
        "            three_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5Syc_qCO-cpI"
      },
      "outputs": [],
      "source": [
        "#@title 4 year peaks function\n",
        "\n",
        "# def fouryearpeak(df, valuestring):\n",
        "# returns a dataframe containing 4 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 4 year stretches of 'valuestring' AND the listed years from each 4 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fouryearpeak(import_player_since74_per100_df, 'PTS') returns 4 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-19', 'Kris Middleton', 'MIL' '22.11', '1213' '28'\n",
        "def fouryearpeak(df, valuestring):\n",
        "  four_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 4 year peaks); begin as 0's\n",
        "    for i in range(0, 3):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    four_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_four_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_four_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[2]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 3):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 4 consecutive seasons\n",
        "          if present_year >= original_year+3 and len(indexlist) >=4:\n",
        "            if (prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[2] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}'.format(prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if four_seasons_count == original_year+4 and len(indexlist) >=4:\n",
        "            four_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 2\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 2\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          four_seasons_count = four_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 4:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_four_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_four_year_peak_val, running_min, games]], columns=cols)\n",
        "            four_year_peak = four_year_peak.append(df_temp)\n",
        "            outfile = f\"four_year_peak_{valuestring}_data.csv\"\n",
        "            four_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iAmiC4OO9Ypf"
      },
      "outputs": [],
      "source": [
        "#@title 5 year peaks function\n",
        "\n",
        "# def fiveyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 5 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 5 year stretches of 'valuestring' AND the listed years from each 5 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 5 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-20', 'Kris Middleton', 'MIL' '22.11', '1639 '34'\n",
        "def fiveyearpeak(df, valuestring):\n",
        "  five_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 5 year peaks); begin as 0's\n",
        "    for i in range(0, 4):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    five_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_five_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_five_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[3]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 4):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 5 consecutive seasons\n",
        "          if present_year >= original_year+4 and len(indexlist) >=5:\n",
        "            if (prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[3] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}'.format(prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if five_seasons_count == original_year+5 and len(indexlist) >=5:\n",
        "            five_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 3\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 3\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          five_seasons_count = five_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 5:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_five_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_five_year_peak_val, running_min, games]], columns=cols)\n",
        "            five_year_peak = five_year_peak.append(df_temp)\n",
        "            outfile = f\"five_year_peak_{valuestring}_data.csv\"\n",
        "            five_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OdOIKhKi8z_t"
      },
      "outputs": [],
      "source": [
        "#@title 6 year peaks function\n",
        "\n",
        "# def sixyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 6 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 6 year stretches of 'valuestring' AND the listed years from each 6 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 6 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-21', 'Kris Middleton', 'MIL' '22.11', '1119' '46'\n",
        "def sixyearpeak(df, valuestring):\n",
        "  six_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 6 year peaks); begin as 0's\n",
        "    for i in range(0, 5):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    six_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_six_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_six_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[4]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 5):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 6 consecutive seasons\n",
        "          if present_year >= original_year+5 and len(indexlist) >=6:\n",
        "            if (prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[4] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}'.format(prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if six_seasons_count == original_year+6 and len(indexlist) >=6:\n",
        "            six_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 4\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 4\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          six_seasons_count = six_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 6:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_six_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_six_year_peak_val, running_min, games]], columns=cols)\n",
        "            six_year_peak = six_year_peak.append(df_temp)\n",
        "            outfile = f\"six_year_peak_{valuestring}_data.csv\"\n",
        "            six_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4rrbqSWm8Mvn"
      },
      "outputs": [],
      "source": [
        "#@title 7 year peaks function\n",
        "\n",
        "# def sevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 7 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 7 year stretches of 'valuestring' AND the listed years from each 7 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 7 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-22', 'Kris Middleton', 'MIL' '22.11', '1467' '66'\n",
        "def sevenyearpeak(df, valuestring):\n",
        "  seven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 7 year peaks); begin as 0's\n",
        "    for i in range(0, 6):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    seven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_seven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_seven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[5]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 6):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 7 consecutive seasons\n",
        "          if present_year >= original_year+6 and len(indexlist) >=7:\n",
        "            if (prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[5] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}'.format(prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if seven_seasons_count == original_year+7 and len(indexlist) >=7:\n",
        "            seven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 5\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 5\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          seven_seasons_count = seven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 7:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_seven_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_seven_year_peak_val, running_min, games]], columns=cols)\n",
        "            seven_year_peak = seven_year_peak.append(df_temp)\n",
        "            outfile = f\"seven_year_peak_{valuestring}_data.csv\"\n",
        "            seven_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A4a_yTqH7Z8f"
      },
      "outputs": [],
      "source": [
        "#@title 8 year peaks function\n",
        "\n",
        "# def eightyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 8 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 8 year stretches of 'valuestring' AND the listed years from each 8 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 8 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2013-20', 'Kris Middleton', 'MIL' '22.11', '2139' '66'\n",
        "def eightyearpeak(df, valuestring):\n",
        "  eight_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 8 year peaks); begin as 0's\n",
        "    for i in range(0, 7):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eight_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_eight_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_eight_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[6]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 7):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 8 consecutive seasons\n",
        "          if present_year >= original_year+7 and len(indexlist) >=8:\n",
        "            if (prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[6] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if eight_seasons_count == original_year+8 and len(indexlist) >=8:\n",
        "            eight_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 6\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 6\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          eight_seasons_count = eight_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 8:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_eight_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_eight_year_peak_val, running_min, games]], columns=cols)\n",
        "            eight_year_peak = eight_year_peak.append(df_temp)\n",
        "            outfile = f\"eight_year_peak_{valuestring}_data.csv\"\n",
        "            eight_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CTS30J-_32LS"
      },
      "outputs": [],
      "source": [
        "#@title 9 year peaks function\n",
        "\n",
        "# def nineyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 9 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 9 year stretches of 'valuestring' AND the listed years from each 9 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 9 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2012-20', 'Kris Middleton', 'MIL' '22.11', '2585' '66'\n",
        "def nineyearpeak(df, valuestring):\n",
        "  nine_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 9 year peaks); begin as 0's\n",
        "    for i in range(0, 8):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    nine_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_nine_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_nine_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)) + (prev_back[7] * (prev_min[7] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[7]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 8):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 9 consecutive seasons\n",
        "          if present_year >= original_year+8 and len(indexlist) >=9:\n",
        "            if (prevyear[7]  == (prevyear[6] - 1) and prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[7] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[7] , prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if nine_seasons_count == original_year+9 and len(indexlist) >=9:\n",
        "            nine_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 7\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 7\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          nine_seasons_count = nine_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 9:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[7] and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_nine_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_nine_year_peak_val, running_min, games]], columns=cols)\n",
        "            nine_year_peak = nine_year_peak.append(df_temp)\n",
        "            outfile = f\"nine_year_peak_{valuestring}_data.csv\"\n",
        "            nine_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wJUmrKQyZ7yv"
      },
      "outputs": [],
      "source": [
        "#@title 10 year peaks function\n",
        "\n",
        "# def tenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '2976', '76'\n",
        "def tenyearpeak(df, valuestring):\n",
        "  ten_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 10 year peaks); begin as 0's\n",
        "    for i in range(0, 9):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    ten_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_ten_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_ten_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)) + (prev_back[7] * (prev_min[7] / running_min)) + (prev_back[8] * (prev_min[8] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[8]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 9):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 10 consecutive seasons\n",
        "          if present_year >= original_year+9 and len(indexlist) >=10:\n",
        "            if (prevyear[8] == (prevyear[7] - 1) and prevyear[7]  == (prevyear[6] - 1) and prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[8] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[8] , prevyear[7] , prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if ten_seasons_count == original_year+10 and len(indexlist) >=10:\n",
        "            ten_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 8\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 8\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          ten_seasons_count = ten_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 10:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[7] and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_ten_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_ten_year_peak_val, running_min, games]], columns=cols)\n",
        "            ten_year_peak = ten_year_peak.append(df_temp)\n",
        "            outfile = f\"ten_year_peak_{valuestring}_data.csv\"\n",
        "            ten_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzGqAJSyBU93"
      },
      "source": [
        "**CALCULATE PER 75 AND TS+**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_xOBKntCacv6"
      },
      "outputs": [],
      "source": [
        "#@title Scrape League Average TS% Since 1974 (not working)\n",
        "#@title Scrape NBA regular season advanced\n",
        "def scrape_nba_ts_data(years):\n",
        "\n",
        "    league_avg_ts_df = pd.DataFrame(columns = ['Year', 'TS%'])\n",
        "\n",
        "    for year in years:\n",
        "        league_stats_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\"\n",
        "        \n",
        "        wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "        wd.get(league_stats_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': '#content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': '#all_advanced_team'})\n",
        "          first_table = second_div.find('table', attrs={'id': '#advanced-team'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "        print(rows)\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        advanced_stats = [e for e in advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(advanced_stats)):\n",
        "             advanced_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        print(headers)\n",
        "\n",
        "        each_year = pd.DataFrame(advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        league_avg_ts_df = league_avg_ts_df.append(each_year)\n",
        "\n",
        "        # remove any Na\n",
        "        league_avg_ts_df = league_avg_ts_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(league_avg_ts_df.info)\n",
        "    league_avg_ts_df.to_csv(\"nba_player_since74_advanced_data.csv\", index=False)\n",
        "scrape_nba_ts_data(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Yf83zDkaUNAP"
      },
      "outputs": [],
      "source": [
        "#@title Calculate regular season per 75 and regular season TS+\n",
        "\n",
        "# Calculate per 75 points\n",
        "import_player_since74_per75_df = import_player_since74_per100_df.copy()\n",
        "import_player_since74_per75_df['PTS'] = import_player_since74_per75_df['PTS'] * .75\n",
        "\n",
        "# Add TS+\n",
        "i = 2022\n",
        "for yearloop in range(49):\n",
        "  for j, row in import_player_since74_per75_df.iterrows():\n",
        "    if row['Year'] == i:\n",
        "      import_player_since74_per75_df.iat[j, 1] = (import_player_since74_advanced_df.iat[j, 9] / league_avg_df.iat[yearloop, 1]) * 100\n",
        "  i = i - 1\n",
        "\n",
        "import_player_since74_per75_df = import_player_since74_per75_df[import_player_since74_per75_df['TS%+'].notna()]\n",
        "outfile = f\"nba_player_since74_per75_data.csv\"\n",
        "import_player_since74_per75_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zIfZLq3O3uGQ"
      },
      "outputs": [],
      "source": [
        "#@title Calculate regular season per game TS+\n",
        "\n",
        "import_player_since74_pergame_df = pd.read_csv('/content/nba_player_since74_pergame_data.csv')\n",
        "\n",
        "# Add TS+\n",
        "i = 2022\n",
        "for yearloop in range(49):\n",
        "  for j, row in import_player_since74_pergame_df.iterrows():\n",
        "    if row['Year'] == i:\n",
        "      import_player_since74_pergame_df.iat[j, 1] = (import_player_since74_advanced_df.iat[j, 9] / league_avg_df.iat[yearloop, 1]) * 100\n",
        "  i = i - 1\n",
        "\n",
        "import_player_since74_pergame_df = import_player_since74_pergame_df[import_player_since74_pergame_df['TS%+'].notna()]\n",
        "outfile = f\"nba_player_since74_pergame_data.csv\"\n",
        "import_player_since74_pergame_df.to_csv(outfile, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bFsHXSLEsxVP"
      },
      "outputs": [],
      "source": [
        "#@title Calculate playoffs per 75\n",
        "# Calculate playoffs per 75\n",
        "import_player_since74playoffs_per75_df = import_player_since74playoffs_per100_df.copy()\n",
        "import_player_since74playoffs_per75_df['PTS'] = import_player_since74playoffs_per75_df['PTS'] * .75\n",
        "\n",
        "outfile = f\"nba_player_since74playoffs_per75_data.csv\"\n",
        "import_player_since74playoffs_per75_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPo3JH7bZmrN"
      },
      "source": [
        "**SCRAPE URL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1BJWc9nsob9K"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA Player URL's (since 1997)\n",
        "# import needed libraries\n",
        "def scrape_url_data_97(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        print(year)\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "        wd.get(page_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_pbp_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'pbp_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = player_url_df.append(tmp_df)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_URL_data.csv\", index=False)\n",
        "scrape_all_distribution_data(some_of_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gxLh3jVuAZe4"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA Player URL's (since 1974)\n",
        "# import needed libraries\n",
        "def scrape_url_data_74(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "        wd.get(page_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = player_url_df.append(tmp_df)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_since_74_URL_data.csv\", index=False)\n",
        "scrape_url_data_74(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4yATMvO-BkTW"
      },
      "outputs": [],
      "source": [
        "#@title Shorten URL list to only players with >x playoff minutes\n",
        "def nba_shorten_url_list_by_x(url_df, min_requirement):\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      og_url = url\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      \n",
        "\n",
        "      wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "      wd.get(url)          \n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_advanced-playoffs_advanced'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs_advanced'})\n",
        "        foot = first_table.find('tfoot')\n",
        "\n",
        "      rows = foot.find('tr')\n",
        "      only_for_mp = [[td.getText() for td in rows.findAll('td')]]\n",
        "\n",
        "      # remove empty rows\n",
        "      only_for_mp = [e for e in only_for_mp if e != []]\n",
        "\n",
        "      try: \n",
        "        headers = ['Age', 'Tm',\t'Lg', 'Pos', 'G', 'MP', 'PER',\n",
        "      \t         'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%',\n",
        "                 'STL%', 'BLK%', 'TOV%', 'USG%', 'dum1', 'OWS', 'DWS', \n",
        "                 'WS', 'WS/48', 'dum2', 'OBPM', 'DBPM', 'BPM',\t'VORP']\n",
        "        shooting_dist_data = pd.DataFrame(only_for_mp, columns = headers)\n",
        "      except:\n",
        "        try:\n",
        "          headers = ['Age', 'Tm',\t'Lg', 'Pos', 'G', 'MP', 'PER',\n",
        "                  'TS%', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%',\n",
        "                  'STL%', 'BLK%', 'TOV%', 'USG%', 'dum1', 'OWS', 'DWS', \n",
        "                  'WS', 'WS/48', 'dum2', 'OBPM', 'DBPM', 'BPM',\t'VORP']\n",
        "          shooting_dist_data = pd.DataFrame(only_for_mp, columns = headers)\n",
        "        except:\n",
        "          headers = ['Age', 'Tm',\t'Lg', 'Pos', 'G', 'MP', 'PER',\n",
        "      \t         'TS%', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%',\n",
        "                 'STL%', 'BLK%', 'dum1', 'OWS', 'DWS', \n",
        "                 'WS', 'WS/48', 'dum2', 'OBPM', 'DBPM', 'BPM',\t'VORP']\n",
        "          shooting_dist_data = pd.DataFrame(only_for_mp, columns = headers)\n",
        "\n",
        "      tmp_df = pd.DataFrame(columns = ['Player', 'URL', 'MP'])\n",
        "      new_df = pd.DataFrame(columns = ['Player', 'URL', 'MP'])\n",
        "\n",
        "      # took only long mid range FGA\n",
        "      if int(shooting_dist_data['MP']) <= min_requirement:\n",
        "        continue\n",
        "      else:\n",
        "        mp = int(shooting_dist_data['MP'])\n",
        "\n",
        "      tmp_df.loc[len(tmp_df)] = [player, og_url, mp]\n",
        "      new_df.append(tmp_df)\n",
        "      print(tmp_df)\n",
        "    outfile = f\"NBA_Player_97_URL_List_{min_requirement}_Min_df.csv\"\n",
        "    new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLzLiVsSJUU2"
      },
      "outputs": [],
      "source": [
        "player_urls = pd.read_csv('/content/nba_player_URL_data.csv', index_col=False, encoding='utf8')\n",
        "nba_shorten_url_list_by_x(player_urls, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD8d3BbjSsZN"
      },
      "source": [
        "**SCRAPE PLAYOFF TEAMS' DEFENSIVE STATS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c3AiSZmzKjg4"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA Teams' TS% Allowed (since 1974)\n",
        "def scrape_team_ts_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team' 'TS% Allowed'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_totals_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'totals-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['TS% Allowed'] = each_years_teams['PTS'] / ( ( (each_years_teams['FTA'] * .44) + (each_years_teams['FGA']) ) * 2)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(team_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"NBA_Team_TS_Percentage_Allowed_df.csv\", index=False)\n",
        "scrape_team_ts_allowed_data(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EGHnzxWqfkQ3"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA Teams' DefRtg \n",
        "def scrape_team_defrtg_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(team_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"NBA_Team_defrtg_Allowed_df.csv\", index=False)\n",
        "scrape_team_defrtg_allowed_data(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p9WLoXEwa5vj"
      },
      "outputs": [],
      "source": [
        "#@title Scrape Reg Avg DefRtg\n",
        "def scrape_nba_player_avg_defrtg(years):\n",
        "\n",
        "  final_team_data_df = pd.DataFrame(columns = ['Year', 'Avg DefRtg'])\n",
        "    \n",
        "  for year in years:\n",
        "\n",
        "        wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        avg_def_rtg = each_year['PTS'].mean()\n",
        "\n",
        "\n",
        "\n",
        "        new_row = {'Year':year, 'Avg DefRtg':avg_def_rtg}\n",
        "        final_team_data_df = final_team_data_df.append(new_row, ignore_index=True)\n",
        "        final_team_data_df['Year'] = final_team_data_df['Year'].astype(int)\n",
        "        print(new_row)\n",
        "        \n",
        "  # print final_df\n",
        "  final_team_data_df.to_csv(\"Avg_Def_Rtg.csv\", index=False)\n",
        "scrape_nba_player_avg_defrtg(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "H2LJ0S7vjYLd"
      },
      "outputs": [],
      "source": [
        "#@title Scrape Adjusted Playoff TS+\n",
        "def adjust_scoring_efficiency(url_df, teams_ts_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'TS+', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      print(player)\n",
        "      \n",
        "\n",
        "      wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "      wd.get(url)          \n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        body = first_table.find('tbody')\n",
        "        head = first_table.find('thead')\n",
        "\n",
        "      # grab rows\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "\n",
        "      headers_t = head.findAll('tr')[1:]\n",
        "      for label in headers_t.select('label'):\n",
        "        headers = label.string\n",
        "      print(headers)\n",
        "      print(series_stats)\n",
        "\n",
        "      series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      \n",
        "\n",
        "      # convert ABA seasons to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SSL\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"VIR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SAA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"INA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"UTS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"KEN\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"CAR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1960\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1961\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1962\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1963\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1964\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1965\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1966\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1967\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1968\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1969\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1970\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1971\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1972\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1973\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data['MP'] = series_data['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "\n",
        "      # add TS% allowed\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      teams_ts_df['Team'] = teams_ts_df['Team'].astype(str)\n",
        "      teams_ts_df['Year'] = teams_ts_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "\n",
        "\n",
        "      years_list = []\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "        opponent_ts = teams_ts_df[(teams_ts_df['Team'] == current_opp) & ((teams_ts_df['Year'] == current_year))]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "        if row['PTS'] == 0:\n",
        "          tsplus = 0\n",
        "        else:\n",
        "          tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        series_data.loc[i,'TS+'] = tsplus\n",
        "        if series_data.loc[i,'Year'] not in years_list:\n",
        "          years_list.append(series_data.loc[i,'Year'])\n",
        "      \n",
        "      #series_data['TS+'] = (float(series_data['PTS']) / ( ( (float(series_data['FTA']) * .44) + (float(series_data['FGA'])) ) * 2)) / \n",
        "\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'FGA', 'FTA', 'PTS', 'MPG'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = series_data[(series_data['Year'] == year)]\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "\n",
        "        new_row = {'Player':player, 'Year':year, 'TS+':total_ts, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        print(new_row)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "    print(final_season_df)\n",
        "    outfile = f\"NBA_Playoff_Adjusted_TS_df.csv\"\n",
        "    final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhL-arWPFvb8"
      },
      "source": [
        "**SCRAPE AND ADJUST PLAYOFF SCORING EFFICIENCY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "V5D3qCAUcglZ"
      },
      "outputs": [],
      "source": [
        "#@title Scrape Adjusted Playoff TS+ & Opponent Adjust Scoring\n",
        "\n",
        "import time \n",
        "\n",
        "def adjust_scoring_efficiency(url_df, opp_ts_df, opp_defrtg_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'TS+', 'PTS_coeff', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      time.sleep(5)\n",
        "      print(player)\n",
        "      \n",
        "\n",
        "      wd.get(url)\n",
        "\n",
        "      html = wd.page_source\n",
        "      time.sleep(5)\n",
        "      soup = BeautifulSoup(html)\n",
        "      time.sleep(5)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      # grab rows\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "\n",
        "      # post 3PA\n",
        "      try:\n",
        "        headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                  'G',\t'W', 'L',\t'MP', 'FG', 'FGA', '3P', '3PA', 'FT', \n",
        "                  'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                  'PTS', 'dum2', 'FG%', '3P%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                          'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                          'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                          'FG%', '3P%', 'FT%', 'dum3', 'PTS/G', 'TRB/G', 'AST/G'], axis=1)\n",
        "      except:\n",
        "        # post TOV pre 3PA\n",
        "        try:\n",
        "          headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                    'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                    'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                    'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                            'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                            'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                            'FG%', '3P%', 'FT%', 'dum3', 'PTS/G', 'TRB/G', 'AST/G'], axis=1)\n",
        "        # pre TOV and pre 3PA\n",
        "        except:\n",
        "          try:\n",
        "            headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                      'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                      'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'PF',\n",
        "                      'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']  \n",
        "\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                              'G',\t'W', 'L', 'FG', 'FT', 'ORB', \n",
        "                              'TRB',\t'AST', 'STL', 'BLK', 'PF', 'dum2',\n",
        "                              'FG%', 'FT%', 'dum3', 'PTS/G', 'TRB/G', 'AST/G'], axis=1)\n",
        "          # post TOV and pre 3PA \n",
        "          except:\n",
        "            headers = [th.getText() for th in first_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            headers = headers[1:]\n",
        "            headers[2] = 'Year'\n",
        "            headers[27] = 'MP/G'\n",
        "            headers[28] = 'PTS/G'\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      \n",
        "\n",
        "      # convert ABA seasons to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SSL\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"VIR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SAA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"INA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"UTS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"KEN\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"CAR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1960\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1961\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1962\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1963\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1964\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1965\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1966\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1967\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1968\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1969\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1970\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1971\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1972\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1973\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data['MP'] = series_data['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "\n",
        "      # add TS% allowed\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "\n",
        "\n",
        "      years_list = []\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "\n",
        "        # get ts% allowed by opponent\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & ((opp_ts_df['Year'] == current_year))]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        # get defrtg allowed by opponent\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "        \n",
        "        if row['PTS'] == 0:\n",
        "          tsplus = 0\n",
        "        else:\n",
        "          tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        series_data.loc[i,'TS+'] = tsplus\n",
        "        series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "        if series_data.loc[i,'Year'] not in years_list:\n",
        "          years_list.append(series_data.loc[i,'Year'])\n",
        "      \n",
        "      #series_data['TS+'] = (float(series_data['PTS']) / ( ( (float(series_data['FTA']) * .44) + (float(series_data['FGA'])) ) * 2)) / \n",
        "\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'FGA', 'FTA', 'PTS', 'MPG'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = series_data[(series_data['Year'] == year)]\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "          \n",
        "        \n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "\n",
        "\n",
        "        new_row = {'Player':player, 'Year':year, 'TS+':total_ts, 'PTS_coeff':total_coeff, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "      outfile = f\"NBA_Playoff_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)\n",
        "    print(final_season_df)\n",
        "    #outfile = f\"NBA_Playoff_Adjusted_TS_df.csv\"\n",
        "    #final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tPP2QwEUVAKq"
      },
      "outputs": [],
      "source": [
        "#@title Run Adjusted Playoff TS+ Scrape\n",
        "team_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = pd.read_csv('/content/fragment97.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "adjust_scoring_efficiency(url_txt_df, team_ts_allowed_df, opponent_adj_pts_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uavrTm3rmdeb"
      },
      "outputs": [],
      "source": [
        "#@title Create DataFrame of Adjusted TS+ Data\n",
        "start_to_ajust_playoffs_per_75 = import_player_since74playoffs_per75_df.copy()\n",
        "adj_ts_list = pd.read_csv('/content/NBA_Playoff_Adjusted_TS_df.csv', index_col=False, encoding='utf8') \n",
        "\n",
        "players_used_list = []\n",
        "\n",
        "names = [x for x in start_to_ajust_playoffs_per_75.columns]\n",
        "\n",
        "# Create empty DataFrame with those column names\n",
        "adjusted_playoff_per_75_df = pd.DataFrame(columns=names)\n",
        "\n",
        "for outer_index, adj_player_season in adj_ts_list.iterrows():\n",
        "\n",
        "  adj_player_season['Player'] = str(adj_player_season['Player'])\n",
        "  adj_player_season['Year'] = str(adj_player_season['Year'])\n",
        "  start_to_ajust_playoffs_per_75['Player'] = start_to_ajust_playoffs_per_75['Player'].astype(str)\n",
        "  start_to_ajust_playoffs_per_75['Year'] = start_to_ajust_playoffs_per_75['Year'].astype(str)\n",
        "\n",
        "  current_player = adj_player_season.loc['Player']\n",
        "  current_year = adj_player_season.loc['Year']\n",
        "  smaller_start_adj_list = start_to_ajust_playoffs_per_75[(start_to_ajust_playoffs_per_75['Player'] == current_player) & ((start_to_ajust_playoffs_per_75['Year'] == current_year))]\n",
        "  smaller_start_adj_list['TS%+'] = adj_player_season['TS+']\n",
        "  smaller_start_adj_list['PTS'] = smaller_start_adj_list['PTS'] * adj_player_season['PTS_coeff']\n",
        "  adjusted_playoff_per_75_df = adjusted_playoff_per_75_df.append(smaller_start_adj_list, ignore_index=True)\n",
        "print(adjusted_playoff_per_75_df)\n",
        "outfile = f\"since74_adj_ts_playoffs_per75_data.csv\"\n",
        "adjusted_playoff_per_75_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVqAezfQWawI"
      },
      "source": [
        "**ERA ADJUST SCORING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5mQaltbM50mP"
      },
      "outputs": [],
      "source": [
        "#@title Inflate Playoff Scoring for Both Era and Opponent \n",
        "playoff_75_data = pd.read_csv('/content/nba_player_since74_per75_data.csv')\n",
        "\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in playoff_75_data.iterrows():\n",
        "  era_adj = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PTS'] = float(row['PTS']) * float(era_adj['Coefficient'])\n",
        "  #row['PTS'] = float(row['PTS']) * float(row['PTS_coeff'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"era_opponent_adjusted_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ax9wp0mPgnBr"
      },
      "outputs": [],
      "source": [
        "#@title Era Adjust BPM\n",
        "reg_playoff_per_75_df = import_player_since74_advanced_df.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in reg_playoff_per_75_df.iterrows():\n",
        "  sub_mess = bpm_coeff[(bpm_coeff['Year'] == row['Year'])]\n",
        "  row['BPM'] = float(row['BPM'] * sub_mess['BPM_Coefficient'])\n",
        "  row['OBPM'] = float(row['OBPM'] * sub_mess['OBPM_Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"inflation_adjusted_reg_bpm_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoP5OjWDf5yI"
      },
      "source": [
        "**SCRAPE AND ADJUST PLAYOFF SCORING EFFICIENCY (SERIES-BY-SERIES)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XBKkL-oJvRqw"
      },
      "outputs": [],
      "source": [
        "#@title Scrape Adjusted Playoff TS+ Series by Series (not working)\n",
        "def adjust_scoring_efficiency_series(url_df, teams_ts_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'Opp', 'PTS/G', 'TS+', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      print(player)\n",
        "      \n",
        "\n",
        "      wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "      wd.get(url)          \n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      # grab rows\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "\n",
        "      # post 3PA\n",
        "      try:\n",
        "        headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                  'G',\t'W', 'L',\t'MP', 'FG', 'FGA', '3P', '3PA', 'FT', \n",
        "                  'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                  'PTS', 'dum2', 'FG%', '3P%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                          'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                          'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                          'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "      except:\n",
        "        # post TOV pre 3PA\n",
        "        try:\n",
        "          headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                    'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                    'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                    'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                            'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                            'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                            'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "        # pre TOV and pre 3PA\n",
        "        except:\n",
        "          try:\n",
        "            headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                      'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                      'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'PF',\n",
        "                      'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']  \n",
        "\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                              'G',\t'W', 'L', 'FG', 'FT', 'ORB', \n",
        "                              'TRB',\t'AST', 'STL', 'BLK', 'PF', 'dum2',\n",
        "                              'FG%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "          # post TOV and pre 3PA \n",
        "          except:\n",
        "            headers = [th.getText() for th in first_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            headers = headers[1:]\n",
        "            headers[2] = 'Year'\n",
        "            headers[27] = 'MP/G'\n",
        "            headers[28] = 'PTS/G'\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      \n",
        "\n",
        "      # convert ABA seasons to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SSL\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"VIR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SAA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"INA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"UTS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"KEN\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"CAR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1960\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1961\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1962\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1963\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1964\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1965\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1966\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1967\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1968\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1969\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1970\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1971\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1972\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1973\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data['MP'] = series_data['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "\n",
        "      # add TS% allowed\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['PTS/G'] = series_data['PTS/G'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      teams_ts_df['Team'] = teams_ts_df['Team'].astype(str)\n",
        "      teams_ts_df['Year'] = teams_ts_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "      opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "      series_data['opp_ts'] = opponent_ts['TS% Allowed'] np.where ( teams_ts_df['Opp'] == series_data['Opp'] & teams_ts_df['Year'] == series_data['Year'] )\n",
        "      series_data['opp_ts'] = series_data['opp_ts'].astype(float)\n",
        "        \n",
        "      if series_data['PTS/G'] == 0:\n",
        "        series_data['TS+'] = 0\n",
        "      else:\n",
        "        series_data['TS+'] = ((series_data['PTS'] / (((series_data['FTA'] * .44) + series_data['FGA']) * 2)) / series_data['opp_ts']) * 100\n",
        "        series_data['TS+'] = '%.2f' % round(series_data['TS+'], 2)\n",
        "\n",
        "      new_row = {'Player':series_data['Player'], 'Year':series_data['Player'], 'Opp':series_data['Opp'], 'PTS/G':series_data['PTS/G'], 'TS+':series_data['TS+'], 'MP':int(series_data['MP'])}\n",
        "      final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "    print(final_season_df)\n",
        "    outfile = f\"NBA_Playoff_Series_Adjusted_TS_df.csv\"\n",
        "    final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RRlU93sn61Rl"
      },
      "outputs": [],
      "source": [
        "#@title Scrape Adjusted Playoff TS+ Series by Series\n",
        "def adjust_scoring_efficiency_series(url_df, opp_ts_df, opp_defrtg_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'Opp', 'PTS/G', 'TS+', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      print(player)\n",
        "      \n",
        "\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      time.sleep(5)\n",
        "      soup = BeautifulSoup(html)\n",
        "      time.sleep(5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      # grab rows\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "\n",
        "      # post 3PA\n",
        "      try:\n",
        "        headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                  'G',\t'W', 'L',\t'MP', 'FG', 'FGA', '3P', '3PA', 'FT', \n",
        "                  'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                  'PTS', 'dum2', 'FG%', '3P%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                          'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                          'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                          'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "      except:\n",
        "        # post TOV pre 3PA\n",
        "        try:\n",
        "          headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                    'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                    'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                    'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                            'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                            'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                            'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "        # pre TOV and pre 3PA\n",
        "        except:\n",
        "          try:\n",
        "            headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                      'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                      'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'PF',\n",
        "                      'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']  \n",
        "\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                              'G',\t'W', 'L', 'FG', 'FT', 'ORB', \n",
        "                              'TRB',\t'AST', 'STL', 'BLK', 'PF', 'dum2',\n",
        "                              'FG%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "          # post TOV and pre 3PA \n",
        "          except:\n",
        "            headers = [th.getText() for th in first_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            headers = headers[1:]\n",
        "            headers[2] = 'Year'\n",
        "            headers[27] = 'MP/G'\n",
        "            headers[28] = 'PTS/G'\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      \n",
        "\n",
        "      # convert ABA seasons to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SSL\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"VIR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SAA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"INA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"UTS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"KEN\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"CAR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1960\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1961\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1962\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1963\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1964\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1965\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1966\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1967\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1968\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1969\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1970\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1971\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1972\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1973\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data['MP'] = series_data['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "\n",
        "      # add TS% allowed\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['PTS/G'] = series_data['PTS/G'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "        # get ts% allowed by opponent\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & ((opp_ts_df['Year'] == current_year))]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        # get defrtg allowed by opponent\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        if row['PTS/G'] == 0:\n",
        "          tsplus = 0\n",
        "        else:\n",
        "          tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        pts = row['PTS/G']\n",
        "        tsplus = '%.2f' % round(tsplus, 2)\n",
        "        pts = pts * pts_coeff\n",
        "\n",
        "        new_row = {'Player':player, 'Year':current_year, 'Opp':current_opp, 'PTS/G':pts, 'TS+':tsplus, 'MP':int(row['MP'])}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "    outfile = f\"NBA_Playoff_Series_Adjusted_Scoring_df.csv\"\n",
        "    final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNmY18XS86dV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run Adjusted Playoff TS+ Scrape Series by Series\n",
        "opp_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = pd.read_csv('/content/fragment97.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "adjust_scoring_efficiency_series(url_txt_df, opp_ts_allowed_df, opponent_adj_pts_coeff)\n",
        "\n",
        "spurs_guys = pd.read_csv('/content/NBA_Playoff_Series_Adjusted_Scoring_df.csv', index_col=False, encoding='utf8')\n",
        "spurs_guys = spurs_guys.sort_values('Year', ascending=True)\n",
        "\n",
        "outfile = f\"Player_Scoring_Series.csv\"\n",
        "spurs_guys.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "71q1QOchqIgf"
      },
      "outputs": [],
      "source": [
        "#@title Inflate Series Stats \n",
        "player_df = pd.read_csv('Player_Scoring_Series.csv')\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in player_df.iterrows():\n",
        "\n",
        "  url_txt_df = pd.read_csv('/content/fragment97.csv', index_col=False, encoding='utf8')\n",
        "  url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "\n",
        "  for a, b in url_txt_df.itertuples(index=False):\n",
        "    player = a\n",
        "\n",
        "  # era adjust\n",
        "  #sub_coeff = per_game_coeff[(per_game_coeff['Year'] == row['Year'])]\n",
        "  #row['PTS/G'] = float(row['PTS/G'] * sub_coeff['Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"{player}_Inflated_Series_Stats.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df['MP'] = new_df['MP'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)\n",
        "print(new_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qmY0vNuq8QXA"
      },
      "outputs": [],
      "source": [
        "#@title David Robinson Custom Series Data (After removing some series)\n",
        "\n",
        "new_df = new_df[(new_df['Opp'] != \"UTA\")]\n",
        "new_df['G'] = 0\n",
        "new_df['Tm'] = 'SAS'\n",
        "new_df = new_df.rename(columns={\"Year\": \"Year\", \"Player\": \"Player\", \"Team\": \"Team\", \"PTS/G\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "teams_ts_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'PTS', 'TS%+', 'MP'])\n",
        "years_list = []\n",
        "player = 'David Robinson'\n",
        "for i, row in new_df.iterrows():\n",
        "      current_opp = new_df.loc[i, 'Opp']\n",
        "      current_year = new_df.loc[i,'Year']\n",
        "      opponent_ts = teams_ts_df[(teams_ts_df['Team'] == current_opp) & ((teams_ts_df['Year'] == current_year))]\n",
        "      opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "      if new_df.loc[i,'Year'] not in years_list:\n",
        "        years_list.append(new_df.loc[i,'Year'])\n",
        "       \n",
        "\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = new_df[(new_df['Year'] == year)]\n",
        "        total_pts = 0\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for ind_pts in tmp_sub_df['PTS']:\n",
        "          ind_pts = float(ind_pts)\n",
        "          total_pts += float(ind_pts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        total_pts = '%.2f' % round(total_pts, 2)\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "\n",
        "        new_row = {'Player':player, 'Year':year, 'PTS':total_pts, 'TS%+':total_ts, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "final_season_df = final_season_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")     \n",
        "print(final_season_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X7wa6qNOjrd"
      },
      "source": [
        "**REG TO PLAYOFFS CALCULATIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cvk_rdRbrv7P"
      },
      "outputs": [],
      "source": [
        "#@title Functional declarations of playoff scoring changes calculations\n",
        "\n",
        "# def comparePlayers(a, b, df) \n",
        "# given player a and player b from DataFrame df, print the scoring rate and effieciency for each player\n",
        "def comparePlayers(a, b, df):\n",
        "\n",
        "  player_a = df[(df.Player == a)]\n",
        "  player_b = df[(df.Player == b)]\n",
        "  total_mp_a = 0\n",
        "  total_pts_a = 0\n",
        "  total_ts_a = 0\n",
        "\n",
        "  total_mp_b = 0\n",
        "  total_pts_b = 0\n",
        "  total_ts_b = 0\n",
        "  mp_list_a = []\n",
        "  mp_list_b = []\n",
        "\n",
        "  # find total minutes a\n",
        "  for row in player_a['MP']:\n",
        "    mp_list_a.append(row)\n",
        "    total_mp_a += row\n",
        "  print(player_a.iat[0, 3], \"\\nMP: \", total_mp_a)\n",
        "\n",
        "  # find total PTS a\n",
        "  i = 0\n",
        "  for row in player_a['PTS']:\n",
        "    total_pts_a += row * (mp_list_a[i] / total_mp_a)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+ a\n",
        "  i = 0\n",
        "  for row in player_a['TS%+']:\n",
        "    total_ts_a += row * (mp_list_a[i] / total_mp_a)\n",
        "    i = i + 1\n",
        "\n",
        "  print(\"PTS per 75: \", total_pts_a)\n",
        "  print(\"TS+: \",total_ts_a)\n",
        "\n",
        "  # find total minutes\n",
        "  for row in player_b['MP']:\n",
        "    mp_list_b.append(row)\n",
        "    total_mp_b += row\n",
        "  print(\"\\n\")\n",
        "  print(player_b.iat[0, 3], \"\\nminutes: \", total_mp_b)\n",
        "\n",
        "  # find total PTS\n",
        "  i = 0\n",
        "  for row in player_b['PTS']:\n",
        "    total_pts_b += row * (mp_list_b[i] / total_mp_b)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+\n",
        "  i = 0\n",
        "  for row in player_b['TS%+']:\n",
        "    total_ts_b += row * (mp_list_b[i] / total_mp_b)\n",
        "    i = i + 1\n",
        "\n",
        "  print(\"PTS per 75: \", total_pts_b)\n",
        "  print(\"TS+: \",total_ts_b)\n",
        "\n",
        "# def reg_playoff_comp(a, dfa, dfb) \n",
        "# print the change in scoring rate and effieciency for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoff_comp(a, dfa, dfb):\n",
        "\n",
        "  player_a = dfa[(dfa.Player == a)]\n",
        "  player_b = dfb[(dfb.Player == a)]\n",
        "  total_mp_a = 0\n",
        "  pts_list_a = []\n",
        "  ts_list_a = []\n",
        "\n",
        "  total_mp_b = 0\n",
        "  pts_list_b = []\n",
        "  ts_list_b = []\n",
        "\n",
        "  mp_list_a = []\n",
        "  mp_list_b = []\n",
        "\n",
        "\n",
        "  # find total PTS a\n",
        "  i = 0\n",
        "  for row in player_a['PTS']:\n",
        "    pts_list_a.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+ a\n",
        "  i = 0\n",
        "  for row in player_a['TS%+']:\n",
        "    ts_list_a.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total minutes\n",
        "  for row in player_b['MP']:\n",
        "    mp_list_b.append(row)\n",
        "    total_mp_b += row\n",
        "  print(\"\\n\")\n",
        "  print(player_b.iat[0, 3], \"\\nPlayoffs\\n\\nminutes: \", total_mp_b)\n",
        "\n",
        "  # find total PTS\n",
        "  i = 0\n",
        "  for row in player_b['PTS']:\n",
        "    pts_list_b.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+\n",
        "  i = 0\n",
        "  for row in player_b['TS%+']:\n",
        "    ts_list_b.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  total_pts = 0\n",
        "  total_ts = 0\n",
        "  while i <= j-1:\n",
        "    total_pts += ((pts_list_b[i] - pts_list_a[i]) * (mp_list_b[i] / total_mp_b))\n",
        "    print(pts_list_b[i] - pts_list_a[i])\n",
        "    print(((pts_list_b[i] - pts_list_a[i]) * (mp_list_b[i] / total_mp_b)))\n",
        "    total_ts += ((ts_list_b[i] - ts_list_a[i]) * (mp_list_b[i] / total_mp_b))\n",
        "    i = i + 1\n",
        "\n",
        "  print(\"\\n\\nRegular Season to Playoffs Change\\n\")\n",
        "  if total_pts > 0:\n",
        "    form_string = \"PTS per 75: +{}\".format(total_pts)\n",
        "    print(form_string)\n",
        "  else: \n",
        "    print(\"PTS per 75: \", total_pts)\n",
        "  if total_ts > 0:\n",
        "    form_string = \"TS+ {}\".format(total_ts)\n",
        "    print(form_string)\n",
        "  else:\n",
        "    print(\"TS+: \",total_ts)\n",
        "\n",
        "\n",
        "# print the change in scoring rate and effieciency for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoffs_functional_use(a, dfa, dfb):\n",
        "\n",
        "  player_reg = dfa[(dfa.Player == a)]\n",
        "  player_playoff = dfb[(dfb.Player == a)]\n",
        "\n",
        "  total_mp_reg = 0\n",
        "  pts_list_reg = []\n",
        "  ts_list_reg = []\n",
        "\n",
        "  total_mp_playoff = 0\n",
        "  pts_list_playoff = []\n",
        "  ts_list_playoff = []\n",
        "\n",
        "  mp_list_reg = []\n",
        "  mp_list_playoff = []\n",
        "\n",
        "  total_pts_change = 0\n",
        "  total_ts_change = 0\n",
        "  total_pts = 0\n",
        "  total_ts = 0\n",
        "\n",
        "  # find total reg PTS\n",
        "  i = 0\n",
        "  for row in player_reg['PTS']:\n",
        "    pts_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total reg TS+\n",
        "  i = 0\n",
        "  for row in player_reg['TS%+']:\n",
        "    ts_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff minutes\n",
        "  for row in player_playoff['MP']:\n",
        "    mp_list_playoff.append(row)\n",
        "    total_mp_playoff += row\n",
        "\n",
        "  # find total playoff PTS\n",
        "  i = 0\n",
        "  for row in player_playoff['PTS']:\n",
        "    pts_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff TS+\n",
        "  i = 0\n",
        "  for row in player_playoff['TS%+']:\n",
        "    ts_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "  if len(pts_list_reg) != len(pts_list_playoff):\n",
        "    j = j-1\n",
        "\n",
        "  i = 0\n",
        "  while i <= j-1:\n",
        "    total_pts_change += ((pts_list_playoff[i] - pts_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_ts_change += ((ts_list_playoff[i] - ts_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_pts += (pts_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_ts += (ts_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    i = i + 1\n",
        "  return (a, total_pts, total_ts, total_pts_change, total_ts_change, total_mp_playoff)\n",
        "\n",
        "\n",
        "# print the change in BPM and OBPM for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoffs_functional_use_bpm(a, dfa, dfb):\n",
        "\n",
        "  player_reg = dfa[(dfa.Player == a)]\n",
        "  player_playoff = dfb[(dfb.Player == a)]\n",
        "\n",
        "  total_mp_reg = 0\n",
        "  bpm_list_reg = []\n",
        "  obpm_list_reg = []\n",
        "\n",
        "  total_mp_playoff = 0\n",
        "  bpm_list_playoff = []\n",
        "  obpm_list_playoff = []\n",
        "\n",
        "  mp_list_reg = []\n",
        "  mp_list_playoff = []\n",
        "\n",
        "  total_bpm_change = 0\n",
        "  total_obpm_change = 0\n",
        "  total_bpm = 0\n",
        "  total_obpm = 0\n",
        "\n",
        "  # find total reg PTS\n",
        "  i = 0\n",
        "  for row in player_reg['BPM']:\n",
        "    bpm_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total reg TS+\n",
        "  i = 0\n",
        "  for row in player_reg['OBPM']:\n",
        "    obpm_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff minutes\n",
        "  for row in player_playoff['MP']:\n",
        "    mp_list_playoff.append(row)\n",
        "    total_mp_playoff += row\n",
        "\n",
        "  # find total playoff PTS\n",
        "  i = 0\n",
        "  for row in player_playoff['BPM']:\n",
        "    bpm_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff TS+\n",
        "  i = 0\n",
        "  for row in player_playoff['OBPM']:\n",
        "    obpm_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "  if len(bpm_list_reg) != len(bpm_list_playoff):\n",
        "    j = j-1\n",
        "\n",
        "  i = 0\n",
        "  while i <= j-1:\n",
        "    total_bpm_change += ((bpm_list_playoff[i] - bpm_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_obpm_change += ((obpm_list_playoff[i] - obpm_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_bpm += (bpm_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_obpm += (obpm_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    i = i + 1\n",
        "  return (a, total_bpm, total_obpm, total_bpm_change, total_obpm_change, total_mp_playoff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eb96uEuGsGDN"
      },
      "outputs": [],
      "source": [
        "#@title Function declaration of playoff scoring changes (career)  \n",
        "# output file containing change in scoring rate and efficiency from regular season to playoffs (Entire Career)\n",
        "# use only regular seasons in which a player made the playoffs\n",
        "def regToPlayoffsProductionTightScope(reg_df, playoff_db):\n",
        "\n",
        "  new_df = pd.DataFrame(columns = ['Player','PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  headers_list = ['Player', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post']\n",
        "  players_finished = []\n",
        "  used_years = []\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "    used_years = []\n",
        "    if row['Player'] not in players_finished:\n",
        "      player_playoff_db = playoff_db[(playoff_db.Player == row[\"Player\"])]\n",
        "      for use_idx, use_row in player_playoff_db.iterrows():\n",
        "        used_years.append(use_row['Year'])\n",
        "      player_reg_db = reg_df[reg_df['Year'].isin(used_years)]\n",
        "      player_reg_db = player_reg_db[(player_reg_db.Player == row[\"Player\"])]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "      players_finished.append(row['Player'])\n",
        "  outfile = f\"Career_Playoff_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  \n",
        "  new_df.to_csv(outfile, index=False)\n",
        "  \n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XaAVm7LcZedf"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff scoring changes (career)\n",
        "# CAREER\n",
        "\n",
        " \n",
        "\n",
        "regToPlayoffsProductionTightScope(era_adj_reg_per_75_df, era_opponent_adj_playoff_per_75_df)\n",
        "import_player_scoring_changes_df = pd.read_csv('Career_Playoff_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_scoring_changes_df = import_player_scoring_changes_df.dropna()\n",
        "\n",
        "\n",
        "\n",
        "one_thousand_min_filter = import_player_scoring_changes_df[(import_player_scoring_changes_df['MP_post'] >= 2000)]\n",
        "outfile_1000 = f\"Career_Playoff_Scoring_Change_2000min.csv\"\n",
        "one_thousand_min_filter.to_csv(outfile_1000, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "74v74ArIIZdT"
      },
      "outputs": [],
      "source": [
        "#@title Functional declarations of playoff scoring changes (x year stretches)\n",
        "\n",
        "# def twoYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every two year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def twoYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year2 = int(year2)\n",
        "        season_list = '{} - {}'.format(year1, year2)\n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = int(year2)\n",
        "        season_list = '{}, {}'.format(year1, year2)\n",
        "\n",
        "      \n",
        "\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Two_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def threeYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every three year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def threeYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-1\n",
        "        year3 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year3 = int(year3)\n",
        "        season_list = '{} - {}'.format(year1, year3)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "        year3 = years.split()[2]\n",
        "        year3 = int(year3)\n",
        "        season_list = '{}, {}, {}'.format(year1, year2, year3)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Three_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def fourYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every four year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def fourYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-2\n",
        "        year3 = int(years.split()[2])-1\n",
        "        year4 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year4)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}'.format(year1, year2, year3, year4)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Four_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def fiveYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every five year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def fiveYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-3\n",
        "        year3 = int(years.split()[2])-2\n",
        "        year4 = int(years.split()[2])-1\n",
        "        year5 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year5)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Five_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def sixYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def sixYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-4\n",
        "        year3 = int(years.split()[2])-3\n",
        "        year4 = int(years.split()[2])-2\n",
        "        year5 = int(years.split()[2])-1\n",
        "        year6 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year6)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Six_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def sevenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def sevenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-5\n",
        "        year3 = int(years.split()[2])-4\n",
        "        year4 = int(years.split()[2])-3\n",
        "        year5 = int(years.split()[2])-2\n",
        "        year6 = int(years.split()[2])-1\n",
        "        year7 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year7)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Seven_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def eightYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every eight year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def eightYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-6\n",
        "        year3 = int(years.split()[2])-5\n",
        "        year4 = int(years.split()[2])-4\n",
        "        year5 = int(years.split()[2])-3\n",
        "        year6 = int(years.split()[2])-2\n",
        "        year7 = int(years.split()[2])-1\n",
        "        year8 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year8)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Eight_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def nineYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every nine year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def nineYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year9)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8) | (adjusted_playoff_per_75_df.Year == year9))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Nine_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def tenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every ten year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def tenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = int(years.split()[2])-1\n",
        "        year10 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year10)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = year9.replace(',', '')\n",
        "        year9 = int(year9)\n",
        "\n",
        "        year10 = years.split()[9]\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9, year10)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9) | (reg_df.Year == year10))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8) | (adjusted_playoff_per_75_df.Year == year9) | (adjusted_playoff_per_75_df.Year == year10))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Ten_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aZ85A5uLjDIJ"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff scoring changes (x year stretches)\n",
        "import_player_pts_playoff10peaks_df = pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "tenYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff10peaks_df)\n",
        "\n",
        "import_player_pts_playoff9peaks_df = pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "nineYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff9peaks_df)\n",
        "\n",
        "import_player_pts_playoff8peaks_df = pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "eightYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff8peaks_df)\n",
        "\n",
        "import_player_pts_playoff7peaks_df = pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "sevenYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff7peaks_df)\n",
        "\n",
        "import_player_pts_playoff6peaks_df = pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "sixYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff6peaks_df)\n",
        "\n",
        "import_player_pts_playoff5peaks_df = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "fiveYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff5peaks_df)\n",
        "\n",
        "import_player_pts_playoff4peaks_df = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "fourYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff4peaks_df)\n",
        "\n",
        "import_player_pts_playoff3peaks_df = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "threeYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff3peaks_df)\n",
        "\n",
        "import_player_pts_playoff2peaks_df = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "twoYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff2peaks_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PpVhZVsYcV0E"
      },
      "outputs": [],
      "source": [
        "#@title Function declaration of playoff BPM changes (career)  \n",
        "# output file containing change in scoring rate and efficiency from regular season to playoffs (Entire Career)\n",
        "# use only regular seasons in which a player made the playoffs\n",
        "def regToPlayoffsProductionTightScopeBPM(reg_df, playoff_db):\n",
        "\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "  players_finished = []\n",
        "  used_years = []\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "    used_years = []\n",
        "    if row['Player'] not in players_finished:\n",
        "      player_playoff_db = playoff_db[(playoff_db.Player == row[\"Player\"])]\n",
        "      for use_idx, use_row in player_playoff_db.iterrows():\n",
        "        used_years.append(use_row['Year'])\n",
        "      player_reg_db = reg_df[reg_df['Year'].isin(used_years)]\n",
        "      player_reg_db = player_reg_db[(player_reg_db.Player == row[\"Player\"])]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "      players_finished.append(row['Player'])\n",
        "  outfile = f\"Career_Playoff_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "  \n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  \n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q3UBqs5tb-Ea"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff BPM changes (career)\n",
        "# CAREER\n",
        "\n",
        " \n",
        "\n",
        "regToPlayoffsProductionTightScopeBPM(era_adj_reg_per_75_df, era_opponent_adj_playoff_per_75_df)\n",
        "import_player_scoring_changes_df = pd.read_csv('Career_Playoff_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_scoring_changes_df = import_player_scoring_changes_df.dropna()\n",
        "\n",
        "\n",
        "\n",
        "one_thousand_min_filter = import_player_scoring_changes_df[(import_player_scoring_changes_df['MP_post'] >= 2000)]\n",
        "outfile_1000 = f\"Career_Playoff_Scoring_Change_2000min.csv\"\n",
        "one_thousand_min_filter.to_csv(outfile_1000, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cXgIpAWbAXC1"
      },
      "outputs": [],
      "source": [
        "#@title Functional declarations of playoff BPM changes (x year stretches)\n",
        "\n",
        "# def twoYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every two year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def twoYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year2 = int(year2)\n",
        "        season_list = '{} - {}'.format(year1, year2)\n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = int(year2)\n",
        "        season_list = '{}, {}'.format(year1, year2)\n",
        "\n",
        "      \n",
        "\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2))]\n",
        "      player_playoff_db = playoff_bpm_data[(playoff_bpm_data.Player == row[\"Player\"]) & ((playoff_bpm_data.Year == year1) | (playoff_bpm_data.Year == year2))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Two_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def threeYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every three year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def threeYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-1\n",
        "        year3 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year3 = int(year3)\n",
        "        season_list = '{} - {}'.format(year1, year3)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "        year3 = years.split()[2]\n",
        "        year3 = int(year3)\n",
        "        season_list = '{}, {}, {}'.format(year1, year2, year3)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Three_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def fourYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every four year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def fourYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-2\n",
        "        year3 = int(years.split()[2])-1\n",
        "        year4 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year4)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}'.format(year1, year2, year3, year4)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Four_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def fiveYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every five year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def fiveYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-3\n",
        "        year3 = int(years.split()[2])-2\n",
        "        year4 = int(years.split()[2])-1\n",
        "        year5 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year5)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Five_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def sixYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def sixYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-4\n",
        "        year3 = int(years.split()[2])-3\n",
        "        year4 = int(years.split()[2])-2\n",
        "        year5 = int(years.split()[2])-1\n",
        "        year6 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year6)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Six_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def sevenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def sevenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-5\n",
        "        year3 = int(years.split()[2])-4\n",
        "        year4 = int(years.split()[2])-3\n",
        "        year5 = int(years.split()[2])-2\n",
        "        year6 = int(years.split()[2])-1\n",
        "        year7 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year7)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Seven_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def eightYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every eight year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def eightYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-6\n",
        "        year3 = int(years.split()[2])-5\n",
        "        year4 = int(years.split()[2])-4\n",
        "        year5 = int(years.split()[2])-3\n",
        "        year6 = int(years.split()[2])-2\n",
        "        year7 = int(years.split()[2])-1\n",
        "        year8 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year8)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Eight_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def nineYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every nine year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def nineYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year9)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8) | (playoff_bpm_data .Year == year9))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Nine_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def tenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every ten year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def tenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = int(years.split()[2])-1\n",
        "        year10 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year10)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = year9.replace(',', '')\n",
        "        year9 = int(year9)\n",
        "\n",
        "        year10 = years.split()[9]\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9, year10)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9) | (reg_df.Year == year10))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8) | (playoff_bpm_data .Year == year9) | (playoff_bpm_data .Year == year10))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Ten_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Me79i0gHKVE3"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff bpm changes (x year stretches)\n",
        "import_player_bpm_playoff10peaks_df = pd.read_csv('/content/Ten_Year_BPM_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "tenYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff10peaks_df)\n",
        "\n",
        "import_player_bpm_playoff9peaks_df = pd.read_csv('/content/Nine_Year_BPM_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "nineYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff9peaks_df)\n",
        "\n",
        "import_player_bpm_playoff8peaks_df = pd.read_csv('/content/Eight_Year_BPM_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "eightYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff8peaks_df)\n",
        "\n",
        "import_player_bpm_playoff7peaks_df = pd.read_csv('/content/Seven_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "sevenYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff7peaks_df)\n",
        "\n",
        "import_player_bpm_playoff6peaks_df = pd.read_csv('/content/Six_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "sixYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff6peaks_df)\n",
        "\n",
        "import_player_bpm_playoff5peaks_df = pd.read_csv('/content/Five_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "fiveYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff5peaks_df)\n",
        "\n",
        "import_player_bpm_playoff4peaks_df = pd.read_csv('/content/Four_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "fourYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff4peaks_df)\n",
        "\n",
        "import_player_bpm_playoff3peaks_df = pd.read_csv('/content/Three_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "threeYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff3peaks_df)\n",
        "\n",
        "import_player_bpm_playoff2peaks_df = pd.read_csv('/content/Two_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "twoYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff2peaks_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xqYbggXprnkM"
      },
      "outputs": [],
      "source": [
        "#@title Reorganize playoff scoring changes (x year stretches)\n",
        "\n",
        "#2\n",
        "import_player_2scoring_changes_df = pd.read_csv('Two_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_2scoring_changes_df = import_player_2scoring_changes_df.dropna()\n",
        "\n",
        "three_hundred_min_filter = import_player_2scoring_changes_df[(import_player_2scoring_changes_df['MP_post'] >= 300)]\n",
        "eight_hundred_min_filter = import_player_2scoring_changes_df[(import_player_2scoring_changes_df['MP_post'] >= 800)]\n",
        "\n",
        "outfile_300 = f\"2_Adjusted_Playoff_Scoring_Prime_Change_300min.csv\"\n",
        "outfile_800 = f\"2_Adjusted_Playoff_Scoring_Prime_Change_800min.csv\"\n",
        "\n",
        "three_hundred_min_filter.to_csv(outfile_300, index=False)\n",
        "eight_hundred_min_filter.to_csv(outfile_800, index=False)\n",
        "\n",
        "least_20 = eight_hundred_min_filter[(eight_hundred_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"2_Adjusted_Playoff_Scoring_Prime_Change_800min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "least_20 = three_hundred_min_filter[(three_hundred_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"2_Adjusted_Playoff_Scoring_Prime_Change_300min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#3\n",
        "import_player_3scoring_changes_df = pd.read_csv('Three_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_3scoring_changes_df = import_player_3scoring_changes_df.dropna()\n",
        "\n",
        "five_hundred_min_filter = import_player_3scoring_changes_df[(import_player_3scoring_changes_df['MP_post'] >= 500)]\n",
        "one_thousand_min_filter = import_player_3scoring_changes_df[(import_player_3scoring_changes_df['MP_post'] >= 1000)]\n",
        "\n",
        "outfile_500 = f\"3_Adjusted_Playoff_Scoring_Prime_Change_500min.csv\"\n",
        "outfile_1000 = f\"3_Adjusted_Playoff_Scoring_Prime_Change_1000min.csv\"\n",
        "\n",
        "five_hundred_min_filter.to_csv(outfile_500, index=False)\n",
        "one_thousand_min_filter.to_csv(outfile_1000, index=False)\n",
        "\n",
        "least_20 = one_thousand_min_filter[(one_thousand_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"3_Adjusted_Playoff_Scoring_Prime_Change_1000min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "least_20 = five_hundred_min_filter[(five_hundred_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"3_Adjusted_Playoff_Scoring_Prime_Change_500min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#4\n",
        "import_player_4scoring_changes_df = pd.read_csv('Four_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_4scoring_changes_df = import_player_4scoring_changes_df.dropna()\n",
        "\n",
        "min_1500_filter = import_player_4scoring_changes_df[(import_player_4scoring_changes_df['MP_post'] >= 1500)]\n",
        "two_thousand_min_filter = import_player_4scoring_changes_df[(import_player_4scoring_changes_df['MP_post'] >= 2000)]\n",
        "\n",
        "outfile_1500 = f\"4_Adjusted_Playoff_Scoring_Prime_Change_1500min.csv\"\n",
        "outfile_2000 = f\"4_Adjusted_Playoff_Scoring_Prime_Change_2000min.csv\"\n",
        "\n",
        "min_1500_filter.to_csv(outfile_1500, index=False)\n",
        "two_thousand_min_filter.to_csv(outfile_2000, index=False)\n",
        "\n",
        "least_20 = two_thousand_min_filter[(two_thousand_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"4_Adjusted_Playoff_Scoring_Prime_Change_1500min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "least_20 = min_1500_filter[(min_1500_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"4_Adjusted_Playoff_Scoring_Prime_Change_2000min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#5\n",
        "import_player_5scoring_changes_df = pd.read_csv('Five_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_5scoring_changes_df = import_player_5scoring_changes_df.dropna()\n",
        "\n",
        "five_hundred_min_filter = import_player_5scoring_changes_df[(import_player_5scoring_changes_df['MP_post'] >= 500)]\n",
        "one_thousand_min_filter = import_player_5scoring_changes_df[(import_player_5scoring_changes_df['MP_post'] >= 1000)]\n",
        "\n",
        "outfile_500 = f\"5_Adjusted_Playoff_Scoring_Prime_Change_500min.csv\"\n",
        "outfile_1000 = f\"5_Adjusted_Playoff_Scoring_Prime_Change_1000min.csv\"\n",
        "\n",
        "five_hundred_min_filter.to_csv(outfile_500, index=False)\n",
        "one_thousand_min_filter.to_csv(outfile_1000, index=False)\n",
        "\n",
        "least_20 = one_thousand_min_filter[(one_thousand_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"5_Adjusted_Playoff_Scoring_Prime_Change_1000min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "least_20 = five_hundred_min_filter[(five_hundred_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"5_Adjusted_Playoff_Scoring_Prime_Change_500min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#6\n",
        "import_player_6scoring_changes_df = pd.read_csv('Six_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_6scoring_changes_df = import_player_6scoring_changes_df.dropna()\n",
        "\n",
        "min_1500_filter = import_player_6scoring_changes_df[(import_player_6scoring_changes_df['MP_post'] >= 1500)]\n",
        "two_thousand_min_filter = import_player_6scoring_changes_df[(import_player_6scoring_changes_df['MP_post'] >= 2000)]\n",
        "\n",
        "outfile_1500 = f\"6_Adjusted_Playoff_Scoring_Prime_Change_1500min.csv\"\n",
        "outfile_2000 = f\"6_Adjusted_Playoff_Scoring_Prime_Change_2000min.csv\"\n",
        "\n",
        "min_1500_filter.to_csv(outfile_1500, index=False)\n",
        "two_thousand_min_filter.to_csv(outfile_2000, index=False)\n",
        "\n",
        "least_20 = two_thousand_min_filter[(two_thousand_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"6_Adjusted_Playoff_Scoring_Prime_Change_1500min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "least_20 = min_1500_filter[(min_1500_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"6_Adjusted_Playoff_Scoring_Prime_Change_2000min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#7\n",
        "import_player_7scoring_changes_df = pd.read_csv('Seven_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_7scoring_changes_df = import_player_7scoring_changes_df.dropna()\n",
        "\n",
        "min_1500_filter = import_player_7scoring_changes_df[(import_player_7scoring_changes_df['MP_post'] >= 1500)]\n",
        "two_thousand_min_filter = import_player_7scoring_changes_df[(import_player_7scoring_changes_df['MP_post'] >= 2000)]\n",
        "\n",
        "outfile_1500 = f\"7_Adjusted_Playoff_Scoring_Prime_Change_1500min.csv\"\n",
        "outfile_2000 = f\"7_Adjusted_Playoff_Scoring_Prime_Change_2000min.csv\"\n",
        "\n",
        "min_1500_filter.to_csv(outfile_1500, index=False)\n",
        "two_thousand_min_filter.to_csv(outfile_2000, index=False)\n",
        "\n",
        "least_20 = two_thousand_min_filter[(two_thousand_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"7_Adjusted_Playoff_Scoring_Prime_Change_1500min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "least_20 = min_1500_filter[(min_1500_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"7_Adjusted_Playoff_Scoring_Prime_Change_2000min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 8\n",
        "import_player_8scoring_changes_df = pd.read_csv('Eight_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_8scoring_changes_df = import_player_8scoring_changes_df.dropna()\n",
        "\n",
        "min_1500_filter = import_player_8scoring_changes_df[(import_player_8scoring_changes_df['MP_post'] >= 1500)]\n",
        "two_thousand_min_filter = import_player_8scoring_changes_df[(import_player_8scoring_changes_df['MP_post'] >= 2000)]\n",
        "\n",
        "outfile_1500 = f\"8_Adjusted_Playoff_Scoring_Prime_Change_1500min.csv\"\n",
        "outfile_2000 = f\"8_Adjusted_Playoff_Scoring_Prime_Change_2000min.csv\"\n",
        "\n",
        "min_1500_filter.to_csv(outfile_1500, index=False)\n",
        "two_thousand_min_filter.to_csv(outfile_2000, index=False)\n",
        "\n",
        "least_20 = two_thousand_min_filter[(two_thousand_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"8_Adjusted_Playoff_Scoring_Prime_Change_1500min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "least_20 = min_1500_filter[(min_1500_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"8_Adjusted_Playoff_Scoring_Prime_Change_2000min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 9\n",
        "import_player_9scoring_changes_df = pd.read_csv('Nine_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_9scoring_changes_df = import_player_10scoring_changes_df.dropna()\n",
        "\n",
        "two_thousand_min_filter = import_player_10scoring_changes_df[(import_player_10scoring_changes_df['MP_post'] >= 1700)]\n",
        "outfile_2000 = f\"9_Adjusted_Playoff_Scoring_Prime_Change_1700min.csv\"\n",
        "two_thousand_min_filter.to_csv(outfile_2000, index=False)\n",
        "\n",
        "least_20 = two_thousand_min_filter[(two_thousand_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"9_Adjusted_Playoff_Scoring_Prime_Change_1700min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 10\n",
        "import_player_10scoring_changes_df = pd.read_csv('Ten_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_10scoring_changes_df = import_player_10scoring_changes_df.dropna()\n",
        "\n",
        "two_thousand_min_filter = import_player_10scoring_changes_df[(import_player_10scoring_changes_df['MP_post'] >= 2000)]\n",
        "outfile_2000 = f\"10_Adjusted_Playoff_Scoring_Prime_Change_2000min.csv\"\n",
        "two_thousand_min_filter.to_csv(outfile_2000, index=False)\n",
        "\n",
        "least_20 = two_thousand_min_filter[(two_thousand_min_filter['PTS per 75_post'] >= 20)]\n",
        "least_20 = least_20.sort_values('TS+_change', ascending=False)\n",
        "outfile_least20 = f\"10_Adjusted_Playoff_Scoring_Prime_Change_2000min_20points.csv\"\n",
        "least_20.to_csv(outfile_least20, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDmJQufWVk3B"
      },
      "outputs": [],
      "source": [
        "graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "graph_data = graph_data[(graph_data['PTS'] >= 34)]\n",
        "#graph_data = graph_data[(graph_data['Player'] != 'Michael Jordan')]\n",
        "#graph_data = graph_data[(graph_data['MP'] <= 1000)]\n",
        "print(graph_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu-iOQT7Rpj5"
      },
      "source": [
        "**SCORING PLOT FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-3WWnnpkhqr"
      },
      "outputs": [],
      "source": [
        "def label_point(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "      #if i % 2 == 0:\n",
        "      #  ax.text(point['x']+0.25, point['y'], str(point['val']))\n",
        "      #else:\n",
        "      ax.text(point['x']+0.30, point['y'], str(point['val']))\n",
        "      #ax.text(point['x']+0.05, point['y'], str(point['val']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wJ_wS861o8eV"
      },
      "outputs": [],
      "source": [
        "#@title Single Plot Template\n",
        "def plotOneScoring(p1, c1, pts_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Multi-Year Playoff Scoring Stretches (1974 - 2022) [min. 500 MP]', xlabel='PTS per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def plotTwoScoring(p1, p2, c1, c2, ts_floor, ts_ceiling, pts_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Multi-Year Playoff Scoring (1974 - 2022) [min 1000 MP]', xlabel='PTS per 75', ylabel='TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def plotThreeScoring(p1, p2, p3, c1, c2, c3, pts_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Multi-Year Playoff Scoring (1974 - 2022)', xlabel='PTS per 75', ylabel='TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-Nhc4VYkV2Zq"
      },
      "outputs": [],
      "source": [
        "#@title Multiple Plots Template\n",
        "def plotOneScoring(p1, c1, pts_floor, ts_floor, ts_ceiling):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1974-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted) (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1974-2022) [>500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 600)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1974-2022) [>600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1000)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1974-2022) [>1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1200)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1974-2022) [>1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1974-2022) [>1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1974-2022) [>1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1974-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1974-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 400]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1974-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Peaks', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title 2 Guys Scoring Plot Template\n",
        "def plotTwoScoring(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling):\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(115)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1974-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1974-2022) [>500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 600)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1974-2022) [>600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1000)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1974-2022) [>1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1200)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1974-2022) [>1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1974-2022) [>1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1974-2022) [>1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1974-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1974-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1974-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[9].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Peaks', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title 3 Guys Scoring Plot Template\n",
        "def plotThreeScoring(p1, p2, p3, c1, c2, c3, pts_floor, ts_floor, ts_ceiling):\n",
        "  fig, axis = plt.subplots(9)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1974-2022) [> 300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1974-2022) [> 500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 600]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1974-2022) [> 600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1974-2022) [> 1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1200]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1974-2022) [> 1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1400]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1974-2022) [> 1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1974-2022) [> 1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 2000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='10 Year Playoff Scoring (1974-2022) [> 2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='1 Year Playoff Scoring (1974-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring_Peaks', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Gys3Jbx0NXFW"
      },
      "outputs": [],
      "source": [
        "#@title 2 Guys PBP Plot Template\n",
        "def plotTwoPBP(p1, p2, c1, c2):\n",
        "  fig, axis = plt.subplots(7)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_pbp_Peaks_NBA_Playoffs_300_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MPG'] - graph_data['MPG'].min()) / (graph_data['MPG'].max() - graph_data['MPG'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*4, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='3 Year Playoff PBP (1997-2022) [>500 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_pbp_Peaks_NBA_Playoffs_600_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MPG'] - graph_data['MPG'].min()) / (graph_data['MPG'].max() - graph_data['MPG'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*4, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='4 Year Playoff PBP (1997-2022) [>600 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_pbp_Peaks_NBA_Playoffs_1000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MPG'] - graph_data['MPG'].min()) / (graph_data['MPG'].max() - graph_data['MPG'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*4, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='5 Year Playoff PBP (1997-2022) [>1000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_pbp_Peaks_NBA_Playoffs_1400_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MPG'] - graph_data['MPG'].min()) / (graph_data['MPG'].max() - graph_data['MPG'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*4, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='6 Year Playoff PBP (1997-2022) [>1400 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_pbp_Peaks_NBA_Playoffs_2000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MPG'] - graph_data['MPG'].min()) / (graph_data['MPG'].max() - graph_data['MPG'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*4, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='7 Year Playoff PBP (1997-2022) [>2000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MPG'] - graph_data['MPG'].min()) / (graph_data['MPG'].max() - graph_data['MPG'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*4, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='8 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MPG'] - graph_data['MPG'].min()) / (graph_data['MPG'].max() - graph_data['MPG'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*4, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='10 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_PBP_Peaks', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O408rauBGO3I"
      },
      "outputs": [],
      "source": [
        "#plotTwoScoring(\"Manu Ginóbili\", \"Tony Parker\", \"#EF426F\", \"#FF8200\", 20)\n",
        "plotTwoScoring(\"Manu Ginóbili\", \"Tony Parker\", \"#FF8200\", \"#EF426F\", 5, 60, 140)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sy_RXsh-Ctf"
      },
      "source": [
        "**REG->PLAYOFF SCORING CHANGE PLOTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6B5fddTe-Mbr"
      },
      "outputs": [],
      "source": [
        "#@title Scoring Change Single Plot Template\n",
        "def p_plotOneScoringChange(p1, c1, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP_post']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {pts_floor} Pts per 75 Postseason; min. {mp_floor} MP]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys Scoring Change Single Plot Template (TS+ above below league avg)\n",
        "def p_plotOneScoringChange_ab(p1, c1, pts_floor, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['TS+_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PTS_change\": \"PTS_change\", \"TS+_change\": \"TS+_change\", \"PTS per 75_reg\": \"PTS per 75_reg\", \"PTS per 75_post\": \"PTS per 75_post\", \"TS+_reg\": \"TS+_reg\", \"TS+_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((Manu==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "  else:\n",
        "    graph_data['color'] = np.where((Manu==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {threshold} TS+ postseason]\"\n",
        "  ax.set(title=title_string, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "def p_plotTwoScoringChange(p1, p2, c1, c2, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP_post']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022)', xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys Scoring Change Single Plot Template (TS+ above below league avg)\n",
        "def p_plotTwoScoringChange_ab(p1, p2, c1, c2, pts_floor, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['TS+_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PTS_change\": \"PTS_change\", \"TS+_change\": \"TS+_change\", \"PTS per 75_reg\": \"PTS per 75_reg\", \"PTS per 75_post\": \"PTS per 75_post\", \"TS+_reg\": \"TS+_reg\", \"TS+_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((Manu==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.TSpost >= threshold),c2, graph_data.color)\n",
        "  else:\n",
        "    graph_data['color'] = np.where((Manu==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.TSpost <= threshold),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {threshold} TS+ postseason]\"\n",
        "  ax.set(title=title_string, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "def p_plotThreeScoringChange(p1, p2, p3, c1, c2, c3, pts_floor):\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022)', xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring_Changes', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xxGUbQIlBFL6"
      },
      "outputs": [],
      "source": [
        "#@title (Multiple Plots) Changes with Line\n",
        "def p_plotOneScoringChangeWithLines(p1, c1, pts_floor, ts_floor, ts_ceiling, label, mp_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[0]} MP]\"\n",
        "  axis[0].set(title='titlestring', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChangeWithLines(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling, label, mp_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChangeWithLines(p1, p2, p3, c1, c2, c3, pts_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ihbDWbHaHO-S"
      },
      "outputs": [],
      "source": [
        "#@title Career Plot Changes with Line\n",
        "def p_plotOneScoringChangeWithLinesCareer(p1, c1, pts_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChangeWithLinesCareer(p1, p2, c1, c2, pts_floor):\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChangeWithLinesCareer(p1, p2, p3, c1, c2, c3, pts_floor):\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c3, linestyle=\"--\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r597HycnNfI4"
      },
      "outputs": [],
      "source": [
        "# pts_floor, ts_floor, ts_ceiling, label\n",
        "#p_plotTwoBPMChangeWithLines(\"Tony Parker\", \"Manu Ginóbili\", \"#EF426F\", \"#FF8200\", 15, [300, 500, 800, 1200], 0)\n",
        "#p_plotTwoBPMChange(\"Tony Parker\", \"Manu Ginóbili\", \"#EF426F\", \"#FF8200\", 15, 300)\n",
        "#p_plotTwoScoringChangeWithLinesCareer(\"Tony Parker\", \"Manu Ginóbili\", \"#EF426F\", \"#FF8200\", 5)\n",
        "#plotTwoScoring(\"Tony Parker\", \"Manu Ginóbili\", \"#EF426F\", \"#FF8200\", 80, 140, 5)\n",
        "plotTwoScoring(\"Tim Duncan\", \"Kobe Bryant\", \"k\", \"m\", 5, 70, 140)\n",
        "#plotOneScoring(\"Tim Duncan\", \"y\", 5)\n",
        "#p_plotTwoScoringChange(\"Reggie Miller\", \"Jimmy Butler\", \"y\", \"r\", 15, 500)\n",
        "p_plotTwoScoringChange(\"Tim Duncan\",\"Kobe Bryant\", \"k\", \"m\", 20, 3000)\n",
        "#p_plotTwoBPMChange(\"Reggie Miller\", \"Isiah Thomas\", \"y\", \"r\", 15, 500)\n",
        "#p_plotTwoScoringChangeWithLines(\"Reggie Miller\", \"Jimmy Butler\", \"y\", \"r\", 5, 80, 130, 0, [300, 500, 800, 1200])\n",
        "#p_plotTwoScoringChangeWithLines(\"Tim Duncan\", \"Kobe Bryant\", \"k\", \"y\", 5, 60, 140, 0, [300, 500, 600, 1000])\n",
        "#p_plotTwoScoringChangeWithLines(\"Tony Parker\", \"Manu Ginóbili\", \"#EF426F\", \"#FF8200\", 5, 80, 125, 0, [300, 500, 800, 1200])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_2pts = pd.read_csv('/content/Single_Playoff_Adjusted_Data_min_100_min.csv', encoding='utf8')\n",
        "sorted_2pts = sorted_2pts[(sorted_2pts['Player'] == 'Jimmy Butler')]\n",
        "sorted_2pts.to_csv(\"Single.csv\", index=False)"
      ],
      "metadata": {
        "id": "xNj6fC1s7pX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIWuoavMiG_r"
      },
      "source": [
        "**ERA ADJUSTED BPM CHANGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wlYv7A_Iexa8"
      },
      "outputs": [],
      "source": [
        "#@title (Era-Adjusted) p_plot_X_BPMChange (Single Plot)\n",
        "def p_plotOneBPMChange(p1, c1, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys BPM Change Single Plot Template (OBPM above below league avg)\n",
        "def p_plotOneBPMChange_ab(p1, c1, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  \n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['OBPM_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"bpm_change\": \"bpm_change\", \"OBPM_change\": \"OBPM_change\", \"BPM_reg\": \"BPM_reg\", \"BPM_post\": \"BPM_post\", \"OBPM_reg\": \"OBPM_reg\", \"OBPM_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((Manu==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "  else:\n",
        "    graph_data['color'] = np.where((Manu==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"bpm_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [min. {threshold} OBPM postseason]\"\n",
        "  ax.set(title=title_string, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['bpm_change'].max()\n",
        "  x_min = graph_data['bpm_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "def p_plotTwoBPMChange(p1, p2, c1, c2, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys BPM Change Single Plot Template (OBPM above below league avg)\n",
        "def p_plotTwoBPMChange_ab(p1, p2, c1, c2, above_below, threshold, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  \n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['OBPM_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((Manu==True) & (graph_data.BPM_post >= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.BPM_post >= threshold),c2, graph_data.color)\n",
        "  else:\n",
        "    graph_data['color'] = np.where((Manu==True) & (graph_data.BPM_post <= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.BPM_post <= threshold),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [min. {threshold} BPM postseason; [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "def p_plotThreeBPMChange(p1, p2, p3, c1, c2, c3, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data =  pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_BPM_Changes', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pHiJYdZueZoR"
      },
      "outputs": [],
      "source": [
        "#@title (Era-Adjusted) p_plot_X_BPMChangeWithLines (Multiple Plots)\n",
        "def p_plotOneBPMChangeWithLines(p1, c1, pts_floor, mp_floor, label):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}__BPM_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoBPMChangeWithLines(p1, p2, c1, c2, pts_floor, mp_floor, label):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}__BPM_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeBPMChangeWithLines(p1, p2, p3, c1, c2, c3, pts_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_BPM_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B-Yy-4czj7Qc"
      },
      "outputs": [],
      "source": [
        "#@title Space labels\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "np.random.seed(2016)\n",
        "\n",
        "N = 20\n",
        "scatter_data = np.random.rand(N, 3)*10\n",
        "\n",
        "\n",
        "def repel_labels(ax, x, y, labels, k=0.01):\n",
        "    G = nx.DiGraph()\n",
        "    data_nodes = []\n",
        "    init_pos = {}\n",
        "    for xi, yi, label in zip(x, y, labels):\n",
        "        data_str = 'data_{0}'.format(label)\n",
        "        G.add_node(data_str)\n",
        "        G.add_node(label)\n",
        "        G.add_edge(label, data_str)\n",
        "        data_nodes.append(data_str)\n",
        "        init_pos[data_str] = (xi, yi)\n",
        "        init_pos[label] = (xi, yi)\n",
        "\n",
        "    pos = nx.spring_layout(G, pos=init_pos, fixed=data_nodes, k=k)\n",
        "\n",
        "    # undo spring_layout's rescaling\n",
        "    pos_after = np.vstack([pos[d] for d in data_nodes])\n",
        "    pos_before = np.vstack([init_pos[d] for d in data_nodes])\n",
        "    scale, shift_x = np.polyfit(pos_after[:,0], pos_before[:,0], 1)\n",
        "    scale, shift_y = np.polyfit(pos_after[:,1], pos_before[:,1], 1)\n",
        "    shift = np.array([shift_x, shift_y])\n",
        "    for key, val in pos.items():\n",
        "        pos[key] = (val*scale) + shift\n",
        "\n",
        "    for label, data_str in G.edges():\n",
        "        ax.annotate(label,\n",
        "                    xy=pos[data_str], xycoords='data',\n",
        "                    xytext=pos[label], textcoords='data',\n",
        "                    arrowprops=dict(arrowstyle=\"->\",\n",
        "                                    shrinkA=0, shrinkB=0,\n",
        "                                    connectionstyle=\"arc3\", \n",
        "                                    color='red'), )\n",
        "    # expand limits\n",
        "    all_pos = np.vstack(pos.values())\n",
        "    x_span, y_span = np.ptp(all_pos, axis=0)\n",
        "    mins = np.min(all_pos-x_span*0.15, 0)\n",
        "    maxs = np.max(all_pos+y_span*0.15, 0)\n",
        "    ax.set_xlim([mins[0], maxs[0]])\n",
        "    ax.set_ylim([mins[1], maxs[1]])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(scatter_data[:, 0], scatter_data[:, 1],\n",
        "           c=scatter_data[:, 2], s=scatter_data[:, 2] * 150)\n",
        "labels = ['ano_{}'.format(i) for i in range(N)]\n",
        "repel_labels(ax, scatter_data[:, 0], scatter_data[:, 1], labels, k=0.008)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TONY MANU MULTIPLE LINE DRAWN SITUATIONAL CHANGES**"
      ],
      "metadata": {
        "id": "A1FZBFWLaGXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-Bgnirj0wYoA"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu Many changes from Big 3 -> 2/3 (2/3/4/5)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_2_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_3_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='3 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data = pd.read_csv('/content/Combined_4_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='4 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_5_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='5 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5oM4_4esYh2N"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu Many changes from Big 3 -> 2/3  +/- (2/3/4/5)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_2_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[0])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_3_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "  axis[1].set(title='3 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[1])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data = pd.read_csv('/content/Combined_4_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='4 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[2])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_5_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='5 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[3])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zgZ3-e7EQzRl"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu First to Later Rounds (+/-)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_NET\", y=\"Later_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Playoff +/- Change from First Round to Later Rounds (2004-14)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_NET'], graph_data['First_OFF']]\n",
        "  point2 = [graph_data['Later_NET'], graph_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_NET'], p2_data['First_OFF']]\n",
        "  point2 = [p2_data['Later_NET'], p2_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_NET'], graph_data['Later_OFF'], graph_data['Later_Years'], axis[0])\n",
        "    label_point(p2_data['Later_NET'], p2_data['Later_OFF'], p2_data['Later_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_NET\", y=\"Later_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Playoff +/- Change from First Round to Later Rounds (2004-14) [3+ opposing starters]', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_NET'], graph_data['First_OFF']]\n",
        "  point2 = [graph_data['Later_NET'], graph_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_NET'], p2_data['First_OFF']]\n",
        "  point2 = [p2_data['Later_NET'], p2_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_NET'], graph_data['Later_OFF'], graph_data['Later_Years'], axis[1])\n",
        "    label_point(p2_data['Later_NET'], p2_data['Later_OFF'], p2_data['Later_Years'], axis[1])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_NET_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loBdpFyEEaxA"
      },
      "source": [
        "**TONY MANU SITUATIONAL CHANGES FROM BIG 3 TO 2/3 BIG 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qw6gPZ85jYOp"
      },
      "outputs": [],
      "source": [
        "#@title Big 3 to Two Thirds\\2004-14\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O8X_Qca_iBDF"
      },
      "outputs": [],
      "source": [
        "#@title Big 3 to Two Thirds\\5 Year\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_5_Year_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Edki8wjYbKWz"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu 2004-14 change from Big 3 -> 2/3 (Tony Only 3 Opposing starters)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # NET\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [Manu 3+ opposing starters; Tony max 3 opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [Manu 3+ opposing starters; Tony max 3 opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0q8D6_zN2C5"
      },
      "source": [
        "**FROM FIRST TO LATER ROUNDS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xZ2si_VlN5mM"
      },
      "outputs": [],
      "source": [
        "#@title First Round to Later Rounds\\2004-14\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EP83nxE0UKmh"
      },
      "outputs": [],
      "source": [
        "#@title First Round to Later Rounds\\5 Year Later Peaks\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_5_Year_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UGlPvsNNcac7"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu 2004-14 change from first to later rounds (Tony Only 3 Opposing starters)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus_Round.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [Manu 3+ opposing starters; Tony max 3 opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus_Round.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [Manu 3+ opposing starters; Tony max 3 opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYaoLW0ASXvx"
      },
      "outputs": [],
      "source": [
        "plotTonyManuSituationalChange(\"Manu Ginóbili\", \"Tony Parker\", \"#FF8200\", \"#EF426F\", 5, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBcJHTYvdqJ9"
      },
      "source": [
        "**MANUAL SUBSET ADJUST TS+**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzgUworfEJgE"
      },
      "source": [
        "MANU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MS29cIwYJqdM"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with both of Tim and Tony on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['23.08', '.5938', '50', 'MEM', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.38', '.6081', '106', 'LAL', '2004', '6.16', '96.52']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['33.08', '.6719', '66', 'DEN', '2005', '13.0', '121.8']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.29', '.6705', '106', 'SEA', '2005', '21.34', '122.92']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.43', '.6327', '112', 'PHO', '2005', '2.40', '121.68']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.82', '.5593', '161', 'DET', '2005', '-0.93', '103.60']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['30.66', '.6154', '112', 'SAC', '2006', '20.24', '125.00']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.95', '.5859', '154', 'DAL', '2006', '7.45', '115.96']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['17.65', '.4194', '78', 'DEN', '2007', '-3.83', '108.50']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.76', '.5784', '114', 'PHO', '2007', '1.48', '108.30']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.58', '.6667', '79', 'UTA', '2007', '7.58', '122.15']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.61', '.6613', '65', 'CLE', '2007', '14.18', '108.20']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['19.51', '.5128', '105', 'PHO', '2008', '3.80', '109.27']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.31', '.5655', '169', 'NOH', '2008', '-10.07', '100.94']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.59', '.5484', '102', 'LAL', '2008', '-3.62', '98.99']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['43.83', '.6481', '91', 'DAL', '2010', '11.94', '123.46']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.02', '.7368', '89', 'PHO', '2010', '5.88', '119.10']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['26.70', '.5795', '102', 'MEM', '2011', '-1.04', '97.91']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.4375', '50', 'UTA', '2012', '-0.19', '109.18']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.20', '.7083', '67', 'LAC', '2012', '30.88', '116.0']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.79', '.6591', '117', 'OKC', '2012', '8.79', '110.08']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['14.47', '.6111', '41', 'LAL', '2013', '19.74', '119.74']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.95', '.3103', '73', 'GSW', '2013', '-13.80', '90.65']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.47', '.5500', '41', 'MEM', '2013', '-17.26', '101.32']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.93', '.6622', '98', 'MIA', '2013', '-1.84', '111.64']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['24.19', '.5375', '97', 'DAL', '2014', '12.92', '116.67']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.81', '.4483', '57', 'POR', '2014', '-2.40', '110.53']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.06', '.7321', '66', 'OKC', '2014', '6.0', '120.61']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.78', '.5469', '87', 'MIA', '2014', '27.22', '128.48']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "manu_one_on = manu_one_on.reset_index(drop=True)\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "497kM8cObznH"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with only 1 of Tim/Tony on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['18.27', '.4048', '56', 'MEM', '2004', '15.14', '106.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.17', '.7000', '66', 'LAL', '2004', '0.0', '107.50']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '76', 'DEN', '2005', '18.88', '109.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '79', 'SEA', '2005', '7.79', '119.59']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '67', 'PHO', '2005', '12.23', '110.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '86', 'DET', '2005', '11.78', '108.97']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '46', 'SAC', '2006', '1.14', '110.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '81', 'DAL', '2006', '2.70', '110.81']\n",
        "\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['32.31', '.5263', '35', 'DEN', '2007', '7.74', '110.77']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.19', '.5167', '71', 'PHO', '2007', '-7.50', '108.70']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.21', '.5370', '54', 'UTA', '2007', '9.22', '104.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.51', '.5750', '36', 'CLE', '2007', '50.79', '123.81']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['42.05', '.5606', '42', 'PHO', '2008', '-0.21', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.72', '.7333', '60', 'NOH', '2008', '28.35', '120.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.72', '.5192', '55', 'LAL', '2008', '-7.09', '100.99']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4457', '102', 'DAL', '2010', '-5.21', '98.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.49', '.4444', '49', 'PHO', '2010', '-19.89', '94.85']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['51.95', '.7800', '38', 'MEM', '2011', '31.20', '128.57']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['16.67', '.4000', '13', 'UTA', '2012', '-43.30', '95.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '10', 'LAC', '2012', '-17.73', '55.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.95', '.6071', '18', 'OKC', '2012', '-49.03', '108.11']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['45.83', '.9167', '12', 'LAL', '2013', '29.17', '137.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.79', '.5256', '83', 'GSW', '2013', '46.44', '130.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.62', '.8889', '41', 'MEM', '2013', '35.38', '117.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.91', '.4444', '75', 'MIA', '2013', '-11.91', '102.99']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['48.39', '.6471', '44', 'DAL', '2014', '26.18', '120.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.97', '.4333', '29', 'POR', '2014', '30.05', '98.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.71', '.6842', '39', 'OKC', '2014', '24.56', '110.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.38', '.5000', '20', 'MIA', '2014', '14.76', '102.56']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SU6mtICYuRvm"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with only 1 of Tim/Tony on (3+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['17.65', '.4000', '29', 'MEM', '2004', '0.0', '90.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.4750', '42', 'LAL', '2004', '-2.26', '105.33']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['47.19', '.7000', '47', 'DEN', '2005', '26.97', '112.36']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['55.56', '.8125', '40', 'SEA', '2005', '14.38', '131.94']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '67', 'PHO', '2005', '12.23', '110.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.97', '.7250', '84', 'DET', '2005', '11.39', '109.22']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['8.70', '.3000', '36', 'SAC', '2006', '-21.74', '102.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.17', '.6528', '63', 'DAL', '2006', '3.42', '108.55']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['30.36', '.5333', '30', 'DEN', '2007', '-1.60', '108.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16', '.4167', '52', 'PHO', '2007', '-9.67', '107.0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.21', '.6667', '24', 'UTA', '2007', '16.59', '123.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.48', '.5000', '17', 'CLE', '2007', '72.41', '124.14']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['28.07', '.5000', '26', 'PHO', '2008', '-16.43', '101.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['44.00', '.7500', '42', 'NOH', '2008', '18.33', '113.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.55', '.5000', '25', 'LAL', '2008', '-21.28', '100.00']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['23.53', '.4872', '93', 'DAL', '2010', '-6.47', '98.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['10.53', '.3333', '28', 'PHO', '2010', '-34.31', '87.72']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['55.77', '.7250', '26', 'MEM', '2011', '17.31', '117.31']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.5000', '9', 'UTA', '2012', '-46.27', '106.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '6', 'LAC', '2012', '-24.18', '61.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['55.56', '.4545', '8', 'OKC', '2012', '-30.72', '122.22']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['60.00', '1.1250', '7', 'LAL', '2013', '40.00', '133.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.76', '.4444', '54', 'GSW', '2013', '44.55', '124.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['11.63', '.8333', '23', 'MEM', '2013', '61.60', '137.21']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['7.46', '.2083', '39', 'MIA', '2013', '-24.64', '94.03']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['62.22', '.6750', '21', 'DAL', '2014', '28.89', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.91', '.3889', '22', 'POR', '2014', '20.98', '97.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.89', '.7000', '26', 'OKC', '2014', '30.34', '111.11']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.05', '.6667', '12', 'MIA', '2014', '41.67', '100.00']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZMIRy4nnvI8E"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with only 1 of Tim/Tony on (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.000', '4', 'MEM', '2004', '6.94', '44.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.58', '.5667', '25', 'LAL', '2004', '8.67', '116.67']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['55.81', '.7059', '26', 'DEN', '2005', '16.90', '104.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['73.33', '1.2222', '16', 'SEA', '2005', '66.25', '160.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.47', '.5000', '44', 'PHO', '2005', '11.87', '114.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['49.25', '.8056', '42', 'DET', '2005', '28.14', '120.90']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['16.67', '.3333', '13', 'SAC', '2006', '-52.88', '62.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.7857', '11', 'DAL', '2006', '-9.09', '90.91']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.3889', '13', 'DEN', '2007', '-41.50', '96.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.25', '.5000', '27', 'PHO', '2007', '-30.22', '101.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '7', 'UTA', '2007', '33.33', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.2500', '6', 'CLE', '2007', '92.42', '109.09']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['22.71', '.5000', '10', 'PHO', '2008', '-19.26', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.46', '.7143', '29', 'NOH', '2008', '20.94', '117.31']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['13.33', '.2500', '8', 'LAL', '2008', '-37.92', '93.33']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['17.27', '.3800', '61', 'DAL', '2010', '-41.56', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['4.76', '.2500', '20', 'PHO', '2010', '-6.40', '91.82']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['56.25', '.7500', '14', 'MEM', '2011', '20.00', '100.00']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5000', '6', 'UTA', '2012', '-97.73', '75.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '3', 'LAC', '2012', '-66.67', '66.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.50', '.3750', '4', 'OKC', '2012', '-100.00', '100.00']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['75.00', '1.500', '4', 'LAL', '2013', '62.50', '162.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.4286', '16', 'GSW', '2013', '41.94', '106.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '14', 'MEM', '2013', '42.63', '138.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '19', 'MIA', '2013', '-49.88', '75.76']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['68.42', '.8571', '8', 'DAL', '2014', '2.79', '126.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.58', '.5000', '16', 'POR', '2014', '9.68', '90.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.43', '.6000', '18', 'OKC', '2014', '11.58', '97.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.6667', '8', 'MIA', '2014', '50.89', '107.14']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8IJyDJSH0uKl"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with both of Tim/Tony on (5+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['5.26', '.5000', '9', 'MEM', '2004']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.86', '.6667', '64', 'LAL', '2004']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['39.73', '.7250', '38', 'DEN', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['56.45', '1.1000', '38', 'SEA', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.6892', '79', 'PHO', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.14', '.6023', '116', 'DET', '2005']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['27.73', '.5333', '67', 'SAC', '2006']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['13.51', '.3462', '42', 'DAL', '2006']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['19.44', '.4762', '56', 'DEN', '2007']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.92', '.5500', '35', 'PHO', '2007']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.65', '.7083', '31', 'UTA', '2007']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.53', '.7727', '22', 'CLE', '2007']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['14.71', '.5000', '34', 'PHO', '2008']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.35', '.6048', '131', 'NOH', '2008']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.31', '.3889', '51', 'LAL', '2008']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['21.90', '.4792', '58', 'DAL', '2010']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.67', '.6500', '31', 'PHO', '2010']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['22.52', '.5435', '60', 'MEM', '2011']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['28.21', '.5500', '19', 'UTA', '2012']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.81', '.5000', '16', 'LAC', '2012']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['8.62', '.5000', '32', 'OKC', '2012']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '3', 'LAL', '2013']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['13.61', '.5000', '18', 'GSW', '2013']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '5', 'MEM', '2013']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.85', '.7333', '41', 'MIA', '2013']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['40.63', '1.0833', '16', 'DAL', '2014']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.00', '.5192', '46', 'POR', '2014']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.00', '.7500', '20', 'OKC', '2014']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['46.15', '.7500', '14', 'MIA', '2014']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jWWthyE7D-OY"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers when he starts (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['19.51', '.5714', '20', 'DEN', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['52.38', '.9118', '35', 'SEA', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.28', '.5600', '149', 'PHO', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.03', '.6250', '171', 'DET', '2005']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['25.76', '.5435', '107', 'SAC', '2006']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25', '.5758', '86', 'DAL', '2006']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5959', '143', 'NOH', '2008']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['4.35', '.1429', '23', 'LAL', '2008']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['28.42', '.5098', '102', 'DAL', '2010']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.06', '.6618', '84', 'PHO', '2010']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['32.11', '.6224', '98', 'MEM', '2011']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['40.26', '.6200', '39', 'OKC', '2012']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['26.72', '.7381', '60', 'MIA', '2013']\n",
        "\n",
        "# 2017\n",
        "tmp_df.loc[len(tmp_df)] = ['5.56', '.2000', '16', 'GSW', '2017']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YdPybQaT_EhZ"
      },
      "outputs": [],
      "source": [
        "#@title Manu Finals Scoring numbers with only 1 of Tim/Tony on games 1 and 2\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['53.85', '.8750', '8', 'DET', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['83.33', '1.1667', '11', 'DET', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.9231', '32', 'DET', '2005']\n",
        "\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pIVKP6D6QBbO"
      },
      "outputs": [],
      "source": [
        "#@title Manu Finals Scoring numbers with only 1 of Tim/Tony on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.27', '.4750', '58', 'NJN', '2003', '31.94', '110.58']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '86', 'DET', '2005', '11.78', '108.97']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.51', '.5750', '36', 'CLE', '2007', '50.79', '123.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.91', '.4444', '75', 'MIA', '2013', '-11.91', '102.99']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.38', '.5000', '20', 'MIA', '2014', '14.76', '102.56']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "V3hVmyGxaEPr"
      },
      "outputs": [],
      "source": [
        "#@title Manu Finals Scoring numbers with only 1 of Tim/Tony on (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['31.43', '.7857', '19', 'NJN', '2003']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['49.25', '.8056', '42', 'DET', '2005']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.2500', '6', 'CLE', '2007']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0', '19', 'MIA', '2013']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.6667', '8', 'MIA', '2014']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fldaF8QeJsBn"
      },
      "outputs": [],
      "source": [
        "#@title Manu 07 numbers\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['25.19', '.4710', '138', 'DEN', '2007', '2.84', '107.89']\n",
        "\n",
        "#g1-4\n",
        "tmp_df.loc[len(tmp_df)] = ['19.67', '.4123', '123', 'PHO', '2007', '-7.02', '105.33']\n",
        "\n",
        "#g5 1Q\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '6', 'PHO', '2007', '-100.00', '33.33']\n",
        "\n",
        "#g5 2Q\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.5000', '9', 'PHO', '2007', '0.00', '106.67']\n",
        "\n",
        "#g5 3Q\n",
        "tmp_df.loc[len(tmp_df)] = ['35.00', '.7000', '10', 'PHO', '2007', '25.00', '115.00']\n",
        "\n",
        "#g5 4Q\n",
        "tmp_df.loc[len(tmp_df)] = ['62.50', '1.0714', '12', 'PHO', '2007', '37.50', '133.33']\n",
        "\n",
        "#g6\n",
        "tmp_df.loc[len(tmp_df)] = ['43.42', '.7857', '36', 'PHO', '2007', '14.42', '118.42']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.56', '.6143', '150', 'UTA', '2007', '8.27', '112.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.81', '.5635', '117', 'CLE', '2007', '20.62', '110.48']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DAJloMNlbvID"
      },
      "outputs": [],
      "source": [
        "#@title Manu 05 numbers\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['38.13', '.6420', '154', 'DEN', '2005', '15.39', '114.05']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.76', '.7000', '187', 'SEA', '2005', '13.25', '120.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.41', '.6033', '183', 'PHO', '2005', '9.20', '120.0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.39', '.6139', '252', 'DET', '2005', '2.71', '104.64']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8M--QwITpdrQ"
      },
      "outputs": [],
      "source": [
        "#@title Manu 07 numbers (3+ starters)\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "#g5 3Q\n",
        "tmp_df.loc[len(tmp_df)] = ['35.00', '.7000', '10', 'PHO', '2007', '25.00', '115.00']\n",
        "\n",
        "#g5 4Q\n",
        "tmp_df.loc[len(tmp_df)] = ['62.50', '1.0714', '12', 'PHO', '2007', '37.50', '133.33']\n",
        "\n",
        "#g6\n",
        "tmp_df.loc[len(tmp_df)] = ['37.93', '.7333', '27', 'PHO', '2007', '13.73', '117.24']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.05', '.6860', '106', 'UTA', '2007', '8.08', '123.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.00', '.5882', '68', 'CLE', '2007', '31.20', '111.20']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fHBTrIh5rMaK"
      },
      "outputs": [],
      "source": [
        "#@title Manu 07 numbers (0-2 starters)\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "\n",
        "#g6\n",
        "tmp_df.loc[len(tmp_df)] = ['61.11', '.9167', '9', 'PHO', '2007', '16.67', '122.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.76', '.5000', '44', 'UTA', '2007', '8.50', '85.88']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.47', '.5345', '49', 'CLE', '2007', '5.96', '109.41']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LJrNbL6nNKg7"
      },
      "outputs": [],
      "source": [
        "#@title Manu alone\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "#tmp_df.loc[len(tmp_df)] = ['17.74', '.4024', '105', 'NJN', '2003', '-14.96', '90.86']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['100.00', '1.000', '1', 'MEM', '2004', '-100.00', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['00.00', '.0000', '1', 'LAL', '2004', '00.00', '0.0']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['48.00', '.5000', '12', 'DEN', '2005', '3.70', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '2', 'SEA', '2005', '-175.00', '0.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['75.00', '.7500', '3', 'PHO', '2005', '150.00', '225.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['00.00', '.00', '5', 'DET', '2005', '-37.50', '62.50']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['31.11', '.5833', '25', 'SAC', '2006', '30.17', '108.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['80.00', '.8571', '8', 'DAL', '2006', '-28.72', '86.67']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['39.58', '.5000', '26', 'DEN', '2007', '17.64', '102.08']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['66.67', '.5000', '12', 'PHO', '2007', '11.11', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.6538', '17', 'UTA', '2007', '6.42', '88.24']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.2971', '16', 'CLE', '2007', '-23.11', '88.00']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['82.35', '.7778', '8', 'PHO', '2008', '-11.76', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.5000', '15', 'NOH', '2008', '26.29', '114.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.000', '3', 'LAL', '2008', '-87.50', '0.00']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.000', '6', 'DAL', '2010', '-40.00', '60.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.14', '.2500', '15', 'PHO', '2010', '-44.83', '68.97']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.3158', '31', 'MEM', '2011', '-8.06', '103.23']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['22.86', '.5000', '36', 'UTA', '2012', '47.14', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.14', '.4783', '35', 'LAC', '2012', '-36.99', '97.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.04', '.7147', '45', 'OKC', '2012', '-21.09', '108.70']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['43.50', '.5476', '25', 'LAL', '2013', '50.94', '126.42']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.53', '.5000', '22', 'GSW', '2013', '-0.05', '113.95']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.66', '.4063', '23', 'MEM', '2013', '8.51', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.69', '.4444', '27', 'MIA', '2013', '-38.22', '86.27']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['34.69', '.6538', '52', 'DAL', '2014', '-10.62', '109.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['6.90', '.1667', '28', 'POR', '2014', '31.88', '148.28']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.38', '.5250', '33', 'OKC', '2014', '-0.29', '118.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['46.88', '.9375', '36', 'MIA', '2014', '56.45', '143.75']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Peak rOffRtg On/Off\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# everything besides OffRtg and MP dummy values\n",
        "\n",
        "# Manu On\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '154', 'DEN', '2005', '18.88', '114.05']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '187', 'SEA', '2005', '7.79', '120.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '183', 'PHO', '2005', '12.23', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '252', 'DET', '2005', '11.78', '104.64']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '184', 'SAC', '2006', '1.14', '119.13']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '243', 'DAL', '2006', '2.70', '113.26']\n",
        "\n",
        "\n",
        "\n",
        "# Manu Off\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '91', 'DEN', '2005', '18.88', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '101', 'SEA', '2005', '7.79', '99.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '57', 'PHO', '2005', '12.23', '105.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '89', 'DET', '2005', '11.78', '98.62']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '109', 'SAC', '2006', '1.14', '114.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '103', 'DAL', '2006', '2.70', '98.98']\n",
        "\n",
        "\n",
        "\n",
        "# Manu On (no Bruce!)\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '57', 'DEN', '2005', '18.88', '108.70']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '61', 'SEA', '2005', '7.79', '124.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '69', 'PHO', '2005', '12.23', '128.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '59', 'DET', '2005', '11.78', '99.04']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '80', 'SAC', '2006', '1.14', '120.13']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '60', 'DAL', '2006', '2.70', '126.50']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tony On\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '131', 'UTA', '2012', '33.82', '111.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '149', 'LAC', '2012', '24.51', '116.36']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '226', 'OKC', '2012', '1.43', '109.36']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '127', 'LAL', '2013', '19.43', '113.08']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '233', 'GSW', '2013', '10.50', '103.60']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '153', 'MEM', '2013', '28.25', '107.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '246', 'MIA', '2013', '1.02', '108.73']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '231', 'DAL', '2014', '0.70', '113.96']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '145', 'POR', '2014', '15.54', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '167', 'OKC', '2014', '2.39', '113.85']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '176', 'MIA', '2014', '4.57', '118.65']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tony Off\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '61', 'UTA', '2012', '33.82', '107.86']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '43', 'LAC', '2012', '24.51', '101.11']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '62', 'OKC', '2012', '1.43', '102.38']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '65', 'LAL', '2013', '19.43', '114.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '70', 'GSW', '2013', '10.50', '112.59']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '49', 'MEM', '2013', '28.25', '107.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '95', 'MIA', '2013', '1.02', '106.29']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '105', 'DAL', '2014', '0.70', '107.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '95', 'POR', '2014', '15.54', '120.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '126', 'OKC', '2014', '2.39', '111.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '64', 'MIA', '2014', '4.57', '123.89']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Im8HJgCBZ-88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Peak rOffRtg On/Off 4+ starters\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# everything besides OffRtg dummy values\n",
        "\n",
        "# Manu On\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '77', 'DEN', '2005', '18.88', '110.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '69', 'SEA', '2005', '7.79', '140.16']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '149', 'PHO', '2005', '12.23', '120.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '171', 'DET', '2005', '11.78', '104.15']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '107', 'SAC', '2006', '1.14', '118.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '102', 'DAL', '2006', '2.70', '108.65']\n",
        "\n",
        "\n",
        "\n",
        "# Manu Off\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '56', 'DEN', '2005', '18.88', '91.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '56', 'SEA', '2005', '7.79', '94.85']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '42', 'PHO', '2005', '12.23', '102.78']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '53', 'DET', '2005', '11.78', '98.75']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '61', 'SAC', '2006', '1.14', '114.41']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '54', 'DAL', '2006', '2.70', '108.57']\n",
        "\n",
        "\n",
        "\n",
        "# Tony On\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '94', 'UTA', '2012', '33.82', '114.13']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '85', 'LAC', '2012', '24.51', '123.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '140', 'OKC', '2012', '1.43', '110.49']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '91', 'LAL', '2013', '19.43', '113.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '127', 'GSW', '2013', '10.50', '96.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '82', 'MEM', '2013', '28.25', '100.68']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '149', 'MIA', '2013', '1.02', '110.47']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '132', 'DAL', '2014', '0.70', '113.47']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '117', 'POR', '2014', '15.54', '109.25']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '92', 'OKC', '2014', '2.39', '112.99']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '95', 'MIA', '2014', '4.57', '112.57']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tony Off\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '15', 'UTA', '2012', '33.82', '103.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '2', 'LAC', '2012', '24.51', '0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '8', 'OKC', '2012', '1.43', '61.11']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '13', 'LAL', '2013', '19.43', '88.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '18', 'GSW', '2013', '10.50', '111.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '14', 'MEM', '2013', '28.25', '115.38']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '28', 'MIA', '2013', '1.02', '94.12']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '14', 'DAL', '2014', '0.70', '143.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '47', 'POR', '2014', '15.54', '122.34']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '32', 'OKC', '2014', '2.39', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '14', 'MIA', '2014', '4.57', '150.00']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c85_peEvlzaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SQe3mtTEK-Y"
      },
      "source": [
        "TONY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzdz_hyZHVns"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with both of Tim and Manu on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.6190', '50', 'MEM', '2004', '36.35', '128.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.88', '.4211', '106', 'LAL', '2004', '6.16', '96.52']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['24.06', '.4706', '66', 'DEN', '2005', '13.0', '121.8']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.34', '.4667', '106', 'SEA', '2005', '21.34', '122.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.43', '.4844', '112', 'PHO', '2005', '2.40', '121.68']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.82', '.5476', '161', 'DET', '2005', '-0.93', '103.60']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['25.94', '.5288', '112', 'SAC', '2006', '20.24', '125.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.47', '.5149', '154', 'DAL', '2006', '7.45', '115.96']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.5233', '78', 'DEN', '2007', '-3.83', '108.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.90', '.3942', '114', 'PHO', '2007', '1.48', '108.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.18', '.6136', '79', 'UTA', '2007', '7.58', '122.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.97', '.5735', '65', 'CLE', '2007', '14.18', '108.20']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['32.20', '.6000', '105', 'PHO', '2008', '3.80', '109.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.06', '.5746', '169', 'NOH', '2008', '-10.07', '100.94']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.03', '.5556', '102', 'LAL', '2008', '-3.62', '98.99']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['25.31', '.5125', '91', 'DAL', '2010', '11.94', '123.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.65', '.5930', '89', 'PHO', '2010', '5.88', '119.10']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['30.37', '.6042', '102', 'MEM', '2011', '-1.04', '97.91']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['43.88', '.6719', '50', 'UTA', '2012', '-0.19', '109.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.40', '.4583', '67', 'LAC', '2012', '30.88', '116.0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.09', '.5362', '117', 'OKC', '2012', '8.79', '110.08']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['44.74', '.5690', '41', 'LAL', '2013', '19.74', '119.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.90', '.4500', '73', 'GSW', '2013', '-13.80', '90.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.21', '.5652', '41', 'MEM', '2013', '-17.26', '101.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.93', '.5698', '98', 'MIA', '2013', '-1.84', '111.64']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.18', '.5179', '97', 'DAL', '2014', '12.92', '116.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.19', '.5741', '57', 'POR', '2014', '-2.40', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.95', '.6296', '66', 'OKC', '2014', '6.0', '120.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.28', '.6375', '87', 'MIA', '2014', '27.22', '128.48']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RYGsEEHwBoxW"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "#tmp_df.loc[len(tmp_df)] = ['17.74', '.4024', '105', 'NJN', '2003', '-14.96', '90.86']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['31.98', '.6875', '94', 'MEM', '2004', '15.11', '114.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.94', '.4310', '125', 'LAL', '2004', '-16.40', '89.91']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['28.65', '.5000', '105', 'DEN', '2005', '7.27', '105.21']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.31', '.5536', '108', 'SEA', '2005', '-0.51', '114.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '71', 'PHO', '2005', '-3.88', '106.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.97', '.3235', '95', 'DET', '2005', '-4.0', '113.61']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['48.18', '.6226', '73', 'SAC', '2006', '-3.09', '117.52']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.67', '.4648', '105', 'DAL', '2006', '-7.77', '109.41']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['23.08', '.4773', '102', 'DEN', '2007', '18.46', '110.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.63', '.5714', '121', 'PHO', '2007', '4.79', '108.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.65', '.4700', '94', 'UTA', '2007', '7.65', '107.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.67', '.6395', '80', 'CLE', '2007', '-3.12', '103.03']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['45.88', '.5821', '92', 'PHO', '2008', '1.69', '107.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.58', '.5000', '93', 'NOH', '2008', '12.40', '119.11']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.74', '.4674', '83', 'LAL', '2008', '-3.81', '101.29']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['42.32', '.5825', '149', 'DAL', '2009', '-0.65', '111.99']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['24.81', '.4714', '73', 'DAL', '2010', '-1.73', '108.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.55', '.4107', '53', 'PHO', '2010', '-24.51', '101.96']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['26.23', '.4898', '97', 'MEM', '2011', '-9.11', '107.65']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '73', 'UTA', '2012', '33.82', '116.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '73', 'LAC', '2012', '24.51', '119.40']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '92', 'OKC', '2012', '1.43', '111.83']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '82', 'LAL', '2013', '19.43', '111.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '141', 'GSW', '2013', '10.50', '111.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '97', 'MEM', '2013', '28.25', '112.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '135', 'MIA', '2013', '1.02', '107.11']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '126', 'DAL', '2014', '0.70', '111.21']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '81', 'POR', '2014', '15.54', '107.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '91', 'OKC', '2014', '2.39', '107.47']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '64', 'MIA', '2014', '4.57', '114.05']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Z9hQvfBWDyBp"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (3+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '63', 'MEM', '2004', '14.55', '114.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '121', 'LAL', '2004', '-20.18', '86.79']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '91', 'DEN', '2005', '11.90', '105.36']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '82', 'SEA', '2005', '-1.77', '116.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '71', 'PHO', '2005', '-3.88', '106.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '92', 'DET', '2005', '-0.56', '116.43']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '66', 'SAC', '2006', '-4.97', '115.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '93', 'DAL', '2006', '-10.43', '107.39']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '98', 'DEN', '2007', '18.18', '110.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '106', 'PHO', '2007', '7.08', '108.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '75', 'UTA', '2007', '8.45', '114.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '66', 'CLE', '2007', '7.62', '105.71']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '82', 'PHO', '2008', '1.31', '105.88']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.46', '.5313', '73', 'NOH', '2008', '14.04', '117.07']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.4848', '55', 'LAL', '2008', '-8.43', '107.92']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['33.60', '.5667', '139', 'DAL', '2009', '-1.93', '110.28']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['19.44', '.3889', '59', 'DAL', '2010', '0.0', '110.19']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.63', '.4063', '33', 'PHO', '2010', '-40.39', '98.41']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['28.29', '.5000', '79', 'MEM', '2011', '-19.63', '101.32']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['27.93', '.4844', '58', 'UTA', '2012', '42.16', '121.62']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.00', '.5000', '59', 'LAC', '2012', '23.17', '124.07']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.39', '.5750', '78', 'OKC', '2012', '2.34', '110.56']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['29.71', '.4750', '75', 'LAL', '2013', '22.39', '112.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.5462', '114', 'GSW', '2013', '0.0', '106.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.56', '.5875', '77', 'MEM', '2013', '26.94', '108.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.33', '.3700', '103', 'MIA', '2013', '-5.12', '103.30']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['30.81', '.4692', '108', 'DAL', '2014', '-0.25', '108.08']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.69', '.5000', '78', 'POR', '2014', '13.61', '106.80']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.94', '.4722', '74', 'OKC', '2014', '4.96', '107.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.02', '.4286', '60', 'MIA', '2014', '-4.70', '107.34']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PjFAAd14T4Pn"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['34.74', '.8684', '55', 'MEM', '2004', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.93', '.4186', '97', 'LAL', '2004', '-24.93', '86.63']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4714', '70', 'DEN', '2005', '1.50', '99.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.56', '.5893', '62', 'SEA', '2005', '6.83', '119.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4630', '59', 'PHO', '2005', '-2.49', '104.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.94', '.2895', '57', 'DET', '2005', '-5.75', '116.47']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['37.84', '.5385', '42', 'SAC', '2006', '5.06', '113.51']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25', '.4138', '49', 'DAL', '2006', '-3.75', '108.33']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['19.29', '.4091', '79', 'DEN', '2007', '13.25', '102.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.77', '.5938', '84', 'PHO', '2007', '4.01', '107.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.55', '.4107', '58', 'UTA', '2007', '11.88', '114.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['44.19', '.6129', '53', 'CLE', '2007', '12.67', '102.33']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['46.28', '.5600', '65', 'PHO', '2008', '4.92', '107.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.60', '.5128', '61', 'NOH', '2008', '0', '115.84']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.63', '.4800', '44', 'LAL', '2008', '-10.95', '102.47']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['46.03', '.6397', '103', 'DAL', '2009', '-0.84', '112.70']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['21.05', '.4444', '20', 'DAL', '2010', '21.34', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['10.34', '.2143', '14', 'PHO', '2010', '-68.86', '65.52']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['23.76', '.4286', '51', 'MEM', '2011', '-19.55', '99.01']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['28.44', '.4844', '56', 'UTA', '2012', '42.63', '119.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.73', '.5000', '51', 'LAC', '2012', '19.45', '127.96']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.06', '.5694', '68', 'OKC', '2012', '0', '108.87']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['23.14', '.3939', '66', 'LAL', '2013', '18.93', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.4286', '77', 'GSW', '2013', '-18.87', '95.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.02', '.5645', '60', 'MEM', '2013', '14.05', '102.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.44', '.3889', '77', 'MIA', '2013', '5.19', '107.30']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.61', '.4900', '84', 'DAL', '2014', '5.18', '107.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.45', '.4881', '65', 'POR', '2014', '8.36', '105.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.81', '.4848', '64', 'OKC', '2014', '2.47', '108.87']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.57', '.3600', '51', 'MIA', '2014', '-9.96', '106.52']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MmXDfzYxTHg_"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (Exactly 3 starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.3333', '8', 'MEM', '2004', '38.43', '126.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.00', '.5000', '23', 'LAL', '2004', '-0.60', '87.50']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['29.79', '.5833', '22', 'DEN', '2005', '41.79', '121.28']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.50', '.4231', '20', 'SEA', '2005', '-25.00', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.78', '.6667', '12', 'PHO', '2005', '-15.94', '117.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.36', '.3462', '35', 'DET', '2005', '8.96', '116.36']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['60.78', '.7750', '24', 'SAC', '2006', '-19.85', '117.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.00', '.5000', '44', 'DAL', '2006', '-17.85', '106.25']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['32.35', '.6875', '19', 'DEN', '2007', '38.49', '147.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.82', '.5833', '22', 'PHO', '2007', '18.29', '113.64']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.71', '.6667', '18', 'UTA', '2007', '-3.23', '112.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['52.63', '.6250', '13', 'CLE', '2007', '-17.84', '121.05']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['31.25', '.5000', '18', 'PHO', '2008', '-11.76', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.6111', '12', 'NOH', '2008', '43.56', '122.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.00', '.5000', '12', 'LAL', '2008', '-8.43', '130.00']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['28.13', '.4091', '36', 'DAL', '2009', '-4.94', '103.13']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['18.57', '.3611', '39', 'DAL', '2010', '-20.30', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.5556', '19', 'PHO', '2010', '-16.39', '126.47']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['37.25', '.6333', '28', 'MEM', '2011', '-19.61', '250.00']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['0.0', '.00', '2', 'UTA', '2012', '110.00', '121.62']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.5000', '9', 'LAC', '2012', '41.18', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.78', '.6250', '10', 'OKC', '2012', '7.22', '122.22']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['76.47', '.8571', '9', 'LAL', '2013', '47.06', '135.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.59', '.7308', '37', 'GSW', '2013', '45.59', '129.41']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.00', '.6667', '17', 'MEM', '2013', '71.94', '130.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.00', '.3214', '26', 'MIA', '2013', '-35.97', '91.11']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['27.91', '.4000', '24', 'DAL', '2014', '-17.78', '109.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.71', '.5556', '13', 'POR', '2014', '36.51', '114.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['11.11', '.3333', '10', 'OKC', '2014', '20.76', '94.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '1.000', '9', 'MIA', '2014', '23.53', '111.76']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FDO0tHxNuAbf"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (At most 3 starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.5238', '40', 'MEM', '2004', '20.68', '116.88']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.43', '.4667', '28', 'LAL', '2004', '14.42', '102.17']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['30.99', '.5500', '36', 'DEN', '2005', '17.03', '115.49']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.22', '.5179', '47', 'SEA', '2005', '-9.46', '107.78']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.78', '.6667', '12', 'PHO', '2005', '-15.94', '117.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.74', '.3667', '38', 'DET', '2005', '-0.32', '109.68']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['60.32', '.7037', '31', 'SAC', '2006', '-12.78', '122.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.62', '.5000', '56', 'DAL', '2006', '-11.12', '110.38']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['35.77', '.6818', '24', 'DEN', '2007', '35.77', '138.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.26', '.5227', '37', 'PHO', '2007', '6.30', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '.5455', '36', 'UTA', '2007', '1.54', '97.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.96', '.7083', '28', 'CLE', '2007', '-35.19', '104.35']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['44.90', '.6471', '27', 'PHO', '2008', '-6.12', '108.16']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.93', '.4750', '32', 'NOH', '2008', '21.43', '125.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.68', '.4524', '40', 'LAL', '2008', '4.00', '100.00']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.4483', '46', 'DAL', '2009', '-0.13', '110.26']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4808', '53', 'DAL', '2010', '-10.91', '107.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.40', '.4762', '38', 'PHO', '2010', '-6.42', '116.44']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['29.27', '.5714', '46', 'MEM', '2011', '-3.66', '118.29']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['16.13', '.4167', '17', 'UTA', '2012', '3.23', '106.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.83', '.4583', '22', 'LAC', '2012', '34.88', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.5714', '24', 'OKC', '2012', '-0.97', '118.18']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['69.70', '.7857', '17', 'LAL', '2013', '21.21', '118.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.45', '.6923', '63', 'GSW', '2013', '46.15', '130.58']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.68', '.6250', '37', 'MEM', '2013', '51.43', '128.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.47', '.4091', '58', 'MIA', '2013', '-4.68', '106.86']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['32.47', '.5435', '42', 'DAL', '2014', '-7.43', '118.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.89', '.6364', '16', 'POR', '2014', '40.36', '113.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.00', '.3636', '27', 'OKC', '2014', '2.08', '104.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['51.72', '.8333', '14', 'MIA', '2014', '53.93', '137.93']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yL-pSRFtZvza"
      },
      "outputs": [],
      "source": [
        "#@title Tony Finals Scoring numbers with only 1 of Tim/Manu on (3+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['15.20', '.3714', '96', 'NJN', '2003']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '92', 'DET', '2005']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '66', 'CLE', '2007']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['20.33', '.3700', '103', 'MIA', '2013']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['22.02', '.4286', '60', 'MIA', '2014']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BLxn9OI0P67R"
      },
      "outputs": [],
      "source": [
        "#@title Tony 07 numbers\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.30', '.4892', '187', 'DEN', '2007', '6.35', '108.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.77', '.4921', '238', 'PHO', '2007', '1.63', '107.49']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.61', '.5372', '174', 'UTA', '2007', '7.49', '114.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.84', '.6049', '151', 'CLE', '2007', '3.73', '104.89']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GZ9Ot6L6GLnF"
      },
      "outputs": [],
      "source": [
        "#@title Tony alone\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "#tmp_df.loc[len(tmp_df)] = ['17.74', '.4024', '105', 'NJN', '2003', '-14.96', '90.86']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['36.50', '.3000', '4', 'MEM', '2004', '33.93', '62.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.2500', '7', 'LAL', '2004', '-21.43', '85.71']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['25.00', '.4000', '8', 'DEN', '2005', '18.75', '27.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.3333', '7', 'SEA', '2005', '-99.39', '114.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.5000', '7', 'PHO', '2005', '-13.33', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '.5000', '9', 'DET', '2005', '22.88', '111.76']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['30.77', '.6667', '21', 'SAC', '2006', '-17.95', '102.56']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.58', '.2727', '9', 'DAL', '2006', '-90.16', '31.58']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '0.00', '7', 'DEN', '2007', '-63.64', '63.64']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['57.14', '.4000', '4', 'PHO', '2007', '-100.00', '57.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '0.000', '1', 'UTA', '2007', '-50.00', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5000', '6', 'CLE', '2007', '-23.72', '91.67']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['36.36', '.3333', '5', 'PHO', '2008', '11.69', '72.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['57.14', '.6667', '4', 'LAL', '2008', '-22.22', '100.00']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['46.15', '.5769', '32', 'DAL', '2009', '-25.06', '84.62']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['40.38', '.5000', '25', 'DAL', '2010', '-12.02', '94.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['44.44', '.3333', '5', 'PHO', '2010', '-31.31', '122.22']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['29.27', '.3750', '22', 'MEM', '2011', '-8.31', '78.05']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['31.25', '.8333', '8', 'UTA', '2012', '-37.50', '87.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.2500', '9', 'LAC', '2012', '-6.25', '93.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.5000', '17', 'OKC', '2012', '-49.68', '90.32']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['57.14', '.6667', '4', 'LAL', '2013', '10.71', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.3125', '20', 'GSW', '2013', '-15.52', '94.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.92', '.5000', '15', 'MEM', '2013', '-39.56', '96.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.00', '.6000', '14', 'MIA', '2013', '-4.07', '103.33']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['36.84', '.5833', '9', 'DAL', '2014', '15.17', '121.05']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '.7500', '8', 'POR', '2014', '17.65', '117.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.00', '.5000', '10', 'OKC', '2014', '20.00', '125.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.3333', '24', 'MIA', '2014', '-25.00', '97.92']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sHrWJxvESTy"
      },
      "source": [
        "TIM/KOBE/HARDEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kiy6VUHnKplT"
      },
      "outputs": [],
      "source": [
        "#@title Harden Scoring numbers with Gordon/CP3/Russ Off (2+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2018\n",
        "tmp_df.loc[len(tmp_df)] = ['125', '.8333', '3', 'MIN', '2018']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['51.52', '.7083', '17', 'GSW', '2018']\n",
        "\n",
        "# 2019\n",
        "tmp_df.loc[len(tmp_df)] = ['67.39', '.6200', '22', 'UTA', '2019']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['53.85', '.6176', '19', 'GSW', '2019']\n",
        "\n",
        "\n",
        "\n",
        "# 2020\n",
        "tmp_df.loc[len(tmp_df)] = ['51.48', '.6797', '82', 'OKC', '2020']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['54', '.6750', '26', 'LAL', '2020']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ihbawreUAq0C"
      },
      "outputs": [],
      "source": [
        "#@title Tim Scoring numbers vs Lakers\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 1999\n",
        "tmp_df.loc[len(tmp_df)] = ['31.97333', '.6000', '177', 'LAL', '1999']\n",
        "\n",
        "# 2001\n",
        "tmp_df.loc[len(tmp_df)] = ['29.30', '.5349', '169', 'LAL', '2001']\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['36.07', '.5106', '224', 'LAL', '2002']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['37', '.5714', '241', 'LAL', '2003']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['27.25', '.5210', '251', 'LAL', '2004']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['29.55', '.4628', '201', 'LAL', '2008']\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PKE4AXzvDn3t"
      },
      "outputs": [],
      "source": [
        "#@title Kobe Scoring numbers vs Spurs\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2001\n",
        "tmp_df.loc[len(tmp_df)] = ['42.36', '.5690', '168', 'SAS', '2001']\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['33.42', '.4851', '218', 'SAS', '2002']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['39.27', '.5275', '261', 'SAS', '2003']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['32.64', '.5304', '264', 'SAS', '2004']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.5887', '201', 'SAS', '2008']\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2NZwjbmh3GYh"
      },
      "outputs": [],
      "source": [
        "#@title Kobe Scoring numbers vs Spurs (Tim On)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2001\n",
        "tmp_df.loc[len(tmp_df)] = ['40.69', '.5673', '157', 'SAS', '2001']\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['32.80', '.4766', '209', 'SAS', '2002']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['38.90', '.5185', '232', 'SAS', '2003']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['32.30', '.5271', '232', 'SAS', '2004']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.5862', '188', 'SAS', '2008']\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NWwiLOog3IMM"
      },
      "outputs": [],
      "source": [
        "#@title Kobe Scoring numbers vs Spurs (Tim Off)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2001\n",
        "tmp_df.loc[len(tmp_df)] = ['62.5', '.5833', '11', 'SAS', '2001']\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['47.06', '.6667', '9', 'SAS', '2002']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['42.11', '.6000', '29', 'SAS', '2003']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['34.92', '.5526', '31', 'SAS', '2004']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['38.46', '.6250', '13', 'SAS', '2008']\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gyquQ3GSSk4s"
      },
      "outputs": [],
      "source": [
        "#@title Kobe Shaq 2001\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# Kobe\n",
        "tmp_df.loc[len(tmp_df)] = ['40.00', '.5756', '173', 'SAC', '2001', '11.15', '110.86']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.36', '.5690', '168', 'SAS', '2001', '23.54', '116.24']\n",
        "\n",
        "# Shaq\n",
        "tmp_df.loc[len(tmp_df)] = ['40.67', '.5885', '163', 'SAC', '2001', '7.35', '105.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.24', '.5455', '156', 'SAS', '2001', '22.70', '114.48']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXEdTPyqEUUH"
      },
      "source": [
        "**RUN SUBSETS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "2n5FivB9QcKn"
      },
      "outputs": [],
      "source": [
        "#@title Adjusted Playoff TS+ of Manual Subset\n",
        "def manual_adjust_scoring_efficiency(player_df, opp_ts_df, opp_defrtg_df, opp_literal_defrtg, player):\n",
        "\n",
        "      final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'PTS', 'TS+', 'NetRtg', 'rOffRtg', 'MP'])\n",
        "\n",
        "      years_list = []\n",
        "\n",
        "      player_df['PP75'] = player_df['PP75'].astype(float)\n",
        "      player_df['PP75'] = player_df['PP75'] * .75\n",
        "\n",
        "\n",
        "      player_df['TS%'] = player_df['TS%'].astype(float)\n",
        "\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(int)\n",
        "      opp_defrtg_df['Team'] = opp_defrtg_df['Team'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(int)\n",
        "      opp_literal_defrtg['Team'] = opp_literal_defrtg['Team'].astype(str)\n",
        "      opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "      player_df['Opp'] = player_df['Opp'].astype(str)\n",
        "      player_df['Year'] = player_df['Year'].astype(int)\n",
        "\n",
        "      for i, row in player_df.iterrows():\n",
        "\n",
        "        current_opp = player_df.loc[i, 'Opp']\n",
        "        current_year = player_df.loc[i, 'Year']\n",
        "\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & (opp_ts_df['Year'] == current_year)]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        opponent_literal_def = opp_literal_defrtg[(opp_literal_defrtg['Team'] == current_opp) & ((opp_literal_defrtg['Year'] == current_year))]\n",
        "        opp_def_rtg = float(opponent_literal_def['DefRtg'])\n",
        "\n",
        "        player_ts = player_df.loc[i, 'TS%']\n",
        "        tsplus = (float(player_ts) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        relOffRtg = float(row['OffRtg']) - opp_def_rtg\n",
        "\n",
        "        player_df.loc[i,'TS+'] = tsplus\n",
        "        player_df.loc[i,'PTS_coeff'] = pts_coeff\n",
        "        player_df.loc[i,'rOffRtg'] = relOffRtg\n",
        "\n",
        "\n",
        "        if player_df.loc[i, 'Year'] not in years_list:\n",
        "          years_list.append(player_df.loc[i, 'Year'])\n",
        "\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'TS%', 'PTS', 'PTS_coeff'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = player_df[(player_df['Year'] == year)]\n",
        "\n",
        "        total_pts = 0\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        total_net = 0\n",
        "        total_off = 0\n",
        "\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "         #PTS\n",
        "        iter = 0\n",
        "        for ind_pts in tmp_sub_df['PP75']:\n",
        "          ind_pts = float(ind_pts)\n",
        "          total_pts += float(ind_pts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        #coeff\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        total_pts = total_pts * total_coeff\n",
        "\n",
        "\n",
        "        # NetRtg\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['NetRtg']:\n",
        "          ind_net = float(ind_coeff)\n",
        "          total_net += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        # OffRtg\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['rOffRtg']:\n",
        "          ind_off = float(ind_coeff)\n",
        "          total_off += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "        total_off = '%.2f' % round(total_off, 2)\n",
        "        total_net = '%.2f' % round(total_net, 2)\n",
        "\n",
        "        new_row = {'Player':player, 'Year':year,  'PTS':total_pts, 'TS+':total_ts, 'NetRtg':total_net, 'rOffRtg': total_off, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "      print(final_season_df)\n",
        "      outfile = f\"NBA_Playoff_Manual_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r98uILnQWl_t"
      },
      "outputs": [],
      "source": [
        "#@title Inflate Scoring for Manual Subset\n",
        "new_df = pd.DataFrame()\n",
        "per_75_coeff['Year'] = per_75_coeff['Year'].astype(int)\n",
        "manu_one_on['Year'] = manu_one_on['Year'].astype(float)\n",
        "manu_one_on['PP75'] = manu_one_on['PP75'].astype(float)\n",
        "for i, row in manu_one_on.iterrows():\n",
        "  sub_coeff = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PP75'] = float((row['PP75'] * sub_coeff['Coefficient']))\n",
        "  new_df = new_df.append(row)\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df['PP75'] = new_df['PP75'].astype(float)\n",
        "new_df['TS%'] = new_df['TS%'].astype(float)\n",
        "new_df['MP'] = new_df['MP'].astype(int)\n",
        "new_df['Opp'] = new_df['Opp'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyHtvc0gQHqb",
        "outputId": "c9f7bdc5-7a31-45e1-a410-78559962e616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Only Member of Big 3 On\n",
            "\n",
            "       Player      Year     PTS      TS+    NetRtg rOffRtg  MP\n",
            "0   Manu Ginóbili  2004  18.524517   52.04   -1.30  -24.36  11\n",
            "1   Manu Ginóbili  2005  25.668884   84.30  -13.97  -17.29  31\n",
            "2   Manu Ginóbili  2006  24.771083  103.99  -39.61  -23.73  30\n",
            "3   Manu Ginóbili  2007  19.102326   48.45  -57.66  -30.98  18\n",
            "4   Manu Ginóbili  2008  36.097446   91.65   -3.38  -22.09   9\n",
            "5   Manu Ginóbili  2009  35.777001  107.06  -25.06  -23.78  32\n",
            "6   Manu Ginóbili  2010  32.348682   88.40  -15.23   -8.05  30\n",
            "7   Manu Ginóbili  2011  23.412662   68.84   -8.31  -27.05  22\n",
            "8   Manu Ginóbili  2012  16.342016   97.95  -35.32  -13.98  34\n",
            "9   Manu Ginóbili  2013  22.064717   89.49  -17.32   -6.91  53\n",
            "10  Manu Ginóbili  2014  18.116512   88.05   -2.40    4.22  51\n"
          ]
        }
      ],
      "source": [
        "#@title Run Manual Subset\n",
        "pd.options.mode.chained_assignment = None\n",
        "print(\"                 Only Member of Big 3 On\\n\")\n",
        "team_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "team_ts_allowed_df['TS% Allowed'] = team_ts_allowed_df['TS% Allowed'].astype(float)\n",
        "team_ts_allowed_df['Year'] = team_ts_allowed_df['Year'].astype(int)\n",
        "\n",
        "opp_literal_defrtg = pd.read_csv('/content/NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "\n",
        "\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "\n",
        "manual_adjust_scoring_efficiency(new_df, team_ts_allowed_df, opponent_adj_pts_coeff, opp_literal_defrtg, 'Manu Ginóbili')\n",
        "\n",
        "#Manu Ginóbili"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QQT2n6FFd9pf"
      },
      "outputs": [],
      "source": [
        "#@title Larger Circumstance\n",
        "def manu_tony_compare(player, sit):\n",
        "\n",
        "  manu_only_one_adjusted = pd.read_csv('/content/NBA_Playoff_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('two_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('two_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('two_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('four_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('four_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('four_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('five_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('five_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('five_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('six_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('six_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('six_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('seven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('eight_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('nine_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('ten_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('eleven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eleven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('eleven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eleven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  import_pts_twopeaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_ts_twopeaks_df = pd.read_csv('two_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_peaks_df = pd.read_csv('two_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_peaks_df = pd.read_csv('two_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_peaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_peaks_df = pd.read_csv('three_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg3_peaks_df = pd.read_csv('three_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg3_peaks_df = pd.read_csv('three_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_4peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_4peaks_df = pd.read_csv('four_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_4peaks_df = pd.read_csv('four_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_4peaks_df = pd.read_csv('four_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_5peaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_5peaks_df = pd.read_csv('five_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_5peaks_df = pd.read_csv('five_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_5peaks_df = pd.read_csv('five_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_6peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_6peaks_df = pd.read_csv('six_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_6peaks_df = pd.read_csv('six_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_6peaks_df = pd.read_csv('six_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_7peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_7peaks_df = pd.read_csv('seven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_7peaks_df = pd.read_csv('seven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_7peaks_df = pd.read_csv('seven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_8peaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_8peaks_df = pd.read_csv('eight_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_8peaks_df = pd.read_csv('eight_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_8peaks_df = pd.read_csv('eight_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_9peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_9peaks_df = pd.read_csv('nine_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_9peaks_df = pd.read_csv('nine_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_9peaks_df = pd.read_csv('nine_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_10peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_10peaks_df = pd.read_csv('ten_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_10peaks_df = pd.read_csv('ten_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_10peaks_df = pd.read_csv('ten_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_11peaks_df = pd.read_csv('eleven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_11peaks_df = pd.read_csv('eleven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_11peaks_df = pd.read_csv('eleven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_11peaks_df = pd.read_csv('eleven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #2 year playoff scoring peaks Output File\n",
        "  peaks_df = import_pts_twopeaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_ts_twopeaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Two\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_2_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #3 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg3_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg3_peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Three\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_3_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #4 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_4peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_4peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_4peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_4peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Four\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_4_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #5 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_5peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_5peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_5peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_5peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Five\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_5_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #6 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_6peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_6peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_6peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_6peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Six\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_6_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #7 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_7peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_7peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_7peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_7peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Seven\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_7_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #8 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_8peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_8peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_8peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_8peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Eight\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_8_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #9 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_9peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_9peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_9peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_9peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Nine\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_9_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #10 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_10peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_10peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_10peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_10peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Ten\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_10_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  #11 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_11peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_11peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_11peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_11peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Eleven\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_11_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bIT3n1JeMyZ2"
      },
      "outputs": [],
      "source": [
        "#@title Smaller Circumstance \n",
        "\n",
        "manu_only_one_adjusted = pd.read_csv('/content/NBA_Playoff_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "twoyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_PTS_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "twoyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "import_player_longTS_peaks_df = pd.read_csv('two_year_peak_TS+_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_TS+_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "threeyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_PTS_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "threeyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "import_player_longTS_peaks_df = pd.read_csv('three_year_peak_TS+_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_TS+_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "import_pts_twopeaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_ts_twopeaks_df = pd.read_csv('two_year_peak_TS+_data.csv', encoding='utf8')\n",
        "\n",
        "import_player_pts_peaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_ts_peaks_df = pd.read_csv('three_year_peak_TS+_data.csv', encoding='utf8')\n",
        "\n",
        "#2 year playoff scoring peaks Output File\n",
        "at_least_400_min_2pts = import_pts_twopeaks_df.copy()\n",
        "at_least_400_min_2ts = import_ts_twopeaks_df.copy()\n",
        "\n",
        "sorted_2pts = at_least_400_min_2pts.copy()\n",
        "sorted_2pts.insert(4, \"TS+\", at_least_400_min_2ts['PeakValue'])\n",
        "sorted_2pts = sorted_2pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\"})\n",
        "\n",
        "sorted_2pts = sorted_2pts.sort_values('PTS', ascending=False)\n",
        "columns_titles = ['Player', 'Years', 'PTS', 'TS+', 'MP',]\n",
        "sorted_2pts = sorted_2pts.reindex(columns=columns_titles)\n",
        "\n",
        "sixyearpeak_manual_data\n",
        "\n",
        "print(\"Two\")\n",
        "print(sorted_2pts)\n",
        "\n",
        "sorted_2pts.to_csv(\"Manu_2_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#3 year playoff scoring peaks Output File\n",
        "at_least_400_min_2pts = import_player_pts_peaks_df.copy()\n",
        "at_least_400_min_2ts = import_player_ts_peaks_df.copy()\n",
        "\n",
        "sorted_2pts = at_least_400_min_2pts.copy()\n",
        "sorted_2pts.insert(4, \"TS+\", at_least_400_min_2ts['PeakValue'])\n",
        "sorted_2pts = sorted_2pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\"})\n",
        "\n",
        "sorted_2pts = sorted_2pts.sort_values('PTS', ascending=False)\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'PTS', 'TS+', 'MP',]\n",
        "sorted_2pts = sorted_2pts.reindex(columns=columns_titles)\n",
        "\n",
        "print(\"Three\")\n",
        "print(sorted_2pts)\n",
        "\n",
        "sorted_2pts.to_csv(\"Manu_3_scoring_Playoff_Peaks.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "632Vlw2nH8ir"
      },
      "outputs": [],
      "source": [
        "manu_tony_compare(\"Manu\", \"Both\")\n",
        "# Manu Ginóbili"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"         Situation               Years         PTS         TS+       NetRtg    rOffRtg   MP\")\n",
        "print(\"Manu Big 3                    2004 - 2008     21.02       111.88      5.60      6.38    1579\")\n",
        "print(\"Manu 2/3                      2004 - 2008     27.30       112.73      9.20      5.65    910\")\n",
        "print(\"Manu 2/3 (3+ opp. starters)   2004 - 2008     27.49       111.90      6.16      4.96    624\")\n",
        "print(\"Manu 2/3 (4+ opp. starters)   2004 - 2008     30.14       114.86      7.85      5.34    281\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xSH9iqjvk1y",
        "outputId": "9577efc0-2a34-4979-a0c8-2bfc43adb2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Situation               Years         PTS         TS+       NetRtg    rOffRtg   MP\n",
            "Manu Big 3                    2004 - 2008     21.02       111.88      5.60      6.38    1579\n",
            "Manu 2/3                      2004 - 2008     27.30       112.73      9.20      5.65    910\n",
            "Manu 2/3 (3+ opp. starters)   2004 - 2008     27.49       111.90      6.16      4.96    624\n",
            "Manu 2/3 (4+ opp. starters)   2004 - 2008     30.14       114.86      7.85      5.34    281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"         Situation               Years         PTS         TS+       NetRtg    rOffRtg   MP\")\n",
        "print(\"Manu Big 3                    2012 - 2014     17.98       108.20      7.41      7.50    794\")\n",
        "print(\"Manu 2/3                      2012 - 2014     21.39       107.50      16.71     9.93    384\")\n",
        "print(\"Manu 2/3 (3+ opp. starters)   2012 - 2014     20.59       96.71       20.67     7.64    227\")\n",
        "print(\"Manu 2/3 (4+ opp. starters)   2012 - 2014     18.47       78.20       1.52     -2.71    116\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQdgKFS05aS0",
        "outputId": "06e95af8-3603-4799-db4e-4d64b70718ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Situation               Years         PTS         TS+       NetRtg    rOffRtg   MP\n",
            "Manu Big 3                    2012 - 2014     17.98       108.20      7.41      7.50    794\n",
            "Manu 2/3                      2012 - 2014     21.39       107.50      16.71     9.93    384\n",
            "Manu 2/3 (3+ opp. starters)   2012 - 2014     20.59       96.71       20.67     7.64    227\n",
            "Manu 2/3 (4+ opp. starters)   2012 - 2014     18.47       78.20       1.52     -2.71    116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"         Situation               Years         PTS         TS+       NetRtg    rOffRtg   MP\")\n",
        "print(\"Manu 2/3                      2004 - 2008     27.30       112.73      9.20      5.65    910\")\n",
        "print(\"Manu 2/3 (4+ opp. starters)   2004 - 2008     30.14       114.86      7.85      5.34    281\")\n",
        "print(\"Manu 2/3                      2012 - 2014     21.39       107.50      16.71     9.93    384\")\n",
        "print(\"Manu 2/3 (4+ opp. starters)   2012 - 2014     18.47       78.20       1.52     -2.71    116\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMFzXrd1BRIv",
        "outputId": "8bc20db0-fdd1-414c-8e8c-bba283a9f81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Situation               Years         PTS         TS+       NetRtg    rOffRtg   MP\n",
            "Manu 2/3                      2004 - 2008     27.30       112.73      9.20      5.65    910\n",
            "Manu 2/3 (4+ opp. starters)   2004 - 2008     30.14       114.86      7.85      5.34    281\n",
            "Manu 2/3                      2012 - 2014     21.39       107.50      16.71     9.93    384\n",
            "Manu 2/3 (4+ opp. starters)   2012 - 2014     18.47       78.20       1.52     -2.71    116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"         Situation               Years         PTS         TS+       NetRtg    rOffRtg   MP\")\n",
        "print(\"         Manu Solo            2005 - 2008     33.79       96.68      5.60      -7.33    152\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLlpwlcg9oUx",
        "outputId": "c721fa40-9932-4748-aef2-16e2cb092dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Situation               Years         PTS         TS+       NetRtg    rOffRtg   MP\n",
            "         Manu Solo            2005 - 2008     33.79       96.68      5.60      -7.33    152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0unXklbF571"
      },
      "source": [
        "**PLOT SHOOTING DISTRIBUTION DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9V1JtkppSWJ3"
      },
      "outputs": [],
      "source": [
        "#@title David Robinson\n",
        "graph_data =  pd.read_csv('/content/Five_Year_pbp_Peaks_NBA_Playoffs_1000_min.csv', encoding='utf8')\n",
        "graph_data = graph_data.dropna()\n",
        "graph_data = graph_data.sort_values('Player', ascending=False)\n",
        "\n",
        "graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "\n",
        "Robinson = (graph_data['Player']=='David Robinson')\n",
        "graph_data['color']= np.where( Robinson==True , \"#C5B783\", \"#00B2A9\")\n",
        "\n",
        "#D_color_label = {\"#C5B783\": \"David Robinson\",\n",
        "#                  \"#00B2A9\": \"Everyone Else\"}\n",
        "#colors = list(graph_data[\"color\"].unique())\n",
        "#labels = [D_color_label[x] for x in graph_data[\"color\"].unique()]\n",
        "\n",
        "\n",
        "size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "plt.figure(figsize=(10,6), tight_layout=True)\n",
        "sns.color_palette(\"flare\", as_cmap=True)\n",
        "ax = sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':1.0, 's':size*4, 'linewidth':0})\n",
        "ax.set(title='5 Year Playoff PBP (1997-2022)', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label='David Robinson', markerfacecolor='#C5B783',  markersize=10)]\n",
        "ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "\n",
        "# ridge regression\n",
        "x_pred = graph_data['OnCourt']\n",
        "x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "y_pred = graph_data['On-Off']\n",
        "reg = linear_model.Ridge(alpha=10)\n",
        "reg.fit(x_pred, y_pred)\n",
        "pred = reg.predict(x_pred)\n",
        "ax.plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnneH6_bURi6"
      },
      "source": [
        "**MISC**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "P6ldoreCOllW"
      },
      "outputs": [],
      "source": [
        "#@title working cell\n",
        "kd = era_opponent_adj_playoff_per_75_df[(era_opponent_adj_playoff_per_75_df['Player'] == 'Kevin Durant')]\n",
        "kd = kd[(kd['Tm'] != 'GSW')]\n",
        "print(kd)\n",
        "\n",
        "\n",
        "tim = era_opponent_adj_playoff_per_75_df[(era_opponent_adj_playoff_per_75_df['Player'] == 'Manu Ginóbili')]\n",
        "#print(tim)\n",
        "\n",
        "green = era_opponent_adj_playoff_per_75_df.copy()\n",
        "green = green.drop(columns=['TeamColor', 'Pos', 'Age', 'GS', 'ORB', 'DRB','STL', 'BLK', 'TOV', 'PF', 'FG', 'FGA', 'TRB', 'AST', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT','FTA','FT%', 'ORtg', 'DRtg'])\n",
        "green['MP'] = green['MP'].astype(int)\n",
        "green['G'] = green['G'].astype(int)\n",
        "\n",
        "\n",
        "green = green.rename(columns={\"Year\": \"Year\", \"Player\": \"Player\", \"Tm\": \"Team\", \"PTS\": \"PTS per 75\", \"MP\": \"MP\", \"TS%+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "green = green.sort_values('PTS per 75', ascending=False)\n",
        "\n",
        "columns_titles = ['Player', 'Year', 'Team', 'PTS per 75', 'TS+', 'MP', 'G']\n",
        "green = green.reindex(columns=columns_titles)\n",
        "\n",
        "green['PTS per 75'] = green['PTS per 75'].round(2)\n",
        "green['TS+'] = green['TS+'].round(2)\n",
        "\n",
        "green = green.dropna()\n",
        "green = green[(green['MP'] >= 100)]\n",
        "\n",
        "print(green)\n",
        "\n",
        "green.to_csv(\"Single_Playoff_Adjusted_Data_min_100_min.csv\", index=False)\n",
        "\n",
        "players = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', index_col=False, encoding='utf8')\n",
        "players = players.sort_values('PTS per 75_post', ascending=False)\n",
        "players = players[(players['PTS per 75_post'] >= 25)]\n",
        "players = players.drop(columns=['PTS_change',  'TS+_change'])\n",
        "print(players)\n",
        "\n",
        "players.to_csv(\"top_25.csv\", index=False)\n",
        "\n",
        "players = pd.read_csv('/content/All_Scoring_Changes_300min.csv', index_col=False, encoding='utf8')\n",
        "players = players.sort_values('PTS per 75_post', ascending=False)\n",
        "players = players[(players['Player'] == '')]\n",
        "players = players[(players['MP_post'] >= 2000)]\n",
        "print(players)\n",
        "\n",
        "players.to_csv(\"high_stretches.csv\", index=False)\n",
        "\n",
        "players = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', index_col=False, encoding='utf8')\n",
        "players = players.sort_values('TS+', ascending=False)\n",
        "players = players[(players['Player'] == 'Kobe Bryant')]\n",
        "players = players[(players['PTS'] >= 26)]\n",
        "players = players[(players['TS+'] >= 107)]\n",
        "players = players[(players['MP'] >= 3000)]\n",
        "players = players[(players['MP'] <= 4000)]\n",
        "print(players)\n",
        "\n",
        "players.to_csv(\"high_stretches.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oWUgnEPoEmNw"
      },
      "outputs": [],
      "source": [
        "#@title D-Rob compare PTS/G to league PTS per 75\n",
        "def p_plotOneScoringChangeWithLines(p1, c1, pts_floor, ts_floor, ts_ceiling, label):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Inflated_Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['PTS']) >= pts_floor]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['TS+']) >=  ts_floor]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['TS+']) <=  ts_ceiling]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='PTS/G (era-adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Inflated_Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['PTS']) >= pts_floor]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['TS+']) >=  ts_floor]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['TS+']) <=  ts_ceiling]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='PTS/G (era-adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Inflated_Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['PTS']) >= pts_floor]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['TS+']) >=  ts_floor]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['TS+']) <=  ts_ceiling]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='PTS/G (era-adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Inflated_Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['PTS']) >= pts_floor]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['TS+']) >=  ts_floor]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['TS+']) <=  ts_ceiling]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='PTS/G (era-adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChangeWithLines(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling, label):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75 (era adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75 (era adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75 (era adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75 (era adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChangeWithLines(p1, p2, p3, c1, c2, c3, pts_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Precise_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Pts per 75', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui7G7bAvZzPq"
      },
      "source": [
        "FORMAT UN-NORMALIZED DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07v_723zXnVv"
      },
      "outputs": [],
      "source": [
        "player_urls = pd.read_csv('/content/nba_player_since_74_URL_data.csv', index_col=False, encoding='utf8')\n",
        "player_urls = player_urls.sort_values('Player', ascending=True)\n",
        "outfile = f\"nba_player_since_74_URL_data.csv\"\n",
        "player_urls.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfw3lfqFaiGG"
      },
      "outputs": [],
      "source": [
        "player_urls = pd.read_csv('/content/so_far_itsthis_trimmed.txt', index_col=False, encoding='utf8')\n",
        "outfile = f\"so_far_itsthis_trimmed.csv\"\n",
        "player_urls.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "87z0O3d_mjZ-"
      },
      "outputs": [],
      "source": [
        "#@title Fix Teams' TS% Allowed part 1\n",
        "bad_words = ['TS% Allowed', 'usr/local']\n",
        "with open('/content/justfixthis.txt') as oldfile, open('tmp.txt', 'w') as newfile:\n",
        "    for line in oldfile:\n",
        "       if not any(bad_word in line for bad_word in bad_words):\n",
        "         s = line\n",
        "         s = ' '.join(s.split()[1:])\n",
        "         s = re.sub(\"\\s+\", \",\", s)\n",
        "         newfile.write(s+\"\\n\")\n",
        "\n",
        "#@title Fix Teams' TS% Allowed part 2\n",
        "player_urls = pd.read_csv('/content/tmp.txt', index_col=False, encoding='utf8')\n",
        "outfile = f\"NBA_Team_TS_Percentage_Allowed_df.csv\"\n",
        "player_urls.to_csv(outfile, index=False)\n",
        "player_mid = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "player_mid = player_mid.loc[:, ~player_mid.columns.str.contains('^Unnamed')]\n",
        "print(player_mid)\n",
        "outfile = f\"NBA_Team_TS_Percentage_Allowed_df\"\n",
        "player_mid.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pHE6vI1u1-4-"
      },
      "outputs": [],
      "source": [
        "#@title Format pasted data part 1\n",
        "\n",
        "def rreplace(s, old, new, occurrence):\n",
        "  li = s.rsplit(old, occurrence)\n",
        "  return new.join(li)\n",
        "\n",
        "with open('tmp4.txt') as oldfile, open('tmp5.txt', 'w') as newfile:\n",
        "    for line in oldfile:\n",
        "      s = line\n",
        "      removal = \",\"\n",
        "      reverse_removal = removal[::-1]\n",
        "\n",
        "      replacement = \"\"\n",
        "      reverse_replacement = replacement[::-1]\n",
        "\n",
        "      newstr = s[::-1].replace(reverse_removal, reverse_replacement, 1)[::-1]\n",
        "      newfile.write(newstr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PH_PrZPVV4Cr"
      },
      "outputs": [],
      "source": [
        "#@title Combine segments of TS+ data\n",
        "a = pd.read_csv('/content/A_df.csv', index_col=False, encoding='utf8')\n",
        "b = pd.read_csv('/content/B_df.csv', index_col=False, encoding='utf8')\n",
        "btwo = pd.read_csv('/content/B2_df.csv', index_col=False, encoding='utf8')\n",
        "c = pd.read_csv('/content/C_df.csv', index_col=False, encoding='utf8')\n",
        "d = pd.read_csv('/content/DtoF_df.csv', index_col=False, encoding='utf8')\n",
        "g = pd.read_csv('/content/GtoJ_df.csv', index_col=False, encoding='utf8')\n",
        "j = pd.read_csv('/content/JtoS_df.csv', index_col=False, encoding='utf8')\n",
        "t = pd.read_csv('/content/TtoZ_df.csv', index_col=False, encoding='utf8')\n",
        "jerks = pd.read_csv('/content/jerks.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "start_to_adj_list = a.append(b, ignore_index=1)\n",
        "start_to_adj_list = start_to_adj_list.append(btwo, ignore_index=1)\n",
        "start_to_adj_list = start_to_adj_list.append(c, ignore_index=1)\n",
        "start_to_adj_list = start_to_adj_list.append(d, ignore_index=1)\n",
        "start_to_adj_list = start_to_adj_list.append(g, ignore_index=1)\n",
        "start_to_adj_list = start_to_adj_list.append(j, ignore_index=1)\n",
        "start_to_adj_list = start_to_adj_list.append(t, ignore_index=1)\n",
        "start_to_adj_list = start_to_adj_list.append(jerks, ignore_index=1)\n",
        "outfile = f\"Complete_Adjusted_TS_List.csv\"\n",
        "start_to_adj_list.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YK1lbtbKOnNG"
      },
      "outputs": [],
      "source": [
        "#@title Append Scoring Stretches\n",
        "two = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "three = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "four = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "five = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "six = pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "seven = pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "eight = pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', index_col=False, encoding='utf8')\n",
        "nine = pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', index_col=False, encoding='utf8')\n",
        "ten = pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "two = two.append(three)\n",
        "two = two.append(four)\n",
        "two = two.append(five)\n",
        "two = two.append(six)\n",
        "two = two.append(seven)\n",
        "two = two.append(eight)\n",
        "two = two.append(nine)\n",
        "two = two.append(ten)\n",
        "two = two[(two['MP'] >= 500)]\n",
        "print(two)\n",
        "\n",
        "outfile = f\"All_Scoring_Stretches_500min.csv\"\n",
        "two.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q-AWQpDM9zWF"
      },
      "outputs": [],
      "source": [
        "#@title Append into one\n",
        "two = pd.read_csv('/content/Two_Year_BPM_Change.csv', encoding='utf8')\n",
        "three = pd.read_csv('/content/Three_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "four = pd.read_csv('/content/Four_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "five = pd.read_csv('/content/Five_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "six = pd.read_csv('/content/Six_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "seven = pd.read_csv('/content/Seven_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "eight = pd.read_csv('/content/Eight_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "nine = pd.read_csv('/content/Nine_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "ten = pd.read_csv('/content/Ten_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "two = two.append(three)\n",
        "two = two.append(four)\n",
        "two = two.append(five)\n",
        "two = two.append(six)\n",
        "two = two.append(seven)\n",
        "two = two.append(eight)\n",
        "two = two.append(nine)\n",
        "two = two.append(ten)\n",
        "two = two[(two['MP_post'] >= 300)]\n",
        "print(two)\n",
        "\n",
        "outfile = f\"All_BPM_Changes_300min.csv\"\n",
        "two.to_csv(outfile, index=False)\n",
        "\n",
        "#@title Append into one\n",
        "two = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "three = pd.read_csv('/content/Three_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "four = pd.read_csv('/content/Four_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "five = pd.read_csv('/content/Five_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "six = pd.read_csv('/content/Six_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "seven = pd.read_csv('/content/Seven_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "eight = pd.read_csv('/content/Eight_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "nine = pd.read_csv('/content/Nine_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "ten = pd.read_csv('/content/Ten_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "two = two.append(three)\n",
        "two = two.append(four)\n",
        "two = two.append(five)\n",
        "two = two.append(six)\n",
        "two = two.append(seven)\n",
        "two = two.append(eight)\n",
        "two = two.append(nine)\n",
        "two = two.append(ten)\n",
        "two = two[(two['MP_post'] >= 300)]\n",
        "print(two)\n",
        "\n",
        "outfile = f\"All_Scoring_Changes_300min.csv\"\n",
        "two.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2EzybONyP4Fh"
      },
      "outputs": [],
      "source": [
        "#@title Combine All Scoring and BPM changes\n",
        "bpm = pd.read_csv('/content/All_BPM_Changes_300min.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = bpm.rename(columns={\"Player\": \"Player\", \"Years\": \"Years\", \"bpm_change\": \"BPM_change\", \"OBPM_change\": \"OBPM_change\", \"BPM_post\": \"BPM_post\", \"OBPM_post\": \"OBPM_post\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "scoring = pd.read_csv('/content/All_Scoring_Changes_300min.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "final_season_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_Change', 'TS+_Change', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "\n",
        "for idx, row in scoring.iterrows():\n",
        "  sub_second_df = bpm[(bpm['Player'] == row['Player'])]\n",
        "  for jdx, inner_row in sub_second_df.iterrows():\n",
        "    if inner_row['Player'] == row['Player'] and inner_row['Years'] == row['Years']:\n",
        "      new_row = {'Player':inner_row['Player'], 'Years':inner_row['Years'], 'PTS per 75_post':row['PTS per 75_post'], 'TS+_post':row['TS+_post'], 'PTS_Change':row['PTS_change'], 'TS+_Change':row['TS+_change'], 'BPM_post':inner_row['BPM_post'], 'OBPM_post':inner_row['OBPM_post'], 'BPM_change':inner_row['BPM_change'], 'OBPM_change':inner_row['OBPM_change'], 'MP_post':int(inner_row['MP_post'])}\n",
        "      final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "\n",
        "outfile = f\"All_Scoring_BPM_Changes_300min.csv\"\n",
        "final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3bBmu92gXOiE"
      },
      "outputs": [],
      "source": [
        "#@title 'Combine x year scoring and bpm changes' Function\n",
        "def combine_scoring_bpm_changes(scoring_df, bpm_df, year):\n",
        "  final_season_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_Change', 'TS+_Change', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  for idx, row in scoring_df.iterrows():\n",
        "    sub_second_df = bpm_df[(bpm_df['Player'] == row['Player'])]\n",
        "    for jdx, inner_row in sub_second_df.iterrows():\n",
        "      if inner_row['Player'] == row['Player'] and inner_row['Years'] == row['Years']:\n",
        "        new_row = {'Player':inner_row['Player'], 'Years':inner_row['Years'], 'PTS per 75_post':row['PTS per 75_post'], 'TS+_post':row['TS+_post'], 'PTS_Change':row['PTS_change'], 'TS+_Change':row['TS+_change'], 'BPM_post':inner_row['BPM_post'], 'OBPM_post':inner_row['OBPM_post'], 'BPM_change':inner_row['BPM_change'], 'OBPM_change':inner_row['OBPM_change'], 'MP_post':int(inner_row['MP_post'])}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  final_season_df = final_season_df[(final_season_df['MP_post'] >= 300)]\n",
        "  outfile = f\"{year}_Year_Scoring_BPM_Changes_300min.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3VNf4cGdXn40"
      },
      "outputs": [],
      "source": [
        "#@title Run 'Combine x year scoring and bpm changes'\n",
        "scoring = pd.read_csv('/content/Two_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Two_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Two\")\n",
        "\n",
        "scoring = pd.read_csv('/content/Three_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Three_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Three\")\n",
        "\n",
        "\n",
        "scoring = pd.read_csv('/content/Four_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Four_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Four\")\n",
        "\n",
        "\n",
        "scoring = pd.read_csv('/content/Five_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Five_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Five\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FIVy6IDJYfP2"
      },
      "outputs": [],
      "source": [
        "#@title Print Medians\n",
        "def printmedians(pts_floor):\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_reg'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"2 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"2 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_reg'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"3 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"3 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_reg'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 800)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"4 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"4 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_reg'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1000)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"5 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"5 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_reg'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1200)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"6 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"6 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_reg'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1400)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"7 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"7 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_reg'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1500)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"8 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"8 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_reg'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 2000)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"10 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"10 Year Median TS+ decline\")\n",
        "  print(med_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-xXRuU0mbJ-g"
      },
      "outputs": [],
      "source": [
        "#@title Print Distribution of Scoring Changes\n",
        "def printTSdistribution(all_some, pts_floor):\n",
        "  if all_some == 0:\n",
        "    # 2 year\n",
        "    graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "\n",
        "    # 3 year\n",
        "    tmp_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 4 year\n",
        "    tmp_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 5 year\n",
        "    tmp_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 6 year\n",
        "    tmp_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 7 year\n",
        "    tmp_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 8 year\n",
        "    tmp_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 10 year\n",
        "    tmp_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_reg']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "  else:\n",
        "    graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_reg']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data['PTS_change'] = graph_data['PTS_change'].round(1)\n",
        "  graph_data['TS+_change'] = graph_data['TS+_change'].round(1)\n",
        "\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "\n",
        "  pd.cut(graph_data['TS+_change'], \n",
        "       bins=[-17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8], \n",
        "       labels = ['-17% or worse', '-16%', '-15%', '-14%', '-13%', '-12%', '-11%', '-10%', '-9%', '-8%', '-7%', '-6%', '-5%', '-4%',\n",
        "                 '-3%', '-2%', '-1%', '0%', '+1%', '+2%', '+3%', '+4%', '+5%', '+6%',\n",
        "                 '+7% or better'])\\\n",
        "  .value_counts(sort=False).plot.bar()\n",
        "  title_string = f\"Reg->Post Scoring Change; Multi Year Playoff Stretches; >= {pts_floor} PP75 Reg (1974-2022)\"\n",
        "  plt.title(title_string)\n",
        "  plt.xlabel('Change in TS+')\n",
        "  plt.ylabel('Count')\n",
        "  plt.show()\n",
        "  print(graph_data['TS+_change'].quantile(0.98))\n",
        "\n",
        "def printPTSdistribution(all_some, pts_floor):\n",
        "  if all_some == 0:\n",
        "    # 2 year\n",
        "    graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "\n",
        "    # 3 year\n",
        "    tmp_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 4 year\n",
        "    tmp_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 5 year\n",
        "    tmp_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 6 year\n",
        "    tmp_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 7 year\n",
        "    tmp_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 8 year\n",
        "    tmp_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 10 year\n",
        "    tmp_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_reg']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "  else:\n",
        "    graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_reg']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data['PTS_change'] = graph_data['PTS_change'].round(1)\n",
        "  graph_data['TS+_change'] = graph_data['TS+_change'].round(1)\n",
        "\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "\n",
        "  pd.cut(graph_data['PTS_change'], \n",
        "       bins=[-6, -5.5, -5, -4.5, -4, -3.5, -3, -2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5], \n",
        "       labels = ['-6 PTS or worse', '-5.5', '-5', '-4.5', '-4', '-3.5', '-3', '-2.5', '-2', '-1.5', '-1', '-0.5', '0', '+0.5', '+1', '+1.5', '+2', '+2.5', '+3', '+3.5', '+4', '+4.5% or better'])\\\n",
        "  .value_counts(sort=False).plot.bar()\n",
        "  title_string = f\"Reg->Post Scoring Change; Multi Year Playoff Stretches; >= {pts_floor} PP75 Reg (1974-2022)\"\n",
        "  plt.title(title_string)\n",
        "  plt.xlabel('Change in PTS per 75')\n",
        "  plt.ylabel('Count')\n",
        "  plt.show()\n",
        "  print(graph_data['PTS_change'].quantile(0.8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrnCdHn6Z4hM"
      },
      "outputs": [],
      "source": [
        "#printmedians(20)\n",
        "printTSdistribution(1, 29)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-2HN46tS8Ew7"
      },
      "outputs": [],
      "source": [
        "#@title Table for 3 and 5 year \n",
        "five_changes = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "five_changes = five_changes.loc[(five_changes['Player'] == \"Tim Duncan\") | (five_changes['Player'] == 'Giannis Antetokounmpo')]\n",
        "\n",
        "three_changes = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "three_changes = three_changes.loc[(three_changes['Player'] == \"Tim Duncan\") | (three_changes['Player'] == 'Giannis Antetokounmpo')]\n",
        "\n",
        "\n",
        "five_changes['PTS'] = five_changes['PTS'].round(2)\n",
        "five_changes['TS+'] = five_changes['TS+'].round(2)\n",
        "\n",
        "three_changes['PTS'] = three_changes['PTS'].round(2)\n",
        "three_changes['TS+'] = three_changes['TS+'].round(2)\n",
        "\n",
        "\n",
        "three_changes['Years'] = three_changes['Years'].replace(\"\\,\", '#', regex=True)\n",
        "five_changes['Years'] = five_changes['Years'].replace(\"\\,\", '#', regex=True)\n",
        "\n",
        "\n",
        "outfile_three = f\"klay3.csv\"\n",
        "three_changes.to_csv(outfile_three, index=False)\n",
        "\n",
        "outfile_five = f\"klay5.csv\"\n",
        "five_changes.to_csv(outfile_five, index=False)\n",
        "\n",
        "print(\"3 Year Playoffs\")\n",
        "print(three_changes)\n",
        "print(\"5 Year Playoffs\")\n",
        "print(five_changes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CnygkJdO3VSy"
      },
      "outputs": [],
      "source": [
        "#@title Player Changes Format\n",
        "# 2\n",
        "player_change_file = pd.read_csv('/content/2_Adjusted_Playoff_Scoring_Prime_Change_300min.csv', encoding='utf8')\n",
        "player_change_file = player_change_file[(player_change_file['Player'] == 'Tony Parker')]\n",
        "\n",
        "player_change_file['TS+_change'] = player_change_file['TS+_change'].round(2)\n",
        "player_change_file['PTS_change'] = player_change_file['PTS_change'].round(2)\n",
        "player_change_file['PTS per 75_reg'] = player_change_file['PTS per 75_reg'].round(2)\n",
        "player_change_file['PTS per 75_post'] = player_change_file['PTS per 75_post'].round(2)\n",
        "player_change_file['TS+_reg'] = player_change_file['TS+_reg'].round(2)\n",
        "player_change_file['TS+_post'] = player_change_file['TS+_post'].round(2)\n",
        "\n",
        "player_change_file['Years'] = player_change_file['Years'].replace(\"\\,\", '#', regex=True)\n",
        "\n",
        "outfile_2 = f\"tonychange2.csv\"\n",
        "player_change_file.to_csv(outfile_2, index=False)\n",
        "\n",
        "# 3                      \n",
        "player_change_file = pd.read_csv('/content/3_Adjusted_Playoff_Scoring_Prime_Change_500min.csv', encoding='utf8')\n",
        "player_change_file = player_change_file[(player_change_file['Player'] == 'Tony Parker')]\n",
        "\n",
        "player_change_file['TS+_change'] = player_change_file['TS+_change'].round(2)\n",
        "player_change_file['PTS_change'] = player_change_file['PTS_change'].round(2)\n",
        "player_change_file['PTS per 75_reg'] = player_change_file['PTS per 75_reg'].round(2)\n",
        "player_change_file['PTS per 75_post'] = player_change_file['PTS per 75_post'].round(2)\n",
        "player_change_file['TS+_reg'] = player_change_file['TS+_reg'].round(2)\n",
        "player_change_file['TS+_post'] = player_change_file['TS+_post'].round(2)\n",
        "\n",
        "player_change_file['Years'] = player_change_file['Years'].replace(\"\\,\", '#', regex=True)\n",
        "\n",
        "outfile_3 = f\"tonychange3.csv\"\n",
        "player_change_file.to_csv(outfile_3, index=False)\n",
        "\n",
        "# 5\n",
        "player_change_file = pd.read_csv('/content/5_Adjusted_Playoff_Scoring_Prime_Change_500min.csv', encoding='utf8')\n",
        "player_change_file = player_change_file[(player_change_file['Player'] == 'Tony Parker')]\n",
        "\n",
        "player_change_file['TS+_change'] = player_change_file['TS+_change'].round(2)\n",
        "player_change_file['PTS_change'] = player_change_file['PTS_change'].round(2)\n",
        "player_change_file['PTS per 75_reg'] = player_change_file['PTS per 75_reg'].round(2)\n",
        "player_change_file['PTS per 75_post'] = player_change_file['PTS per 75_post'].round(2)\n",
        "player_change_file['TS+_reg'] = player_change_file['TS+_reg'].round(2)\n",
        "player_change_file['TS+_post'] = player_change_file['TS+_post'].round(2)\n",
        "\n",
        "player_change_file['Years'] = player_change_file['Years'].replace(\"\\,\", '#', regex=True)\n",
        "\n",
        "outfile_5 = f\"tonychange5.csv\"\n",
        "player_change_file.to_csv(outfile_5, index=False)\n",
        "                          \n",
        "\n",
        "player_change_file = pd.read_csv('/content/8_Adjusted_Playoff_Scoring_Prime_Change_1500min.csv', encoding='utf8')\n",
        "player_change_file = player_change_file[(player_change_file['Player'] == 'Tony Parker')]\n",
        "\n",
        "player_change_file['TS+_change'] = player_change_file['TS+_change'].round(2)\n",
        "player_change_file['PTS_change'] = player_change_file['PTS_change'].round(2)\n",
        "player_change_file['PTS per 75_reg'] = player_change_file['PTS per 75_reg'].round(2)\n",
        "player_change_file['PTS per 75_post'] = player_change_file['PTS per 75_post'].round(2)\n",
        "player_change_file['TS+_reg'] = player_change_file['TS+_reg'].round(2)\n",
        "player_change_file['TS+_post'] = player_change_file['TS+_post'].round(2)\n",
        "\n",
        "player_change_file['Years'] = player_change_file['Years'].replace(\"\\,\", '#', regex=True)\n",
        "\n",
        "outfile_8 = f\"tonychange8.csv\"\n",
        "player_change_file.to_csv(outfile_8, index=False)\n",
        "\n",
        "#@title Table for changes\n",
        "five_changes = pd.read_csv('/content/5_Playoff_Scoring_Prime_Change_500min.csv', encoding='utf8')\n",
        "\n",
        "eight_changes = pd.read_csv('/content/8_Playoff_Scoring_Prime_Change_1500min.csv', encoding='utf8')\n",
        "\n",
        "ten_changes = pd.read_csv('/content/10_Playoff_Scoring_Prime_Change_2000min.csv', encoding='utf8')\n",
        "\n",
        "career_changes = pd.read_csv('/content/Tight_Career_Playoff_Scoring_Change.csv', encoding='utf8') \n",
        "\n",
        "five_changes = five_changes[(five_changes['TS+_change'] <= -10) | (five_changes['PTS_change'] <= -3)]\n",
        "eight_changes = eight_changes[(eight_changes['TS+_change'] <= -10) | (eight_changes['PTS_change'] <= -3)]\n",
        "ten_changes = ten_changes[(ten_changes['TS+_change'] <= -10) | (ten_changes['PTS_change'] <= -3)]\n",
        "career_changes = career_changes[(career_changes['TS+_change'] <= -8) | (career_changes['PTS_change'] <= -3)]\n",
        "career_changes = career_changes[(career_changes['MP_post'] >= 2000)]\n",
        "\n",
        "five_changes = five_changes.sort_values('TS+_change', ascending=True)\n",
        "eight_changes = eight_changes.sort_values('TS+_change', ascending=True)\n",
        "ten_changes = ten_changes.sort_values('TS+_change', ascending=True)\n",
        "career_changes = career_changes.sort_values('TS+_change', ascending=True)\n",
        "                                          \n",
        "\n",
        "five_changes['TS+_change'] = five_changes['TS+_change'].round(2)\n",
        "five_changes['PTS_change'] = five_changes['PTS_change'].round(2)\n",
        "five_changes['PTS per 75_reg'] = five_changes['PTS per 75_reg'].round(2)\n",
        "five_changes['PTS per 75_post'] = five_changes['PTS per 75_post'].round(2)\n",
        "five_changes['TS+_reg'] = five_changes['TS+_reg'].round(2)\n",
        "five_changes['TS+_post'] = five_changes['TS+_post'].round(2)\n",
        "\n",
        "eight_changes['TS+_change'] = eight_changes['TS+_change'].round(2)\n",
        "eight_changes['PTS_change'] = eight_changes['PTS_change'].round(2)\n",
        "eight_changes['PTS per 75_reg'] = eight_changes['PTS per 75_reg'].round(2)\n",
        "eight_changes['PTS per 75_post'] = eight_changes['PTS per 75_post'].round(2)\n",
        "eight_changes['TS+_reg'] = eight_changes['TS+_reg'].round(2)\n",
        "eight_changes['TS+_post'] = eight_changes['TS+_post'].round(2)\n",
        "\n",
        "ten_changes['TS+_change'] = ten_changes['TS+_change'].round(2)\n",
        "ten_changes['PTS_change'] = ten_changes['PTS_change'].round(2)\n",
        "ten_changes['PTS per 75_reg'] = ten_changes['PTS per 75_reg'].round(2)\n",
        "ten_changes['PTS per 75_post'] = ten_changes['PTS per 75_post'].round(2)\n",
        "ten_changes['TS+_reg'] = ten_changes['TS+_reg'].round(2)\n",
        "ten_changes['TS+_post'] = ten_changes['TS+_post'].round(2)\n",
        "\n",
        "career_changes['TS+_change'] = career_changes['TS+_change'].round(2)\n",
        "career_changes['PTS_change'] = career_changes['PTS_change'].round(2)\n",
        "career_changes['PTS per 75_reg'] = career_changes['PTS per 75_reg'].round(2)\n",
        "career_changes['PTS per 75_post'] = career_changes['PTS per 75_post'].round(2)\n",
        "career_changes['TS+_reg'] = career_changes['TS+_reg'].round(2)\n",
        "career_changes['TS+_post'] = career_changes['TS+_post'].round(2)\n",
        "\n",
        "five_changes['Years'] = five_changes['Years'].replace(\"\\,\", '#', regex=True)\n",
        "eight_changes['Years'] = eight_changes['Years'].replace(\"\\,\", '#', regex=True)\n",
        "ten_changes['Years'] = ten_changes['Years'].replace(\"\\,\", '#', regex=True)\n",
        "\n",
        "\n",
        "outfile_five = f\"5.csv\"\n",
        "five_changes.to_csv(outfile_five, index=False)\n",
        "\n",
        "outfile_eight = f\"8.csv\"\n",
        "eight_changes.to_csv(outfile_eight, index=False)\n",
        "\n",
        "outfile_ten = f\"10.csv\"\n",
        "ten_changes.to_csv(outfile_ten, index=False)\n",
        "\n",
        "outfile_career = f\"Career.csv\"\n",
        "career_changes.to_csv(outfile_career, index=False)\n",
        "\n",
        "print(\"5 Year Playoffs\")\n",
        "print(five_changes)\n",
        "print(\"8 Year Playoffs\")\n",
        "print(eight_changes)\n",
        "print(\"10 Year Playoffs\")\n",
        "print(ten_changes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1KNOV-aK5JdN"
      },
      "outputs": [],
      "source": [
        "#@title Manual comparisons function\n",
        "sorted_playoffs_pts = import_player_since74playoffs_per75_df.copy()\n",
        "sorted_reg_pts = import_player_since74_per75_df.copy()\n",
        "\n",
        "#player_a = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Damian Lillard\") & ((sorted_playoffs_pts.Year == 2014) | (sorted_playoffs_pts.Year == 2015)  | (sorted_playoffs_pts.Year == 2016) | (sorted_playoffs_pts.Year == 2017) | (sorted_playoffs_pts.Year == 2019) | (sorted_playoffs_pts.Year == 2020) | (sorted_playoffs_pts.Year == 2021))]\n",
        "#player_b = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Kobe Bryant\") & ((sorted_playoffs_pts.Year == 2001) | (sorted_playoffs_pts.Year == 2006)  | (sorted_playoffs_pts.Year == 2007) | (sorted_playoffs_pts.Year == 2008) | (sorted_playoffs_pts.Year == 2009) | (sorted_playoffs_pts.Year == 2010) | (sorted_playoffs_pts.Year == 2003) | (sorted_playoffs_pts.Year == 2012))]\n",
        "\n",
        "player_b = sorted_reg_pts[(sorted_reg_pts.Player == \"Damian Lillard\") & ((sorted_reg_pts.Year == 2014) | (sorted_reg_pts.Year == 2015)  | (sorted_reg_pts.Year == 2016) | (sorted_reg_pts.Year == 2016) | (sorted_reg_pts.Year == 2017) | (sorted_reg_pts.Year == 2019) | (sorted_reg_pts.Year == 2020) | (sorted_reg_pts.Year == 2021))]\n",
        "\n",
        "#player_a = sorted_pts[(sorted_pts.Player == \"Kawhi Leonard\") & ((sorted_pts.Year == 2012) | (sorted_pts.Year == 2014)  | (sorted_pts.Year == 2019) | (sorted_pts.Year == 2016) | (sorted_pts.Year == 2015) | (sorted_pts.Year == 2017) | (sorted_pts.Year == 2020) | (sorted_pts.Year == 2021))]\n",
        "\n",
        "player_a = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Klay Thompson\") & ((sorted_playoffs_pts.Year == 2013) | (sorted_playoffs_pts.Year == 2014)  | (sorted_playoffs_pts.Year == 2015) | (sorted_playoffs_pts.Year == 2016) | (sorted_playoffs_pts.Year == 2017) | (sorted_playoffs_pts.Year == 2018) | (sorted_playoffs_pts.Year == 2019))]\n",
        "#player_b = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Kobe Bryant\")]\n",
        "#player_a = df[(df.Player == a)]\n",
        "#player_b = df[(df.Player == b)]\n",
        "total_mp_a = 0\n",
        "total_pts_a = 0\n",
        "total_ts_a = 0\n",
        "\n",
        "total_mp_b = 0\n",
        "total_pts_b = 0\n",
        "total_ts_b = 0\n",
        "mp_list_a = []\n",
        "mp_list_b = []\n",
        "\n",
        "# find total minutes a\n",
        "for row in player_a['MP']:\n",
        "  mp_list_a.append(row)\n",
        "  total_mp_a += row\n",
        "print(player_a.iat[0, 3], \"\\nminutes: \", total_mp_a)\n",
        "\n",
        "# find total PTS a\n",
        "i = 0\n",
        "for row in player_a['PTS']:\n",
        "  total_pts_a += row * (mp_list_a[i] / total_mp_a)\n",
        "  i = i + 1\n",
        "\n",
        "# find total TS+ a\n",
        "i = 0\n",
        "for row in player_a['TS%+']:\n",
        "  total_ts_a += row * (mp_list_a[i] / total_mp_a)\n",
        "  i = i + 1\n",
        "\n",
        "print(\"PTS per 75: \", total_pts_a)\n",
        "print(\"TS+: \",total_ts_a)\n",
        "\n",
        "# find total minutes\n",
        "for row in player_b['MP']:\n",
        "  mp_list_b.append(row)\n",
        "  total_mp_b += row\n",
        "print(\"\\n\")\n",
        "print(player_b.iat[0, 3], \"\\nminutes: \", total_mp_b)\n",
        "\n",
        "# find total PTS\n",
        "i = 0\n",
        "for row in player_b['PTS']:\n",
        "  total_pts_b += row * (mp_list_b[i] / total_mp_b)\n",
        "  i = i + 1\n",
        "\n",
        "# find total TS+\n",
        "i = 0\n",
        "for row in player_b['TS%+']:\n",
        "  total_ts_b += row * (mp_list_b[i] / total_mp_b)\n",
        "  i = i + 1\n",
        "\n",
        "print(\"PTS per 75: \", total_pts_b)\n",
        "print(\"TS+: \",total_ts_b)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M8yAW7WASwDX"
      },
      "outputs": [],
      "source": [
        "#@title def reg_playoff_comp(a, dfa, dfb) \n",
        "# def reg_playoff_comp(a, dfa, dfb) \n",
        "# print the change in scoring rate and effieciency for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoff_comp(a, dfa, dfb):\n",
        "\n",
        "  player_a = dfa[(dfa.Player == a)]\n",
        "  player_b = dfb[(dfb.Player == a)]\n",
        "  total_mp_a = 0\n",
        "  pts_list_a = []\n",
        "  ts_list_a = []\n",
        "\n",
        "  total_mp_b = 0\n",
        "  pts_list_b = []\n",
        "  ts_list_b = []\n",
        "\n",
        "  mp_list_a = []\n",
        "  mp_list_b = []\n",
        "\n",
        "\n",
        "  # find total PTS a\n",
        "  i = 0\n",
        "  for row in player_a['PTS']:\n",
        "    pts_list_a.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+ a\n",
        "  i = 0\n",
        "  for row in player_a['TS%+']:\n",
        "    ts_list_a.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total minutes\n",
        "  for row in player_b['MP']:\n",
        "    mp_list_b.append(row)\n",
        "    total_mp_b += row\n",
        "  print(\"\\n\")\n",
        "  print(player_b.iat[0, 3], \"\\nPlayoffs\\n\\nminutes: \", total_mp_b)\n",
        "\n",
        "  # find total PTS\n",
        "  i = 0\n",
        "  for row in player_b['PTS']:\n",
        "    pts_list_b.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+\n",
        "  i = 0\n",
        "  for row in player_b['TS%+']:\n",
        "    ts_list_b.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  total_pts = 0\n",
        "  total_ts = 0\n",
        "  while i <= j-1:\n",
        "    total_pts += ((pts_list_b[i] - pts_list_a[i]) * (mp_list_b[i] / total_mp_b))\n",
        "    print(pts_list_b[i] - pts_list_a[i])\n",
        "    print(((pts_list_b[i] - pts_list_a[i]) * (mp_list_b[i] / total_mp_b)))\n",
        "    total_ts += ((ts_list_b[i] - ts_list_a[i]) * (mp_list_b[i] / total_mp_b))\n",
        "    i = i + 1\n",
        "\n",
        "  print(\"\\n\\nRegular Season to Playoffs Change\\n\")\n",
        "  if total_pts > 0:\n",
        "    form_string = \"PTS per 75: +{}\".format(total_pts)\n",
        "    print(form_string)\n",
        "  else: \n",
        "    print(\"PTS per 75: \", total_pts)\n",
        "  if total_ts > 0:\n",
        "    form_string = \"TS+ {}\".format(total_ts)\n",
        "    print(form_string)\n",
        "  else:\n",
        "    print(\"TS+: \",total_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Oy0wPePVsfsg"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#@title Manual Comparisons (playoff change and compare regular season statistics)\n",
        "#reg_playoff_comp(\"Kobe Bryant\", import_player_since74_per75_df,import_player_since74playoffs_per75_df)\n",
        "\n",
        "seasons = [2015, 2017, 2018, 2019, 2020, 2021, 2022]\n",
        "#seasons = [2021, 2022]\n",
        "#seasons = np.arange(2003, 2019)\n",
        "#seasons = [1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007]\n",
        "\n",
        "player_name = \"Giannis Antetokounmpo\"\n",
        "\n",
        "playoff_db = createDataBase(player_name, adjusted_playoff_per_75_df, seasons)\n",
        "reg_db = createDataBase(player_name, import_player_since74_per75_df, seasons)\n",
        "\n",
        "reg_playoff_comp(player_name, reg_db, playoff_db)\n",
        "#reg_playoff_comp(player_name, import_player_since74_per75_df, import_player_since74playoffs_per75_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "a_seasons = np.arange(2015, 2022, 1)\n",
        "b_seasons = np.arange(2016, 2017, 1)\n",
        "c_seasons = np.arange(2011, 2020, 1)\n",
        "d_seasons = np.arange(2001, 2013, 1)\n",
        "\n",
        "#a = createDataBase(\"James Harden\", import_player_since74playoffs_per75_df, a_seasons)\n",
        "#b = createDataBase(\"Klay Thompson\", import_player_since74playoffs_per75_df, b_seasons)\n",
        "#c = createDataBase(\"Kevin Durant\", import_player_since74playoffs_per75_df, c_seasons)\n",
        "#d = createDataBase(\"Kobe Bryant\", import_player_since74playoffs_per75_df, d_seasons)\n",
        "\n",
        "#a = a.append(b)\n",
        "#a = a.append(c)\n",
        "#a = a.append(d)\n",
        "\n",
        "#comparePlayers(\"James Harden\", \"Klay Thompson\", a)\n",
        "#comparePlayers(\"Kevin Durant\", \"Kobe Bryant\", a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ1Q1Vf25HB8"
      },
      "source": [
        "**SCORING PEAK FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NXifsLAWa2m_"
      },
      "outputs": [],
      "source": [
        "#@title Run Scoring Peaks\n",
        "\n",
        "# 2\n",
        "twoyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "twoyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('two_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 3 \n",
        "threeyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "threeyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('three_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 4 \n",
        "fouryearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "fouryearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('four_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 5 \n",
        "fiveyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "fiveyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('five_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 6 \n",
        "sixyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "sixyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('six_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 7 \n",
        "sevenyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "sevenyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('seven_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 8 \n",
        "eightyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "eightyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('eight_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 9 \n",
        "nineyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "nineyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('nine_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 10 \n",
        "tenyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "tenyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('ten_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "18EL_SvjcEnR"
      },
      "outputs": [],
      "source": [
        "#@title Import Scoring Peaks\n",
        "\n",
        "# 2\n",
        "import_adjpts_twopeaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_twopeaks_df = import_adjpts_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_twopeaks_df = pd.read_csv('two_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_twopeaks_df = import_adjts_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_twopeaks_df['TeamColor'] = import_adjpts_twopeaks_df['Team'].map(team_colors)\n",
        "import_adjts_twopeaks_df['TeamColor'] = import_adjts_twopeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_threepeaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_threepeaks_df = import_adjpts_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_threepeaks_df = pd.read_csv('three_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_threepeaks_df = import_adjts_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_threepeaks_df['TeamColor'] = import_adjpts_threepeaks_df['Team'].map(team_colors)\n",
        "import_adjts_threepeaks_df['TeamColor'] = import_adjts_threepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_4peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_4peaks_df = import_adjpts_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_4peaks_df = pd.read_csv('four_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_4peaks_df = import_adjts_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_4peaks_df['TeamColor'] = import_adjpts_4peaks_df['Team'].map(team_colors)\n",
        "import_adjts_4peaks_df['TeamColor'] = import_adjts_4peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_fivepeaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_fivepeaks_df = import_adjpts_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_fivepeaks_df = pd.read_csv('five_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_fivepeaks_df = import_adjts_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_fivepeaks_df['TeamColor'] = import_adjpts_fivepeaks_df['Team'].map(team_colors)\n",
        "import_adjts_fivepeaks_df['TeamColor'] = import_adjts_fivepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_6peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_6peaks_df = import_adjpts_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_6peaks_df = pd.read_csv('six_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_6peaks_df = import_adjts_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjts_6peaks_df['TeamColor'] = import_adjts_6peaks_df['Team'].map(team_colors)\n",
        "import_adjpts_6peaks_df['TeamColor'] = import_adjpts_6peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_7peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_7peaks_df = import_adjpts_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_7peaks_df = pd.read_csv('seven_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_7peaks_df = import_adjts_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjts_7peaks_df['TeamColor'] = import_adjts_7peaks_df['Team'].map(team_colors)\n",
        "import_adjpts_7peaks_df['TeamColor'] = import_adjpts_7peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_eightpeaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_eightpeaks_df = import_adjpts_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_eightpeaks_df = pd.read_csv('eight_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_eightpeaks_df = import_adjts_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_eightpeaks_df['TeamColor'] = import_adjpts_eightpeaks_df['Team'].map(team_colors)\n",
        "import_adjts_eightpeaks_df['TeamColor'] = import_adjts_eightpeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_9peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_9peaks_df = import_adjpts_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_9peaks_df = pd.read_csv('nine_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_9peaks_df = import_adjts_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_9peaks_df['TeamColor'] = import_adjpts_9peaks_df['Team'].map(team_colors)\n",
        "import_adjts_9peaks_df['TeamColor'] = import_adjts_9peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_10peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_10peaks_df = import_adjpts_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_10peaks_df = pd.read_csv('ten_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_10peaks_df = import_adjts_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_10peaks_df['TeamColor'] = import_adjpts_10peaks_df['Team'].map(team_colors)\n",
        "import_adjts_10peaks_df['TeamColor'] = import_adjts_10peaks_df['Team'].map(team_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Fo8KJtggdtZC"
      },
      "outputs": [],
      "source": [
        "#@title Output Scoring Peaks\n",
        "\n",
        "# 2\n",
        "at_least_400_min_2pts = import_adjpts_twopeaks_df[(import_adjpts_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2pts = at_least_400_min_2pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_2ts = import_adjts_twopeaks_df[(import_adjts_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2ts = at_least_400_min_2ts.reset_index(drop=True)\n",
        "\n",
        "sorted_2pts = at_least_400_min_2pts.copy()\n",
        "sorted_2pts.insert(6, \"TS+\", at_least_400_min_2ts['PeakValue'])\n",
        "sorted_2pts = sorted_2pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_2pts = sorted_2pts.sort_values('PTS', ascending=False)\n",
        "sorted_2pts = sorted_2pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_2pts = sorted_2pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_2pts['PTS'] = sorted_2pts['PTS'].round(2)\n",
        "sorted_2pts['TS+'] = sorted_2pts['TS+'].round(2)\n",
        "\n",
        "sorted_2pts = sorted_2pts.dropna()\n",
        "\n",
        "print(sorted_2pts)\n",
        "\n",
        "sorted_2pts.to_csv(\"Two_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 3\n",
        "at_least_400_min_pts = import_adjpts_threepeaks_df[(import_adjpts_threepeaks_df['MP'] >= 400)]\n",
        "at_least_400_min_pts = at_least_400_min_pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_ts = import_adjts_threepeaks_df[(import_adjts_threepeaks_df['MP'] >= 400)]\n",
        "at_least_400_min_ts = at_least_400_min_ts.reset_index(drop=True)\n",
        "\n",
        "sorted_3pts = at_least_400_min_pts.copy()\n",
        "sorted_3pts.insert(6, \"TS+\", at_least_400_min_ts['PeakValue'])\n",
        "sorted_3pts = sorted_3pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3pts = sorted_3pts.sort_values('PTS', ascending=False)\n",
        "sorted_3pts = sorted_3pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_3pts = sorted_3pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3pts['PTS'] = sorted_3pts['PTS'].round(2)\n",
        "sorted_3pts['TS+'] = sorted_3pts['TS+'].round(2)\n",
        "\n",
        "sorted_3pts = sorted_3pts.dropna()\n",
        "\n",
        "print(sorted_3pts)\n",
        "\n",
        "sorted_3pts.to_csv(\"Three_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 4\n",
        "at_least_400_min_pts = import_adjpts_4peaks_df[(import_adjpts_4peaks_df['MP'] >= 600)]\n",
        "at_least_400_min_pts = at_least_400_min_pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_ts = import_adjts_4peaks_df[(import_adjts_4peaks_df['MP'] >= 600)]\n",
        "at_least_400_min_ts = at_least_400_min_ts.reset_index(drop=True)\n",
        "\n",
        "sorted_3pts = at_least_400_min_pts.copy()\n",
        "sorted_3pts.insert(6, \"TS+\", at_least_400_min_ts['PeakValue'])\n",
        "sorted_3pts = sorted_3pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3pts = sorted_3pts.sort_values('PTS', ascending=False)\n",
        "sorted_3pts = sorted_3pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_3pts = sorted_3pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3pts['PTS'] = sorted_3pts['PTS'].round(2)\n",
        "sorted_3pts['TS+'] = sorted_3pts['TS+'].round(2)\n",
        "\n",
        "sorted_3pts = sorted_3pts.dropna()\n",
        "\n",
        "print(sorted_3pts)\n",
        "\n",
        "sorted_3pts.to_csv(\"Four_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 5\n",
        "at_least_800_min_pts = import_adjpts_fivepeaks_df[(import_adjpts_fivepeaks_df['MP'] >= 800)]\n",
        "at_least_800_min_ts = import_adjts_fivepeaks_df[(import_adjts_fivepeaks_df['MP'] >= 800)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Five_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 6\n",
        "at_least_800_min_pts = import_adjpts_6peaks_df[(import_adjpts_6peaks_df['MP'] >= 1000)]\n",
        "at_least_800_min_ts = import_adjts_6peaks_df[(import_adjts_6peaks_df['MP'] >= 1000)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Six_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 7\n",
        "at_least_800_min_pts = import_adjpts_7peaks_df[(import_adjpts_7peaks_df['MP'] >= 1200)]\n",
        "at_least_800_min_ts = import_adjts_7peaks_df[(import_adjts_7peaks_df['MP'] >= 1200)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Seven_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 8\n",
        "at_least_1500_min_pts = import_adjpts_eightpeaks_df[(import_adjpts_eightpeaks_df['MP'] >= 1500)]\n",
        "at_least_1500_min_ts = import_adjts_eightpeaks_df[(import_adjts_eightpeaks_df['MP'] >= 1500)]\n",
        "\n",
        "\n",
        "sorted_8pts = at_least_1500_min_pts.copy()\n",
        "sorted_8pts.insert(6, \"TS+\", at_least_1500_min_ts['PeakValue'])\n",
        "sorted_8pts = sorted_8pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_8pts = sorted_8pts.sort_values('PTS', ascending=False)\n",
        "sorted_8pts = sorted_8pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_8pts = sorted_8pts.reindex(columns=columns_titles)\n",
        "sorted_8pts = sorted_8pts.reset_index(drop=True)\n",
        "\n",
        "sorted_8pts['PTS'] = sorted_8pts['PTS'].round(2)\n",
        "sorted_8pts['TS+'] = sorted_8pts['TS+'].round(2)\n",
        "\n",
        "sorted_8pts = sorted_8pts.dropna()\n",
        "\n",
        "\n",
        "print(sorted_8pts)\n",
        "\n",
        "sorted_8pts.to_csv(\"Eight_Year_scoring_Playoff_Peaks_1500min.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 9\n",
        "at_least_1500_min_pts = import_adjpts_9peaks_df[(import_adjpts_9peaks_df['MP'] >= 1700)]\n",
        "at_least_1500_min_ts = import_adjts_9peaks_df[(import_adjts_9peaks_df['MP'] >= 1700)]\n",
        "\n",
        "\n",
        "sorted_9pts = at_least_1500_min_pts.copy()\n",
        "sorted_9pts.insert(6, \"TS+\", at_least_1500_min_ts['PeakValue'])\n",
        "sorted_9pts = sorted_9pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_9pts = sorted_9pts.sort_values('PTS', ascending=False)\n",
        "sorted_9pts = sorted_9pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_9pts = sorted_9pts.reindex(columns=columns_titles)\n",
        "sorted_9pts = sorted_9pts.reset_index(drop=True)\n",
        "\n",
        "sorted_9pts['PTS'] = sorted_9pts['PTS'].round(2)\n",
        "sorted_9pts['TS+'] = sorted_9pts['TS+'].round(2)\n",
        "\n",
        "sorted_9pts = sorted_9pts.dropna()\n",
        "\n",
        "\n",
        "print(sorted_9pts)\n",
        "\n",
        "sorted_9pts.to_csv(\"Nine_Year_scoring_Playoff_Peaks_1700min.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 10\n",
        "at_least_2000_min_pts = import_adjpts_10peaks_df[(import_adjpts_10peaks_df['MP'] >= 2000)]\n",
        "at_least_2000_min_ts = import_adjts_10peaks_df[(import_adjts_10peaks_df['MP'] >= 2000)]\n",
        "\n",
        "\n",
        "sorted_10pts = at_least_2000_min_pts.copy()\n",
        "sorted_10pts.insert(6, \"TS+\", at_least_2000_min_ts['PeakValue'])\n",
        "sorted_10pts = sorted_10pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_10pts = sorted_10pts.sort_values('PTS', ascending=False)\n",
        "sorted_10pts = sorted_10pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_10pts = sorted_10pts.reindex(columns=columns_titles)\n",
        "sorted_10pts = sorted_10pts.reset_index(drop=True)\n",
        "sorted_10pts['PTS'] = sorted_10pts['PTS'].round(2)\n",
        "sorted_10pts['TS+'] = sorted_10pts['TS+'].round(2)\n",
        "\n",
        "sorted_10pts = sorted_10pts.dropna()\n",
        "\n",
        "print(sorted_10pts)\n",
        "\n",
        "sorted_10pts.to_csv(\"Ten_Year_scoring_Playoff_Peaks_2000min.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OM1-1yIMN51-"
      },
      "outputs": [],
      "source": [
        "#@title Run Scoring Peaks\n",
        "\n",
        "# 2\n",
        "twoyearpeak(kd, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "twoyearpeak(kd, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('two_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 3 \n",
        "threeyearpeak(kd, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "threeyearpeak(kd, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('three_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 4 \n",
        "fouryearpeak(kd, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "fouryearpeak(kd, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('four_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 5 \n",
        "fiveyearpeak(kd, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "fiveyearpeak(kd, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('five_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 6 \n",
        "sixyearpeak(kd, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "sixyearpeak(kd, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('six_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 7 \n",
        "sevenyearpeak(kd, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "sevenyearpeak(kd, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('seven_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 8 \n",
        "eightyearpeak(kd, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "eightyearpeak(kd, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('eight_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "# 9 \n",
        "nineyearpeak(kd, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "nineyearpeak(kd, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('nine_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NSk6GkswOR-k"
      },
      "outputs": [],
      "source": [
        "#@title Import Scoring Peaks\n",
        "\n",
        "# 2\n",
        "import_adjpts_twopeaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_twopeaks_df = import_adjpts_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_twopeaks_df = pd.read_csv('two_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_twopeaks_df = import_adjts_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_twopeaks_df['TeamColor'] = import_adjpts_twopeaks_df['Team'].map(team_colors)\n",
        "import_adjts_twopeaks_df['TeamColor'] = import_adjts_twopeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_threepeaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_threepeaks_df = import_adjpts_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_threepeaks_df = pd.read_csv('three_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_threepeaks_df = import_adjts_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_threepeaks_df['TeamColor'] = import_adjpts_threepeaks_df['Team'].map(team_colors)\n",
        "import_adjts_threepeaks_df['TeamColor'] = import_adjts_threepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_4peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_4peaks_df = import_adjpts_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_4peaks_df = pd.read_csv('four_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_4peaks_df = import_adjts_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_4peaks_df['TeamColor'] = import_adjpts_4peaks_df['Team'].map(team_colors)\n",
        "import_adjts_4peaks_df['TeamColor'] = import_adjts_4peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_fivepeaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_fivepeaks_df = import_adjpts_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_fivepeaks_df = pd.read_csv('five_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_fivepeaks_df = import_adjts_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_fivepeaks_df['TeamColor'] = import_adjpts_fivepeaks_df['Team'].map(team_colors)\n",
        "import_adjts_fivepeaks_df['TeamColor'] = import_adjts_fivepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_6peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_6peaks_df = import_adjpts_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_6peaks_df = pd.read_csv('six_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_6peaks_df = import_adjts_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjts_6peaks_df['TeamColor'] = import_adjts_6peaks_df['Team'].map(team_colors)\n",
        "import_adjpts_6peaks_df['TeamColor'] = import_adjpts_6peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_7peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_7peaks_df = import_adjpts_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_7peaks_df = pd.read_csv('seven_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_7peaks_df = import_adjts_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjts_7peaks_df['TeamColor'] = import_adjts_7peaks_df['Team'].map(team_colors)\n",
        "import_adjpts_7peaks_df['TeamColor'] = import_adjpts_7peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_eightpeaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_eightpeaks_df = import_adjpts_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_eightpeaks_df = pd.read_csv('eight_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_eightpeaks_df = import_adjts_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_eightpeaks_df['TeamColor'] = import_adjpts_eightpeaks_df['Team'].map(team_colors)\n",
        "import_adjts_eightpeaks_df['TeamColor'] = import_adjts_eightpeaks_df['Team'].map(team_colors)\n",
        "\n",
        "\n",
        "import_adjpts_ninepeaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_ninepeaks_df = import_adjpts_ninepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_ninepeaks_df = pd.read_csv('nine_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_ninepeaks_df = import_adjts_ninepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_eightpeaks_df['TeamColor'] = import_adjpts_eightpeaks_df['Team'].map(team_colors)\n",
        "import_adjts_eightpeaks_df['TeamColor'] = import_adjts_eightpeaks_df['Team'].map(team_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JYL1WiG4OW5j"
      },
      "outputs": [],
      "source": [
        "#@title Output Scoring Peaks\n",
        "\n",
        "print(\"TWO\")\n",
        "\n",
        "# 2\n",
        "at_least_400_min_2pts = import_adjpts_twopeaks_df[(import_adjpts_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2pts = at_least_400_min_2pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_2ts = import_adjts_twopeaks_df[(import_adjts_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2ts = at_least_400_min_2ts.reset_index(drop=True)\n",
        "\n",
        "sorted_2pts = at_least_400_min_2pts.copy()\n",
        "sorted_2pts.insert(6, \"TS+\", at_least_400_min_2ts['PeakValue'])\n",
        "sorted_2pts = sorted_2pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_2pts = sorted_2pts.sort_values('PTS', ascending=False)\n",
        "sorted_2pts = sorted_2pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_2pts = sorted_2pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_2pts['PTS'] = sorted_2pts['PTS'].round(2)\n",
        "sorted_2pts['TS+'] = sorted_2pts['TS+'].round(2)\n",
        "\n",
        "sorted_2pts = sorted_2pts.dropna()\n",
        "\n",
        "print(sorted_2pts)\n",
        "\n",
        "sorted_2pts.to_csv(\"Two_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "print(\"THREE\")\n",
        "\n",
        "# 3\n",
        "at_least_400_min_pts = import_adjpts_threepeaks_df[(import_adjpts_threepeaks_df['MP'] >= 400)]\n",
        "at_least_400_min_pts = at_least_400_min_pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_ts = import_adjts_threepeaks_df[(import_adjts_threepeaks_df['MP'] >= 400)]\n",
        "at_least_400_min_ts = at_least_400_min_ts.reset_index(drop=True)\n",
        "\n",
        "sorted_3pts = at_least_400_min_pts.copy()\n",
        "sorted_3pts.insert(6, \"TS+\", at_least_400_min_ts['PeakValue'])\n",
        "sorted_3pts = sorted_3pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3pts = sorted_3pts.sort_values('PTS', ascending=False)\n",
        "sorted_3pts = sorted_3pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_3pts = sorted_3pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3pts['PTS'] = sorted_3pts['PTS'].round(2)\n",
        "sorted_3pts['TS+'] = sorted_3pts['TS+'].round(2)\n",
        "\n",
        "sorted_3pts = sorted_3pts.dropna()\n",
        "\n",
        "print(sorted_3pts)\n",
        "\n",
        "sorted_3pts.to_csv(\"Three_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "print(\"FOUR\")\n",
        "\n",
        "\n",
        "\n",
        "# 4\n",
        "at_least_400_min_pts = import_adjpts_4peaks_df[(import_adjpts_4peaks_df['MP'] >= 600)]\n",
        "at_least_400_min_pts = at_least_400_min_pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_ts = import_adjts_4peaks_df[(import_adjts_4peaks_df['MP'] >= 600)]\n",
        "at_least_400_min_ts = at_least_400_min_ts.reset_index(drop=True)\n",
        "\n",
        "sorted_3pts = at_least_400_min_pts.copy()\n",
        "sorted_3pts.insert(6, \"TS+\", at_least_400_min_ts['PeakValue'])\n",
        "sorted_3pts = sorted_3pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3pts = sorted_3pts.sort_values('PTS', ascending=False)\n",
        "sorted_3pts = sorted_3pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_3pts = sorted_3pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3pts['PTS'] = sorted_3pts['PTS'].round(2)\n",
        "sorted_3pts['TS+'] = sorted_3pts['TS+'].round(2)\n",
        "\n",
        "sorted_3pts = sorted_3pts.dropna()\n",
        "\n",
        "print(sorted_3pts)\n",
        "\n",
        "sorted_3pts.to_csv(\"Four_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "print(\"FIVE\")\n",
        "\n",
        "# 5\n",
        "at_least_800_min_pts = import_adjpts_fivepeaks_df[(import_adjpts_fivepeaks_df['MP'] >= 800)]\n",
        "at_least_800_min_ts = import_adjts_fivepeaks_df[(import_adjts_fivepeaks_df['MP'] >= 800)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Five_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "print(\"SIX\")\n",
        "\n",
        "# 6\n",
        "at_least_800_min_pts = import_adjpts_6peaks_df[(import_adjpts_6peaks_df['MP'] >= 1000)]\n",
        "at_least_800_min_ts = import_adjts_6peaks_df[(import_adjts_6peaks_df['MP'] >= 1000)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Six_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "print(\"SEVEN\")\n",
        "\n",
        "# 7\n",
        "at_least_800_min_pts = import_adjpts_7peaks_df[(import_adjpts_7peaks_df['MP'] >= 1200)]\n",
        "at_least_800_min_ts = import_adjts_7peaks_df[(import_adjts_7peaks_df['MP'] >= 1200)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Seven_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "print(\"EIGHT\")\n",
        "\n",
        "# 8\n",
        "at_least_1500_min_pts = import_adjpts_eightpeaks_df[(import_adjpts_eightpeaks_df['MP'] >= 1500)]\n",
        "at_least_1500_min_ts = import_adjts_eightpeaks_df[(import_adjts_eightpeaks_df['MP'] >= 1500)]\n",
        "\n",
        "\n",
        "sorted_8pts = at_least_1500_min_pts.copy()\n",
        "sorted_8pts.insert(6, \"TS+\", at_least_1500_min_ts['PeakValue'])\n",
        "sorted_8pts = sorted_8pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_8pts = sorted_8pts.sort_values('PTS', ascending=False)\n",
        "sorted_8pts = sorted_8pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_8pts = sorted_8pts.reindex(columns=columns_titles)\n",
        "sorted_8pts = sorted_8pts.reset_index(drop=True)\n",
        "\n",
        "sorted_8pts['PTS'] = sorted_8pts['PTS'].round(2)\n",
        "sorted_8pts['TS+'] = sorted_8pts['TS+'].round(2)\n",
        "\n",
        "sorted_8pts = sorted_8pts.dropna()\n",
        "\n",
        "\n",
        "print(sorted_8pts)\n",
        "\n",
        "sorted_8pts.to_csv(\"Eight_Year_scoring_Playoff_Peaks_1500min.csv\", index=False)\n",
        "\n",
        "print(\"NINE\")\n",
        "\n",
        "# 9\n",
        "at_least_1500_min_pts = import_adjpts_ninepeaks_df[(import_adjpts_ninepeaks_df['MP'] >= 1500)]\n",
        "at_least_1500_min_ts = import_adjts_ninepeaks_df[(import_adjts_ninepeaks_df['MP'] >= 1500)]\n",
        "\n",
        "\n",
        "sorted_8pts = at_least_1500_min_pts.copy()\n",
        "sorted_8pts.insert(6, \"TS+\", at_least_1500_min_ts['PeakValue'])\n",
        "sorted_8pts = sorted_8pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_8pts = sorted_8pts.sort_values('PTS', ascending=False)\n",
        "sorted_8pts = sorted_8pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_8pts = sorted_8pts.reindex(columns=columns_titles)\n",
        "sorted_8pts = sorted_8pts.reset_index(drop=True)\n",
        "\n",
        "sorted_8pts['PTS'] = sorted_8pts['PTS'].round(2)\n",
        "sorted_8pts['TS+'] = sorted_8pts['TS+'].round(2)\n",
        "\n",
        "sorted_8pts = sorted_8pts.dropna()\n",
        "\n",
        "\n",
        "print(sorted_8pts)\n",
        "\n",
        "sorted_8pts.to_csv(\"Eight_Year_scoring_Playoff_Peaks_1500min.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9leRo7p78g-t"
      },
      "source": [
        "**BPM PEAK FILES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w_maV6Oy-7B1"
      },
      "outputs": [],
      "source": [
        "#@title Run BPM Peaks\n",
        "twoyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('two_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "twoyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('two_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "# 3\n",
        "threeyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('three_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "threeyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('three_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#4\n",
        "fouryearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('four_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "fouryearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('four_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#5\n",
        "fiveyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('five_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "fiveyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('five_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#6\n",
        "sixyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('six_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "sixyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('six_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#7\n",
        "sevenyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('seven_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "sevenyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#\n",
        "eightyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('eight_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "eightyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#9\n",
        "nineyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('nine_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "nineyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#10\n",
        "tenyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('ten_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "tenyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XMGgOIAq70p1"
      },
      "outputs": [],
      "source": [
        "#@title Import BPM Peaks\n",
        "import_bpm_twopeaks_df = pd.read_csv('two_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_twopeaks_df = import_bpm_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_twopeaks_df = pd.read_csv('two_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_twopeaks_df = import_obpm_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_twopeaks_df['TeamColor'] = import_bpm_twopeaks_df['Team'].map(team_colors)\n",
        "import_obpm_twopeaks_df['TeamColor'] = import_obpm_twopeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_threepeaks_df = pd.read_csv('three_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_threepeaks_df = import_bpm_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_threepeaks_df = pd.read_csv('three_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_threepeaks_df = import_obpm_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_threepeaks_df['TeamColor'] = import_bpm_threepeaks_df['Team'].map(team_colors)\n",
        "import_obpm_threepeaks_df['TeamColor'] = import_obpm_threepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_4peaks_df = pd.read_csv('four_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_4peaks_df = import_bpm_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_4peaks_df = pd.read_csv('four_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_4peaks_df = import_obpm_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_4peaks_df['TeamColor'] = import_bpm_4peaks_df['Team'].map(team_colors)\n",
        "import_obpm_4peaks_df['TeamColor'] = import_obpm_4peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_fivepeaks_df = pd.read_csv('five_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_fivepeaks_df = import_bpm_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_fivepeaks_df = pd.read_csv('five_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_fivepeaks_df = import_obpm_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_fivepeaks_df['TeamColor'] = import_bpm_fivepeaks_df['Team'].map(team_colors)\n",
        "import_obpm_fivepeaks_df['TeamColor'] = import_obpm_fivepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_6peaks_df = pd.read_csv('six_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_6peaks_df = import_bpm_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_6peaks_df = pd.read_csv('six_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_6peaks_df = import_obpm_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_obpm_6peaks_df['TeamColor'] = import_obpm_6peaks_df['Team'].map(team_colors)\n",
        "import_bpm_6peaks_df['TeamColor'] = import_bpm_6peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_7peaks_df = pd.read_csv('seven_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_7peaks_df = import_bpm_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_7peaks_df = pd.read_csv('seven_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_7peaks_df = import_obpm_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_obpm_7peaks_df['TeamColor'] = import_obpm_7peaks_df['Team'].map(team_colors)\n",
        "import_bpm_7peaks_df['TeamColor'] = import_bpm_7peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_eightpeaks_df = pd.read_csv('eight_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_eightpeaks_df = import_bpm_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_eightpeaks_df = pd.read_csv('eight_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_eightpeaks_df = import_obpm_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_eightpeaks_df['TeamColor'] = import_bpm_eightpeaks_df['Team'].map(team_colors)\n",
        "import_obpm_eightpeaks_df['TeamColor'] = import_obpm_eightpeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_9peaks_df = pd.read_csv('nine_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_9peaks_df = import_bpm_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_9peaks_df = pd.read_csv('nine_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_9peaks_df = import_obpm_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_9peaks_df['TeamColor'] = import_bpm_9peaks_df['Team'].map(team_colors)\n",
        "import_obpm_9peaks_df['TeamColor'] = import_obpm_9peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_10peaks_df = pd.read_csv('ten_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_10peaks_df = import_bpm_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_10peaks_df = pd.read_csv('ten_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_10peaks_df = import_obpm_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_10peaks_df['TeamColor'] = import_bpm_10peaks_df['Team'].map(team_colors)\n",
        "import_obpm_10peaks_df['TeamColor'] = import_obpm_10peaks_df['Team'].map(team_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7g56Mu1U8gL7"
      },
      "outputs": [],
      "source": [
        "#@title Output BPM Peaks\n",
        "\n",
        "at_least_400_min_2bpm = import_bpm_twopeaks_df[(import_bpm_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2bpm = at_least_400_min_2bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_2obpm = import_obpm_twopeaks_df[(import_obpm_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2obpm = at_least_400_min_2obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_2bpm = at_least_400_min_2bpm.copy()\n",
        "sorted_2bpm.insert(6, \"OBPM\", at_least_400_min_2obpm['PeakValue'])\n",
        "sorted_2bpm = sorted_2bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_2bpm = sorted_2bpm.sort_values('BPM', ascending=False)\n",
        "sorted_2bpm = sorted_2bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_2bpm = sorted_2bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_2bpm['BPM'] = sorted_2bpm['BPM'].round(2)\n",
        "sorted_2bpm['OBPM'] = sorted_2bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_2bpm = sorted_2bpm.dropna()\n",
        "\n",
        "print(sorted_2bpm)\n",
        "\n",
        "sorted_2bpm.to_csv(\"Two_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 3 year adjusted playoff scoring peaks (>= 400 min) Output File\n",
        "\n",
        "# 400 minutes filter\n",
        "at_least_400_min_bpm = import_bpm_threepeaks_df[(import_bpm_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_bpm = at_least_400_min_bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_obpm = import_obpm_threepeaks_df[(import_obpm_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_obpm = at_least_400_min_obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_3bpm = at_least_400_min_bpm.copy()\n",
        "sorted_3bpm.insert(6, \"OBPM\", at_least_400_min_obpm['PeakValue'])\n",
        "sorted_3bpm = sorted_3bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.sort_values('BPM', ascending=False)\n",
        "sorted_3bpm = sorted_3bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_3bpm = sorted_3bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3bpm['BPM'] = sorted_3bpm['BPM'].round(2)\n",
        "sorted_3bpm['OBPM'] = sorted_3bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.dropna()\n",
        "\n",
        "print(sorted_3bpm)\n",
        "\n",
        "sorted_3bpm.to_csv(\"Three_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 4 year adjusted playoff scoring peaks (>= 600 min) Output File\n",
        "\n",
        "# 400 minutes filter\n",
        "at_least_400_min_bpm = import_bpm_4peaks_df[(import_bpm_4peaks_df['MP'] >= 300)]\n",
        "at_least_400_min_bpm = at_least_400_min_bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_obpm = import_obpm_4peaks_df[(import_obpm_4peaks_df['MP'] >= 300)]\n",
        "at_least_400_min_obpm = at_least_400_min_obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_3bpm = at_least_400_min_bpm.copy()\n",
        "sorted_3bpm.insert(6, \"OBPM\", at_least_400_min_obpm['PeakValue'])\n",
        "sorted_3bpm = sorted_3bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.sort_values('BPM', ascending=False)\n",
        "sorted_3bpm = sorted_3bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_3bpm = sorted_3bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3bpm['BPM'] = sorted_3bpm['BPM'].round(2)\n",
        "sorted_3bpm['OBPM'] = sorted_3bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.dropna()\n",
        "\n",
        "print(sorted_3bpm)\n",
        "\n",
        "sorted_3bpm.to_csv(\"Four_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 5 year adjusted playoff scoring peaks (>=800 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_fivepeaks_df[(import_bpm_fivepeaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_fivepeaks_df[(import_obpm_fivepeaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Five_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 6 year adjusted playoff scoring peaks (>=1000 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_6peaks_df[(import_bpm_6peaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_6peaks_df[(import_obpm_6peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Six_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 7 year adjusted playoff scoring peaks (>=1200 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_7peaks_df[(import_bpm_7peaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_7peaks_df[(import_obpm_7peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Seven_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 8 year adjusted playoff scoring peaks (>=1500 min) Output File\n",
        "\n",
        "at_least_1500_min_bpm = import_bpm_eightpeaks_df[(import_bpm_eightpeaks_df['MP'] >= 300)]\n",
        "at_least_1500_min_obpm = import_obpm_eightpeaks_df[(import_obpm_eightpeaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_8bpm = at_least_1500_min_bpm.copy()\n",
        "sorted_8bpm.insert(6, \"OBPM\", at_least_1500_min_obpm['PeakValue'])\n",
        "sorted_8bpm = sorted_8bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_8bpm = sorted_8bpm.sort_values('BPM', ascending=False)\n",
        "sorted_8bpm = sorted_8bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_8bpm = sorted_8bpm.reindex(columns=columns_titles)\n",
        "sorted_8bpm = sorted_8bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_8bpm['BPM'] = sorted_8bpm['BPM'].round(2)\n",
        "sorted_8bpm['OBPM'] = sorted_8bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_8bpm = sorted_8bpm.dropna()\n",
        "\n",
        "\n",
        "print(sorted_8bpm)\n",
        "\n",
        "sorted_8bpm.to_csv(\"Eight_Year_BPM_Playoff_Peaks_1500min.csv\", index=False)\n",
        "\n",
        "#@title 9 year adjusted playoff scoring peaks (>=1700 min) Output File\n",
        "\n",
        "at_least_1500_min_bpm = import_bpm_9peaks_df[(import_bpm_9peaks_df['MP'] >= 300)]\n",
        "at_least_1500_min_obpm = import_obpm_9peaks_df[(import_obpm_9peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_9bpm = at_least_1500_min_bpm.copy()\n",
        "sorted_9bpm.insert(6, \"OBPM\", at_least_1500_min_obpm['PeakValue'])\n",
        "sorted_9bpm = sorted_9bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_9bpm = sorted_9bpm.sort_values('BPM', ascending=False)\n",
        "sorted_9bpm = sorted_9bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_9bpm = sorted_9bpm.reindex(columns=columns_titles)\n",
        "sorted_9bpm = sorted_9bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_9bpm['BPM'] = sorted_9bpm['BPM'].round(2)\n",
        "sorted_9bpm['OBPM'] = sorted_9bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_9bpm = sorted_9bpm.dropna()\n",
        "\n",
        "\n",
        "print(sorted_9bpm)\n",
        "\n",
        "sorted_9bpm.to_csv(\"Nine_Year_BPM_Playoff_Peaks_1700min.csv\", index=False)\n",
        "\n",
        "#@title 10 year adjusted playoff scoring peaks (>=2000 min) Output File\n",
        "\n",
        "at_least_2000_min_bpm = import_bpm_10peaks_df[(import_bpm_10peaks_df['MP'] >= 300)]\n",
        "at_least_2000_min_obpm = import_obpm_10peaks_df[(import_obpm_10peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_10bpm = at_least_2000_min_bpm.copy()\n",
        "sorted_10bpm.insert(6, \"OBPM\", at_least_2000_min_obpm['PeakValue'])\n",
        "sorted_10bpm = sorted_10bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_10bpm = sorted_10bpm.sort_values('BPM', ascending=False)\n",
        "sorted_10bpm = sorted_10bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_10bpm = sorted_10bpm.reindex(columns=columns_titles)\n",
        "sorted_10bpm = sorted_10bpm.reset_index(drop=True)\n",
        "sorted_10bpm['BPM'] = sorted_10bpm['BPM'].round(2)\n",
        "sorted_10bpm['OBPM'] = sorted_10bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_10bpm = sorted_10bpm.dropna()\n",
        "\n",
        "print(sorted_10bpm)\n",
        "\n",
        "sorted_10bpm.to_csv(\"Ten_Year_BPM_Playoff_Peaks_2000min.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjnG8CpstskX"
      },
      "source": [
        "**SMALL USE CASE PEAK FUNCTION DEFINITIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oAcCFD7_sNPw"
      },
      "outputs": [],
      "source": [
        "#@title 2 year fragmented peaks function\n",
        "\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '4231'\n",
        "def fragtwoyearpeak(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes played\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = [0, 0]\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # store team player played on a season and 2 seasons ago in case they change teams during peak 3 years.\n",
        "    prevyear = 0\n",
        "    prevYearTeam = 0\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevYearTeam = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prevyear = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 2 consecutive seasons (not reached after 2 rows of a player is found)\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear, present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+2 and len(indexlist) >=2:\n",
        "            two_seasons_count = player['Year']\n",
        "\n",
        "          # move present value to previous year's value\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=2:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP']\n",
        "            if (old_team == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_two_year_peak_val, running_min]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_two_year_peak_val, running_min]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "            outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "            two_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jTUzLULMfPWF"
      },
      "outputs": [],
      "source": [
        "#@title 2 year peaks (manual data) function\n",
        "\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '4231'\n",
        "def twoyearpeak_manual_data(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # store the team a player played with 1 season and 2 seasons ago in case they change teams during peak 3 years.\n",
        "\n",
        "    prevyear = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear, present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            two_seasons_count = player['Year']\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=2:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_two_year_peak_val, running_min]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "            outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "            two_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UmPc3p1yf8yn"
      },
      "outputs": [],
      "source": [
        "#@title 3 year peaks (manual data) function\n",
        "\n",
        "# def threeyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 3 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 3 year stretches of 'valuestring' AND the listed years from each 3 year stretch + minutes played across the 3 seasons.\n",
        "# EX: threeyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-20', 'Kris Middleton', 'MIL' '23.32', '7120'\n",
        "def threeyearpeak_manual_data(df, valuestring):\n",
        "  three_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue and minutes\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    three_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # previous two years; e.g. 2014, 2015 before 2016. 2016, 2019 if these were the two most recent seasons for a player before 2020.\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "\n",
        "    indexlist = []\n",
        "    running_three_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_three_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+2 and len(indexlist) >=3:\n",
        "            if (prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev2year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}'.format(prev2year, prevyear, present_year)\n",
        "\n",
        "          if three_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            three_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          three_seasons_count = three_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=3:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_three_year_peak_val, running_min]], columns=cols)\n",
        "            three_year_peak = three_year_peak.append(df_temp)\n",
        "            outfile = f\"three_year_peak_{valuestring}_data.csv\"\n",
        "            three_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rmsFRVZVdwVO"
      },
      "outputs": [],
      "source": [
        "#@title 4 year peaks (manual data) function\n",
        "\n",
        "# returns a dataframe containing 4 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 4 year stretches of 'valuestring' AND the listed years from each 4 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 4 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-19', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def fouryearpeak_manual_data(df, valuestring):\n",
        "  four_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    four_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_four_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_four_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+3 and len(indexlist) >=4:\n",
        "            if (prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev3year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}'.format(prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if four_seasons_count == original_year+4 and len(indexlist) >=4:\n",
        "            four_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          four_seasons_count = four_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=4:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_four_year_peak_val, running_min]], columns=cols)\n",
        "            four_year_peak = four_year_peak.append(df_temp)\n",
        "            outfile = f\"four_year_peak_{valuestring}_data.csv\"\n",
        "            four_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EnUFxmsuggQE"
      },
      "outputs": [],
      "source": [
        "#@title 5 year peaks (manual data) function\n",
        "\n",
        "# def fiveyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 5 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 5 year stretches of 'valuestring' AND the listed years from each 5 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 5 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def fiveyearpeak_manual_data(df, valuestring):\n",
        "  five_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    five_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_five_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_five_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+4 and len(indexlist) >=5:\n",
        "            if (prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev4year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}'.format(prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if five_seasons_count == original_year+5 and len(indexlist) >=5:\n",
        "            five_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          five_seasons_count = five_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=5:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_five_year_peak_val, running_min]], columns=cols)\n",
        "            five_year_peak = five_year_peak.append(df_temp)\n",
        "            outfile = f\"five_year_peak_{valuestring}_data.csv\"\n",
        "            five_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1JJMMFhYDuR9"
      },
      "outputs": [],
      "source": [
        "#@title 6 year peaks (manual data) function\n",
        "\n",
        "# def sixyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 6 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 6 year stretches of 'valuestring' AND the listed years from each 6 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 6 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-21', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def sixyearpeak_manual_data(df, valuestring):\n",
        "  six_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    six_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_six_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_six_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+5 and len(indexlist) >=6:\n",
        "            if (prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev5year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}'.format(prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if six_seasons_count == original_year+6 and len(indexlist) >=6:\n",
        "            six_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          six_seasons_count = six_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=6:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_six_year_peak_val, running_min]], columns=cols)\n",
        "            six_year_peak = six_year_peak.append(df_temp)\n",
        "            outfile = f\"six_year_peak_{valuestring}_data.csv\"\n",
        "            six_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "W7ekPIQA2w3W"
      },
      "outputs": [],
      "source": [
        "#@title 7 year peaks (manual data) function\n",
        "\n",
        "# def sevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def sevenyearpeak_manual_data(df, valuestring):\n",
        "  seven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    seven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_seven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_seven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+6 and len(indexlist) >=7:\n",
        "            if (prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev6year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}'.format(prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if seven_seasons_count == original_year+7 and len(indexlist) >=7:\n",
        "            seven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          seven_seasons_count = seven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=7:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_seven_year_peak_val, running_min]], columns=cols)\n",
        "            seven_year_peak = seven_year_peak.append(df_temp)\n",
        "            outfile = f\"seven_year_peak_{valuestring}_data.csv\"\n",
        "            seven_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OzJU2Mo5g8R3"
      },
      "outputs": [],
      "source": [
        "#@title 8 year peaks (manual data) function\n",
        "\n",
        "# def eightyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def eightyearpeak_manual_data(df, valuestring):\n",
        "  eight_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eight_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_eight_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_eight_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+7 and len(indexlist) >=8:\n",
        "            if (prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev7year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}'.format(prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if eight_seasons_count == original_year+8 and len(indexlist) >=8:\n",
        "            eight_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          eight_seasons_count = eight_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=8:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_eight_year_peak_val, running_min]], columns=cols)\n",
        "            eight_year_peak = eight_year_peak.append(df_temp)\n",
        "            outfile = f\"eight_year_peak_{valuestring}_data.csv\"\n",
        "            eight_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-Y1YHmAX4pbb"
      },
      "outputs": [],
      "source": [
        "#@title 9 year peaks (manual data) function\n",
        "\n",
        "# def nineyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 9 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 9 year stretches of 'valuestring' AND the listed years from each 9 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 9 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def nineyearpeak_manual_data(df, valuestring):\n",
        "  nine_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    nine_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_nine_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_nine_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+8 and len(indexlist) >=9:\n",
        "            if (prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev8year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if nine_seasons_count == original_year+9 and len(indexlist) >=9:\n",
        "            nine_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          nine_seasons_count = nine_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=9:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_nine_year_peak_val, running_min]], columns=cols)\n",
        "            nine_year_peak = nine_year_peak.append(df_temp)\n",
        "            outfile = f\"nine_year_peak_{valuestring}_data.csv\"\n",
        "            nine_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qAP9lFfXhn3q"
      },
      "outputs": [],
      "source": [
        "#@title 10 year peaks (manual data) function\n",
        "\n",
        "# def tenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def tenyearpeak_manual_data(df, valuestring):\n",
        "  ten_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # 9 seasons ago's peakvalue\n",
        "    prev_9back = 0\n",
        "    prev_9min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    ten_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "    prev9year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_ten_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min + prev_9min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_ten_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)) + (prev_9back * (prev_9min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev9year = 0\n",
        "            prev_9back = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            prev_9min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+9 and len(indexlist) >=10:\n",
        "            if (prev9year == (prev8year-1) and prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev9year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev9year, prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if ten_seasons_count == original_year+10 and len(indexlist) >=10:\n",
        "            ten_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          ten_seasons_count = ten_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=10:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_ten_year_peak_val, running_min]], columns=cols)\n",
        "            ten_year_peak = ten_year_peak.append(df_temp)\n",
        "            outfile = f\"ten_year_peak_{valuestring}_data.csv\"\n",
        "            ten_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TinbWijiH-SL"
      },
      "outputs": [],
      "source": [
        "#@title 11 year peaks (manual data) function\n",
        "\n",
        "# def elevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 11 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 11 year stretches of 'valuestring' AND the listed years from each 11 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 11 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-21', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def elevenyearpeak_manual_data(df, valuestring):\n",
        "  eleven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # 9 seasons ago's peakvalue\n",
        "    prev_9back = 0\n",
        "    prev_9min = 0\n",
        "\n",
        "    prev_10back = 0\n",
        "    prev_10min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eleven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "    prev9year = 0\n",
        "    prev10year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_eleven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min + prev_9min + prev_10min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_eleven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)) + (prev_9back * (prev_9min / running_min))+ (prev_10back * (prev_10min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev9year = 0\n",
        "            prev10year = 0\n",
        "            prev_10back = 0\n",
        "            prev_9back = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            prev_9min = 0\n",
        "            prev_10min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+10 and len(indexlist) >=11:\n",
        "            if (prev10year == (prev9year-1) and prev9year == (prev8year-1) and prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev10year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev10year, prev9year, prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if eleven_seasons_count == original_year+11 and len(indexlist) >=11:\n",
        "            eleven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_10back = prev_9back\n",
        "            prev_10min = prev_9min\n",
        "            prev10year = prev9year\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_10back = prev_9back\n",
        "            prev_10min = prev_9min\n",
        "            prev10year = prev9year\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          eleven_seasons_count = eleven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=11:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_eleven_year_peak_val, running_min]], columns=cols)\n",
        "            eleven_year_peak = eleven_year_peak.append(df_temp)\n",
        "            outfile = f\"eleven_year_peak_{valuestring}_data.csv\"\n",
        "            eleven_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape NBA playoffs series possession data\n",
        "def scrape_nba_player_series_data(url, player, player_ref):\n",
        "                       \n",
        "  wd.get(url)   \n",
        "  html = wd.page_source\n",
        "  soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "  for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'div_other_scores'})\n",
        "          hrefs = second_div.findAll('td', attrs={'class': 'right gamelink'})\n",
        "          hrefs = str(hrefs)\n",
        "          ref_urls = re.findall(r'/\\d+\\w+\\D\\w+', hrefs)\n",
        "          urls = []\n",
        "          for ref_url in ref_urls:\n",
        "            ref_url = \"https://www.basketball-reference.com/boxscores/pbp\" + ref_url\n",
        "            urls.append(ref_url)\n",
        "  for game_url in urls:\n",
        "\n",
        "    wd.get(game_url)   \n",
        "    html = wd.page_source\n",
        "    soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "    for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'all_pbp'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'pbp'})\n",
        "            body = first_table.find('tbody')\n",
        "    # grab rows\n",
        "    rows = body.findAll('tr')[0:]\n",
        "\n",
        "    total_poss = 0\n",
        "    player_out_wait = 0\n",
        "    beg_q = 0\n",
        "    extra_poss = 0\n",
        "    non_shooting = 0\n",
        "\n",
        "\n",
        "    possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "    fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "    player_out = [f'enters the game for <a href=\"{player_ref}\">{player}']\n",
        "    player_in = [f'{player}']\n",
        "\n",
        "    hes_back_but_subtly = [f'{player}</a> misses 2-pt']\n",
        "    for row in rows:\n",
        "      row = str(row)\n",
        "\n",
        "\n",
        "      if player_out_wait == 1:\n",
        "        if f'{player}</a> misses 2-pt' in row:\n",
        "          total_poss = total_poss + extra_poss\n",
        "          extra_poss = 0\n",
        "          player_out_wait = 0\n",
        "          beg_q = 0\n",
        "\n",
        "      if 'Q' in row:\n",
        "        beg_q = 1\n",
        "\n",
        "      if any(iny in row for iny in player_in):\n",
        "        player_out_wait = 0\n",
        "      if any(outy in row for outy in player_out):\n",
        "        player_out_wait = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in fts_no_shooting_foul) and player_out_wait == 0 and non_shooting == 1):\n",
        "        total_poss = total_poss + 1\n",
        "\n",
        "      if ('foul' in row and 'Shooting' not in row):\n",
        "        non_shooting = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "        total_poss = total_poss + 1\n",
        "        non_shooting = 0\n",
        "      \n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 1 and beg_q == 1):\n",
        "        extra_poss = extra_poss + 1\n",
        "        non_shooting = 0\n",
        "      \n",
        "    print(\"Missing Possessions\")\n",
        "    print(total_poss/2)\n",
        "\n",
        "    #@title Default possessions\n",
        "\n",
        "    total_poss = 0\n",
        "    player_out_wait = 0\n",
        "    beg_q = 0\n",
        "    extra_poss = 0\n",
        "    non_shooting = 0\n",
        "\n",
        "\n",
        "    possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "    fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "    player_out = [f'enters the game for <a href=\"{player_ref}\">{player}']\n",
        "    player_in = [f'{player}']\n",
        "\n",
        "    hes_back_but_subtly = [f'{player}</a> misses 2-pt']\n",
        "\n",
        "    for row in rows:\n",
        "      row = str(row)\n",
        "\n",
        "      if any(iny in row for iny in player_in):\n",
        "        player_out_wait = 0\n",
        "      if any(outy in row for outy in player_out):\n",
        "        player_out_wait = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "        total_poss = total_poss + 1\n",
        "      \n",
        "    print(\"Default Possessions\")\n",
        "    print(total_poss/2)\n",
        "scrape_nba_player_series_data(\"https://www.basketball-reference.com/playoffs/1999-nba-western-conference-semifinals-lakers-vs-spurs.html\", 'T. Duncan', '/players/d/duncati01.html')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ij-9Pa2Tz-Nh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "053f1494-3f3d-4c20-be8d-8a8ea18aa6c7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Possessions\n",
            "88.0\n",
            "Default Possessions\n",
            "83.0\n",
            "Missing Possessions\n",
            "83.5\n",
            "Default Possessions\n",
            "76.5\n",
            "Missing Possessions\n",
            "93.0\n",
            "Default Possessions\n",
            "87.5\n",
            "Missing Possessions\n",
            "99.0\n",
            "Default Possessions\n",
            "91.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = f\"https://www.basketball-reference.com/playoffs/1999-nba-western-conference-semifinals-lakers-vs-spurs.html\"\n",
        "wd.get(url)   \n",
        "html = wd.page_source\n",
        "soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'div_other_scores'})\n",
        "        hrefs = second_div.findAll('td', attrs={'class': 'right gamelink'})\n",
        "        print(hrefs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRykK75MSWw6",
        "outputId": "1140d03b-21dd-4d8d-aea2-209d376f38a3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<td class=\"right gamelink\">\n",
            "<a href=\"/boxscores/199905170SAS.html\">F<span class=\"no_mobile\">inal</span></a>\n",
            "</td>, <td class=\"right gamelink\">\n",
            "<a href=\"/boxscores/199905190SAS.html\">F<span class=\"no_mobile\">inal</span></a>\n",
            "</td>, <td class=\"right gamelink\">\n",
            "<a href=\"/boxscores/199905220LAL.html\">F<span class=\"no_mobile\">inal</span></a>\n",
            "</td>, <td class=\"right gamelink\">\n",
            "<a href=\"/boxscores/199905230LAL.html\">F<span class=\"no_mobile\">inal</span></a>\n",
            "</td>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hrefs = str(hrefs)\n",
        "ref_urls = re.findall(r'/\\d+\\w+\\D\\w+', hrefs)\n",
        "urls = []\n",
        "for ref_url in ref_urls:\n",
        "  ref_url = \"https://www.basketball-reference.com/boxscores/pbp\" + ref_url\n",
        "  urls.append(ref_url)\n",
        "print(urls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9iiwXNnSSl1",
        "outputId": "b6cf0c1c-86bd-4f46-f9ba-cfe32ddbbbd3"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.basketball-reference.com/boxscores/pbp/199905170SAS.html', 'https://www.basketball-reference.com/boxscores/pbp/199905190SAS.html', 'https://www.basketball-reference.com/boxscores/pbp/199905220LAL.html', 'https://www.basketball-reference.com/boxscores/pbp/199905230LAL.html']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#url = f\"https://www.basketball-reference.com/boxscores/pbp/199906250NYK.html\"\n",
        "player = 'T. Duncan'\n",
        "urls = [\"https://www.basketball-reference.com/boxscores/pbp/199905170SAS.html\", \"https://www.basketball-reference.com/boxscores/pbp/199905190SAS.html\", \"https://www.basketball-reference.com/boxscores/pbp/199905220LAL.html\", \"https://www.basketball-reference.com/boxscores/pbp/199905230LAL.html\"]\n",
        "for url in urls:\n",
        "  wd.get(url)   \n",
        "  html = wd.page_source\n",
        "  soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "  for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_pbp'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'pbp'})\n",
        "          body = first_table.find('tbody')\n",
        "  # grab rows\n",
        "  rows = body.findAll('tr')[0:]\n",
        "\n",
        "  #@title Missing possessions\n",
        "\n",
        "  total_poss = 0\n",
        "  player_out_wait = 0\n",
        "  beg_q = 0\n",
        "  extra_poss = 0\n",
        "  non_shooting = 0\n",
        "\n",
        "\n",
        "  possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "  fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "  player_out = ['enters the game for <a href=\"/players/d/duncati01.html\">T. Duncan']\n",
        "  player_in = ['T. Duncan']\n",
        "\n",
        "  hes_back_but_subtly = ['T. Duncan</a> misses 2-pt']\n",
        "\n",
        "  for row in rows:\n",
        "    row = str(row)\n",
        "\n",
        "\n",
        "    if player_out_wait == 1:\n",
        "      if 'T. Duncan</a> misses 2-pt' in row:\n",
        "        total_poss = total_poss + extra_poss\n",
        "        extra_poss = 0\n",
        "        player_out_wait = 0\n",
        "        beg_q = 0\n",
        "\n",
        "    if 'Q' in row:\n",
        "      beg_q = 1\n",
        "\n",
        "    if any(iny in row for iny in player_in):\n",
        "      player_out_wait = 0\n",
        "    if any(outy in row for outy in player_out):\n",
        "      player_out_wait = 1\n",
        "\n",
        "    if (any(end_poss in row for end_poss in fts_no_shooting_foul) and player_out_wait == 0 and non_shooting == 1):\n",
        "      total_poss = total_poss + 1\n",
        "\n",
        "    if ('foul' in row and 'Shooting' not in row):\n",
        "      non_shooting = 1\n",
        "\n",
        "    if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "      total_poss = total_poss + 1\n",
        "      non_shooting = 0\n",
        "    \n",
        "    if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 1 and beg_q == 1):\n",
        "      extra_poss = extra_poss + 1\n",
        "      non_shooting = 0\n",
        "    \n",
        "  print(\"Missing\")\n",
        "  print(total_poss/2)\n",
        "\n",
        "  #@title Default possessions\n",
        "\n",
        "  total_poss = 0\n",
        "  player_out_wait = 0\n",
        "  beg_q = 0\n",
        "  extra_poss = 0\n",
        "  non_shooting = 0\n",
        "\n",
        "\n",
        "  possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "  fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "  player_out = ['enters the game for <a href=\"/players/d/duncati01.html\">T. Duncan']\n",
        "  player_in = ['T. Duncan']\n",
        "\n",
        "  hes_back_but_subtly = ['T. Duncan</a> misses 2-pt']\n",
        "\n",
        "  for row in rows:\n",
        "    row = str(row)\n",
        "\n",
        "    if any(iny in row for iny in player_in):\n",
        "      player_out_wait = 0\n",
        "    if any(outy in row for outy in player_out):\n",
        "      player_out_wait = 1\n",
        "\n",
        "    if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "      total_poss = total_poss + 1\n",
        "    \n",
        "  print(\"Total\")\n",
        "  print(total_poss/2)"
      ],
      "metadata": {
        "id": "P-MuLGLg5gTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "1f1c3624-5f3f-4610-b173-582ccbc2ffc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing\n",
            "88.0\n",
            "Total\n",
            "83.0\n",
            "Missing\n",
            "83.5\n",
            "Total\n",
            "76.5\n",
            "Missing\n",
            "93.0\n",
            "Total\n",
            "87.5\n",
            "Missing\n",
            "99.0\n",
            "Total\n",
            "91.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Missing possessions\n",
        "\n",
        "total_poss = 0\n",
        "player_out_wait = 0\n",
        "beg_q = 0\n",
        "extra_poss = 0\n",
        "non_shooting = 0\n",
        "\n",
        "\n",
        "possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "player_out = ['enters the game for <a href=\"/players/d/duncati01.html\">T. Duncan']\n",
        "player_in = ['T. Duncan']\n",
        "\n",
        "hes_back_but_subtly = ['T. Duncan</a> misses 2-pt']\n",
        "\n",
        "for row in rows:\n",
        "  row = str(row)\n",
        "\n",
        "\n",
        "  if player_out_wait == 1:\n",
        "    if 'T. Duncan</a> misses 2-pt' in row:\n",
        "      total_poss = total_poss + extra_poss\n",
        "      extra_poss = 0\n",
        "      player_out_wait = 0\n",
        "      beg_q = 0\n",
        "\n",
        "  if 'Q' in row:\n",
        "    beg_q = 1\n",
        "\n",
        "  if any(iny in row for iny in player_in):\n",
        "    player_out_wait = 0\n",
        "  if any(outy in row for outy in player_out):\n",
        "    player_out_wait = 1\n",
        "\n",
        "  if (any(end_poss in row for end_poss in fts_no_shooting_foul) and player_out_wait == 0 and non_shooting == 1):\n",
        "    total_poss = total_poss + 1\n",
        "\n",
        "  if ('foul' in row and 'Shooting' not in row):\n",
        "    non_shooting = 1\n",
        "\n",
        "  if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "    total_poss = total_poss + 1\n",
        "    non_shooting = 0\n",
        "  \n",
        "  if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 1 and beg_q == 1):\n",
        "    extra_poss = extra_poss + 1\n",
        "    non_shooting = 0\n",
        "  \n",
        "\n",
        "print(total_poss/2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "6NvO53nr5v5O",
        "outputId": "4be444e9-1657-4008-9692-fffd5ef2e4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default possessions\n",
        "\n",
        "total_poss = 0\n",
        "player_out_wait = 0\n",
        "beg_q = 0\n",
        "extra_poss = 0\n",
        "non_shooting = 0\n",
        "\n",
        "\n",
        "possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "player_out = ['enters the game for <a href=\"/players/d/duncati01.html\">T. Duncan']\n",
        "player_in = ['T. Duncan']\n",
        "\n",
        "hes_back_but_subtly = ['T. Duncan</a> misses 2-pt']\n",
        "\n",
        "for row in rows:\n",
        "  row = str(row)\n",
        "\n",
        "  if any(iny in row for iny in player_in):\n",
        "    player_out_wait = 0\n",
        "  if any(outy in row for outy in player_out):\n",
        "    player_out_wait = 1\n",
        "\n",
        "  if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "    total_poss = total_poss + 1\n",
        "  \n",
        "\n",
        "print(total_poss/2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "MOvbODyxK5Cl",
        "outputId": "8e6a38fb-cd7c-470c-dcb0-bc5b5a0ced3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tim series\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "# 1999\n",
        "tmp_df.loc[len(tmp_df)] = ['34.2688331', '.5938', '50', 'LAL', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.349469', '.5938', '50', 'NYK', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "manu_one_on = manu_one_on.reset_index(drop=True)\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "a8EsRGnBMhuF",
        "outputId": "0e9ddf4e-4e28-4a3b-b12e-2bde0bc438c7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     PP75     TS%    MP Opp   Year NetRtg  OffRtg\n",
            "0  31.911967  .5938  50  LAL  1999  36.35  128.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inflate Scoring for Manual Subset\n",
        "new_df = pd.DataFrame()\n",
        "per_75_coeff['Year'] = per_75_coeff['Year'].astype(int)\n",
        "manu_one_on['Year'] = manu_one_on['Year'].astype(float)\n",
        "manu_one_on['PP75'] = manu_one_on['PP75'].astype(float)\n",
        "for i, row in manu_one_on.iterrows():\n",
        "  sub_coeff = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PP75'] = float((row['PP75'] * sub_coeff['Coefficient']))\n",
        "  new_df = new_df.append(row)\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df['PP75'] = new_df['PP75'].astype(float)\n",
        "new_df['TS%'] = new_df['TS%'].astype(float)\n",
        "new_df['MP'] = new_df['MP'].astype(int)\n",
        "new_df['Opp'] = new_df['Opp'].astype(str)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZIfGRVwZM4qh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Manual Subset\n",
        "pd.options.mode.chained_assignment = None\n",
        "print(\"                 Only Member of Big 3 On\\n\")\n",
        "team_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "team_ts_allowed_df['TS% Allowed'] = team_ts_allowed_df['TS% Allowed'].astype(float)\n",
        "team_ts_allowed_df['Year'] = team_ts_allowed_df['Year'].astype(int)\n",
        "\n",
        "opp_literal_defrtg = pd.read_csv('/content/NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "\n",
        "\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "\n",
        "manual_adjust_scoring_efficiency(new_df, team_ts_allowed_df, opponent_adj_pts_coeff, opp_literal_defrtg, 'Tim Duncan')\n",
        "\n",
        "#Manu Ginóbili"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "TGTZh3uIM6lh",
        "outputId": "c4580ba4-a4d3-4aa5-d288-f6f3ad960762"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Only Member of Big 3 On\n",
            "\n",
            "     Player    Year     PTS      TS+   NetRtg rOffRtg  MP\n",
            "0  Tim Duncan  1999  25.598054  115.13  36.35   24.27  50\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}