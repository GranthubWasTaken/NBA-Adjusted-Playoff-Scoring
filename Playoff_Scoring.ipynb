{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "KA1adZNvGkBH"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "pd.set_option('display.colheader_justify', 'center')\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "\n",
        "import scipy.stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "\n",
        "from inspect import signature\n",
        "\n",
        "def someMethod(self, arg1, kwarg1=None):\n",
        "    pass\n",
        "\n",
        "possession_data_seasons = np.arange(1974, 2023, 1)\n",
        "play_by_play_data_seasons = np.arange(1997, 2023, 1)\n",
        "pre_possesson_data_seasons = np.arange(1952, 1974, 1)\n",
        "aba_seasons = np.arange(1974, 1977, 1)\n",
        "aba_pre_possession_seasons = np.arange(1968, 1974, 1)\n",
        "\n",
        "# plot\n",
        "import seaborn as sns\n",
        "import ast\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.pyplot import *\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as font_manager\n",
        "sns.set_style('darkgrid')        # darkgrid, white grid, dark, white and ticks\n",
        "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=14)     # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=13)    # legend fontsize\n",
        "plt.rc('font', size=13)          # controls default text sizes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Selenium\n",
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install chromium chromium-driver\n",
        "\n",
        "# Install selenium\n",
        "pip install selenium"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cn6OcXIY66Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start Webdriver and VirtualDisplay\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "url = \"http://example.com\" \n",
        "options = Options()\n",
        "options.add_argument(\"--headless\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "\n",
        "options.headless = True\n",
        "\n",
        "wd = webdriver.Chrome(\"/usr/bin/chromedriver\", options=options)\n",
        "\n",
        "!pip install pyvirtualdisplay\n",
        "!apt-get install xvfb\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(800, 800))  \n",
        "display.start()\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jozq2eJRHQHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NncsPba_zEg"
      },
      "source": [
        "**IMPORT RAW DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "cellView": "form",
        "id": "u6CkVfCOGD-g"
      },
      "outputs": [],
      "source": [
        "#@title Manually add team abbrev, league_avg TS%, and teamcolors\n",
        "\n",
        "aba_league_avg = pd.DataFrame(columns=['Year','TS%'])\n",
        "\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1968\",\n",
        "     \"TS%\":  .483, }, ignore_index=True)\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1969\",\n",
        "     \"TS%\":  .502, }, ignore_index=True)\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1970\",\n",
        "     \"TS%\":  .506, }, ignore_index=True)\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1971\",\n",
        "     \"TS%\":  .513, }, ignore_index=True)\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1972\",\n",
        "     \"TS%\":  .519, }, ignore_index=True)\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1973\",\n",
        "     \"TS%\":  .527, }, ignore_index=True)\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1974\",\n",
        "     \"TS%\":  .509, }, ignore_index=True)\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1975\",\n",
        "     \"TS%\":  .520, }, ignore_index=True)\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1976\",\n",
        "     \"TS%\":  .517, }, ignore_index=True)\n",
        "\n",
        "league_avg_df = pd.DataFrame(columns=['Year','TS%'])\n",
        "\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2022\",\n",
        "     \"TS%\":  .566, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2021\",\n",
        "     \"TS%\":  .572, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2020\",\n",
        "     \"TS%\":  .565, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2019\",\n",
        "     \"TS%\":  .560, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2018\",\n",
        "     \"TS%\":  .556, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2017\",\n",
        "     \"TS%\":  .552, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2016\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2015\",\n",
        "     \"TS%\":  .534, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2014\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2013\",\n",
        "     \"TS%\":  .535, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2012\",\n",
        "     \"TS%\":  .527, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2011\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2010\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2009\",\n",
        "     \"TS%\":  .544, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2008\",\n",
        "     \"TS%\":  .540, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2007\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2006\",\n",
        "     \"TS%\":  .536, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({  \n",
        "     \"Year\": \"2005\",\n",
        "     \"TS%\":  .529, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2004\",\n",
        "     \"TS%\":  .516, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2003\",\n",
        "     \"TS%\":  .519, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2002\",\n",
        "     \"TS%\":  .520, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2001\",\n",
        "     \"TS%\":  .518, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2000\",\n",
        "     \"TS%\":  .523, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1999\",\n",
        "     \"TS%\":  .511, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1998\",\n",
        "     \"TS%\":  .524, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1997\",\n",
        "     \"TS%\":  .536, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1996\",\n",
        "     \"TS%\":  .542, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1995\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1994\",\n",
        "     \"TS%\":  .528, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "      \"Year\": \"1993\",\n",
        "     \"TS%\":  .536, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1992\",\n",
        "     \"TS%\":  .531, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1991\",\n",
        "     \"TS%\":  .534, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1990\",\n",
        "     \"TS%\":  .537, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1989\",\n",
        "     \"TS%\":  .537, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1988\",\n",
        "     \"TS%\":  .538, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1987\",\n",
        "     \"TS%\":  .538, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1986\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1985\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)   \n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1984\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1983\",\n",
        "     \"TS%\":  .531, }, ignore_index=True) \n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1982\",\n",
        "     \"TS%\":  .539, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1981\",\n",
        "     \"TS%\":  .534, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "    \"Year\": \"1980\",\n",
        "     \"TS%\":  .531, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1979\",\n",
        "     \"TS%\":  .530, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1978\",\n",
        "     \"TS%\":  .515, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1977\",\n",
        "     \"TS%\":  .511, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1976\",\n",
        "     \"TS%\":  .504, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1975\",\n",
        "     \"TS%\":  .502, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1974\",\n",
        "     \"TS%\":  .503, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1973\",\n",
        "     \"TS%\":  .498, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1972\",\n",
        "     \"TS%\":  .504, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1971\",\n",
        "     \"TS%\":  .500, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1970\",\n",
        "     \"TS%\":  .511, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1969\",\n",
        "     \"TS%\":  .491, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1968\",\n",
        "     \"TS%\":  .498, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1967\",\n",
        "     \"TS%\":  .493, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1966\",\n",
        "     \"TS%\":  .487, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1965\",\n",
        "     \"TS%\":  .479, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1964\",\n",
        "     \"TS%\":  .485, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1963\",\n",
        "     \"TS%\":  .493, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1962\",\n",
        "     \"TS%\":  .479, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1961\",\n",
        "     \"TS%\":  .469, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1960\",\n",
        "     \"TS%\":  .463, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1959\",\n",
        "     \"TS%\":  .457, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1958\",\n",
        "     \"TS%\":  .449, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1957\",\n",
        "     \"TS%\":  .449, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1956\",\n",
        "     \"TS%\":  .458, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1955\",\n",
        "     \"TS%\":  .455, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1954\",\n",
        "     \"TS%\":  .442, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1953\",\n",
        "     \"TS%\":  .445, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1952\",\n",
        "     \"TS%\":  .438, }, ignore_index=True)\n",
        "\n",
        "team_colors = {\"ATL\": \"#E03A3E\", \"BOS\": \"#007A33\", \"BRK\": \"#000000\", \"BUF\": \"#ff6314\", \"CAP\": \"#E31837\", \"CHA\": \"#00788C\", \n",
        "               \"CHI\": \"#CE1141\", \"CHO\": \"#f26631\", \"CLE\": \"#860038\", \"DAL\": \"#00538C\", \"DEN\": \"#0E2240\", \"DET\": \"#1D42BA\",\n",
        "               \"GSW\": \"#FFC72C\", \"HOU\": \"#CE1141\", \"IND\": \"#002D62\", \"KCO\": \"#5A2D81\", \"KCK\": \"#5A2D81\", \"LAC\": \"#C8102E\", \n",
        "               \"LAL\": \"#552583\", \"MEM\": \"#5D76A9\", \"MIA\": \"#98002E\", \"MIL\": \"#00471B\", \"MIN\": \"#78BE20\", \"NOH\": \"#008fc5\", \n",
        "               \"NOP\": \"#85714D\", \"NOJ\": \"#00471B\", \"NJN\": \"#00275d\", \"NYK\": \"#006BB6\", \"OKC\": \"#007AC1\", \"ORL\": \"#0077C0\", \n",
        "               \"PHI\": \"#006BB6\", \"PHO\": \"#1D1160\", \"POR\": \"#E03A3E\", \"SAC\": \"#5A2D81\", \"SAS\": \"#C4CED4\", \"SEA\": \"#00653A\", \n",
        "               \"TOR\": \"#CE1141\", \"TOT\": \"pink\", \"UTA\": \"#00471B\", \"WAS\": \"#E31837\", \"WSB\": \"#E31837\"}\n",
        "\n",
        "team_abbrev = {\"Atlanta Hawks\" : \"ATL\",       \"Boston Celtics\": \"BOS\",        \"Brooklyn Nets\": \"BRK\",         \"Charlotte Bobcats\": \"CHA\", \n",
        "               \"Chicago Bulls\": \"CHI\",      \"Charlotte Hornets\": \"CHO\",      \"Cleveland Cavaliers\": \"CLE\",     \"Dallas Mavericks\": \"DAL\",\n",
        "               \"Denver Nuggets\": \"DEN\",     \"Detroit Pistons\": \"DET\",       \"Golden State Warriors\": \"GSW\",     \"Houston Rockets\": \"HOU\",\n",
        "               \"Indiana Pacers\": \"IND\",     \"Los Angeles Clippers\": \"LAC\",  \"Los Angeles Lakers\": \"LAL\",      \"Memphis Grizzlies\": \"MEM\",\n",
        "               \"Miami Heat\": \"MIA\",         \"Milwaukee Bucks\": \"MIL\",     \"Minnesota Timberwolves\": \"MIN\",  \"New Orleans Hornets\": \"NOH\",\n",
        "               \"New Orleans Pelicans\": \"NOP\", \"New Jersey Nets\": \"NJN\",     \"New York Knicks\": \"NYK\",     \"Oklahoma City Thunder\": \"OKC\", \n",
        "               \"Orlando Magic\": \"ORL\",     \"Philadelphia 76ers\": \"PHI\",      \"Phoenix Suns\": \"PHO\",       \"Portland Trail Blazers\": \"POR\",\n",
        "               \"Sacramento Kings\": \"SAC\",    \"San Antonio Spurs\": \"SAS\",       \"Toronto Raptors\": \"TOR\",               \"Utah Jazz\": \"UTA\", \n",
        "               \"Washington Wizards\": \"WAS\", \"Capital Bullets\": \"CAP\", \"Buffalo Braves\": \"BUF\", \"Seattle SuperSonics\": \"SEA\", \"Washington Bullets\": \"WSB\",\n",
        "               \"Kansas City-Omaha Kings\": \"KCO\", \"Kansas City Kings\": \"KCK\", \"Charlotte Hornets\": \"CHH\"}\n",
        "\n",
        "\n",
        "aba_abbrev = {\"Denver Nuggets\": \"DNA\", \"Indiana Pacers\": \"INA\", \"New York Nets\": \"NYA\", \"San Antonio Spurs\": \"SAA\",\n",
        "              \"Virginia Squires\": \"VIR\", \"Carolina Cougars\": \"CAR\", \"San Diego Conquistadors\": \"SDA\", \"Kentucky Colonels\": \"KEN\",\n",
        "              \"Utah Stars\": \"UTS\", \"Carolina Cougars\": \"CAR\", \"San Diego Sails\": \"SDS\", \"Spirits of St. Louis\": \"SSL\",\n",
        "              \"Memphis Sounds\": \"MMS\", \"Denver Rockets\": \"DNR\"}\n",
        "\n",
        "aba_pre_poss_abbrev = {\"Denver Nuggets\": \"DNA\", \"Indiana Pacers\": \"INA\", \"New York Nets\": \"NYA\", \"San Antonio Spurs\": \"SAA\",\n",
        "              \"Virginia Squires\": \"VIR\", \"Carolina Cougars\": \"CAR\", \"San Diego Conquistadors\": \"SDA\", \"Kentucky Colonels\": \"KEN\",\n",
        "              \"Utah Stars\": \"UTS\", \"Carolina Cougars\": \"CAR\", \"San Diego Sails\": \"SDS\", \"Spirits of St. Louis\": \"SSL\",\n",
        "              \"Memphis Sounds\": \"MMS\", \"Denver Rockets\": \"DNR\", \"Pittsburgh Pipers\": \"PTP\", \"Minnesota Muskies\": \"MNM\",\n",
        "              \"New Orleans Buccaneers\": \"NOB\", \"Dallas Chaparrals\": \"DLC\", \"Texas Chaparrals\": \"TEX\", \"Houston Mavericks\": \"HSM\",\n",
        "              \"Oakland Oaks\": \"OAK\", \"Miami Floridians\": \"MMF\", \"Minnesota Pipers\": \"MNP\", \"Washington Capitols\": \"WSA\",\n",
        "              \"Los Angeles Stars\": \"LAS\", \"The Floridians\": \"FLO\", \"Memphis Pros\": \"MMP\", \"New Jersey Americans\": \"NJA\",\n",
        "              \"Anaheim Amigos\": \"ANA\", \"Pittsburgh Condors\": \"PTC\", \"Memphis Tams\": \"MMT\"}\n",
        "\n",
        "team_52_73_abbrev = {\"Milwaukee Hawks\" : \"MLH\",  \"Syracuse Nationals\": \"SYR\",        \"Minneapolis Lakers\": \"MNL\",         \"Rochester Royals\": \"ROC\", \n",
        "               \"Chicago Bulls\": \"CHI\",      \"Boston Celtics\": \"BOS\",      \"Cleveland Cavaliers\": \"CLE\",     \"Fort Wayne Pistons\": \"FTW\",\n",
        "               \"Indianapolis Olympians\": \"INO\",     \"Detroit Pistons\": \"DET\",       \"Golden State Warriors\": \"GSW\",     \"Houston Rockets\": \"HOU\",\n",
        "               \"St. Louis Hawks\": \"STL\",  \"Los Angeles Lakers\": \"LAL\",      \"Philadelphia Warriors\": \"PHW\",\n",
        "               \"Cincinnati Royals\": \"CIN\",         \"Milwaukee Bucks\": \"MIL\", \"San Diego Rockets\": \"SDR\",     \n",
        "               \"New York Knicks\": \"NYK\",   \"Philadelphia 76ers\": \"PHI\",      \"Phoenix Suns\": \"PHO\",       \"Portland Trail Blazers\": \"POR\",\n",
        "               \"Baltimore Bullets\": \"BAL\", \"Buffalo Braves\": \"BUF\", \"Seattle SuperSonics\": \"SEA\", \"Washington Bullets\": \"WSB\",\n",
        "               \"Kansas City-Omaha Kings\": \"KCO\", \"Kansas City Kings\": \"KCK\", \"San Francisco Warriors\": \"SFW\", \"Atlanta Hawks\": \"ATL\",\n",
        "               \"Chicago Packers\": \"CHP\", \"Chicago Zephyrs\": \"CHZ\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "cellView": "form",
        "id": "xTVOqjCkD24f"
      },
      "outputs": [],
      "source": [
        "#@title Import data and add team colors for advanced, play-by-play, per 100, and league avg data\n",
        "\n",
        "# per 100 posssessions\n",
        "#import_player_since74_per100_df = pd.read_csv('nba_player_since74_per100_data.csv')\n",
        "\n",
        "# add team color for per 100 posssessions\n",
        "#import_player_since74_per100_df['TeamColor'] = import_player_since74_per100_df['Tm'].map(team_colors)\n",
        "# per 100 playoff posssessions\n",
        "#import_player_since74playoffs_per100_df = pd.read_csv('nba_player_since74playoffs_per100_data.csv')\n",
        "# add team color for playoff per 100 posssessions\n",
        "#import_player_since74playoffs_per100_df['TeamColor'] = import_player_since74playoffs_per100_df['Tm'].map(team_colors)\n",
        "\n",
        "# advanced\n",
        "import_player_since74_advanced_df = pd.read_csv('nba_player_since74_advanced_data.csv', encoding='utf8')\n",
        "\n",
        "# advanced playoffs\n",
        "import_player_since74playoffs_advanced_df = pd.read_csv('nba_player_since74playoffs_advanced_data.csv', encoding='utf8')\n",
        "\n",
        "\n",
        "# play-by-play\n",
        "import_player_regular_playbyplay_df = pd.read_csv('nba_player_regular_playbyplay_data.csv', encoding='utf8')\n",
        "\n",
        "# add team color for play-by-play\n",
        "import_player_regular_playbyplay_df['TeamColor'] = import_player_regular_playbyplay_df['Tm'].map(team_colors)\n",
        "\n",
        "# play-by-play playoffs\n",
        "import_player_since74playoffs_playbyplay_df = pd.read_csv('nba_player_playoff_playbyplay_data.csv', encoding='utf8')\n",
        "\n",
        "# add team color for playoff play-by-play\n",
        "import_player_since74playoffs_playbyplay_df['TeamColor'] = import_player_since74playoffs_playbyplay_df['Tm'].map(team_colors)\n",
        "\n",
        "\n",
        "# import league avg data\n",
        "\n",
        "# league avg\n",
        "import_leagueavgsince74_df = pd.read_csv('nba_leaguestats_data.csv')\n",
        "\n",
        "# drop NBA seasons from inception of league until 1973 (final year without per possession data)\n",
        "import_leagueavgsince74_df.drop(import_leagueavgsince74_df.tail(26).index,inplace=True)\n",
        "\n",
        "# change from '2020-21' to '2021' and '2019-20' to '2020'... and so on\n",
        "for i, trial in import_leagueavgsince74_df.iterrows():\n",
        "   import_leagueavgsince74_df.loc[i, \"Season\"] = 2022-i\n",
        "\n",
        "league_avg_df['Year'] = league_avg_df['Year'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "cellView": "form",
        "id": "b0yr4pEL4W7l"
      },
      "outputs": [],
      "source": [
        "#@title Import per 75 data (can be used in place of 'Calculate per 75' cells with necessitated imported data')\n",
        "\n",
        "# per 75 posssessions\n",
        "import_player_since74_per75_df = pd.read_csv('nba_player_since74_per75_data.csv')\n",
        "\n",
        "# add team color for per 75 posssessions\n",
        "import_player_since74_per75_df['TeamColor'] = import_player_since74_per75_df['Tm'].map(team_colors)\n",
        "\n",
        "# per 75 playoff posssessions\n",
        "import_player_since74playoffs_per75_df = pd.read_csv('nba_player_since74playoffs_per75_data.csv')\n",
        "\n",
        "# add team color for playoff per 75 posssessions\n",
        "import_player_since74playoffs_per75_df['TeamColor'] = import_player_since74playoffs_per75_df['Tm'].map(team_colors)\n",
        "\n",
        "# per 75 adjusted ts playoff posssessions\n",
        "#adjusted_playoff_per_75_df = pd.read_csv('/content/since74_adj_ts_playoffs_per75_data.csv')\n",
        "# add team color for playoff per 75 adjusted posssessions\n",
        "#adjusted_playoff_per_75_df['TeamColor'] = adjusted_playoff_per_75_df['Tm'].map(team_colors)\n",
        "\n",
        "# era/opponent adjusted scoring\n",
        "era_adj_reg_per_75_df = pd.read_csv('/content/era_adjusted_reg_per75_data.csv')\n",
        "era_opponent_adj_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_ts = era_adj_reg_per_75_df.copy()\n",
        "top_ts = top_ts[(top_ts['MP'] >= 1500)]\n",
        "top_ts = top_ts[(top_ts['PTS']) >= 20]\n",
        "top_ts = top_ts[(top_ts['Year']) < 1980]\n",
        "top_ts = top_ts.sort_values('TS%+', ascending=False)\n",
        "print(top_ts)\n",
        "\n",
        "top_ts = pd.read_csv('/content/All_Scoring_Changes_300min.csv')\n",
        "top_ts = top_ts[(top_ts['MP_post'] >= 1000)]\n",
        "top_ts = top_ts[(top_ts['MP_post'] <= 1500)]\n",
        "top_ts = top_ts[(top_ts['PTS per 75_post']) >= 20]\n",
        "top_ts = top_ts[(top_ts['PTS_change']) <= -2]\n",
        "top_ts = top_ts[(top_ts['TS+_change']) <= -8]\n",
        "top_ts['MP_post'] = top_ts['MP_post'].astype(int)\n",
        "top_ts = top_ts.sort_values('PTS_change', ascending=False)\n",
        "print(top_ts)\n",
        "\n",
        "top_ts.to_csv(\"badasd.csv\", index=False)"
      ],
      "metadata": {
        "id": "TLnYHrcpNUeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "cellView": "form",
        "id": "f4veohWtxhJh"
      },
      "outputs": [],
      "source": [
        "#@title Create scoring coefficients\n",
        "\n",
        "# era-adjust per game data\n",
        "per_game_coeff = pd.read_csv('/content/Avg_Reg_PTS_G.csv', index_col=False, encoding='utf8')\n",
        "per_game_coeff['Coefficient'] = per_game_coeff['Average PTS_G'].max() / per_game_coeff['Average PTS_G'] \n",
        "\n",
        "# era-adjust per 75 data\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "#aba_per75_coeff = pd.read_csv('/content/Avg_ABA_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "#aba_per75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / aba_per75_coeff['Average PP75']\n",
        "\n",
        "bpm_coeff = pd.read_csv('/content/Avg_Reg_BPM.csv', index_col=False, encoding='utf8')\n",
        "bpm_coeff['Average BPM'] = bpm_coeff['Average BPM'] +  1\n",
        "bpm_coeff['Average OBPM'] = bpm_coeff['Average OBPM'] + 1\n",
        "bpm_coeff['BPM_Coefficient'] = bpm_coeff['Average BPM'].max() / bpm_coeff['Average BPM']\n",
        "bpm_coeff['OBPM_Coefficient'] = bpm_coeff['Average OBPM'].max() / bpm_coeff['Average OBPM']\n",
        "\n",
        "try:\n",
        "  opponent_adj_pts_coeff = pd.DataFrame(columns = ['Year', 'Team', 'PTS_coeff'])\n",
        "\n",
        "  team_def_rtg = pd.read_csv('NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "  league_avg_def_rtg = pd.read_csv('/content/Avg_Def_Rtg.csv', index_col=False, encoding='utf8')\n",
        "  for idx, row in team_def_rtg.iterrows():\n",
        "          match_df = league_avg_def_rtg[(league_avg_def_rtg['Year'] == row['Year'])]\n",
        "          avg = match_df['Avg DefRtg']\n",
        "          avg = float(avg)\n",
        "          coeff = avg / row['DefRtg']\n",
        "\n",
        "          new_row = {'Year':row['Year'], 'Team':row['Team'], 'PTS_coeff':coeff}\n",
        "          opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "          opponent_adj_pts_coeff = opponent_adj_pts_coeff.append(new_row, ignore_index=True)\n",
        "\n",
        "  outfile = f\"opponent_adj_pts_coeff.csv\"\n",
        "  opponent_adj_pts_coeff.to_csv(outfile, index=False)\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create ABA scoring coefficients\n",
        "aba_per75_coeff = pd.read_csv('/content/Avg_ABA_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "aba_per75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / aba_per75_coeff['Average PP75']\n",
        "\n",
        "opponent_adj_pts_coeff = pd.DataFrame(columns = ['Year', 'Team', 'PTS_coeff'])\n",
        "\n",
        "team_def_rtg = pd.read_csv('ABA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "league_avg_def_rtg = pd.read_csv('Avg_Def_Rtg_ABA_68-76.csv', index_col=False, encoding='utf8')\n",
        "for idx, row in team_def_rtg.iterrows():\n",
        "        match_df = league_avg_def_rtg[(league_avg_def_rtg['Year'] == row['Year'])]\n",
        "        avg = match_df['Avg DefRtg']\n",
        "        avg = float(avg)\n",
        "        coeff = avg / row['DefRtg']\n",
        "\n",
        "        new_row = {'Year':row['Year'], 'Team':row['Team'], 'PTS_coeff':coeff}\n",
        "        opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "        opponent_adj_pts_coeff = opponent_adj_pts_coeff.append(new_row, ignore_index=True)\n",
        "\n",
        "outfile = f\"aba_opponent_adj_pts_coeff.csv\"\n",
        "opponent_adj_pts_coeff.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vuhvc-NKzlTp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outputting Cells**"
      ],
      "metadata": {
        "id": "fdjvCUzH819P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Single Playoffs Import\n",
        "sing = era_opponent_adj_playoff_per_75_df.copy()\n",
        "#sing = sing.drop(['TeamColor', 'Pos', 'Age', 'GS', 'DRB', 'TRB', 'AST', 'STL', 'PF', 'FG', 'FGA', '3P', '3PA', 'TOV', '2P', '2PA', 'FG%', '3P%', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'BLK', 'Possessions','eFG%'], axis=1)\n",
        "\n",
        "#sing = era_opponent_adj_playoff_per_75_df.copy()\n",
        "sing = sing.drop(['TeamColor', 'Pos', 'Age', 'GS', 'DRB', 'TRB', 'AST', 'STL', 'PF', 'ORtg', 'DRtg', 'FG', 'FGA', '3P', '3PA', 'TOV', '2P', '2PA', 'FG%', '3P%', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'BLK'], axis=1)\n",
        "\n",
        "sing = sing.rename(columns={\"Year\": \"Year\", \"Player\": \"Player\", \"Tm\": \"Team\", \"TS%+\": \"TS+\", \"PTS\": \"PP75\"})\n",
        "\n",
        "columns_titles = ['Year', 'Player', 'Team', 'PP75', 'TS+', 'MP', 'G']\n",
        "sing = sing.reindex(columns=columns_titles)\n",
        "\n",
        "sing['PP75'] = sing['PP75'].round(2)\n",
        "sing['TS+'] = sing['TS+'].round(2)\n",
        "sing['MP'] = sing['MP'].astype(int)\n",
        "\n",
        "sing = sing.sort_values(by = ['Player', 'Year'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "print(sing)\n",
        "sing.to_csv(\"Single_Playoffs_Adjusted_Scoring.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TeBHK4mouJzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Single Playoffs Custom Dataframes\n",
        "sing = pd.read_csv('/content/52-22_Single_Playoffs_Adjusted_Scoring.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "sing['MP'] = sing['MP'].astype(int)\n",
        "sing['G'] = sing['G'].astype(int)\n",
        "\n",
        "sing = sing[(sing['MP'] >= 300)]\n",
        "sing = sing[(sing['PP75'] >= 30)]\n",
        "sing = sing[(sing['TS+'] >= 115)]\n",
        "\n",
        "sing = sing.sort_values(by = ['Year', 'Player'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "print(sing)\n",
        "#sing.to_csv(\"Single_Playoffs_Adjusted_Scoring.csv\", index=False)"
      ],
      "metadata": {
        "id": "-FZKHrYKP9MP",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e60a47a-0b15-4ed5-e4de-c3a3b2fc3eed"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Year        Player        Team  PP75     TS+   MP    G\n",
            "1073  1958          Cliff Hagan  STL  30.00  131.23  418  11\n",
            "1857  1961         Elgin Baylor  LAL  31.36  115.66  540  12\n",
            "3061  1970  Kareem Abdul-Jabbar  MIL  31.22  123.17  435  10\n",
            "4578  1970           Rick Barry  WSA  35.82  121.62  302   7\n",
            "4991  1970      Spencer Haywood  DNR  31.09  115.91  568  12\n",
            "3034  1976        Julius Erving  NYA  30.56  119.53  551  13\n",
            "3066  1977  Kareem Abdul-Jabbar  LAL  31.98  126.16  467  11\n",
            "3069  1980  Kareem Abdul-Jabbar  LAL  30.07  119.42  618  15\n",
            "3924  1991       Michael Jordan  CHI  32.81  116.53  689  17\n",
            "4920  1998     Shaquille O'Neal  LAL  34.75  117.40  501  13\n",
            "143   2005    Amar'e Stoudemire  PHO  31.40  119.99  601  15\n",
            "3460  2009         LeBron James  CLE  38.01  118.56  580  14\n",
            "1663  2011        Dirk Nowitzki  DAL  31.15  115.42  826  21\n",
            "3465  2014         LeBron James  MIA  32.69  127.39  763  20\n",
            "3103  2017        Kawhi Leonard  SAS  31.02  121.54  429  12\n",
            "3172  2017         Kevin Durant  GSW  30.08  126.69  533  15\n",
            "3468  2017         LeBron James  CLE  30.97  119.78  744  18\n",
            "3174  2019         Kevin Durant  GSW  32.76  118.84  442  12\n",
            "2505  2020         James Harden  HOU  30.23  115.39  448  12\n",
            "3106  2021        Kawhi Leonard  LAC  30.26  122.15  432  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Edit Text\n",
        "with open('/content/tmpurllist.txt', 'r') as f, open('better_format', 'w') as f1:\n",
        "  Lines = f.readlines()\n",
        "  \n",
        "  count = 0\n",
        "  # Strips the newline character\n",
        "  for line in Lines:\n",
        "    if \"Player\" in line:\n",
        "      continue\n",
        "    else:\n",
        "      new_line = re.sub('/pla', r',/pla', line)\n",
        "      print(new_line)\n",
        "    f1.write(new_line)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OppF_CK9sXic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_xOBKntCacv6"
      },
      "outputs": [],
      "source": [
        "#@title Scrape League Average TS% Since 1974 (not working)\n",
        "#@title Scrape NBA regular season advanced\n",
        "def scrape_nba_ts_data(years):\n",
        "\n",
        "    league_avg_ts_df = pd.DataFrame(columns = ['Year', 'TS%'])\n",
        "\n",
        "    for year in years:\n",
        "        league_stats_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\"\n",
        "        \n",
        "        wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "        wd.get(league_stats_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': '#content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': '#all_advanced_team'})\n",
        "          first_table = second_div.find('table', attrs={'id': '#advanced-team'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "        print(rows)\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        advanced_stats = [e for e in advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(advanced_stats)):\n",
        "             advanced_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        print(headers)\n",
        "\n",
        "        each_year = pd.DataFrame(advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        league_avg_ts_df = league_avg_ts_df.append(each_year)\n",
        "\n",
        "        # remove any Na\n",
        "        league_avg_ts_df = league_avg_ts_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(league_avg_ts_df.info)\n",
        "    league_avg_ts_df.to_csv(\"nba_player_since74_advanced_data.csv\", index=False)\n",
        "scrape_nba_ts_data(all_the_years)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NBA 1952-73 (estimated) DATA**"
      ],
      "metadata": {
        "id": "9DTh1HKJ2cGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scrape_team_estimated_playoff_pace_data(pre_possesson_data_seasons)\n",
        "#scrape_nba_player_pergame_data([pre_possesson_data_seasons])\n",
        "#scrape_nba_player_advanced_data([pre_possesson_data_seasons])\n",
        "#scrape_nba_player_pergame_data(pre_possesson_data_seasons)\n",
        "#scrape_nba_player_total_mp_data(pre_possesson_data_seasons)"
      ],
      "metadata": {
        "id": "XlhmwilWyuBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA 1952-73 Scrape Functions\n",
        "\n",
        "# Scrape NBA Teams' Playoff Pace (1952-73 [estimated])\n",
        "# Grab Team and Opponent Total stats to estimate pace of play for each NBA team from 1952-73\n",
        "def scrape_team_estimated_playoff_pace_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'Pace/G', 'ORtg', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/playoffs/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "\n",
        "        #Find table body of team stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-team'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year and pace column to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "             team_allowed_stats[i].insert(1, 0) \n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"Pace/G\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        each_years_teams = each_years_teams.sort_values('Team', ascending=True)\n",
        "\n",
        "        # estimate pace\n",
        "        if year >= 1971:\n",
        "          ORB_percent = 0.319\n",
        "        else:\n",
        "          ORB_percent = 0.303\n",
        "        if year >= 1971:\n",
        "          TOV_percent = 0.158\n",
        "        else:\n",
        "          TOV_percent = 0.161\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FG'] = each_years_teams['FG'].astype(float)\n",
        "        each_years_teams['G'] = each_years_teams['G'].astype(float)\n",
        "        each_years_teams['Pace/G'] = (each_years_teams['FGA'] + (0.4 * each_years_teams['FTA']) - ORB_percent * (each_years_teams['FGA'] - each_years_teams['FG']) + (-TOV_percent * (each_years_teams['FGA'] + 0.44 * each_years_teams['FTA']) / (TOV_percent - 1)))\n",
        "        each_years_teams['Ortg'] = (each_years_teams['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'], axis=1, inplace=True)\n",
        "\n",
        "        \n",
        "\n",
        "        #Find table body of opponent stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each row\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        def_rtg_df = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        def_rtg_df = def_rtg_df.sort_values('Team', ascending=True)\n",
        "\n",
        "        def_rtg_df['PTS'] = def_rtg_df['PTS'].astype(float)\n",
        "        each_years_teams['Drtg'] = (def_rtg_df['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"NBA_Team_Estimated_Playoff_Pace_52-73_df.csv\", index=False)\n",
        "\n",
        "    \n",
        "\n",
        "# Scrape NBA regular season per game (1952-73)\n",
        "def scrape_nba_player_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = final_players_pergame_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"52-73_reg_pergame_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season advanced (1952-73)\n",
        "def scrape_nba_player_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        print(year)\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        time.sleep(5)\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_advanced_df = final_players_advanced_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"52-73_reg_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoff per game (1952-73)\n",
        "def scrape_nba_player_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        time.sleep(5)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = final_players_pergame_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"52-73_playoff_pergame_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoff totals (1952-73)\n",
        "def scrape_nba_player_total_mp_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_totals.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        time.sleep(5)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = final_players_pergame_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"52-73_total_mp_playoff_data.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "s9oi73XB3Uru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA 1952-73 Ancillary Calculations\n",
        "\n",
        "# NBA 1952-73 Calculate reg per 75 and TS+\n",
        "pergame = pd.read_csv('52-73_reg_pergame_data.csv', encoding='utf8', index_col=False)\n",
        "pace_sup = pd.read_csv('abbrev_52-73 reg pace ortg drtg.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "pergame['PTS'] = pergame['PTS'].astype(float)\n",
        "pergame['MP'] = pergame['MP'].astype(float)\n",
        "pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "\n",
        "\n",
        "for idx, row in pergame.iterrows():\n",
        "  team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "  team_pace = team['Pace/G']\n",
        "  # changed team in middle of year. Two paces to account for.\n",
        "  if row['Tm'] == 'TOT':\n",
        "    print(row['Player'])\n",
        "    print(row['Year'])\n",
        "    continue\n",
        "  # team folded and didn't play for another team that season.\n",
        "  elif row['Tm'] == 'BLB' and row['Year'] == 1955:\n",
        "    continue\n",
        "  pergame.iat[idx, 31] = team_pace * (pergame.iat[idx, 9]/48)\n",
        "  pergame.iat[idx, 31] = pergame.iat[idx, 31].astype(float)\n",
        "  ind_poss_coeff = pergame.iat[idx, 31] / 75\n",
        "  pergame.iat[idx, 30] = pergame.iat[idx, 30]  / ind_poss_coeff\n",
        "pergame.to_csv(\"52-73_reg_per_75_data.csv\", index=False)\n",
        "\n",
        "# NBA 1952-73 Calculate playoff per 75\n",
        "pergame = pd.read_csv('52-73_playoff_pergame_data.csv', encoding='utf8', index_col=False)\n",
        "pace_sup = pd.read_csv('Abbrev_Playoff_Pace_52-73.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "pergame['PTS'] = pergame['PTS'].astype(float)\n",
        "pergame['MP'] = pergame['MP'].astype(float)\n",
        "pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "\n",
        "\n",
        "for idx, row in pergame.iterrows():\n",
        "  team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "  team_pace = team['Pace/G']\n",
        "  pergame.iat[idx, 31] = team_pace * (pergame.iat[idx, 9]/48)\n",
        "  pergame.iat[idx, 31] = pergame.iat[idx, 31].astype(float)\n",
        "  ind_poss_coeff = pergame.iat[idx, 31] / 75\n",
        "  pergame.iat[idx, 30] = pergame.iat[idx, 30]  / ind_poss_coeff\n",
        "pergame.to_csv(\"52-73_playoff_per_75_data.csv\", index=False)\n",
        "\n",
        "\n",
        "# Calculate average PTS per 75 (1952-73)\n",
        "# year by year find what the league average PTS per 75 possessions was. Each row (player)'s points scaled for minutes.\n",
        "avg_pts_per_75 = pd.read_csv('/content/52-73_reg_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "total_mp = 0\n",
        "running_pts_avg = []\n",
        "year_list = []\n",
        "final_df = pd.DataFrame()\n",
        "for year in pre_possesson_data_seasons:\n",
        "  year_list.append(year)\n",
        "  this_years_players = avg_pts_per_75[(avg_pts_per_75['Year']) == year]\n",
        "  this_years_players['MP'] = this_years_players['MP'].astype(float)\n",
        "  total_mp = this_years_players['MP'].sum()\n",
        "  this_years_players['AdjPts'] = (this_years_players['PTS'].astype(float)) * (this_years_players['MP'].astype(float) / total_mp)\n",
        "  running_pts_avg.append(this_years_players['AdjPts'].sum())\n",
        "\n",
        "final_df['Year'] = year_list\n",
        "final_df['Average PP75'] = running_pts_avg\n",
        "        \n",
        "final_df.to_csv(\"Avg_52-73_Reg_PP75.csv\", index=False)\n",
        "\n",
        "\n",
        "# Calculate average DefRtg (1952-73)\n",
        "# year by year find what the league average DefRtg was.\n",
        "avg_pts_per_75 = pd.read_csv('/content/abbrev_52-73 reg pace ortg drtg.csv', index_col=False, encoding='utf8')\n",
        "running_pts_avg = []\n",
        "year_list = []\n",
        "final_df = pd.DataFrame()\n",
        "for year in pre_possesson_data_seasons:\n",
        "  year_list.append(year)\n",
        "  this_years_players = avg_pts_per_75[(avg_pts_per_75['Year']) == year]\n",
        "  running_pts_avg.append(this_years_players['Drtg'].mean())\n",
        "\n",
        "final_df['Year'] = year_list\n",
        "final_df['Average DefRtg'] = running_pts_avg\n",
        "        \n",
        "final_df.to_csv(\"Avg_52-73_DefRtg.csv\", index=False)\n",
        "\n",
        "# Replace Per 75 'MPG' with total 'MP'\n",
        "per75 = pd.read_csv('52-73_playoff_per_75_data.csv', encoding='utf8', index_col=False)\n",
        "total_mp = pd.read_csv('52-73_total_mp_playoff_data.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "per75['MP'] = total_mp['MP'].astype(int)\n",
        "per75.to_csv(\"52-73_playoff_per_75_data.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4KlWoPonuSwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ABA 1968-73 DATA**"
      ],
      "metadata": {
        "id": "rcQQeiXhYijl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA 1968-73 Scrape Functions\n",
        "def scrape_aba_team_estimated_playoff_pace_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'Pace/G', 'OffRtg', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/playoffs/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "\n",
        "        #Find table body of team stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-team'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year and pace column to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "             team_allowed_stats[i].insert(1, 0) \n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"Pace/G\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        each_years_teams = each_years_teams.sort_values('Team', ascending=True)\n",
        "\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FG'] = each_years_teams['FG'].astype(float)\n",
        "        each_years_teams['FG'] = each_years_teams['FG'].astype(float)\n",
        "        each_years_teams['G'] = each_years_teams['G'].astype(float)\n",
        "        \n",
        "\n",
        "        ORB_percent = 0.321\n",
        "        if year == 1971:\n",
        "          TOV_percent = 0.158\n",
        "          each_years_teams['Pace/G'] = (each_years_teams['FGA'] + (0.4 * each_years_teams['FTA']) - ORB_percent * (each_years_teams['FGA'] - each_years_teams['FG']) + (-TOV_percent * (each_years_teams['FGA'] + 0.44 * each_years_teams['FTA']) / (TOV_percent - 1)))\n",
        "          each_years_teams['OffRtg'] = (each_years_teams['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "        else:\n",
        "          each_years_teams['TOV'] = each_years_teams['TOV'].astype(float)\n",
        "          each_years_teams['Pace/G'] = (each_years_teams['FGA'] + (0.4 * each_years_teams['FTA']) - ORB_percent * (each_years_teams['FGA'] - each_years_teams['FG']) + each_years_teams['TOV'])\n",
        "          each_years_teams['OffRtg'] = (each_years_teams['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'], axis=1, inplace=True)\n",
        "\n",
        "        \n",
        "\n",
        "        #Find table body of opponent stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each row\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        def_rtg_df = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        def_rtg_df = def_rtg_df.sort_values('Team', ascending=True)\n",
        "\n",
        "        def_rtg_df['PTS'] = def_rtg_df['PTS'].astype(float)\n",
        "        each_years_teams['DefRtg'] = (def_rtg_df['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(aba_pre_poss_abbrev)\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"ABA_Team_Estimated_Playoff_Pace_68-73_df.csv\", index=False)\n",
        "\n",
        "# ABA Scrape reg pace \n",
        "def scrape_aba_team_estimated_pace_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'Pace/G', 'OffRtg', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "\n",
        "        #Find table body of team stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-team'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year and pace column to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "             team_allowed_stats[i].insert(1, 0) \n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"Pace/G\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        each_years_teams = each_years_teams.sort_values('Team', ascending=True)\n",
        "\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FG'] = each_years_teams['FG'].astype(float)\n",
        "        each_years_teams['FG'] = each_years_teams['FG'].astype(float)\n",
        "        each_years_teams['G'] = each_years_teams['G'].astype(float)\n",
        "        \n",
        "\n",
        "        ORB_percent = 0.321\n",
        "        each_years_teams['TOV'] = each_years_teams['TOV'].astype(float)\n",
        "        each_years_teams['Pace/G'] = (each_years_teams['FGA'] + (0.4 * each_years_teams['FTA']) - ORB_percent * (each_years_teams['FGA'] - each_years_teams['FG']) + each_years_teams['TOV'])\n",
        "        each_years_teams['OffRtg'] = (each_years_teams['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'], axis=1, inplace=True)\n",
        "\n",
        "        \n",
        "\n",
        "        #Find table body of opponent stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each row\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        def_rtg_df = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        def_rtg_df = def_rtg_df.sort_values('Team', ascending=True)\n",
        "\n",
        "        def_rtg_df['PTS'] = def_rtg_df['PTS'].astype(float)\n",
        "        each_years_teams['DefRtg'] = (def_rtg_df['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(aba_pre_poss_abbrev)\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"ABA_Team_Estimated_Pace_68-73_df.csv\", index=False)\n",
        "\n",
        "\n",
        "# Scrape NBA regular season advanced (1968-73)\n",
        "def scrape_aba_player_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        print(year)\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        time.sleep(5)\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_advanced_df = final_players_advanced_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"68-73_reg_advanced_data.csv\", index=False)\n",
        "\n",
        "\n",
        "# Scrape ABA regular season per game (1968-73)\n",
        "def scrape_aba_player_reg_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = final_players_pergame_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"68-73_reg_pergame_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA playoff per game (1968-73)\n",
        "def scrape_aba_player_playoff_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        time.sleep(5)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = final_players_pergame_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"68-73_playoff_pergame_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA playoff totals (1968-73)\n",
        "def scrape_aba_player_total_mp_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_totals.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        time.sleep(5)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = final_players_pergame_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"68-73_total_mp_playoff_data.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JEfswM1KYPLG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA 1968-73 Ancillary Calculations\n",
        "\n",
        "# ABA 1968-73 Calculate reg per 75\n",
        "pergame = pd.read_csv('68-73_reg_pergame_data.csv', encoding='utf8', index_col=False)\n",
        "pace_sup = pd.read_csv('ABA_Team_Estimated_Pace_68-73_df.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "pergame['PTS'] = pergame['PTS'].astype(float)\n",
        "pergame['MP'] = pergame['MP'].astype(float)\n",
        "pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "\n",
        "\n",
        "for idx, row in pergame.iterrows():\n",
        "  team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "  team_pace = team['Pace/G']\n",
        "  # changed team in middle of year. Two paces to account for.\n",
        "  if row['Tm'] == 'TOT':\n",
        "    continue\n",
        "  pergame.iat[idx, 31] = team_pace * (pergame.iat[idx, 9]/48)\n",
        "  pergame.iat[idx, 31] = pergame.iat[idx, 31].astype(float)\n",
        "  ind_poss_coeff = pergame.iat[idx, 31] / 75\n",
        "  pergame.iat[idx, 30] = pergame.iat[idx, 30]  / ind_poss_coeff\n",
        "pergame.to_csv(\"68-73_reg_per_75_data.csv\", index=False)\n",
        "\n",
        "\n",
        "# Calculate average PTS per 75 (1968-73)\n",
        "# year by year find what the league average PTS per 75 possessions was. Each row (player)'s points scaled for minutes.\n",
        "avg_pts_per_75 = pd.read_csv('/content/68-73_reg_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "avg_pts_per_75 = avg_pts_per_75[(avg_pts_per_75['Tm'] != \"TOT\")]\n",
        "total_mp = 0\n",
        "running_pts_avg = []\n",
        "year_list = []\n",
        "final_df = pd.DataFrame()\n",
        "for year in pre_possesson_data_seasons:\n",
        "  year_list.append(year)\n",
        "  this_years_players = avg_pts_per_75[(avg_pts_per_75['Year']) == year]\n",
        "  this_years_players['MP'] = this_years_players['MP'].astype(float)\n",
        "  total_mp = this_years_players['MP'].sum()\n",
        "  this_years_players['AdjPts'] = (this_years_players['PTS'].astype(float)) * (this_years_players['MP'].astype(float) / total_mp)\n",
        "  running_pts_avg.append(this_years_players['AdjPts'].sum())\n",
        "\n",
        "final_df['Year'] = year_list\n",
        "final_df['Average PP75'] = running_pts_avg\n",
        "        \n",
        "final_df.to_csv(\"Avg_68-73_Reg_PP75.csv\", index=False)\n",
        "\n",
        "# ABA 1968-73 Calculate playoff per 75\n",
        "pergame = pd.read_csv('68-73_playoff_pergame_data.csv', encoding='utf8', index_col=False)\n",
        "pace_sup = pd.read_csv('ABA_Team_Estimated_Playoff_Pace_68-73_df.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "pergame['PTS'] = pergame['PTS'].astype(float)\n",
        "pergame['MP'] = pergame['MP'].astype(float)\n",
        "pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "\n",
        "\n",
        "for idx, row in pergame.iterrows():\n",
        "  team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "  team_pace = team['Pace/G']\n",
        "  pergame.iat[idx, 31] = team_pace * (pergame.iat[idx, 9]/48)\n",
        "  pergame.iat[idx, 31] = pergame.iat[idx, 31].astype(float)\n",
        "  ind_poss_coeff = pergame.iat[idx, 31] / 75\n",
        "  pergame.iat[idx, 30] = pergame.iat[idx, 30]  / ind_poss_coeff\n",
        "pergame.to_csv(\"68-73_playoff_per_75_data.csv\", index=False)\n",
        "\n",
        "\n",
        "# Calculate average DefRtg (1968-73)\n",
        "# year by year find what the league average DefRtg was.\n",
        "avg_pts_per_75 = pd.read_csv('ABA_Team_Estimated_Pace_68-73_df.csv', index_col=False, encoding='utf8')\n",
        "running_pts_avg = []\n",
        "year_list = []\n",
        "final_df = pd.DataFrame()\n",
        "for year in aba_pre_possession_seasons:\n",
        "  year_list.append(year)\n",
        "  this_years_players = avg_pts_per_75[(avg_pts_per_75['Year']) == year]\n",
        "  running_pts_avg.append(this_years_players['DefRtg'].mean())\n",
        "\n",
        "final_df['Year'] = year_list\n",
        "final_df['Average DefRtg'] = running_pts_avg\n",
        "        \n",
        "final_df.to_csv(\"Avg_68-73_DefRtg.csv\", index=False)\n",
        "\n",
        "# Replace Per 75 'MPG' with total 'MP'\n",
        "per75 = pd.read_csv('68-73_playoff_per_75_data.csv', encoding='utf8', index_col=False)\n",
        "total_mp = pd.read_csv('68-73_total_mp_playoff_data.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "per75['MP'] = total_mp['MP'].astype(int)\n",
        "per75.to_csv(\"68-73_playoff_per_75_data.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2pYxkLUbkWek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ABA 1974-76 DATA**"
      ],
      "metadata": {
        "id": "HtCLgfbO4rpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scrape_aba_player_per100_data(aba_seasons)\n",
        "#scrape_aba_advanced_data(aba_seasons)\n",
        "#scrape_nba_player_per100_aba_data(aba_seasons)\n",
        "#scrape_team_ts_allowed_data(aba_seasons)\n",
        "#scrape_nba_player_reg_avg_per_100(aba_seasons)\n",
        "#scrape_team_defrtg_allowed_data(aba_seasons)\n",
        "#scrape_nba_player_avg_defrtg(aba_seasons)"
      ],
      "metadata": {
        "id": "YvT4wDHZ5Ihd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA 1974-76 Scrape Functions\n",
        "# Scrape ABA regular season per 100\n",
        "def scrape_aba_player_per100_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = final_players_per100_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"aba_player_since74_per100_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA regular season advanced\n",
        "def scrape_aba_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP'\n",
        "                                                        ])\n",
        "    for year in years:\n",
        "        player_advanced_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_advanced_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_advanced_stats = [e for e in player_advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_advanced_stats)):\n",
        "             player_advanced_stats[i].insert(0, year)\n",
        "             player_advanced_stats[i].insert(5, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(5, \"TeamColor\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_advanced_df = final_players_advanced_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "        #final_players_advanced_df['Player'] = final_players_advanced_df['Player'].apply(ast.literal_eval).str.decode(\"utf-8\")\n",
        "        #final_players_advanced_df['Player'] = unidecode(final_players_advanced_df['Player'])\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"aba_player_since74_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA playoffs per 100\n",
        "def scrape_nba_player_per100_aba_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = final_players_per100_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"nba_player_since74playoffs_per100_aba_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA Teams' TS% Allowed\n",
        "def scrape_team_ts_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team' 'TS% Allowed'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_totals_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'totals-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['TS% Allowed'] = each_years_teams['PTS'] / ( ( (each_years_teams['FTA'] * .44) + (each_years_teams['FGA']) ) * 2)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(aba_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"ABA_Team_TS_Percentage_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape ABA Reg Avg Per 75 Scoring\n",
        "def scrape_nba_player_reg_avg_per_100(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PP75'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = (each_year['PTS'].astype(float) * .75) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        new_row = {'Year':year, 'Average PP75':running_pts_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_ABA_Reg_PP75.csv\", index=False)\n",
        "\n",
        "# Scrape ABA Teams' DefRtg \n",
        "def scrape_team_defrtg_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(aba_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"ABA_Team_defrtg_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape ABA League Avg DefRtg\n",
        "def scrape_nba_player_avg_defrtg(years):\n",
        "\n",
        "  final_team_data_df = pd.DataFrame(columns = ['Year', 'Avg DefRtg'])\n",
        "    \n",
        "  for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        avg_def_rtg = each_year['PTS'].mean()\n",
        "\n",
        "\n",
        "\n",
        "        new_row = {'Year':year, 'Avg DefRtg':avg_def_rtg}\n",
        "        final_team_data_df = final_team_data_df.append(new_row, ignore_index=True)\n",
        "        final_team_data_df['Year'] = final_team_data_df['Year'].astype(int)\n",
        "        print(new_row)\n",
        "        \n",
        "  # print final_df\n",
        "  final_team_data_df.to_csv(\"Avg_ABA_Def_Rtg.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0ybCHOcAfCBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA 1974-76 Ancillary Calculations\n",
        "\n",
        "# Calculate ABA reg per 75 points\n",
        "aba_per100_reg_df = pd.read_csv('/content/aba_player_since74_per100_data.csv')\n",
        "aba_per100_reg_df['PTS'] = aba_per100_reg_df['PTS'] * .75\n",
        "aba_advanced_reg_df = pd.read_csv('/content/aba_player_since74_advanced_data.csv')\n",
        "\n",
        "\n",
        "# Add ABA reg TS+\n",
        "# TS% from advanced dataframge (aba_advanced_reg_df.iat[j, 9]) divided by league average TS% (aba_league_avg.iat[yearloop, 1])\n",
        "i = 1976\n",
        "for yearloop in range(49):\n",
        "  for j, row in aba_per100_reg_df.iterrows():\n",
        "    if row['Year'] == i:\n",
        "      aba_per100_reg_df.iat[j, 1] = (aba_advanced_reg_df.iat[j, 9] / aba_league_avg.iat[yearloop, 1]) * 100\n",
        "  i = i - 1\n",
        "\n",
        "aba_per100_reg_df = aba_per100_reg_df[import_player_since74_per75_df['TS%+'].notna()]\n",
        "outfile = f\"aba_per75_reg_data.csv\"\n",
        "aba_per100_reg_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OIcwUzC7Swym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ylkdaUS_rxK"
      },
      "source": [
        "**NBA 1974-2022 DATA**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scrape_nba_player_reg_per100_data(possession_data_seasons)\n",
        "#scrape_nba_player_post_per100_data(possession_data_seasons)\n",
        "#scrape_nba_advanced_reg_data(possession_data_seasons)\n",
        "#scrape_nba_advanced_post_data(possession_data_seasons)\n",
        "#scrape_nba_reg_playbyplay_data(play_by_play_data_seasons)\n",
        "#scrape_nba_post_playbyplay_data(play_by_play_data_seasons)\n",
        "#scrape_nba_leaguestats_data(possession_data_seasons)\n",
        "#scrape_nba_player_reg_avg_per_75(possession_data_seasons)\n",
        "#scrape_nba_player_playoff_avg_per_75(possession_data_seasons)\n",
        "#scrape_nba_player_reg_bpm_avg(possession_data_seasons)\n",
        "#scrape_team_ts_allowed_data(all_the_years)\n",
        "#scrape_team_defrtg_allowed_data(all_the_years)\n",
        "#scrape_nba_player_avg_defrtg(all_the_years)"
      ],
      "metadata": {
        "id": "VUlmu6LP6eAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "28WIXVx2GuiM"
      },
      "outputs": [],
      "source": [
        "#@title NBA 1974-2022 Scrape Functions\n",
        "\n",
        "# Scrape NBA regular season per 100\n",
        "def scrape_nba_player_reg_per100_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = final_players_per100_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"nba_player_since74_per100_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoffs per 100\n",
        "def scrape_nba_player_post_per100_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = final_players_per100_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"nba_player_since74playoffs_per100_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season advanced\n",
        "def scrape_nba_reg_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP'\n",
        "                                                        ])\n",
        "    for year in years:\n",
        "        player_advanced_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_advanced_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_advanced_stats = [e for e in player_advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_advanced_stats)):\n",
        "             player_advanced_stats[i].insert(0, year)\n",
        "             player_advanced_stats[i].insert(5, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(5, \"TeamColor\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_advanced_df = final_players_advanced_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "        #final_players_advanced_df['Player'] = final_players_advanced_df['Player'].apply(ast.literal_eval).str.decode(\"utf-8\")\n",
        "        #final_players_advanced_df['Player'] = unidecode(final_players_advanced_df['Player'])\n",
        "        final_players_advanced_df['Player'].apply(unidecode)\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"nba_player_since74_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoffs advanced\n",
        "def scrape_nba_post_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP'\n",
        "                                                        ])\n",
        "    for year in years:\n",
        "        player_advanced_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_advanced_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_advanced_stats = [e for e in player_advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_advanced_stats)):\n",
        "             player_advanced_stats[i].insert(0, year)\n",
        "             player_advanced_stats[i].insert(5, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(5, \"TeamColor\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_advanced_df = final_players_advanced_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "        #final_players_advanced_df['Player'] = final_players_advanced_df['Player'].apply(ast.literal_eval).str.decode(\"utf-8\")\n",
        "        #final_players_advanced_df['Player'] = unidecode(final_players_advanced_df['Player'])\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"nba_player_since74playoffs_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season play-by-play\n",
        "def scrape_nba_reg_playbyplay_data(years):\n",
        " \n",
        "    final_players_playbyplay_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age',\n",
        "                                                          'Tm', 'G', 'MP','OnCourt', 'On-Off', 'BadPass', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1'\n",
        "                                                         ])\n",
        "    \n",
        "    for year in years:\n",
        "        player_playbyplay_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        html = urlopen(player_playbyplay_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        # grab tr[1], as tr[0] is populated with categorical headers. Not headers for each columns of data (which are in tr[1])\n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"Blkd\")+1]\n",
        "\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_playbyplay_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_playbyplay_stats = [e for e in player_playbyplay_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_playbyplay_stats)):\n",
        "             player_playbyplay_stats[i].insert(0, year)   \n",
        "        headers.insert(0, \"Year\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_playbyplay_stats, columns = headers)\n",
        "\n",
        "        #rename some columns for less ambiguity\n",
        "        each_year.columns=['Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'MP','PG%', 'SG%', 'SF%', 'PF%', 'C%',\n",
        "                            'OnCourt', 'On-Off', 'BadPass', 'LostBall', 'ShootCommit', 'OffCommit', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1', 'Blkd']\n",
        "        # drop irrelevant columns\n",
        "        each_year = each_year.drop(['PG%', 'SG%', 'SF%', 'PF%', 'C%', 'LostBall', 'ShootCommit', 'OffCommit', 'Blkd'], axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_playbyplay_df['Player'] = final_players_playbyplay_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_playbyplay_df.info)\n",
        "    final_players_playbyplay_df.to_csv(\"nba_player_regular_playbyplay_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoffs play-by-play\n",
        "# import needed libraries\n",
        "def scrape_nba_post_playbyplay_data(years):\n",
        " \n",
        "    final_players_playbyplay_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age',\n",
        "                                                          'Tm', 'G', 'MP','OnCourt', 'On-Off', 'BadPass', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1'\n",
        "                                                         ])\n",
        "    \n",
        "    for year in years:\n",
        "        player_playbyplay_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        html = urlopen(player_playbyplay_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        # grab tr[1], as tr[0] is populated with categorical headers. Not headers for each columns of data (which are in tr[1])\n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"Blkd\")+1]\n",
        "\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_playbyplay_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_playbyplay_stats = [e for e in player_playbyplay_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_playbyplay_stats)):\n",
        "             player_playbyplay_stats[i].insert(0, year)   \n",
        "        headers.insert(0, \"Year\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_playbyplay_stats, columns = headers)\n",
        "\n",
        "        #rename some columns for less ambiguity\n",
        "        each_year.columns=['Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'MP','PG%', 'SG%', 'SF%', 'PF%', 'C%',\n",
        "                            'OnCourt', 'On-Off', 'BadPass', 'LostBall', 'ShootCommit', 'OffCommit', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1', 'Blkd']\n",
        "        # drop irrelevant columns\n",
        "        each_year = each_year.drop(['PG%', 'SG%', 'SF%', 'PF%', 'C%', 'LostBall', 'ShootCommit', 'OffCommit', 'Blkd'], axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_playbyplay_df['Player'] = final_players_playbyplay_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_playbyplay_df.info)\n",
        "    final_players_playbyplay_df.to_csv(\"nba_player_playoff_playbyplay_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season league average\n",
        "def scrape_nba_leaguestats_data():\n",
        "\n",
        "        final_leaguestats_df = pd.DataFrame(columns = ['Year',\t'Lg',\t'Age',\t'Ht',\t'Wt',\t'G',\t'MP',\t'FG',\t'FGA',\t'3P',\n",
        "                                                      '3PA',\t'FT',\t'FTA',\t'ORB',\t'DRB',\t'TRB',\t'AST',\t'STL',\t'BLK',\t'TOV',\n",
        "                                                      'PF',\t'PTS',\t'FG%',\t'3P%',\t'FT%',\t'Pace',\t'eFG%',\t'TOV%',\t'ORB%',\n",
        "                                                      'FT/FGA',\t'ORtg', 'TS%'])\n",
        "        \n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_stats_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"ORtg\")+1]\n",
        "        headers.insert(32, \"TS%\")\n",
        "        print(headers)\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        #rows = soup.findAll('tr', class=None)[1:]\n",
        "        rows = soup.findAll('tr', class_=None)[1:]\n",
        "\n",
        "\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "          player_base_stats[i].insert(32, 0)\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        final_leaguestats_df = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        final_leaguestats_df = final_leaguestats_df.drop(['Lg'], axis=1)\n",
        "\n",
        "        final_leaguestats_df = final_leaguestats_df.iloc[1: , :]\n",
        "\n",
        "        final_leaguestats_df.drop(final_leaguestats_df.index[20])\n",
        "        final_leaguestats_df.drop(final_leaguestats_df.index[21])\n",
        "        \n",
        "        # print final_df\n",
        "        print(final_leaguestats_df.info)\n",
        "        final_leaguestats_df.to_csv(\"nba_leaguestats_data.csv\", index=False)\n",
        "\n",
        "# Scrape Reg Avg Per 75 Scoring\n",
        "def scrape_nba_player_reg_avg_per_75(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PP75'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = (each_year['PTS'].astype(float) * .75) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        new_row = {'Year':year, 'Average PP75':running_pts_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_Reg_PP75.csv\", index=False)\n",
        "\n",
        "# Scrape Playoff Avg Per 75 Scoring\n",
        "def scrape_nba_player_playoff_avg_per_75(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PP75'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = (each_year['PTS'].astype(float) * .75) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        year = year.astype(int)\n",
        "        new_row = {'Year':year, 'Average PP75':running_pts_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_Playoff_PP75.csv\", index=False)\n",
        "\n",
        "# Scrape Reg Avg BPM\n",
        "def scrape_nba_player_reg_bpm_avg(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average BPM', 'Average OBPM'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_bpm_avg = 0\n",
        "        running_obpm_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['BPM'] = each_year['BPM'].astype(float)\n",
        "        each_year['OBPM'] = each_year['OBPM'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['adjBPM'] = each_year['BPM'].astype(float) * (each_year['MP'].astype(float) / total_mp)\n",
        "        each_year['adjOBPM'] = each_year['OBPM'].astype(float) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_bpm_avg = each_year['adjBPM'].sum()\n",
        "        running_obpm_avg = each_year['adjOBPM'].sum()\n",
        "\n",
        "        running_bpm_avg = running_bpm_avg + 1\n",
        "        running_obpm_avg = running_obpm_avg + 1\n",
        "\n",
        "\n",
        "        new_row = {'Year':year, 'Average BPM':running_bpm_avg, 'Average OBPM':running_obpm_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        final_df['Year'] = final_df['Year'].astype(int)\n",
        "        \n",
        "    # print final_df\n",
        "    final_df.to_csv(\"Avg_Reg_BPM.csv\", index=False)\n",
        "\n",
        "# Scrape NBA Teams' TS% Allowed\n",
        "def scrape_team_ts_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team' 'TS% Allowed'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_totals_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'totals-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['TS% Allowed'] = each_years_teams['PTS'] / ( ( (each_years_teams['FTA'] * .44) + (each_years_teams['FGA']) ) * 2)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(team_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"NBA_Team_TS_Percentage_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape NBA Teams' DefRtg \n",
        "def scrape_team_defrtg_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(team_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"NBA_Team_defrtg_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape League Avg DefRtg\n",
        "def scrape_nba_player_avg_defrtg(years):\n",
        "\n",
        "  final_team_data_df = pd.DataFrame(columns = ['Year', 'Avg DefRtg'])\n",
        "    \n",
        "  for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        avg_def_rtg = each_year['PTS'].mean()\n",
        "\n",
        "\n",
        "\n",
        "        new_row = {'Year':year, 'Avg DefRtg':avg_def_rtg}\n",
        "        final_team_data_df = final_team_data_df.append(new_row, ignore_index=True)\n",
        "        final_team_data_df['Year'] = final_team_data_df['Year'].astype(int)\n",
        "        print(new_row)\n",
        "        \n",
        "  # print final_df\n",
        "  final_team_data_df.to_csv(\"Avg_Def_Rtg.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA 1974-2022 Ancillary Calculations\n",
        "\n",
        "# Calculate NBA reg per 75 points\n",
        "import_player_since74_per75_df = import_player_since74_per100_df.copy()\n",
        "import_player_since74_per75_df['PTS'] = import_player_since74_per75_df['PTS'] * .75\n",
        "\n",
        "# Add NBA reg TS+\n",
        "# TS% from advanced dataframge (import_player_since74_advanced_df.iat[j, 9]) divided by league average TS% (league_avg_df.iat[yearloop, 1])\n",
        "i = 2022\n",
        "for yearloop in range(49):\n",
        "  for j, row in import_player_since74_per75_df.iterrows():\n",
        "    if row['Year'] == i:\n",
        "      import_player_since74_per75_df.iat[j, 1] = (import_player_since74_advanced_df.iat[j, 9] / league_avg_df.iat[yearloop, 1]) * 100\n",
        "  i = i - 1\n",
        "\n",
        "import_player_since74_per75_df = import_player_since74_per75_df[import_player_since74_per75_df['TS%+'].notna()]\n",
        "outfile = f\"nba_player_since74_per75_data.csv\"\n",
        "import_player_since74_per75_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate Playoffs per 75\n",
        "#import_player_since74playoffs_per75_df = import_player_since74playoffs_per100_df.copy()\n",
        "#import_player_since74playoffs_per75_df['PTS'] = import_player_since74playoffs_per75_df['PTS'] * .75\n",
        "\n",
        "aba_per75_pts = pd.read_csv('/content/aba_player_since74playoffs_per100_data.csv')\n",
        "aba_per75_pts['PTS'] = aba_per75_pts['PTS'] * .75\n",
        "\n",
        "outfile = f\"aba_player_since74playoffs_per75_data.csv\"\n",
        "aba_per75_pts.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_ntucsSc6SDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPo3JH7bZmrN"
      },
      "source": [
        "**SCRAPE URL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape NBA Player URL's (1952-73)\n",
        "# import needed libraries\n",
        "def scrape_url_data_52_73(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        wd.get(page_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_game_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = player_url_df.append(tmp_df)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_52-73_URL_data.csv\", index=False)\n",
        "scrape_url_data_52_73(pre_possesson_data_seasons)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Vj0vFAsXBecy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape ABA Player URL's (1968-73)\n",
        "# import needed libraries\n",
        "def scrape_url_data_aba(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_per_game.html\"\n",
        "        \n",
        "        wd.get(page_url)       \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_game_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = player_url_df.append(tmp_df)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"aba_player_URL_data.csv\", index=False)\n",
        "scrape_url_data_aba(aba_pre_possession_seasons)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "U2QkVE4z66FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape ABA Player URL's (1974-76)\n",
        "# import needed libraries\n",
        "def scrape_url_data_aba(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        wd.get(page_url)       \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(15)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = player_url_df.append(tmp_df)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_aba_URL_data.csv\", index=False)\n",
        "scrape_url_data_aba([1974, 1975, 1976])"
      ],
      "metadata": {
        "id": "tl9YBqUF8T4H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gxLh3jVuAZe4"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA Player URL's (1974-2022)\n",
        "# import needed libraries\n",
        "def scrape_url_data_74(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        wd.get(page_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(15)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = player_url_df.append(tmp_df)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_since_74_URL_data.csv\", index=False)\n",
        "scrape_url_data_74(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1BJWc9nsob9K"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA Player URL's (1997-2022)\n",
        "# import needed libraries\n",
        "def scrape_url_data_97(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        print(year)\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        wd.get(page_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(15)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_pbp_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'pbp_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = player_url_df.append(tmp_df)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_URL_data.csv\", index=False)\n",
        "scrape_all_distribution_data(some_of_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "cellView": "form",
        "id": "4yATMvO-BkTW"
      },
      "outputs": [],
      "source": [
        "#@title Shorten URL list to only players with >x playoff minutes\n",
        "def nba_shorten_url_list_by_x(url_df, min_requirement):\n",
        "\n",
        "    new_df = pd.DataFrame(columns = ['Player', 'URL', 'MP'])\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      og_url = url\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      \n",
        "\n",
        "      wd.get(url)          \n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "      time.sleep(5)\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_advanced-playoffs_advanced'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs_advanced'})\n",
        "        foot = first_table.find('tfoot')\n",
        "\n",
        "      rows = foot.find('tr')\n",
        "      only_for_mp = [[td.getText() for td in rows.findAll('td')]]\n",
        "\n",
        "      # remove empty rows\n",
        "      only_for_mp = [e for e in only_for_mp if e != []]\n",
        "\n",
        "      url_data = pd.DataFrame(only_for_mp)\n",
        "\n",
        "      tmp_df = pd.DataFrame(columns = ['Player', 'URL', 'MP'])\n",
        "      \n",
        "\n",
        "      # took only long mid range FGA\n",
        "      if int(url_data[5]) <= min_requirement:\n",
        "        continue\n",
        "      else:\n",
        "        mp = int(url_data[5])\n",
        "\n",
        "      tmp_df.loc[len(tmp_df)] = [player, og_url, mp]\n",
        "      new_df = new_df.append(tmp_df)\n",
        "      outfile = f\"NBA_Player_68-73_URL_List_{min_requirement}_Min_df.csv\"\n",
        "      new_df.to_csv(outfile, index=False)\n",
        "      print(tmp_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLzLiVsSJUU2"
      },
      "outputs": [],
      "source": [
        "player_urls = pd.read_csv('', index_col=False, encoding='utf8')\n",
        "nba_shorten_url_list_by_x(player_urls, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NBA 1952-73 ADJUSTED PLAYOFF TS+ (Opponent Adjustment)**"
      ],
      "metadata": {
        "id": "UGB9Dqwm8Srb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA 1952-73 Adjusted Playoff TS+\n",
        "def adjust_scoring_efficiency(url_df, tmp_league_avg_df, opp_defrtg_df, rr_df):\n",
        "    from itertools import chain\n",
        "\n",
        "    tmp_league_avg_df['Year'] = tmp_league_avg_df['Year'].astype(int)\n",
        "    tmp_league_avg_df['Year'] = tmp_league_avg_df['Year'].astype(str)\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'TS+', 'PTS_coeff', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      time.sleep(5)\n",
        "      print(player)\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        header = first_table.find('thead')\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "      try:\n",
        "        headers[32] = 'MP/G'\n",
        "        headers[33] = 'PTS/G'\n",
        "         # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "        # remove empty rows\n",
        "        series_stats = [e for e in series_stats if e != []]\n",
        "        series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        missing_mp_data = series_data.copy()\n",
        "        missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      except:\n",
        "        try:\n",
        "          headers[31] = 'MP/G'\n",
        "          headers[32] = 'PTS/G'\n",
        "          # grab rows\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "          # remove empty rows\n",
        "          series_stats = [e for e in series_stats if e != []]\n",
        "          series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          missing_mp_data = series_data.copy()\n",
        "          missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "        except:\n",
        "          try:\n",
        "            headers[30] = 'MP/G'\n",
        "            headers[31] = 'PTS/G'\n",
        "            # grab rows\n",
        "            rows = body.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            missing_mp_data = series_data.copy()\n",
        "            missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "          except:\n",
        "            try:\n",
        "              headers[29] = 'MP/G'\n",
        "              headers[30] = 'PTS/G'\n",
        "              # grab rows\n",
        "              rows = body.findAll('tr')[0:]\n",
        "              series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "              # remove empty rows\n",
        "              series_stats = [e for e in series_stats if e != []]\n",
        "              series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "              series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "              missing_mp_data = series_data.copy()\n",
        "              missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "            except:\n",
        "              try:\n",
        "                headers[27] = 'MP/G'\n",
        "                headers[28] = 'PTS/G'\n",
        "                # grab rows\n",
        "                rows = body.findAll('tr')[0:]\n",
        "                series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "                # remove empty rows\n",
        "                series_stats = [e for e in series_stats if e != []]\n",
        "                series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "                series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "                missing_mp_data = series_data.copy()\n",
        "                missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "              except:\n",
        "                try:\n",
        "                  headers[24] = 'MP/G'\n",
        "                  headers[25] = 'PTS/G'\n",
        "                  # grab rows\n",
        "                  rows = body.findAll('tr')[0:]\n",
        "                  series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "                  # remove empty rows\n",
        "                  series_stats = [e for e in series_stats if e != []]\n",
        "                  series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "                  series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "                  missing_mp_data = series_data.copy()\n",
        "                  missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "                except:\n",
        "                  headers[19] = 'MP/G'\n",
        "                  headers[20] = 'PTS/G'\n",
        "                  # grab rows\n",
        "                  rows = body.findAll('tr')[0:]\n",
        "                  series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "                  # remove empty rows\n",
        "                  series_stats = [e for e in series_stats if e != []]\n",
        "                  series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "                  series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "                  missing_mp_data = series_data.copy()\n",
        "                  missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      \n",
        "      # drop seasons which have definite possession data (as opposed to estimated data being generated)\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1992\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1991\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1990\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1989\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1988\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1987\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1986\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1985\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1984\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1983\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1982\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1981\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1980\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1979\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1978\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1977\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1976\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1975\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1974\", float('NaN'))\n",
        "\n",
        "      # remove seasons preceding 1952\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1951\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1950\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1949\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1948\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1947\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1946\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1945\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1944\", float('NaN'))\n",
        "\n",
        "      # convert ABA seasons to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SSL\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"VIR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SAA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"INA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"UTS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"KEN\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"CAR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))    \n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "      series_data = series_data.reset_index()\n",
        "\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['G'] = series_data['G'].astype(float)\n",
        "\n",
        "      \n",
        "      # may be missing MP data.\n",
        "      # divide the missing estimated total numbers equally among games w/o MP data.\n",
        "      missing_mp_data = series_data.copy()\n",
        "      missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      years_list = []\n",
        "      \n",
        "      remaining_mp = []\n",
        "      missing_index = 0\n",
        "      \n",
        "      \n",
        "      for mp_idx, row in missing_mp_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_mp_data.loc[mp_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which MP aren't accounted for\n",
        "          working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # MP accounted for \n",
        "          accounted_for_mp = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_mp['MP'] = accounted_for_mp['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_mp.dropna(inplace=True)\n",
        "          accounted_for_mp = (accounted_for_mp['MP'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total MP\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x <= 1973 and x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "\n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_mp = selected_year['MP'].astype(float)\n",
        "          \n",
        "\n",
        "          # remaining MP contains estimated MP for this year's series with missing MP\n",
        "          remaining_mp.append(total_mp - accounted_for_mp)\n",
        "\n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            idx = int(idx)\n",
        "            if working_missing_year.shape[0]  == 1:\n",
        "              series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index])\n",
        "            elif working_missing_year.shape[0]  == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0]  == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      # may be missing FGA data.\n",
        "      # divide the missing estimated total numbers equally among games w/o FGA data.\n",
        "      missing_fg_data = series_data.copy()\n",
        "      missing_fg_data = missing_fg_data[(missing_fg_data['FGA'] == '')]\n",
        "      years_list = []\n",
        "      remaining_fg = []\n",
        "      missing_index = 0\n",
        "\n",
        "      for fg_idx, row in missing_fg_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_fg_data.loc[fg_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which FGA aren't accounted for \n",
        "          working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # FGA accounted for \n",
        "          accounted_for_fg = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_fg['FGA'] = accounted_for_fg['FGA'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_fg.dropna(inplace=True)\n",
        "          accounted_for_fg = (accounted_for_fg['FGA'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total FGA\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          from itertools import chain\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x <= 1973 and x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_fg = selected_year['FGA'].astype(float)\n",
        "          selected_year['Tm'] = selected_year['Tm'].astype(str)\n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          # remaining FGA contains estimated FGA for this year's series with missing FGA\n",
        "          remaining_fg.append(total_fg - accounted_for_fg)\n",
        "          \n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            if working_missing_year.shape[0] == 1:\n",
        "              series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index])\n",
        "            elif working_missing_year.shape[0] == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0] == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data['FGA'].iat[idx] = float(remaining_fg[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      series_data['TS+'] = 0\n",
        "      years_list = []\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "\n",
        "        # get defrtg allowed by opponent\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        this_year = tmp_league_avg_df[(tmp_league_avg_df['Year'] == current_year)]\n",
        "        league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "        league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "        # estimate TS+ allowed\n",
        "        predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "        #find raw TS% compared to league average\n",
        "        raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "        if row['PTS'] == 0:\n",
        "          tsplus = 0\n",
        "        else:\n",
        "          tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed)) * 100\n",
        "        series_data.loc[i,'TS+'] = tsplus\n",
        "        series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "        if series_data.loc[i,'Year'] not in years_list:\n",
        "          years_list.append(series_data.loc[i,'Year'])\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'FGA', 'FTA', 'PTS', 'MPG'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = series_data[(series_data['Year'] == year)]\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "        new_row = {'Player':player, 'Year':year, 'TS+':total_ts, 'PTS_coeff':total_coeff, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "      outfile = f\"NBA_Playoff_Estimated_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)\n",
        "    print(final_season_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Zp1fwXJViD1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Adjusted Playoff TS+ Scrape\n",
        "\n",
        "# correlation will be used to estimate TS%'s allowed by teams from 1952-1973\n",
        "rdRtg = pd.read_csv(\"/content/remove reg teams.csv\", index_col=False, encoding='utf8')\n",
        "rTS = pd.read_csv(\"/content/NBA_Team_TS_Percentage_Allowed_df.csv\", index_col=False, encoding='utf8')\n",
        "\n",
        "rTS['Year'] = rTS['Year'].astype(int)\n",
        "league_avg_df['Year'] = league_avg_df['Year'].astype(float)\n",
        "\n",
        "rTS['rTS'] = 0\n",
        "\n",
        "for idx, row in rTS.iterrows():     \n",
        "          match_df = league_avg_df[(league_avg_df['Year'] == row['Year'])]\n",
        "          rTS.iat[idx, 3] = float(rTS.iat[idx, 2] / (match_df['TS%']))\n",
        "          \n",
        "rTS = rTS.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "rdRtg = rdRtg.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "import scipy.stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "x_pred = rdRtg['PTS_coeff']\n",
        "x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "y_pred = rTS['rTS']\n",
        "\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(x_pred, y_pred)\n",
        "pred = lr.predict(x_pred)\n",
        "#plt.plot(x_pred, pred, color=\"blue\", linewidth=3)\n",
        "#plt.scatter(rdRtg['PTS_coeff'], rTS['rTS'])\n",
        "\n",
        "# Run Adjusted Playoff TS+ Scrape\n",
        "url_txt_df = pd.read_csv('/content/problematic.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "rr_df = pd.read_csv('/content/RR_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "adjust_scoring_efficiency(url_txt_df, league_avg_df, opponent_adj_pts_coeff, rr_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N80qT1UsMUn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create DataFrame of Adjusted TS+ Data and Adjust for Era\n",
        "start_to_ajust_playoffs_per_75 = pd.read_csv('/content/52-73_playoff_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "adj_ts_list = pd.read_csv('NBA_Playoff_Estimated_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "names = [x for x in start_to_ajust_playoffs_per_75.columns]\n",
        "adjusted_playoff_per_75_df = pd.DataFrame(columns=names)\n",
        "\n",
        "for outer_index, adj_player_season in adj_ts_list.iterrows():\n",
        "\n",
        "  adj_player_season['Player'] = str(adj_player_season['Player'])\n",
        "  adj_player_season['Year'] = str(adj_player_season['Year'])\n",
        "  start_to_ajust_playoffs_per_75['Player'] = start_to_ajust_playoffs_per_75['Player'].astype(str)\n",
        "  start_to_ajust_playoffs_per_75['Year'] = start_to_ajust_playoffs_per_75['Year'].astype(str)\n",
        "\n",
        "  current_player = adj_player_season.loc['Player']\n",
        "  current_year = adj_player_season.loc['Year']\n",
        "  smaller_start_adj_list = start_to_ajust_playoffs_per_75[(start_to_ajust_playoffs_per_75['Player'] == current_player) & ((start_to_ajust_playoffs_per_75['Year'] == current_year))]\n",
        "  smaller_start_adj_list['TS%+'] = adj_player_season['TS+']\n",
        "  smaller_start_adj_list['PTS'] = smaller_start_adj_list['PTS'] * adj_player_season['PTS_coeff']\n",
        "  adjusted_playoff_per_75_df = adjusted_playoff_per_75_df.append(smaller_start_adj_list, ignore_index=True)\n",
        "outfile = f\"since52_adj_ts_playoffs_per75_data.csv\"\n",
        "adjusted_playoff_per_75_df.to_csv(outfile, index=False)\n",
        "\n",
        "# Era Adjustment\n",
        "playoff_75_data = pd.read_csv('since52_adj_ts_playoffs_per75_data.csv')\n",
        "\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in playoff_75_data.iterrows():\n",
        "  era_adj = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PTS'] = float(row['PTS']) * float(era_adj['Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"52-73_era_opponent_adjusted_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lj225Dkh9LzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Remove round robin data\n",
        "       # remove round robin data\n",
        "          if current_year == '1954':\n",
        "            remove_rr_url = url + \"/gamelog/1954\"\n",
        "            time.sleep(5)\n",
        "            wd.get(remove_rr_url)\n",
        "            html = wd.page_source\n",
        "            soup = BeautifulSoup(html)\n",
        "            rr_df\n",
        "            selected_year = selected_year.sort_index(inplace=True)\n",
        "            rr_df = rr_df.sort_index(inplace=True)\n",
        "            print(selected_year['Tm'])\n",
        "\n",
        "            rr_df['Team'] = rr_df['Team'].astype(str)\n",
        "\n",
        "            selected_rr = rr_df[(rr_df['Team'] == selected_year['Tm'])]\n",
        "            rr_games = selected_rr['G']\n",
        "\n",
        "            # scrape Playoff shooting distribution data\n",
        "            for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "              second_div = first_div.find('div', attrs={'id': 'div_pgl_basic_playoffs'})\n",
        "              first_table = second_div.find('table', attrs={'id': 'pgl_basic_playoffs'})\n",
        "              header = first_table.find('thead')\n",
        "              body = first_table.find('tbody')\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "            print(headers)\n",
        "\n",
        "            # grab total stats\n",
        "            rows = body.findAll('tr')[0:]\n",
        "            player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "            player_total_stats = [e for e in player_total_stats if e != []]\n",
        "            #if player_total_stats[0, ]\n",
        "            print(player_total_stats)\n",
        "            print(total_fg)\n",
        "            total_fg = total_fg - (total_fg * (selected_year['G'] - rr_games))\n",
        "            print(total_fg)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0eOsSzoYechU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ABA 1968-73 ADJUSTED PLAYOFF TS+ (Opponent Adjustment)**"
      ],
      "metadata": {
        "id": "HEio76fz1q9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA 1968-73 Adjusted Playoff TS+\n",
        "def adjust_scoring_efficiency(url_df, tmp_league_avg_df, opp_defrtg_df, rr_df):\n",
        "    from itertools import chain\n",
        "\n",
        "    tmp_league_avg_df['Year'] = tmp_league_avg_df['Year'].astype(int)\n",
        "    tmp_league_avg_df['Year'] = tmp_league_avg_df['Year'].astype(str)\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'TS+', 'PTS_coeff', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      time.sleep(5)\n",
        "      print(player)\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        header = first_table.find('thead')\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "      try:\n",
        "        headers[32] = 'MP/G'\n",
        "        headers[33] = 'PTS/G'\n",
        "         # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "        # remove empty rows\n",
        "        series_stats = [e for e in series_stats if e != []]\n",
        "        series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        missing_mp_data = series_data.copy()\n",
        "        missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      except:\n",
        "        try:\n",
        "          headers[31] = 'MP/G'\n",
        "          headers[32] = 'PTS/G'\n",
        "          # grab rows\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "          # remove empty rows\n",
        "          series_stats = [e for e in series_stats if e != []]\n",
        "          series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          missing_mp_data = series_data.copy()\n",
        "          missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "        except:\n",
        "          try:\n",
        "            headers[30] = 'MP/G'\n",
        "            headers[31] = 'PTS/G'\n",
        "            # grab rows\n",
        "            rows = body.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            missing_mp_data = series_data.copy()\n",
        "            missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "          except:\n",
        "            try:\n",
        "              headers[29] = 'MP/G'\n",
        "              headers[30] = 'PTS/G'\n",
        "              # grab rows\n",
        "              rows = body.findAll('tr')[0:]\n",
        "              series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "              # remove empty rows\n",
        "              series_stats = [e for e in series_stats if e != []]\n",
        "              series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "              series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "              missing_mp_data = series_data.copy()\n",
        "              missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "            except:\n",
        "              try:\n",
        "                headers[27] = 'MP/G'\n",
        "                headers[28] = 'PTS/G'\n",
        "                # grab rows\n",
        "                rows = body.findAll('tr')[0:]\n",
        "                series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "                # remove empty rows\n",
        "                series_stats = [e for e in series_stats if e != []]\n",
        "                series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "                series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "                missing_mp_data = series_data.copy()\n",
        "                missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "              except:\n",
        "                try:\n",
        "                  headers[24] = 'MP/G'\n",
        "                  headers[25] = 'PTS/G'\n",
        "                  # grab rows\n",
        "                  rows = body.findAll('tr')[0:]\n",
        "                  series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "                  # remove empty rows\n",
        "                  series_stats = [e for e in series_stats if e != []]\n",
        "                  series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "                  series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "                  missing_mp_data = series_data.copy()\n",
        "                  missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "                except:\n",
        "                  headers[19] = 'MP/G'\n",
        "                  headers[20] = 'PTS/G'\n",
        "                  # grab rows\n",
        "                  rows = body.findAll('tr')[0:]\n",
        "                  series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "                  # remove empty rows\n",
        "                  series_stats = [e for e in series_stats if e != []]\n",
        "                  series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "                  series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "                  missing_mp_data = series_data.copy()\n",
        "                  missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      \n",
        "      # drop seasons which have definite possession data (as opposed to estimated data being generated)\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1992\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1991\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1990\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1989\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1988\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1987\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1986\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1985\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1984\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1983\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1982\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1981\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1980\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1979\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1978\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1977\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1976\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1975\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1974\", float('NaN'))  \n",
        "      series_data['Year'] = series_data['Year'].replace(\"1967\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1966\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1965\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1964\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1963\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1962\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1961\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1960\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1959\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1958\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1957\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1956\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1955\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1954\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1953\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1952\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "      series_data = series_data.reset_index()\n",
        "\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['G'] = series_data['G'].astype(float)\n",
        "\n",
        "      \n",
        "      # may be missing MP data.\n",
        "      # divide the missing estimated total numbers equally among games w/o MP data.\n",
        "      missing_mp_data = series_data.copy()\n",
        "      missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      years_list = []\n",
        "      \n",
        "      remaining_mp = []\n",
        "      missing_index = 0\n",
        "      \n",
        "      \n",
        "      for mp_idx, row in missing_mp_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_mp_data.loc[mp_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which MP aren't accounted for\n",
        "          working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # MP accounted for \n",
        "          accounted_for_mp = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_mp['MP'] = accounted_for_mp['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_mp.dropna(inplace=True)\n",
        "          accounted_for_mp = (accounted_for_mp['MP'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total MP\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x <= 1973 and x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "\n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_mp = selected_year['MP'].astype(float)\n",
        "          \n",
        "\n",
        "          # remaining MP contains estimated MP for this year's series with missing MP\n",
        "          remaining_mp.append(total_mp - accounted_for_mp)\n",
        "\n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            idx = int(idx)\n",
        "            if working_missing_year.shape[0]  == 1:\n",
        "              series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index])\n",
        "            elif working_missing_year.shape[0]  == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0]  == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      # may be missing FGA data.\n",
        "      # divide the missing estimated total numbers equally among games w/o FGA data.\n",
        "      missing_fg_data = series_data.copy()\n",
        "      missing_fg_data = missing_fg_data[(missing_fg_data['FGA'] == '')]\n",
        "      years_list = []\n",
        "      remaining_fg = []\n",
        "      missing_index = 0\n",
        "\n",
        "      for fg_idx, row in missing_fg_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_fg_data.loc[fg_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which FGA aren't accounted for \n",
        "          working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # FGA accounted for \n",
        "          accounted_for_fg = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_fg['FGA'] = accounted_for_fg['FGA'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_fg.dropna(inplace=True)\n",
        "          accounted_for_fg = (accounted_for_fg['FGA'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total FGA\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          from itertools import chain\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x <= 1973 and x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_fg = selected_year['FGA'].astype(float)\n",
        "          selected_year['Tm'] = selected_year['Tm'].astype(str)\n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          # remaining FGA contains estimated FGA for this year's series with missing FGA\n",
        "          remaining_fg.append(total_fg - accounted_for_fg)\n",
        "          \n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            if working_missing_year.shape[0] == 1:\n",
        "              series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index])\n",
        "            elif working_missing_year.shape[0] == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0] == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      series_data['TS+'] = 0\n",
        "      years_list = []\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "\n",
        "        # get defrtg allowed by opponent\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        this_year = tmp_league_avg_df[(tmp_league_avg_df['Year'] == current_year)]\n",
        "        league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "        league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "        # estimate TS+ allowed\n",
        "        predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "        #find raw TS% compared to league average\n",
        "        raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "        if row['PTS'] == 0:\n",
        "          tsplus = 0\n",
        "        else:\n",
        "          tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed)) * 100\n",
        "        series_data.loc[i,'TS+'] = tsplus\n",
        "        series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "        if series_data.loc[i,'Year'] not in years_list:\n",
        "          years_list.append(series_data.loc[i,'Year'])\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'FGA', 'FTA', 'PTS', 'MPG'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = series_data[(series_data['Year'] == year)]\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "        new_row = {'Player':player, 'Year':year, 'TS+':total_ts, 'PTS_coeff':total_coeff, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "      outfile = f\"ABA_Playoff_Estimated_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)\n",
        "    print(final_season_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5Sudicew1oPA"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Adjusted Playoff TS+ Scrape\n",
        "\n",
        "# correlation will be used to estimate TS%'s allowed by teams from 1952-1973\n",
        "rdRtg = pd.read_csv(\"/content/remove reg teams.csv\", index_col=False, encoding='utf8')\n",
        "rTS = pd.read_csv(\"/content/NBA_Team_TS_Percentage_Allowed_df.csv\", index_col=False, encoding='utf8')\n",
        "\n",
        "rTS['Year'] = rTS['Year'].astype(int)\n",
        "league_avg_df['Year'] = league_avg_df['Year'].astype(float)\n",
        "\n",
        "rTS['rTS'] = 0\n",
        "\n",
        "for idx, row in rTS.iterrows():     \n",
        "          match_df = league_avg_df[(league_avg_df['Year'] == row['Year'])]\n",
        "          rTS.iat[idx, 3] = float(rTS.iat[idx, 2] / (match_df['TS%']))\n",
        "          \n",
        "rTS = rTS.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "rdRtg = rdRtg.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "import scipy.stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "x_pred = rdRtg['PTS_coeff']\n",
        "x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "y_pred = rTS['rTS']\n",
        "\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(x_pred, y_pred)\n",
        "pred = lr.predict(x_pred)\n",
        "#plt.plot(x_pred, pred, color=\"blue\", linewidth=3)\n",
        "#plt.scatter(rdRtg['PTS_coeff'], rTS['rTS'])\n",
        "\n",
        "# Run Adjusted Playoff TS+ Scrape\n",
        "url_txt_df = pd.read_csv('/content/fragment.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/aba_opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "rr_df = pd.read_csv('/content/RR_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "adjust_scoring_efficiency(url_txt_df, aba_league_avg, opponent_adj_pts_coeff, rr_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "reVRXfYH1iOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create DataFrame of Adjusted TS+ Data and Adjust for Era\n",
        "start_to_ajust_playoffs_per_75 = pd.read_csv('/content/68-73_playoff_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "adj_ts_list = pd.read_csv('ABA_Playoff_Estimated_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "# remove NBA playoffs\n",
        "aba_teams = [\"DNA\", \"INA\", \"NYA\", \"SAA\", \"VIR\", \"CAR\", \"SDA\", \"KEN\",\n",
        "             \"UTS\", \"CAR\", \"SDS\", \"SSL\", \"MMS\", \"DNR\", \"PTP\", \"MNM\",\n",
        "             \"NOB\", \"DLC\", \"TEX\", \"HSM\", \"OAK\", \"MMF\", \"MNP\", \"WSA\",\n",
        "             \"LAS\", \"FLO\", \"MMP\", \"NJA\", \"ANA\", \"PTC\", \"MMT\"]\n",
        "\n",
        "names = [x for x in start_to_ajust_playoffs_per_75.columns]\n",
        "adjusted_playoff_per_75_df = pd.DataFrame(columns=names)\n",
        "\n",
        "for outer_index, adj_player_season in adj_ts_list.iterrows():\n",
        "\n",
        "  adj_player_season['Player'] = str(adj_player_season['Player'])\n",
        "  adj_player_season['Year'] = str(adj_player_season['Year'])\n",
        "  start_to_ajust_playoffs_per_75['Player'] = start_to_ajust_playoffs_per_75['Player'].astype(str)\n",
        "  start_to_ajust_playoffs_per_75['Year'] = start_to_ajust_playoffs_per_75['Year'].astype(str)\n",
        "\n",
        "  current_player = adj_player_season.loc['Player']\n",
        "  current_year = adj_player_season.loc['Year']\n",
        "  smaller_start_adj_list = start_to_ajust_playoffs_per_75[(start_to_ajust_playoffs_per_75['Player'] == current_player) & ((start_to_ajust_playoffs_per_75['Year'] == current_year))]\n",
        "  smaller_start_adj_list['TS%+'] = adj_player_season['TS+']\n",
        "  smaller_start_adj_list['PTS'] = smaller_start_adj_list['PTS'] * adj_player_season['PTS_coeff']\n",
        "  adjusted_playoff_per_75_df = adjusted_playoff_per_75_df.append(smaller_start_adj_list, ignore_index=True)\n",
        "\n",
        "adjusted_playoff_per_75_df = adjusted_playoff_per_75_df[adjusted_playoff_per_75_df.Tm.isin(aba_teams)]\n",
        "outfile = f\"68-73_adj_ts_playoffs_per75_data.csv\"\n",
        "adjusted_playoff_per_75_df.to_csv(outfile, index=False)\n",
        "\n",
        "# Era Adjustment\n",
        "playoff_75_data = pd.read_csv('68-73_adj_ts_playoffs_per75_data.csv')\n",
        "\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in playoff_75_data.iterrows():\n",
        "  era_adj = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PTS'] = float(row['PTS']) * float(era_adj['Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"68-73_era_opponent_adjusted_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Hul4GKL28OcC"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhL-arWPFvb8"
      },
      "source": [
        "**NBA 1974-2022/ABA 1974-76 ADJUSTED PLAYOFF TS+ (Opponent Adjustment)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5D3qCAUcglZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title NBA 1974-2022/ABA 1974-76 Adjusted Playoff TS+\n",
        "def adjust_scoring_efficiency(url_df, opp_ts_df, opp_defrtg_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'TS+', 'PTS_coeff', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      time.sleep(15)\n",
        "      print(player)\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      # grab rows\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "\n",
        "      # post 3PA\n",
        "      try:\n",
        "        headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                  'G',\t'W', 'L',\t'MP', 'FG', 'FGA', '3P', '3PA', 'FT', \n",
        "                  'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                  'PTS', 'dum2', 'FG%', '3P%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                          'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                          'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                          'FG%', '3P%', 'FT%', 'dum3', 'PTS/G', 'TRB/G', 'AST/G'], axis=1)\n",
        "      except:\n",
        "        # post TOV pre 3PA\n",
        "        try:\n",
        "          headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                    'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                    'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                    'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                            'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                            'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                            'FG%', '3P%', 'FT%', 'dum3', 'PTS/G', 'TRB/G', 'AST/G'], axis=1)\n",
        "        # pre TOV and pre 3PA\n",
        "        except:\n",
        "          try:\n",
        "            headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                      'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                      'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'PF',\n",
        "                      'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']  \n",
        "\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                              'G',\t'W', 'L', 'FG', 'FT', 'ORB', \n",
        "                              'TRB',\t'AST', 'STL', 'BLK', 'PF', 'dum2',\n",
        "                              'FG%', 'FT%', 'dum3', 'PTS/G', 'TRB/G', 'AST/G'], axis=1)\n",
        "          # post TOV and pre 3PA \n",
        "          except:\n",
        "            headers = [th.getText() for th in first_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            headers = headers[1:]\n",
        "            headers[2] = 'Year'\n",
        "            headers[27] = 'MP/G'\n",
        "            headers[28] = 'PTS/G'\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      \n",
        "\n",
        "      # convert certain seasons and ABA teams to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1960\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1961\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1962\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1963\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1964\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1965\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1966\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1967\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1968\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1969\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1970\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1971\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1972\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1973\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data['MP'] = series_data['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "\n",
        "      # add TS% allowed\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "\n",
        "\n",
        "      years_list = []\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "\n",
        "        # get ts% allowed by opponent\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & ((opp_ts_df['Year'] == current_year))]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        # get defrtg allowed by opponent\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "        \n",
        "        if row['PTS'] == 0:\n",
        "          tsplus = 0\n",
        "        else:\n",
        "          tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        series_data.loc[i,'TS+'] = tsplus\n",
        "        series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "        if series_data.loc[i,'Year'] not in years_list:\n",
        "          years_list.append(series_data.loc[i,'Year'])\n",
        "      \n",
        "      #series_data['TS+'] = (float(series_data['PTS']) / ( ( (float(series_data['FTA']) * .44) + (float(series_data['FGA'])) ) * 2)) / \n",
        "\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'FGA', 'FTA', 'PTS', 'MPG'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = series_data[(series_data['Year'] == year)]\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "          \n",
        "        \n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "\n",
        "\n",
        "        new_row = {'Player':player, 'Year':year, 'TS+':total_ts, 'PTS_coeff':total_coeff, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "      outfile = f\"NBA_Playoff_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)\n",
        "    print(final_season_df)\n",
        "    #outfile = f\"NBA_Playoff_Adjusted_TS_df.csv\"\n",
        "    #final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPP2QwEUVAKq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run Adjusted Playoff TS+ Scrape\n",
        "team_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = pd.read_csv('', index_col=False, encoding='utf8')\n",
        "url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "adjust_scoring_efficiency(url_txt_df, team_ts_allowed_df, opponent_adj_pts_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uavrTm3rmdeb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Create DataFrame of Adjusted TS+ Data and Adjust for Era\n",
        "\n",
        "# NBA\n",
        "start_to_ajust_playoffs_per_75 = pd.read_csv('/content/nba_player_since74playoffs_per75_data.csv', index_col=False, encoding='utf8')\n",
        "adj_ts_list = pd.read_csv('/content/NBA_Playoff_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "# ABA\n",
        "#start_to_ajust_playoffs_per_75 = pd.read_csv('/content/aba_player_since74playoffs_per75_data.csv', index_col=False, encoding='utf8')\n",
        "#adj_ts_list = pd.read_csv('/content/ABA_Playoff_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "names = [x for x in start_to_ajust_playoffs_per_75.columns]\n",
        "adjusted_playoff_per_75_df = pd.DataFrame(columns=names)\n",
        "\n",
        "for outer_index, adj_player_season in adj_ts_list.iterrows():\n",
        "\n",
        "  adj_player_season['Player'] = str(adj_player_season['Player'])\n",
        "  adj_player_season['Year'] = str(adj_player_season['Year'])\n",
        "  start_to_ajust_playoffs_per_75['Player'] = start_to_ajust_playoffs_per_75['Player'].astype(str)\n",
        "  start_to_ajust_playoffs_per_75['Year'] = start_to_ajust_playoffs_per_75['Year'].astype(str)\n",
        "\n",
        "  current_player = adj_player_season.loc['Player']\n",
        "  current_year = adj_player_season.loc['Year']\n",
        "  smaller_start_adj_list = start_to_ajust_playoffs_per_75[(start_to_ajust_playoffs_per_75['Player'] == current_player) & ((start_to_ajust_playoffs_per_75['Year'] == current_year))]\n",
        "  smaller_start_adj_list['TS%+'] = adj_player_season['TS+']\n",
        "  smaller_start_adj_list['PTS'] = smaller_start_adj_list['PTS'] * adj_player_season['PTS_coeff']\n",
        "  adjusted_playoff_per_75_df = adjusted_playoff_per_75_df.append(smaller_start_adj_list, ignore_index=True)\n",
        "print(adjusted_playoff_per_75_df)\n",
        "outfile = f\"since74_adj_ts_playoffs_per75_data.csv\"\n",
        "adjusted_playoff_per_75_df.to_csv(outfile, index=False)\n",
        "\n",
        "# Era Adjustment\n",
        "playoff_75_data = pd.read_csv('/content/52-73_reg_per_75_data.csv')\n",
        "\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in playoff_75_data.iterrows():\n",
        "  era_adj = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PTS'] = float(row['PTS']) * float(era_adj['Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"era_opponent_adjusted_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoP5OjWDf5yI"
      },
      "source": [
        "**NBA 1974-22 ADJUSTED PLAYOFF SERIES TS+ (Opponent Adjustment)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XBKkL-oJvRqw"
      },
      "outputs": [],
      "source": [
        "#@title Scrape Adjusted Playoff TS+ Series by Series (not working)\n",
        "def adjust_scoring_efficiency_series(url_df, teams_ts_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'Opp', 'PTS/G', 'TS+', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      print(player)\n",
        "      \n",
        "\n",
        "      wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "      wd.get(url)          \n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      # grab rows\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "\n",
        "      # post 3PA\n",
        "      try:\n",
        "        headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                  'G',\t'W', 'L',\t'MP', 'FG', 'FGA', '3P', '3PA', 'FT', \n",
        "                  'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                  'PTS', 'dum2', 'FG%', '3P%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                          'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                          'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                          'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "      except:\n",
        "        # post TOV pre 3PA\n",
        "        try:\n",
        "          headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                    'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                    'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                    'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                            'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                            'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                            'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "        # pre TOV and pre 3PA\n",
        "        except:\n",
        "          try:\n",
        "            headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                      'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                      'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'PF',\n",
        "                      'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']  \n",
        "\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                              'G',\t'W', 'L', 'FG', 'FT', 'ORB', \n",
        "                              'TRB',\t'AST', 'STL', 'BLK', 'PF', 'dum2',\n",
        "                              'FG%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "          # post TOV and pre 3PA \n",
        "          except:\n",
        "            headers = [th.getText() for th in first_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            headers = headers[1:]\n",
        "            headers[2] = 'Year'\n",
        "            headers[27] = 'MP/G'\n",
        "            headers[28] = 'PTS/G'\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      \n",
        "\n",
        "      # convert ABA seasons to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SSL\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"VIR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SAA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"INA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"UTS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"KEN\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"CAR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1960\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1961\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1962\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1963\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1964\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1965\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1966\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1967\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1968\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1969\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1970\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1971\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1972\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1973\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data['MP'] = series_data['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "\n",
        "      # add TS% allowed\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['PTS/G'] = series_data['PTS/G'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      teams_ts_df['Team'] = teams_ts_df['Team'].astype(str)\n",
        "      teams_ts_df['Year'] = teams_ts_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "      opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "      series_data['opp_ts'] = opponent_ts['TS% Allowed'] np.where ( teams_ts_df['Opp'] == series_data['Opp'] & teams_ts_df['Year'] == series_data['Year'] )\n",
        "      series_data['opp_ts'] = series_data['opp_ts'].astype(float)\n",
        "        \n",
        "      if series_data['PTS/G'] == 0:\n",
        "        series_data['TS+'] = 0\n",
        "      else:\n",
        "        series_data['TS+'] = ((series_data['PTS'] / (((series_data['FTA'] * .44) + series_data['FGA']) * 2)) / series_data['opp_ts']) * 100\n",
        "        series_data['TS+'] = '%.2f' % round(series_data['TS+'], 2)\n",
        "\n",
        "      new_row = {'Player':series_data['Player'], 'Year':series_data['Player'], 'Opp':series_data['Opp'], 'PTS/G':series_data['PTS/G'], 'TS+':series_data['TS+'], 'MP':int(series_data['MP'])}\n",
        "      final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "    print(final_season_df)\n",
        "    outfile = f\"NBA_Playoff_Series_Adjusted_TS_df.csv\"\n",
        "    final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RRlU93sn61Rl"
      },
      "outputs": [],
      "source": [
        "#@title NBA 1974-2022 Adjusted Playoff TS+ Series by Series\n",
        "def adjust_scoring_efficiency_series(url_df, opp_ts_df, opp_defrtg_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'Opp', 'PTS/G', 'TS+', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      print(player)\n",
        "      \n",
        "\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      time.sleep(5)\n",
        "      soup = BeautifulSoup(html)\n",
        "      time.sleep(5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      # grab rows\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "\n",
        "      # post 3PA\n",
        "      try:\n",
        "        headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                  'G',\t'W', 'L',\t'MP', 'FG', 'FGA', '3P', '3PA', 'FT', \n",
        "                  'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                  'PTS', 'dum2', 'FG%', '3P%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                          'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                          'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                          'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "      except:\n",
        "        # post TOV pre 3PA\n",
        "        try:\n",
        "          headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                    'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                    'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                    'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                            'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                            'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                            'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "        # pre TOV and pre 3PA\n",
        "        except:\n",
        "          try:\n",
        "            headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                      'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                      'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'PF',\n",
        "                      'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']  \n",
        "\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                              'G',\t'W', 'L', 'FG', 'FT', 'ORB', \n",
        "                              'TRB',\t'AST', 'STL', 'BLK', 'PF', 'dum2',\n",
        "                              'FG%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "          # post TOV and pre 3PA \n",
        "          except:\n",
        "            headers = [th.getText() for th in first_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            headers = headers[1:]\n",
        "            headers[2] = 'Year'\n",
        "            headers[27] = 'MP/G'\n",
        "            headers[28] = 'PTS/G'\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      \n",
        "\n",
        "      # convert ABA seasons to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SSL\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"VIR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SAA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"INA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"UTS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"KEN\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"CAR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1960\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1961\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1962\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1963\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1964\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1965\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1966\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1967\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1968\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1969\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1970\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1971\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1972\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1973\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data['MP'] = series_data['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "\n",
        "      # add TS% allowed\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['PTS/G'] = series_data['PTS/G'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "        # get ts% allowed by opponent\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & ((opp_ts_df['Year'] == current_year))]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        # get defrtg allowed by opponent\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        if row['PTS/G'] == 0:\n",
        "          tsplus = 0\n",
        "        else:\n",
        "          tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        pts = row['PTS/G']\n",
        "        tsplus = '%.2f' % round(tsplus, 2)\n",
        "        pts = pts * pts_coeff\n",
        "\n",
        "        new_row = {'Player':player, 'Year':current_year, 'Opp':current_opp, 'PTS/G':pts, 'TS+':tsplus, 'MP':int(row['MP'])}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "    outfile = f\"NBA_Playoff_Series_Adjusted_Scoring_df.csv\"\n",
        "    final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNmY18XS86dV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run Adjusted Playoff TS+ Series by Series\n",
        "opp_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = pd.read_csv('/content/fragment97.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "adjust_scoring_efficiency_series(url_txt_df, opp_ts_allowed_df, opponent_adj_pts_coeff)\n",
        "\n",
        "spurs_guys = pd.read_csv('/content/NBA_Playoff_Series_Adjusted_Scoring_df.csv', index_col=False, encoding='utf8')\n",
        "spurs_guys = spurs_guys.sort_values('Year', ascending=True)\n",
        "\n",
        "outfile = f\"Player_Scoring_Series.csv\"\n",
        "spurs_guys.to_csv(outfile, index=False)\n",
        "\n",
        "player_df = pd.read_csv('Player_Scoring_Series.csv')\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in player_df.iterrows():\n",
        "\n",
        "  url_txt_df = pd.read_csv('/content/fragment97.csv', index_col=False, encoding='utf8')\n",
        "  url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "\n",
        "  for a, b in url_txt_df.itertuples(index=False):\n",
        "    player = a\n",
        "\n",
        "  # era adjust\n",
        "  #sub_coeff = per_game_coeff[(per_game_coeff['Year'] == row['Year'])]\n",
        "  #row['PTS/G'] = float(row['PTS/G'] * sub_coeff['Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"{player}_Inflated_Series_Stats.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df['MP'] = new_df['MP'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)\n",
        "print(new_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X7wa6qNOjrd"
      },
      "source": [
        "**REG TO PLAYOFFS SCORING CHANGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cvk_rdRbrv7P"
      },
      "outputs": [],
      "source": [
        "#@title Calculation Functions\n",
        "\n",
        "# print the change in scoring rate and effieciency for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoffs_functional_use(a, dfa, dfb):\n",
        "\n",
        "  player_reg = dfa[(dfa.Player == a)]\n",
        "  player_playoff = dfb[(dfb.Player == a)]\n",
        "\n",
        "  total_mp_reg = 0\n",
        "  pts_list_reg = []\n",
        "  ts_list_reg = []\n",
        "\n",
        "  total_mp_playoff = 0\n",
        "  pts_list_playoff = []\n",
        "  ts_list_playoff = []\n",
        "\n",
        "  mp_list_reg = []\n",
        "  mp_list_playoff = []\n",
        "\n",
        "  total_pts_change = 0\n",
        "  total_ts_change = 0\n",
        "  total_pts = 0\n",
        "  total_ts = 0\n",
        "\n",
        "  # find total reg PTS\n",
        "  i = 0\n",
        "  for row in player_reg['PTS']:\n",
        "    pts_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total reg TS+\n",
        "  i = 0\n",
        "  for row in player_reg['TS%+']:\n",
        "    ts_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff minutes\n",
        "  for row in player_playoff['MP']:\n",
        "    mp_list_playoff.append(row)\n",
        "    total_mp_playoff += row\n",
        "\n",
        "  # find total playoff PTS\n",
        "  i = 0\n",
        "  for row in player_playoff['PTS']:\n",
        "    pts_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff TS+\n",
        "  i = 0\n",
        "  for row in player_playoff['TS%+']:\n",
        "    ts_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "  if len(pts_list_reg) != len(pts_list_playoff):\n",
        "    j = j-1\n",
        "\n",
        "  i = 0\n",
        "  while i <= j-1:\n",
        "    total_pts_change += ((pts_list_playoff[i] - pts_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_ts_change += ((ts_list_playoff[i] - ts_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_pts += (pts_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_ts += (ts_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    i = i + 1\n",
        "  return (a, total_pts, total_ts, total_pts_change, total_ts_change, total_mp_playoff)\n",
        "\n",
        "\n",
        "# print the change in BPM and OBPM for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoffs_functional_use_bpm(a, dfa, dfb):\n",
        "\n",
        "  player_reg = dfa[(dfa.Player == a)]\n",
        "  player_playoff = dfb[(dfb.Player == a)]\n",
        "\n",
        "  total_mp_reg = 0\n",
        "  bpm_list_reg = []\n",
        "  obpm_list_reg = []\n",
        "\n",
        "  total_mp_playoff = 0\n",
        "  bpm_list_playoff = []\n",
        "  obpm_list_playoff = []\n",
        "\n",
        "  mp_list_reg = []\n",
        "  mp_list_playoff = []\n",
        "\n",
        "  total_bpm_change = 0\n",
        "  total_obpm_change = 0\n",
        "  total_bpm = 0\n",
        "  total_obpm = 0\n",
        "\n",
        "  # find total reg PTS\n",
        "  i = 0\n",
        "  for row in player_reg['BPM']:\n",
        "    bpm_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total reg TS+\n",
        "  i = 0\n",
        "  for row in player_reg['OBPM']:\n",
        "    obpm_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff minutes\n",
        "  for row in player_playoff['MP']:\n",
        "    mp_list_playoff.append(row)\n",
        "    total_mp_playoff += row\n",
        "\n",
        "  # find total playoff PTS\n",
        "  i = 0\n",
        "  for row in player_playoff['BPM']:\n",
        "    bpm_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff TS+\n",
        "  i = 0\n",
        "  for row in player_playoff['OBPM']:\n",
        "    obpm_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "  if len(bpm_list_reg) != len(bpm_list_playoff):\n",
        "    j = j-1\n",
        "\n",
        "  i = 0\n",
        "  while i <= j-1:\n",
        "    total_bpm_change += ((bpm_list_playoff[i] - bpm_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_obpm_change += ((obpm_list_playoff[i] - obpm_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_bpm += (bpm_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_obpm += (obpm_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    i = i + 1\n",
        "  return (a, total_bpm, total_obpm, total_bpm_change, total_obpm_change, total_mp_playoff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "74v74ArIIZdT"
      },
      "outputs": [],
      "source": [
        "#@title Functional declaration of playoff scoring changes (x year stretches)\n",
        "\n",
        "# def twoYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every two year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def twoYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year2 = int(year2)\n",
        "        season_list = '{} - {}'.format(year1, year2)\n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = int(year2)\n",
        "        season_list = '{}, {}'.format(year1, year2)\n",
        "\n",
        "      \n",
        "\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Two_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def threeYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every three year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def threeYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-1\n",
        "        year3 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year3 = int(year3)\n",
        "        season_list = '{} - {}'.format(year1, year3)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "        year3 = years.split()[2]\n",
        "        year3 = int(year3)\n",
        "        season_list = '{}, {}, {}'.format(year1, year2, year3)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Three_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def fourYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every four year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def fourYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-2\n",
        "        year3 = int(years.split()[2])-1\n",
        "        year4 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year4)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}'.format(year1, year2, year3, year4)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Four_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def fiveYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every five year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def fiveYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-3\n",
        "        year3 = int(years.split()[2])-2\n",
        "        year4 = int(years.split()[2])-1\n",
        "        year5 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year5)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Five_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def sixYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def sixYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-4\n",
        "        year3 = int(years.split()[2])-3\n",
        "        year4 = int(years.split()[2])-2\n",
        "        year5 = int(years.split()[2])-1\n",
        "        year6 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year6)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Six_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def sevenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def sevenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-5\n",
        "        year3 = int(years.split()[2])-4\n",
        "        year4 = int(years.split()[2])-3\n",
        "        year5 = int(years.split()[2])-2\n",
        "        year6 = int(years.split()[2])-1\n",
        "        year7 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year7)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Seven_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def eightYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every eight year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def eightYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-6\n",
        "        year3 = int(years.split()[2])-5\n",
        "        year4 = int(years.split()[2])-4\n",
        "        year5 = int(years.split()[2])-3\n",
        "        year6 = int(years.split()[2])-2\n",
        "        year7 = int(years.split()[2])-1\n",
        "        year8 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year8)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Eight_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def nineYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every nine year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def nineYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year9)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8) | (adjusted_playoff_per_75_df.Year == year9))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Nine_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def tenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every ten year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def tenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = int(years.split()[2])-1\n",
        "        year10 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year10)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = year9.replace(',', '')\n",
        "        year9 = int(year9)\n",
        "\n",
        "        year10 = years.split()[9]\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9, year10)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9) | (reg_df.Year == year10))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8) | (adjusted_playoff_per_75_df.Year == year9) | (adjusted_playoff_per_75_df.Year == year10))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Ten_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eb96uEuGsGDN"
      },
      "outputs": [],
      "source": [
        "#@title Functional declaration of playoff scoring changes (career)  \n",
        "# output file containing change in scoring rate and efficiency from regular season to playoffs (Entire Career)\n",
        "# use only regular seasons in which a player made the playoffs\n",
        "def regToPlayoffsProductionTightScope(reg_df, playoff_db):\n",
        "\n",
        "  new_df = pd.DataFrame(columns = ['Player','PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  headers_list = ['Player', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post']\n",
        "  players_finished = []\n",
        "  used_years = []\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "    used_years = []\n",
        "    if row['Player'] not in players_finished:\n",
        "      player_playoff_db = playoff_db[(playoff_db.Player == row[\"Player\"])]\n",
        "      for use_idx, use_row in player_playoff_db.iterrows():\n",
        "        used_years.append(use_row['Year'])\n",
        "      player_reg_db = reg_df[reg_df['Year'].isin(used_years)]\n",
        "      player_reg_db = player_reg_db[(player_reg_db.Player == row[\"Player\"])]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "      players_finished.append(row['Player'])\n",
        "  outfile = f\"Career_Playoff_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  \n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ85A5uLjDIJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff scoring changes (x year stretches)\n",
        "import_player_pts_playoff10peaks_df = pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "tenYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff10peaks_df)\n",
        "\n",
        "import_player_pts_playoff9peaks_df = pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "nineYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff9peaks_df)\n",
        "\n",
        "import_player_pts_playoff8peaks_df = pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "eightYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff8peaks_df)\n",
        "\n",
        "import_player_pts_playoff7peaks_df = pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "sevenYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff7peaks_df)\n",
        "\n",
        "import_player_pts_playoff6peaks_df = pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "sixYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff6peaks_df)\n",
        "\n",
        "import_player_pts_playoff5peaks_df = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "fiveYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff5peaks_df)\n",
        "\n",
        "import_player_pts_playoff4peaks_df = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "fourYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff4peaks_df)\n",
        "\n",
        "import_player_pts_playoff3peaks_df = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "threeYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff3peaks_df)\n",
        "\n",
        "import_player_pts_playoff2peaks_df = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "twoYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff2peaks_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaAVm7LcZedf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff scoring changes (career)\n",
        "# CAREER\n",
        "\n",
        " \n",
        "\n",
        "regToPlayoffsProductionTightScope(era_adj_reg_per_75_df, era_opponent_adj_playoff_per_75_df)\n",
        "import_player_scoring_changes_df = pd.read_csv('Career_Playoff_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_scoring_changes_df = import_player_scoring_changes_df.dropna()\n",
        "\n",
        "\n",
        "\n",
        "one_thousand_min_filter = import_player_scoring_changes_df[(import_player_scoring_changes_df['MP_post'] >= 2000)]\n",
        "outfile_1000 = f\"Career_Playoff_Scoring_Change_2000min.csv\"\n",
        "one_thousand_min_filter.to_csv(outfile_1000, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REG TO PLAYOFFS BPM CHANGES**"
      ],
      "metadata": {
        "id": "k9F-ko-AtZj7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cXgIpAWbAXC1"
      },
      "outputs": [],
      "source": [
        "#@title Functional declaration of playoff BPM changes (x year stretches)\n",
        "\n",
        "# def twoYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every two year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def twoYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year2 = int(year2)\n",
        "        season_list = '{} - {}'.format(year1, year2)\n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = int(year2)\n",
        "        season_list = '{}, {}'.format(year1, year2)\n",
        "\n",
        "      \n",
        "\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2))]\n",
        "      player_playoff_db = playoff_bpm_data[(playoff_bpm_data.Player == row[\"Player\"]) & ((playoff_bpm_data.Year == year1) | (playoff_bpm_data.Year == year2))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Two_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def threeYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every three year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def threeYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-1\n",
        "        year3 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year3 = int(year3)\n",
        "        season_list = '{} - {}'.format(year1, year3)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "        year3 = years.split()[2]\n",
        "        year3 = int(year3)\n",
        "        season_list = '{}, {}, {}'.format(year1, year2, year3)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Three_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def fourYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every four year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def fourYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-2\n",
        "        year3 = int(years.split()[2])-1\n",
        "        year4 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year4)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}'.format(year1, year2, year3, year4)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Four_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def fiveYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every five year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def fiveYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-3\n",
        "        year3 = int(years.split()[2])-2\n",
        "        year4 = int(years.split()[2])-1\n",
        "        year5 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year5)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Five_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def sixYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def sixYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-4\n",
        "        year3 = int(years.split()[2])-3\n",
        "        year4 = int(years.split()[2])-2\n",
        "        year5 = int(years.split()[2])-1\n",
        "        year6 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year6)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Six_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def sevenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def sevenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-5\n",
        "        year3 = int(years.split()[2])-4\n",
        "        year4 = int(years.split()[2])-3\n",
        "        year5 = int(years.split()[2])-2\n",
        "        year6 = int(years.split()[2])-1\n",
        "        year7 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year7)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Seven_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def eightYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every eight year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def eightYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-6\n",
        "        year3 = int(years.split()[2])-5\n",
        "        year4 = int(years.split()[2])-4\n",
        "        year5 = int(years.split()[2])-3\n",
        "        year6 = int(years.split()[2])-2\n",
        "        year7 = int(years.split()[2])-1\n",
        "        year8 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year8)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Eight_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def nineYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every nine year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def nineYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year9)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8) | (playoff_bpm_data .Year == year9))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Nine_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def tenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every ten year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def tenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = int(years.split()[2])-1\n",
        "        year10 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year10)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = year9.replace(',', '')\n",
        "        year9 = int(year9)\n",
        "\n",
        "        year10 = years.split()[9]\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9, year10)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9) | (reg_df.Year == year10))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8) | (playoff_bpm_data .Year == year9) | (playoff_bpm_data .Year == year10))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Ten_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PpVhZVsYcV0E"
      },
      "outputs": [],
      "source": [
        "#@title Function declaration of playoff BPM changes (career)  \n",
        "# output file containing change in scoring rate and efficiency from regular season to playoffs (Entire Career)\n",
        "# use only regular seasons in which a player made the playoffs\n",
        "def regToPlayoffsProductionTightScopeBPM(reg_df, playoff_db):\n",
        "\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "  players_finished = []\n",
        "  used_years = []\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "    used_years = []\n",
        "    if row['Player'] not in players_finished:\n",
        "      player_playoff_db = playoff_db[(playoff_db.Player == row[\"Player\"])]\n",
        "      for use_idx, use_row in player_playoff_db.iterrows():\n",
        "        used_years.append(use_row['Year'])\n",
        "      player_reg_db = reg_df[reg_df['Year'].isin(used_years)]\n",
        "      player_reg_db = player_reg_db[(player_reg_db.Player == row[\"Player\"])]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "      players_finished.append(row['Player'])\n",
        "  outfile = f\"Career_Playoff_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "  \n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  \n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Me79i0gHKVE3"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff bpm changes (x year stretches)\n",
        "import_player_bpm_playoff10peaks_df = pd.read_csv('/content/Ten_Year_BPM_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "tenYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff10peaks_df)\n",
        "\n",
        "import_player_bpm_playoff9peaks_df = pd.read_csv('/content/Nine_Year_BPM_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "nineYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff9peaks_df)\n",
        "\n",
        "import_player_bpm_playoff8peaks_df = pd.read_csv('/content/Eight_Year_BPM_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "eightYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff8peaks_df)\n",
        "\n",
        "import_player_bpm_playoff7peaks_df = pd.read_csv('/content/Seven_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "sevenYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff7peaks_df)\n",
        "\n",
        "import_player_bpm_playoff6peaks_df = pd.read_csv('/content/Six_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "sixYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff6peaks_df)\n",
        "\n",
        "import_player_bpm_playoff5peaks_df = pd.read_csv('/content/Five_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "fiveYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff5peaks_df)\n",
        "\n",
        "import_player_bpm_playoff4peaks_df = pd.read_csv('/content/Four_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "fourYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff4peaks_df)\n",
        "\n",
        "import_player_bpm_playoff3peaks_df = pd.read_csv('/content/Three_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "threeYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff3peaks_df)\n",
        "\n",
        "import_player_bpm_playoff2peaks_df = pd.read_csv('/content/Two_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "twoYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff2peaks_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q3UBqs5tb-Ea"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff BPM changes (career)\n",
        "# CAREER\n",
        "\n",
        " \n",
        "\n",
        "regToPlayoffsProductionTightScopeBPM(era_adj_reg_per_75_df, era_opponent_adj_playoff_per_75_df)\n",
        "import_player_scoring_changes_df = pd.read_csv('Career_Playoff_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_scoring_changes_df = import_player_scoring_changes_df.dropna()\n",
        "\n",
        "\n",
        "\n",
        "one_thousand_min_filter = import_player_scoring_changes_df[(import_player_scoring_changes_df['MP_post'] >= 2000)]\n",
        "outfile_1000 = f\"Career_Playoff_Scoring_Change_2000min.csv\"\n",
        "one_thousand_min_filter.to_csv(outfile_1000, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu-iOQT7Rpj5"
      },
      "source": [
        "**SCORING PLOT FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-3WWnnpkhqr"
      },
      "outputs": [],
      "source": [
        "def label_point(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "      #if i % 2 == 0:\n",
        "      ax.text(point['x']+0.25, point['y'], str(point['val']))\n",
        "      #else:\n",
        "      #ax.text(point['x']+0.30, point['y'], str(point['val']))\n",
        "      #ax.text(point['x']+0.05, point['y'], str(point['val']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wJ_wS861o8eV"
      },
      "outputs": [],
      "source": [
        "#@title Single Plot Scoring Template\n",
        "def plotOneScoring(p1, c1, pts_floor, ts_floor, ts_ceiling, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Multi-Year Playoff Scoring Stretches (1952 - 2022) [min. 500 MP]', xlabel='PTS per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def plotTwoScoring(p1, p2, c1, c2,  pts_floor, ts_floor, ts_ceiling, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Multi-Year Playoff Scoring (1952 - 2022) [min 1000 MP]', xlabel='PTS per 75 (era/opponent adjusted', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def plotThreeScoring(p1, p2, p3, c1, c2, c3,  pts_floor, ts_floor, ts_ceiling, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Multi-Year Playoff Scoring (1952 - 2022)', xlabel='PTS per 75 (era/opponent adjusted', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nhc4VYkV2Zq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Multiple Plots Scoring Template\n",
        "def plotOneScoring(p1, c1, pts_floor, ts_floor, ts_ceiling):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted) (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [>500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 600)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [>600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1000)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [>1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1200)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [>1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [>1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [>1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Peaks', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title 2 Guys Scoring Plot Template\n",
        "def plotTwoScoring(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling):\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(115)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [>500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 600)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [>600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1000)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [>1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1200)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [>1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [>1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [>1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[9].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Peaks', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title 3 Guys Scoring Plot Template\n",
        "def plotThreeScoring(p1, p2, p3, c1, c2, c3, pts_floor, ts_floor, ts_ceiling):\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [> 300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [> 500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 600]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [> 600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [> 1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1200]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [> 1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1400]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [> 1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [> 1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 2000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [> 2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[9].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring_Peaks', bbox_inches='tight')\n",
        "\n",
        "#@title 4 Guys Scoring Plot Template\n",
        "def plotFourScoring(p1, p2, p3, p4, c1, c2, c3, c4, pts_floor, ts_floor, ts_ceiling):\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [> 300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [> 500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 600]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [> 600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [> 1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1200]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [> 1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1400]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [> 1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [> 1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 2000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [> 2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[9].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_{p4}_Scoring_Peaks', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Gys3Jbx0NXFW"
      },
      "outputs": [],
      "source": [
        "#@title Multiple Plots PBP Template\n",
        "def plotOnePBP(p1, c1):\n",
        "  fig, axis = plt.subplots(8)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_pbp_Peaks_NBA_Playoffs_300_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='3 Year Playoff PBP (1997-2022) [>500 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_pbp_Peaks_NBA_Playoffs_600_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='4 Year Playoff PBP (1997-2022) [>600 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_pbp_Peaks_NBA_Playoffs_1000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='5 Year Playoff PBP (1997-2022) [>1000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_pbp_Peaks_NBA_Playoffs_1400_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='6 Year Playoff PBP (1997-2022) [>1400 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_pbp_Peaks_NBA_Playoffs_2000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='7 Year Playoff PBP (1997-2022) [>2000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='8 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Nine_Year_pbp_Playoff_Peaks_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='9 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='10 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  fig.savefig(f'{p1}_PBP_Peaks', bbox_inches='tight')\n",
        "\n",
        "def plotTwoPBP(p1, p2, c1, c2):\n",
        "  fig, axis = plt.subplots(8)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_pbp_Peaks_NBA_Playoffs_300_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='3 Year Playoff PBP (1997-2022) [>500 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_pbp_Peaks_NBA_Playoffs_600_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='4 Year Playoff PBP (1997-2022) [>600 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_pbp_Peaks_NBA_Playoffs_1000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='5 Year Playoff PBP (1997-2022) [>1000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_pbp_Peaks_NBA_Playoffs_1400_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='6 Year Playoff PBP (1997-2022) [>1400 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_pbp_Peaks_NBA_Playoffs_2000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='7 Year Playoff PBP (1997-2022) [>2000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='8 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Nine_Year_pbp_Playoff_Peaks_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='9 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='10 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_PBP_Peaks', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sy_RXsh-Ctf"
      },
      "source": [
        "**REG->PLAYOFF SCORING CHANGE PLOTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6B5fddTe-Mbr"
      },
      "outputs": [],
      "source": [
        "#@title Single Plot Scoring Change Template\n",
        "def p_plotOneScoringChange(p1, c1, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP_post']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {pts_floor} Pts per 75 Postseason; min. {mp_floor} MP]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChange(p1, p2, c1, c2, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP_post']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {pts_floor} Pts per 75 Postseason; min. {mp_floor} MP]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChange(p1, p2, p3, c1, c2, c3, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP_post']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {pts_floor} Pts per 75 Postseason; min. {mp_floor} MP]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "  \n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title 2 Guys Scoring Change Single Plot Template (TS+ above below league avg)\n",
        "def p_plotOneScoringChange_ab(p1, c1, pts_floor, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['TS+_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PTS_change\": \"PTS_change\", \"TS+_change\": \"TS+_change\", \"PTS per 75_reg\": \"PTS per 75_reg\", \"PTS per 75_post\": \"PTS per 75_post\", \"TS+_reg\": \"TS+_reg\", \"TS+_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {threshold} TS+ postseason]\"\n",
        "  ax.set(title=title_string, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys Scoring Change Single Plot Template (TS+ above below league avg)\n",
        "def p_plotTwoScoringChange_ab(p1, p2, c1, c2, pts_floor, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['TS+_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PTS_change\": \"PTS_change\", \"TS+_change\": \"TS+_change\", \"PTS per 75_reg\": \"PTS per 75_reg\", \"PTS per 75_post\": \"PTS per 75_post\", \"TS+_reg\": \"TS+_reg\", \"TS+_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.TSpost >= threshold),c2, graph_data.color)\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.TSpost <= threshold),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {threshold} TS+ postseason]\"\n",
        "  ax.set(title=title_string, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xxGUbQIlBFL6"
      },
      "outputs": [],
      "source": [
        "#@title Multiple Plots Scoring Change (with lines) Template\n",
        "def p_plotOneScoringChangeWithLines(p1, c1, pts_floor, ts_floor, ts_ceiling, label, mp_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChangeWithLines(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling, label, mp_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChangeWithLines(p1, p2, p3, c1, c2, c3, pts_floor, ts_floor, ts_ceiling, label, mp_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[0])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[1])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[2])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[3])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ihbDWbHaHO-S"
      },
      "outputs": [],
      "source": [
        "#@title Single Plot Career Scoring Change (with lines) Template\n",
        "def p_plotOneScoringChangeWithLinesCareer(p1, c1, pts_floor, ts_floor, ts_ceiling):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <= ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChangeWithLinesCareer(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling):\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <= ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChangeWithLinesCareer(p1, p2, p3, c1, c2, c3, pts_floor, ts_floor, ts_ceiling):\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <= ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c3, linestyle=\"--\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r597HycnNfI4"
      },
      "outputs": [],
      "source": [
        "# Single Plot Scoring Template\n",
        "  # plotNumScoring(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling, mp_floor)\n",
        "# Multiple Plots Scoring Template\n",
        "  # plotNumScoring(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling)\n",
        "#  Multiple Plots PBP Template\n",
        "  # plotTwoPBP(p1, p2, c1, c2)\n",
        "#  Single Plot Scoring Change Template\n",
        "  # p_plotNumScoringChange(p1, p2, c1, c2, pts_floor, mp_floor)\n",
        "#  Multiple Plots Scoring Change w Lines Template\n",
        "  # p_plotNumScoringChangeWithLines(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling, 1or0, [mp_2year, mp_3year, mp_4year, mp_5year])\n",
        "#  Single Plot Scoring Change w Lines Template\n",
        "  # p_plotNumScoringChangeWithLinesCareer(p1, c1, pts_floor, ts_floor, ts_ceiling):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plotTwoPBP(\"Tony Parker\", \"Manu Ginóbili\", \"#EF426F\", \"#FF8200\")\n",
        "#p_plotTwoScoringChange(\"James Harden\", \"Nikola Jokić\", \"r\", \"k\", 20, 300)\n",
        "#p_plotTwoScoringChangeWithLines(\"James Harden\", \"Nikola Jokić\", \"r\", \"k\", 20, 60, 140, 0, [300, 500, 800, 1000])"
      ],
      "metadata": {
        "id": "q_M7VGXk7lGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIWuoavMiG_r"
      },
      "source": [
        "**ERA ADJUSTED BPM CHANGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ax9wp0mPgnBr"
      },
      "outputs": [],
      "source": [
        "#@title Era Adjust BPM\n",
        "reg_playoff_per_75_df = import_player_since74_advanced_df.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in reg_playoff_per_75_df.iterrows():\n",
        "  sub_mess = bpm_coeff[(bpm_coeff['Year'] == row['Year'])]\n",
        "  row['BPM'] = float(row['BPM'] * sub_mess['BPM_Coefficient'])\n",
        "  row['OBPM'] = float(row['OBPM'] * sub_mess['OBPM_Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"inflation_adjusted_reg_bpm_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wlYv7A_Iexa8"
      },
      "outputs": [],
      "source": [
        "#@title (Era-Adjusted) p_plot_X_BPMChange (Single Plot)\n",
        "def p_plotOneBPMChange(p1, c1, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys BPM Change Single Plot Template (OBPM above below league avg)\n",
        "def p_plotOneBPMChange_ab(p1, c1, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  \n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['OBPM_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"bpm_change\": \"bpm_change\", \"OBPM_change\": \"OBPM_change\", \"BPM_reg\": \"BPM_reg\", \"BPM_post\": \"BPM_post\", \"OBPM_reg\": \"OBPM_reg\", \"OBPM_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"bpm_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [min. {threshold} OBPM postseason]\"\n",
        "  ax.set(title=title_string, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['bpm_change'].max()\n",
        "  x_min = graph_data['bpm_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "def p_plotTwoBPMChange(p1, p2, c1, c2, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys BPM Change Single Plot Template (OBPM above below league avg)\n",
        "def p_plotTwoBPMChange_ab(p1, p2, c1, c2, above_below, threshold, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  \n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['OBPM_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.BPM_post >= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.BPM_post >= threshold),c2, graph_data.color)\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.BPM_post <= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.BPM_post <= threshold),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [min. {threshold} BPM postseason; [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "def p_plotThreeBPMChange(p1, p2, p3, c1, c2, c3, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data =  pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_BPM_Changes', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pHiJYdZueZoR"
      },
      "outputs": [],
      "source": [
        "#@title (Era-Adjusted) p_plot_X_BPMChangeWithLines (Multiple Plots)\n",
        "def p_plotOneBPMChangeWithLines(p1, c1, pts_floor, mp_floor, label):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}__BPM_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoBPMChangeWithLines(p1, p2, c1, c2, pts_floor, mp_floor, label):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}__BPM_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeBPMChangeWithLines(p1, p2, p3, c1, c2, c3, pts_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_BPM_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B-Yy-4czj7Qc"
      },
      "outputs": [],
      "source": [
        "#@title Space labels (not working)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "np.random.seed(2016)\n",
        "\n",
        "N = 20\n",
        "scatter_data = np.random.rand(N, 3)*10\n",
        "\n",
        "\n",
        "def repel_labels(ax, x, y, labels, k=0.01):\n",
        "    G = nx.DiGraph()\n",
        "    data_nodes = []\n",
        "    init_pos = {}\n",
        "    for xi, yi, label in zip(x, y, labels):\n",
        "        data_str = 'data_{0}'.format(label)\n",
        "        G.add_node(data_str)\n",
        "        G.add_node(label)\n",
        "        G.add_edge(label, data_str)\n",
        "        data_nodes.append(data_str)\n",
        "        init_pos[data_str] = (xi, yi)\n",
        "        init_pos[label] = (xi, yi)\n",
        "\n",
        "    pos = nx.spring_layout(G, pos=init_pos, fixed=data_nodes, k=k)\n",
        "\n",
        "    # undo spring_layout's rescaling\n",
        "    pos_after = np.vstack([pos[d] for d in data_nodes])\n",
        "    pos_before = np.vstack([init_pos[d] for d in data_nodes])\n",
        "    scale, shift_x = np.polyfit(pos_after[:,0], pos_before[:,0], 1)\n",
        "    scale, shift_y = np.polyfit(pos_after[:,1], pos_before[:,1], 1)\n",
        "    shift = np.array([shift_x, shift_y])\n",
        "    for key, val in pos.items():\n",
        "        pos[key] = (val*scale) + shift\n",
        "\n",
        "    for label, data_str in G.edges():\n",
        "        ax.annotate(label,\n",
        "                    xy=pos[data_str], xycoords='data',\n",
        "                    xytext=pos[label], textcoords='data',\n",
        "                    arrowprops=dict(arrowstyle=\"->\",\n",
        "                                    shrinkA=0, shrinkB=0,\n",
        "                                    connectionstyle=\"arc3\", \n",
        "                                    color='red'), )\n",
        "    # expand limits\n",
        "    all_pos = np.vstack(pos.values())\n",
        "    x_span, y_span = np.ptp(all_pos, axis=0)\n",
        "    mins = np.min(all_pos-x_span*0.15, 0)\n",
        "    maxs = np.max(all_pos+y_span*0.15, 0)\n",
        "    ax.set_xlim([mins[0], maxs[0]])\n",
        "    ax.set_ylim([mins[1], maxs[1]])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(scatter_data[:, 0], scatter_data[:, 1],\n",
        "           c=scatter_data[:, 2], s=scatter_data[:, 2] * 150)\n",
        "labels = ['ano_{}'.format(i) for i in range(N)]\n",
        "repel_labels(ax, scatter_data[:, 0], scatter_data[:, 1], labels, k=0.008)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TONY MANU MULTIPLE LINE DRAWN SITUATIONAL CHANGES**"
      ],
      "metadata": {
        "id": "A1FZBFWLaGXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-Bgnirj0wYoA"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu Many changes from Big 3 -> 2/3 (2/3/4/5)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_2_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_3_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='3 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data = pd.read_csv('/content/Combined_4_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='4 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_5_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='5 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5oM4_4esYh2N"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu Many changes from Big 3 -> 2/3  +/- (2/3/4/5)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_2_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[0])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_3_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "  axis[1].set(title='3 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[1])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data = pd.read_csv('/content/Combined_4_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='4 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[2])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_5_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='5 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[3])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zgZ3-e7EQzRl"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu First to Later Rounds (+/-)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_NET\", y=\"Later_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Playoff +/- Change from First Round to Later Rounds (2004-14)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_NET'], graph_data['First_OFF']]\n",
        "  point2 = [graph_data['Later_NET'], graph_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_NET'], p2_data['First_OFF']]\n",
        "  point2 = [p2_data['Later_NET'], p2_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_NET'], graph_data['Later_OFF'], graph_data['Later_Years'], axis[0])\n",
        "    label_point(p2_data['Later_NET'], p2_data['Later_OFF'], p2_data['Later_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_NET\", y=\"Later_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Playoff +/- Change from First Round to Later Rounds (2004-14) [3+ opposing starters]', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_NET'], graph_data['First_OFF']]\n",
        "  point2 = [graph_data['Later_NET'], graph_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_NET'], p2_data['First_OFF']]\n",
        "  point2 = [p2_data['Later_NET'], p2_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_NET'], graph_data['Later_OFF'], graph_data['Later_Years'], axis[1])\n",
        "    label_point(p2_data['Later_NET'], p2_data['Later_OFF'], p2_data['Later_Years'], axis[1])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_NET_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loBdpFyEEaxA"
      },
      "source": [
        "**TONY MANU SITUATIONAL CHANGES FROM BIG 3 TO 2/3 BIG 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qw6gPZ85jYOp"
      },
      "outputs": [],
      "source": [
        "#@title Big 3 to Two Thirds\\2004-14\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O8X_Qca_iBDF"
      },
      "outputs": [],
      "source": [
        "#@title Big 3 to Two Thirds\\5 Year\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_5_Year_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Edki8wjYbKWz"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu 2004-14 change from Big 3 -> 2/3 (Tony Only 3 Opposing starters)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # NET\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [Manu 3+ opposing starters; Tony max 2 opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [Manu 3+ opposing starters; Tony max 2 opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0q8D6_zN2C5"
      },
      "source": [
        "**FROM FIRST TO LATER ROUNDS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xZ2si_VlN5mM"
      },
      "outputs": [],
      "source": [
        "#@title First Round to Later Rounds\\2004-14\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EP83nxE0UKmh"
      },
      "outputs": [],
      "source": [
        "#@title First Round to Later Rounds\\5 Year Later Peaks\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_5_Year_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UGlPvsNNcac7"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu 2004-14 change from first to later rounds (Tony Only 3 Opposing starters)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus_Round.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [Manu 3+ opposing starters; Tony max 2 opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus_Round.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [Manu 3+ opposing starters; Tony max 2 opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYaoLW0ASXvx"
      },
      "outputs": [],
      "source": [
        "plotTonyManuSituationalChange(\"Manu Ginóbili\", \"Tony Parker\", \"#FF8200\", \"#EF426F\", 5, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KLAY/MANU GRAPHS"
      ],
      "metadata": {
        "id": "rxviYp2iQyeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Klay/Manu 5 Year Change\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Klay_Manu_5_Year_Change.png', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XisSl6juQ0fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Klay/Manu 3 Year Change\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (3 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (3 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (3 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (3 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Klay_Manu_3_Year_Change.png', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "br-VNioYT6LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotTonyManuSituationalChange(\"Manu Ginóbili\", \"Klay Thompson\", \"k\", \"y\", 5, 1)"
      ],
      "metadata": {
        "id": "Wj6lgLfbRRG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MISC**"
      ],
      "metadata": {
        "id": "1BUC_calmAZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-AWQpDM9zWF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Append into one\n",
        "two = pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "three = pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', index_col=False, encoding='utf8')\n",
        "four = pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', index_col=False, encoding='utf8')\n",
        "five = pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "six = pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "seven = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "eight = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "nine = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "ten = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "two = two.append(three)\n",
        "two = two.append(four)\n",
        "two = two.append(five)\n",
        "two = two.append(six)\n",
        "two = two.append(seven)\n",
        "two = two.append(eight)\n",
        "two = two.append(nine)\n",
        "two = two.append(ten)\n",
        "two = two[(two['MP'] >= 500)]\n",
        "two = two.sort_values(by = ['PTS', 'MP'], ascending = [False, False], na_position = 'first')\n",
        "print(two)\n",
        "\n",
        "outfile = f\"All_Scoring_Stretches_500min.csv\"\n",
        "two.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3bBmu92gXOiE"
      },
      "outputs": [],
      "source": [
        "#@title 'Combine x year scoring and bpm changes' Function\n",
        "def combine_scoring_bpm_changes(scoring_df, bpm_df, year):\n",
        "  final_season_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_Change', 'TS+_Change', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  for idx, row in scoring_df.iterrows():\n",
        "    sub_second_df = bpm_df[(bpm_df['Player'] == row['Player'])]\n",
        "    for jdx, inner_row in sub_second_df.iterrows():\n",
        "      if inner_row['Player'] == row['Player'] and inner_row['Years'] == row['Years']:\n",
        "        new_row = {'Player':inner_row['Player'], 'Years':inner_row['Years'], 'PTS per 75_post':row['PTS per 75_post'], 'TS+_post':row['TS+_post'], 'PTS_Change':row['PTS_change'], 'TS+_Change':row['TS+_change'], 'BPM_post':inner_row['BPM_post'], 'OBPM_post':inner_row['OBPM_post'], 'BPM_change':inner_row['BPM_change'], 'OBPM_change':inner_row['OBPM_change'], 'MP_post':int(inner_row['MP_post'])}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  final_season_df = final_season_df[(final_season_df['MP_post'] >= 300)]\n",
        "  outfile = f\"{year}_Year_Scoring_BPM_Changes_300min.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3VNf4cGdXn40"
      },
      "outputs": [],
      "source": [
        "#@title Run 'Combine x year scoring and bpm changes'\n",
        "scoring = pd.read_csv('/content/Two_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Two_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Two\")\n",
        "\n",
        "scoring = pd.read_csv('/content/Three_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Three_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Three\")\n",
        "\n",
        "\n",
        "scoring = pd.read_csv('/content/Four_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Four_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Four\")\n",
        "\n",
        "\n",
        "scoring = pd.read_csv('/content/Five_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Five_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Five\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HISTORICAL PERCENTILES**"
      ],
      "metadata": {
        "id": "Ti-kIv9qTcdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Year Percentiles\n",
        "def Spurs_Playoff_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu PP75', 'Tony PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu PP75', 'Tony PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu TS+', 'Tony TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu TS+', 'Tony TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Year', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title Spurs '2/3' Percentiles\n",
        "def Spurs_Playoff_2_3_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_2-3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu PP75', 'Tony PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu PP75', 'Tony PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 70 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_2-3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu TS+', 'Tony TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu TS+', 'Tony TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 70 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_2-3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Year', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 70 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title Spurs '2/3' Percentiles\n",
        "def Spurs_Playoff_4_Plus_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_4plus_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)', 'Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)'])\n",
        "  columns_titles = ['Year', 'Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_4plus_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)', 'Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)'])\n",
        "  columns_titles = ['Year', 'Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_4plus_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)', 'Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)'])\n",
        "  columns_titles = ['Year', 'Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "BcoxF8ymi6Pf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Series Percentiles\n",
        "def Spurs_Playoff_Series_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_series_percentile.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu PP75', 'Tony PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu PP75', 'Tony PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_series_percentile.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu TS+', 'Tony TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu TS+', 'Tony TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_series_percentile.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[2].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title Spurs Series Percentiles\n",
        "def Spurs_Playoff_Series_Percentile_Approx():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Approx_Scoring_Val_Tony_Manu.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu Approx_Scoring_Val', 'Tony Approx_Scoring_Val']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu Approx_Scoring_Val', 'Tony Approx_Scoring_Val'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile (1952 - 2022) *1954 not included*')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Approx_Scoring_Val_Tony_Manu.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Manu Approx_Scoring_Val', 'Tony Approx_Scoring_Val'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "#@title Spurs Series Percentiles\n",
        "def Spurs_Playoff_Series_Percentile_No_First():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_No_First_Manu_Tony_series_percentile.csv', encoding='utf8')\n",
        "  graph_data['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Manu PP75']) + (0.5 * graph_data['Manu TS+'])\n",
        "  graph_data['Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tony PP75']) + (0.5 * graph_data['Tony TS+'])\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_No_First_Manu_Tony_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "C7xD2Y3KU0Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Big 3 Year Percentiles\n",
        "def Big_3_Playoff_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Tim TS+', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Year', 'Manu PP75', 'Tony PP75', 'Tim PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = graph_data.sort_values('Year', ascending=True)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu PP75', 'Tony PP75', 'Tim PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Year', 'Manu TS+', 'Tony TS+', 'Tim TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = graph_data.sort_values('Year', ascending=True)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu TS+', 'Tony TS+', 'Tim TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+'])\n",
        "  columns_titles = ['Year', 'Manu MP', 'Tony MP', 'Tim MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = graph_data.sort_values('Year', ascending=True)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP', 'Tony MP', 'Tim MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "def Big_3_Playoff_Percentile_Approx():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_percentile.csv', encoding='utf8')\n",
        "  graph_data['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Manu PP75']) + (0.5 * graph_data['Manu TS+'])\n",
        "  graph_data['Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tony PP75']) + (0.5 * graph_data['Tony TS+'])\n",
        "  graph_data['Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tim PP75']) + (0.5 * graph_data['Tim TS+'])\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Year', 'Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = graph_data.sort_values('Year', ascending=True)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)',], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+'])\n",
        "  columns_titles = ['Year', 'Manu MP', 'Tony MP', 'Tim MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = graph_data.sort_values('Year', ascending=True)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP', 'Tony MP', 'Tim MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gZNoLOZqE4Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Big 3 Series Percentiles\n",
        "def Big_3_Playoff_Series_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(45)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Tim TS+', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Series', 'Manu PP75', 'Tony PP75', 'Tim PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu PP75', 'Tony PP75', 'Tim PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Series', 'Manu TS+', 'Tony TS+', 'Tim TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu TS+', 'Tony TS+', 'Tim TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP', 'Tim MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP', 'Tim MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[2].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "def Big_3_Playoff_Series_Percentile_Approx():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(45)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_series_percentile.csv', encoding='utf8')\n",
        "  graph_data['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Manu PP75']) + (0.5 * graph_data['Manu TS+'])\n",
        "  graph_data['Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tony PP75']) + (0.5 * graph_data['Tony TS+'])\n",
        "  graph_data['Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tim PP75']) + (0.5 * graph_data['Tim TS+'])\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Series', 'Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)',], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP', 'Tim MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP', 'Tim MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UBPGkgOEsTJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tim/Kobe Percentiles\n",
        "def Tim_Kobe_Series_Percentile_Approx():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(40)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "  axis[0].tick_params(axis='both', which='major', labelsize=8)\n",
        "  axis[1].tick_params(axis='both', which='major', labelsize=8)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Tim_Kobe_Series.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Tim MP', 'Kobe MP'])\n",
        "  columns_titles = ['Series', 'Tim Approx_Scoring_Val', 'Kobe Approx_Scoring_Val']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Tim Approx_Scoring_Val', 'Kobe Approx_Scoring_Val'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"k\", \"y\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile (1952 - 2022) *1954 not included*')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Tim_Kobe_Series.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Tim Approx_Scoring_Val', 'Kobe Approx_Scoring_Val'])\n",
        "  columns_titles = ['Series', 'Tim MP', 'Kobe MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Tim MP', 'Kobe MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"k\", \"y\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Tim_Kobe_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qtNpaDDdB5DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tim/Kobe Percentiles\n",
        "def Kobe_Shaq_Series_Percentile_Approx():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(40)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "  axis[0].tick_params(axis='both', which='major', labelsize=8)\n",
        "  axis[1].tick_params(axis='both', which='major', labelsize=8)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Kobe_Shaq_Series.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Shaq MP', 'Kobe MP'])\n",
        "  columns_titles = ['Series', 'Shaq Approx_Scoring_Val', 'Kobe Approx_Scoring_Val']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Shaq Approx_Scoring_Val', 'Kobe Approx_Scoring_Val'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"m\", \"y\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile (1952 - 2022) *1954 not included*')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Kobe_Shaq_Series.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Shaq Approx_Scoring_Val', 'Kobe Approx_Scoring_Val'])\n",
        "  columns_titles = ['Series', 'Shaq MP', 'Kobe MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Shaq MP', 'Kobe MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"m\", \"y\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Shaq_Kobe_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mpdO9QZr0h8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0unXklbF571"
      },
      "source": [
        "**PLOT SHOOTING DISTRIBUTION DATA/PRINT MANUAL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FIVy6IDJYfP2"
      },
      "outputs": [],
      "source": [
        "#@title Print Medians\n",
        "def printmedians(pts_floor):\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"2 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"2 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"3 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"3 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 800)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"4 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"4 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1000)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"5 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"5 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1200)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"6 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"6 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1400)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"7 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"7 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1500)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"8 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"8 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 2000)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"10 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"10 Year Median TS+ decline\")\n",
        "  print(med_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-xXRuU0mbJ-g"
      },
      "outputs": [],
      "source": [
        "#@title Print Distribution of Scoring Changes\n",
        "def printTSdistribution(all_some, pts_floor):\n",
        "  if all_some == 0:\n",
        "    # 2 year\n",
        "    graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "\n",
        "    # 3 year\n",
        "    tmp_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 4 year\n",
        "    tmp_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 5 year\n",
        "    tmp_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 6 year\n",
        "    tmp_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 7 year\n",
        "    tmp_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 8 year\n",
        "    tmp_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 10 year\n",
        "    tmp_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "  else:\n",
        "    graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data['PTS_change'] = graph_data['PTS_change'].round(1)\n",
        "  graph_data['TS+_change'] = graph_data['TS+_change'].round(1)\n",
        "\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "\n",
        "  pd.cut(graph_data['TS+_change'], \n",
        "       bins=[-17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8], \n",
        "       labels = ['-17% or worse', '-16%', '-15%', '-14%', '-13%', '-12%', '-11%', '-10%', '-9%', '-8%', '-7%', '-6%', '-5%', '-4%',\n",
        "                 '-3%', '-2%', '-1%', '0%', '+1%', '+2%', '+3%', '+4%', '+5%', '+6%',\n",
        "                 '+7% or better'])\\\n",
        "  .value_counts(sort=False).plot.bar()\n",
        "  title_string = f\"Reg->Post Scoring Change; Multi Year Playoff Stretches; >= {pts_floor} PP75 Post (1974-2022)\"\n",
        "  plt.title(title_string)\n",
        "  plt.xlabel('Change in TS+')\n",
        "  plt.ylabel('Count')\n",
        "  plt.show()\n",
        "  print(graph_data['TS+_change'].quantile(0.98))\n",
        "\n",
        "def printPTSdistribution(all_some, pts_floor):\n",
        "  if all_some == 0:\n",
        "    # 2 year\n",
        "    graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "\n",
        "    # 3 year\n",
        "    tmp_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 4 year\n",
        "    tmp_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 5 year\n",
        "    tmp_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 6 year\n",
        "    tmp_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 7 year\n",
        "    tmp_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 8 year\n",
        "    tmp_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 10 year\n",
        "    tmp_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "  else:\n",
        "    graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data['PTS_change'] = graph_data['PTS_change'].round(1)\n",
        "  graph_data['TS+_change'] = graph_data['TS+_change'].round(1)\n",
        "\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "\n",
        "  pd.cut(graph_data['PTS_change'], \n",
        "       bins=[-6, -5.5, -5, -4.5, -4, -3.5, -3, -2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5], \n",
        "       labels = ['-6 PTS or worse', '-5.5', '-5', '-4.5', '-4', '-3.5', '-3', '-2.5', '-2', '-1.5', '-1', '-0.5', '0', '+0.5', '+1', '+1.5', '+2', '+2.5', '+3', '+3.5', '+4', '+4.5% or better'])\\\n",
        "  .value_counts(sort=False).plot.bar()\n",
        "  title_string = f\"Reg->Post Scoring Change; Multi Year Playoff Stretches; >= {pts_floor} PP75 Post (1974-2022)\"\n",
        "  plt.title(title_string)\n",
        "  plt.xlabel('Change in PTS per 75')\n",
        "  plt.ylabel('Count')\n",
        "  plt.show()\n",
        "  print(graph_data['PTS_change'].quantile(0.8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CnygkJdO3VSy"
      },
      "outputs": [],
      "source": [
        "#@title Round Format\n",
        "player_change_file['TS+_change'] = player_change_file['TS+_change'].round(2)\n",
        "player_change_file['PTS_change'] = player_change_file['PTS_change'].round(2)\n",
        "player_change_file['PTS per 75_post'] = player_change_file['PTS per 75_post'].round(2)\n",
        "player_change_file['TS+_post'] = player_change_file['TS+_post'].round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1KNOV-aK5JdN"
      },
      "outputs": [],
      "source": [
        "#@title Manual comparisons function\n",
        "sorted_playoffs_pts = era_opponent_adj_playoff_per_75_df.copy()\n",
        "sorted_reg_pts = import_player_since74_per75_df.copy()\n",
        "\n",
        "player_a = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Kawhi Leonard\") & ((sorted_playoffs_pts.Year == 2017) | (sorted_playoffs_pts.Year == 2019)  | (sorted_playoffs_pts.Year == 2021))]\n",
        "player_b = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Kevin Durant\") & ((sorted_playoffs_pts.Year == 2012) | (sorted_playoffs_pts.Year == 2017)  | (sorted_playoffs_pts.Year == 2018) | (sorted_playoffs_pts.Year == 2019) | (sorted_playoffs_pts.Year == 2021))]\n",
        "\n",
        "#player_b = sorted_reg_pts[(sorted_reg_pts.Player == \"Damian Lillard\") & ((sorted_reg_pts.Year == 2014) | (sorted_reg_pts.Year == 2015)  | (sorted_reg_pts.Year == 2016) | (sorted_reg_pts.Year == 2016) | (sorted_reg_pts.Year == 2017) | (sorted_reg_pts.Year == 2019) | (sorted_reg_pts.Year == 2020) | (sorted_reg_pts.Year == 2021))]\n",
        "\n",
        "#player_a = sorted_pts[(sorted_pts.Player == \"Kawhi Leonard\") & ((sorted_pts.Year == 2012) | (sorted_pts.Year == 2014)  | (sorted_pts.Year == 2019) | (sorted_pts.Year == 2016) | (sorted_pts.Year == 2015) | (sorted_pts.Year == 2017) | (sorted_pts.Year == 2020) | (sorted_pts.Year == 2021))]\n",
        "\n",
        "#player_a = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Klay Thompson\") & ((sorted_playoffs_pts.Year == 2013) | (sorted_playoffs_pts.Year == 2014)  | (sorted_playoffs_pts.Year == 2015) | (sorted_playoffs_pts.Year == 2016) | (sorted_playoffs_pts.Year == 2017) | (sorted_playoffs_pts.Year == 2018) | (sorted_playoffs_pts.Year == 2019))]\n",
        "#player_b = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Kobe Bryant\")]\n",
        "#player_a = df[(df.Player == a)]\n",
        "#player_b = df[(df.Player == b)]\n",
        "total_mp_a = 0\n",
        "total_pts_a = 0\n",
        "total_ts_a = 0\n",
        "\n",
        "total_mp_b = 0\n",
        "total_pts_b = 0\n",
        "total_ts_b = 0\n",
        "mp_list_a = []\n",
        "mp_list_b = []\n",
        "\n",
        "# find total minutes a\n",
        "for row in player_a['MP']:\n",
        "  mp_list_a.append(row)\n",
        "  total_mp_a += row\n",
        "print(player_a.iat[0, 3], \"\\nminutes: \", total_mp_a)\n",
        "\n",
        "# find total PTS a\n",
        "i = 0\n",
        "for row in player_a['PTS']:\n",
        "  total_pts_a += row * (mp_list_a[i] / total_mp_a)\n",
        "  i = i + 1\n",
        "\n",
        "# find total TS+ a\n",
        "i = 0\n",
        "for row in player_a['TS%+']:\n",
        "  total_ts_a += row * (mp_list_a[i] / total_mp_a)\n",
        "  i = i + 1\n",
        "\n",
        "print(\"PTS per 75: \", total_pts_a)\n",
        "print(\"TS+: \",total_ts_a)\n",
        "\n",
        "# find total minutes\n",
        "for row in player_b['MP']:\n",
        "  mp_list_b.append(row)\n",
        "  total_mp_b += row\n",
        "print(\"\\n\")\n",
        "print(player_b.iat[0, 3], \"\\nminutes: \", total_mp_b)\n",
        "\n",
        "# find total PTS\n",
        "i = 0\n",
        "for row in player_b['PTS']:\n",
        "  total_pts_b += row * (mp_list_b[i] / total_mp_b)\n",
        "  i = i + 1\n",
        "\n",
        "# find total TS+\n",
        "i = 0\n",
        "for row in player_b['TS%+']:\n",
        "  total_ts_b += row * (mp_list_b[i] / total_mp_b)\n",
        "  i = i + 1\n",
        "\n",
        "print(\"PTS per 75: \", total_pts_b)\n",
        "print(\"TS+: \",total_ts_b)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M8yAW7WASwDX"
      },
      "outputs": [],
      "source": [
        "#@title def reg_playoff_comp(a, dfa, dfb) \n",
        "# def reg_playoff_comp(a, dfa, dfb) \n",
        "# print the change in scoring rate and effieciency for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoff_comp(a, dfa, dfb):\n",
        "\n",
        "  player_a = dfa[(dfa.Player == a)]\n",
        "  player_b = dfb[(dfb.Player == a)]\n",
        "  total_mp_a = 0\n",
        "  pts_list_a = []\n",
        "  ts_list_a = []\n",
        "\n",
        "  total_mp_b = 0\n",
        "  pts_list_b = []\n",
        "  ts_list_b = []\n",
        "\n",
        "  mp_list_a = []\n",
        "  mp_list_b = []\n",
        "\n",
        "\n",
        "  # find total PTS a\n",
        "  i = 0\n",
        "  for row in player_a['PTS']:\n",
        "    pts_list_a.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+ a\n",
        "  i = 0\n",
        "  for row in player_a['TS%+']:\n",
        "    ts_list_a.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total minutes\n",
        "  for row in player_b['MP']:\n",
        "    mp_list_b.append(row)\n",
        "    total_mp_b += row\n",
        "  print(\"\\n\")\n",
        "  print(player_b.iat[0, 3], \"\\nPlayoffs\\n\\nminutes: \", total_mp_b)\n",
        "\n",
        "  # find total PTS\n",
        "  i = 0\n",
        "  for row in player_b['PTS']:\n",
        "    pts_list_b.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+\n",
        "  i = 0\n",
        "  for row in player_b['TS%+']:\n",
        "    ts_list_b.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  total_pts = 0\n",
        "  total_ts = 0\n",
        "  while i <= j-1:\n",
        "    total_pts += ((pts_list_b[i] - pts_list_a[i]) * (mp_list_b[i] / total_mp_b))\n",
        "    print(pts_list_b[i] - pts_list_a[i])\n",
        "    print(((pts_list_b[i] - pts_list_a[i]) * (mp_list_b[i] / total_mp_b)))\n",
        "    total_ts += ((ts_list_b[i] - ts_list_a[i]) * (mp_list_b[i] / total_mp_b))\n",
        "    i = i + 1\n",
        "\n",
        "  print(\"\\n\\nRegular Season to Playoffs Change\\n\")\n",
        "  if total_pts > 0:\n",
        "    form_string = \"PTS per 75: +{}\".format(total_pts)\n",
        "    print(form_string)\n",
        "  else: \n",
        "    print(\"PTS per 75: \", total_pts)\n",
        "  if total_ts > 0:\n",
        "    form_string = \"TS+ {}\".format(total_ts)\n",
        "    print(form_string)\n",
        "  else:\n",
        "    print(\"TS+: \",total_ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ1Q1Vf25HB8"
      },
      "source": [
        "**SCORING PEAK FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NXifsLAWa2m_"
      },
      "outputs": [],
      "source": [
        "#@title Run Scoring Peaks\n",
        "\n",
        "# 2\n",
        "twoyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "twoyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('two_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 3 \n",
        "threeyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "threeyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('three_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 4 \n",
        "fouryearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "fouryearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('four_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 5 \n",
        "fiveyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "fiveyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('five_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 6 \n",
        "sixyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "sixyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('six_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 7 \n",
        "sevenyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "sevenyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('seven_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 8 \n",
        "eightyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "eightyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('eight_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 9 \n",
        "nineyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "nineyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('nine_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 10 \n",
        "tenyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "tenyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('ten_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "18EL_SvjcEnR"
      },
      "outputs": [],
      "source": [
        "#@title Import Scoring Peaks\n",
        "\n",
        "# 2\n",
        "import_adjpts_twopeaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_twopeaks_df = import_adjpts_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_twopeaks_df = pd.read_csv('two_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_twopeaks_df = import_adjts_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_twopeaks_df['TeamColor'] = import_adjpts_twopeaks_df['Team'].map(team_colors)\n",
        "import_adjts_twopeaks_df['TeamColor'] = import_adjts_twopeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_threepeaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_threepeaks_df = import_adjpts_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_threepeaks_df = pd.read_csv('three_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_threepeaks_df = import_adjts_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_threepeaks_df['TeamColor'] = import_adjpts_threepeaks_df['Team'].map(team_colors)\n",
        "import_adjts_threepeaks_df['TeamColor'] = import_adjts_threepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_4peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_4peaks_df = import_adjpts_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_4peaks_df = pd.read_csv('four_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_4peaks_df = import_adjts_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_4peaks_df['TeamColor'] = import_adjpts_4peaks_df['Team'].map(team_colors)\n",
        "import_adjts_4peaks_df['TeamColor'] = import_adjts_4peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_fivepeaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_fivepeaks_df = import_adjpts_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_fivepeaks_df = pd.read_csv('five_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_fivepeaks_df = import_adjts_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_fivepeaks_df['TeamColor'] = import_adjpts_fivepeaks_df['Team'].map(team_colors)\n",
        "import_adjts_fivepeaks_df['TeamColor'] = import_adjts_fivepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_6peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_6peaks_df = import_adjpts_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_6peaks_df = pd.read_csv('six_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_6peaks_df = import_adjts_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjts_6peaks_df['TeamColor'] = import_adjts_6peaks_df['Team'].map(team_colors)\n",
        "import_adjpts_6peaks_df['TeamColor'] = import_adjpts_6peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_7peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_7peaks_df = import_adjpts_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_7peaks_df = pd.read_csv('seven_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_7peaks_df = import_adjts_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjts_7peaks_df['TeamColor'] = import_adjts_7peaks_df['Team'].map(team_colors)\n",
        "import_adjpts_7peaks_df['TeamColor'] = import_adjpts_7peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_eightpeaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_eightpeaks_df = import_adjpts_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_eightpeaks_df = pd.read_csv('eight_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_eightpeaks_df = import_adjts_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_eightpeaks_df['TeamColor'] = import_adjpts_eightpeaks_df['Team'].map(team_colors)\n",
        "import_adjts_eightpeaks_df['TeamColor'] = import_adjts_eightpeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_9peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_9peaks_df = import_adjpts_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_9peaks_df = pd.read_csv('nine_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_9peaks_df = import_adjts_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_9peaks_df['TeamColor'] = import_adjpts_9peaks_df['Team'].map(team_colors)\n",
        "import_adjts_9peaks_df['TeamColor'] = import_adjts_9peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_10peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_10peaks_df = import_adjpts_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_10peaks_df = pd.read_csv('ten_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_10peaks_df = import_adjts_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_10peaks_df['TeamColor'] = import_adjpts_10peaks_df['Team'].map(team_colors)\n",
        "import_adjts_10peaks_df['TeamColor'] = import_adjts_10peaks_df['Team'].map(team_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Fo8KJtggdtZC"
      },
      "outputs": [],
      "source": [
        "#@title Output Scoring Peaks\n",
        "\n",
        "# 2\n",
        "at_least_400_min_2pts = import_adjpts_twopeaks_df[(import_adjpts_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2pts = at_least_400_min_2pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_2ts = import_adjts_twopeaks_df[(import_adjts_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2ts = at_least_400_min_2ts.reset_index(drop=True)\n",
        "\n",
        "sorted_2pts = at_least_400_min_2pts.copy()\n",
        "sorted_2pts.insert(6, \"TS+\", at_least_400_min_2ts['PeakValue'])\n",
        "sorted_2pts = sorted_2pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_2pts = sorted_2pts.sort_values('PTS', ascending=False)\n",
        "sorted_2pts = sorted_2pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_2pts = sorted_2pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_2pts['PTS'] = sorted_2pts['PTS'].round(2)\n",
        "sorted_2pts['TS+'] = sorted_2pts['TS+'].round(2)\n",
        "\n",
        "sorted_2pts = sorted_2pts.dropna()\n",
        "\n",
        "print(sorted_2pts)\n",
        "\n",
        "sorted_2pts.to_csv(\"Two_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 3\n",
        "at_least_400_min_pts = import_adjpts_threepeaks_df[(import_adjpts_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_pts = at_least_400_min_pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_ts = import_adjts_threepeaks_df[(import_adjts_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_ts = at_least_400_min_ts.reset_index(drop=True)\n",
        "\n",
        "sorted_3pts = at_least_400_min_pts.copy()\n",
        "sorted_3pts.insert(6, \"TS+\", at_least_400_min_ts['PeakValue'])\n",
        "sorted_3pts = sorted_3pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3pts = sorted_3pts.sort_values('PTS', ascending=False)\n",
        "sorted_3pts = sorted_3pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_3pts = sorted_3pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3pts['PTS'] = sorted_3pts['PTS'].round(2)\n",
        "sorted_3pts['TS+'] = sorted_3pts['TS+'].round(2)\n",
        "\n",
        "sorted_3pts = sorted_3pts.dropna()\n",
        "\n",
        "print(sorted_3pts)\n",
        "\n",
        "sorted_3pts.to_csv(\"Three_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 4\n",
        "at_least_400_min_pts = import_adjpts_4peaks_df[(import_adjpts_4peaks_df['MP'] >= 600)]\n",
        "at_least_400_min_pts = at_least_400_min_pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_ts = import_adjts_4peaks_df[(import_adjts_4peaks_df['MP'] >= 600)]\n",
        "at_least_400_min_ts = at_least_400_min_ts.reset_index(drop=True)\n",
        "\n",
        "sorted_3pts = at_least_400_min_pts.copy()\n",
        "sorted_3pts.insert(6, \"TS+\", at_least_400_min_ts['PeakValue'])\n",
        "sorted_3pts = sorted_3pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3pts = sorted_3pts.sort_values('PTS', ascending=False)\n",
        "sorted_3pts = sorted_3pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_3pts = sorted_3pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3pts['PTS'] = sorted_3pts['PTS'].round(2)\n",
        "sorted_3pts['TS+'] = sorted_3pts['TS+'].round(2)\n",
        "\n",
        "sorted_3pts = sorted_3pts.dropna()\n",
        "\n",
        "print(sorted_3pts)\n",
        "\n",
        "sorted_3pts.to_csv(\"Four_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 5\n",
        "at_least_800_min_pts = import_adjpts_fivepeaks_df[(import_adjpts_fivepeaks_df['MP'] >= 1000)]\n",
        "at_least_800_min_ts = import_adjts_fivepeaks_df[(import_adjts_fivepeaks_df['MP'] >= 1000)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Five_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 6\n",
        "at_least_800_min_pts = import_adjpts_6peaks_df[(import_adjpts_6peaks_df['MP'] >= 1200)]\n",
        "at_least_800_min_ts = import_adjts_6peaks_df[(import_adjts_6peaks_df['MP'] >= 1200)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Six_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 7\n",
        "at_least_800_min_pts = import_adjpts_7peaks_df[(import_adjpts_7peaks_df['MP'] >= 1400)]\n",
        "at_least_800_min_ts = import_adjts_7peaks_df[(import_adjts_7peaks_df['MP'] >= 1400)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Seven_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 8\n",
        "at_least_1500_min_pts = import_adjpts_eightpeaks_df[(import_adjpts_eightpeaks_df['MP'] >= 1500)]\n",
        "at_least_1500_min_ts = import_adjts_eightpeaks_df[(import_adjts_eightpeaks_df['MP'] >= 1500)]\n",
        "\n",
        "\n",
        "sorted_8pts = at_least_1500_min_pts.copy()\n",
        "sorted_8pts.insert(6, \"TS+\", at_least_1500_min_ts['PeakValue'])\n",
        "sorted_8pts = sorted_8pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_8pts = sorted_8pts.sort_values('PTS', ascending=False)\n",
        "sorted_8pts = sorted_8pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_8pts = sorted_8pts.reindex(columns=columns_titles)\n",
        "sorted_8pts = sorted_8pts.reset_index(drop=True)\n",
        "\n",
        "sorted_8pts['PTS'] = sorted_8pts['PTS'].round(2)\n",
        "sorted_8pts['TS+'] = sorted_8pts['TS+'].round(2)\n",
        "\n",
        "sorted_8pts = sorted_8pts.dropna()\n",
        "\n",
        "\n",
        "print(sorted_8pts)\n",
        "\n",
        "sorted_8pts.to_csv(\"Eight_Year_scoring_Playoff_Peaks_1500min.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 9\n",
        "at_least_1500_min_pts = import_adjpts_9peaks_df[(import_adjpts_9peaks_df['MP'] >= 1700)]\n",
        "at_least_1500_min_ts = import_adjts_9peaks_df[(import_adjts_9peaks_df['MP'] >= 1700)]\n",
        "\n",
        "\n",
        "sorted_9pts = at_least_1500_min_pts.copy()\n",
        "sorted_9pts.insert(6, \"TS+\", at_least_1500_min_ts['PeakValue'])\n",
        "sorted_9pts = sorted_9pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_9pts = sorted_9pts.sort_values('PTS', ascending=False)\n",
        "sorted_9pts = sorted_9pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_9pts = sorted_9pts.reindex(columns=columns_titles)\n",
        "sorted_9pts = sorted_9pts.reset_index(drop=True)\n",
        "\n",
        "sorted_9pts['PTS'] = sorted_9pts['PTS'].round(2)\n",
        "sorted_9pts['TS+'] = sorted_9pts['TS+'].round(2)\n",
        "\n",
        "sorted_9pts = sorted_9pts.dropna()\n",
        "\n",
        "\n",
        "print(sorted_9pts)\n",
        "\n",
        "sorted_9pts.to_csv(\"Nine_Year_scoring_Playoff_Peaks_1700min.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 10\n",
        "at_least_2000_min_pts = import_adjpts_10peaks_df[(import_adjpts_10peaks_df['MP'] >= 2000)]\n",
        "at_least_2000_min_ts = import_adjts_10peaks_df[(import_adjts_10peaks_df['MP'] >= 2000)]\n",
        "\n",
        "\n",
        "sorted_10pts = at_least_2000_min_pts.copy()\n",
        "sorted_10pts.insert(6, \"TS+\", at_least_2000_min_ts['PeakValue'])\n",
        "sorted_10pts = sorted_10pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_10pts = sorted_10pts.sort_values('PTS', ascending=False)\n",
        "sorted_10pts = sorted_10pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_10pts = sorted_10pts.reindex(columns=columns_titles)\n",
        "sorted_10pts = sorted_10pts.reset_index(drop=True)\n",
        "sorted_10pts['PTS'] = sorted_10pts['PTS'].round(2)\n",
        "sorted_10pts['TS+'] = sorted_10pts['TS+'].round(2)\n",
        "\n",
        "sorted_10pts = sorted_10pts.dropna()\n",
        "\n",
        "print(sorted_10pts)\n",
        "\n",
        "sorted_10pts.to_csv(\"Ten_Year_scoring_Playoff_Peaks_2000min.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9leRo7p78g-t"
      },
      "source": [
        "**BPM PEAK FILES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w_maV6Oy-7B1"
      },
      "outputs": [],
      "source": [
        "#@title Run BPM Peaks\n",
        "twoyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('two_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "twoyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('two_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "# 3\n",
        "threeyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('three_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "threeyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('three_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#4\n",
        "fouryearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('four_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "fouryearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('four_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#5\n",
        "fiveyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('five_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "fiveyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('five_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#6\n",
        "sixyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('six_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "sixyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('six_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#7\n",
        "sevenyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('seven_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "sevenyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#\n",
        "eightyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('eight_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "eightyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#9\n",
        "nineyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('nine_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "nineyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#10\n",
        "tenyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('ten_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "tenyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XMGgOIAq70p1"
      },
      "outputs": [],
      "source": [
        "#@title Import BPM Peaks\n",
        "import_bpm_twopeaks_df = pd.read_csv('two_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_twopeaks_df = import_bpm_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_twopeaks_df = pd.read_csv('two_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_twopeaks_df = import_obpm_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_twopeaks_df['TeamColor'] = import_bpm_twopeaks_df['Team'].map(team_colors)\n",
        "import_obpm_twopeaks_df['TeamColor'] = import_obpm_twopeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_threepeaks_df = pd.read_csv('three_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_threepeaks_df = import_bpm_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_threepeaks_df = pd.read_csv('three_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_threepeaks_df = import_obpm_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_threepeaks_df['TeamColor'] = import_bpm_threepeaks_df['Team'].map(team_colors)\n",
        "import_obpm_threepeaks_df['TeamColor'] = import_obpm_threepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_4peaks_df = pd.read_csv('four_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_4peaks_df = import_bpm_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_4peaks_df = pd.read_csv('four_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_4peaks_df = import_obpm_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_4peaks_df['TeamColor'] = import_bpm_4peaks_df['Team'].map(team_colors)\n",
        "import_obpm_4peaks_df['TeamColor'] = import_obpm_4peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_fivepeaks_df = pd.read_csv('five_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_fivepeaks_df = import_bpm_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_fivepeaks_df = pd.read_csv('five_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_fivepeaks_df = import_obpm_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_fivepeaks_df['TeamColor'] = import_bpm_fivepeaks_df['Team'].map(team_colors)\n",
        "import_obpm_fivepeaks_df['TeamColor'] = import_obpm_fivepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_6peaks_df = pd.read_csv('six_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_6peaks_df = import_bpm_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_6peaks_df = pd.read_csv('six_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_6peaks_df = import_obpm_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_obpm_6peaks_df['TeamColor'] = import_obpm_6peaks_df['Team'].map(team_colors)\n",
        "import_bpm_6peaks_df['TeamColor'] = import_bpm_6peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_7peaks_df = pd.read_csv('seven_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_7peaks_df = import_bpm_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_7peaks_df = pd.read_csv('seven_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_7peaks_df = import_obpm_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_obpm_7peaks_df['TeamColor'] = import_obpm_7peaks_df['Team'].map(team_colors)\n",
        "import_bpm_7peaks_df['TeamColor'] = import_bpm_7peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_eightpeaks_df = pd.read_csv('eight_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_eightpeaks_df = import_bpm_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_eightpeaks_df = pd.read_csv('eight_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_eightpeaks_df = import_obpm_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_eightpeaks_df['TeamColor'] = import_bpm_eightpeaks_df['Team'].map(team_colors)\n",
        "import_obpm_eightpeaks_df['TeamColor'] = import_obpm_eightpeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_9peaks_df = pd.read_csv('nine_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_9peaks_df = import_bpm_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_9peaks_df = pd.read_csv('nine_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_9peaks_df = import_obpm_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_9peaks_df['TeamColor'] = import_bpm_9peaks_df['Team'].map(team_colors)\n",
        "import_obpm_9peaks_df['TeamColor'] = import_obpm_9peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_10peaks_df = pd.read_csv('ten_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_10peaks_df = import_bpm_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_10peaks_df = pd.read_csv('ten_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_10peaks_df = import_obpm_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_10peaks_df['TeamColor'] = import_bpm_10peaks_df['Team'].map(team_colors)\n",
        "import_obpm_10peaks_df['TeamColor'] = import_obpm_10peaks_df['Team'].map(team_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7g56Mu1U8gL7"
      },
      "outputs": [],
      "source": [
        "#@title Output BPM Peaks\n",
        "\n",
        "at_least_400_min_2bpm = import_bpm_twopeaks_df[(import_bpm_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2bpm = at_least_400_min_2bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_2obpm = import_obpm_twopeaks_df[(import_obpm_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2obpm = at_least_400_min_2obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_2bpm = at_least_400_min_2bpm.copy()\n",
        "sorted_2bpm.insert(6, \"OBPM\", at_least_400_min_2obpm['PeakValue'])\n",
        "sorted_2bpm = sorted_2bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_2bpm = sorted_2bpm.sort_values('BPM', ascending=False)\n",
        "sorted_2bpm = sorted_2bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_2bpm = sorted_2bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_2bpm['BPM'] = sorted_2bpm['BPM'].round(2)\n",
        "sorted_2bpm['OBPM'] = sorted_2bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_2bpm = sorted_2bpm.dropna()\n",
        "\n",
        "print(sorted_2bpm)\n",
        "\n",
        "sorted_2bpm.to_csv(\"Two_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 3 year adjusted playoff scoring peaks (>= 400 min) Output File\n",
        "\n",
        "# 400 minutes filter\n",
        "at_least_400_min_bpm = import_bpm_threepeaks_df[(import_bpm_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_bpm = at_least_400_min_bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_obpm = import_obpm_threepeaks_df[(import_obpm_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_obpm = at_least_400_min_obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_3bpm = at_least_400_min_bpm.copy()\n",
        "sorted_3bpm.insert(6, \"OBPM\", at_least_400_min_obpm['PeakValue'])\n",
        "sorted_3bpm = sorted_3bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.sort_values('BPM', ascending=False)\n",
        "sorted_3bpm = sorted_3bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_3bpm = sorted_3bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3bpm['BPM'] = sorted_3bpm['BPM'].round(2)\n",
        "sorted_3bpm['OBPM'] = sorted_3bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.dropna()\n",
        "\n",
        "print(sorted_3bpm)\n",
        "\n",
        "sorted_3bpm.to_csv(\"Three_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 4 year adjusted playoff scoring peaks (>= 600 min) Output File\n",
        "\n",
        "# 400 minutes filter\n",
        "at_least_400_min_bpm = import_bpm_4peaks_df[(import_bpm_4peaks_df['MP'] >= 300)]\n",
        "at_least_400_min_bpm = at_least_400_min_bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_obpm = import_obpm_4peaks_df[(import_obpm_4peaks_df['MP'] >= 300)]\n",
        "at_least_400_min_obpm = at_least_400_min_obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_3bpm = at_least_400_min_bpm.copy()\n",
        "sorted_3bpm.insert(6, \"OBPM\", at_least_400_min_obpm['PeakValue'])\n",
        "sorted_3bpm = sorted_3bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.sort_values('BPM', ascending=False)\n",
        "sorted_3bpm = sorted_3bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_3bpm = sorted_3bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3bpm['BPM'] = sorted_3bpm['BPM'].round(2)\n",
        "sorted_3bpm['OBPM'] = sorted_3bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.dropna()\n",
        "\n",
        "print(sorted_3bpm)\n",
        "\n",
        "sorted_3bpm.to_csv(\"Four_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 5 year adjusted playoff scoring peaks (>=800 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_fivepeaks_df[(import_bpm_fivepeaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_fivepeaks_df[(import_obpm_fivepeaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Five_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 6 year adjusted playoff scoring peaks (>=1000 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_6peaks_df[(import_bpm_6peaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_6peaks_df[(import_obpm_6peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Six_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 7 year adjusted playoff scoring peaks (>=1200 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_7peaks_df[(import_bpm_7peaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_7peaks_df[(import_obpm_7peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Seven_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 8 year adjusted playoff scoring peaks (>=1500 min) Output File\n",
        "\n",
        "at_least_1500_min_bpm = import_bpm_eightpeaks_df[(import_bpm_eightpeaks_df['MP'] >= 300)]\n",
        "at_least_1500_min_obpm = import_obpm_eightpeaks_df[(import_obpm_eightpeaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_8bpm = at_least_1500_min_bpm.copy()\n",
        "sorted_8bpm.insert(6, \"OBPM\", at_least_1500_min_obpm['PeakValue'])\n",
        "sorted_8bpm = sorted_8bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_8bpm = sorted_8bpm.sort_values('BPM', ascending=False)\n",
        "sorted_8bpm = sorted_8bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_8bpm = sorted_8bpm.reindex(columns=columns_titles)\n",
        "sorted_8bpm = sorted_8bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_8bpm['BPM'] = sorted_8bpm['BPM'].round(2)\n",
        "sorted_8bpm['OBPM'] = sorted_8bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_8bpm = sorted_8bpm.dropna()\n",
        "\n",
        "\n",
        "print(sorted_8bpm)\n",
        "\n",
        "sorted_8bpm.to_csv(\"Eight_Year_BPM_Playoff_Peaks_1500min.csv\", index=False)\n",
        "\n",
        "#@title 9 year adjusted playoff scoring peaks (>=1700 min) Output File\n",
        "\n",
        "at_least_1500_min_bpm = import_bpm_9peaks_df[(import_bpm_9peaks_df['MP'] >= 300)]\n",
        "at_least_1500_min_obpm = import_obpm_9peaks_df[(import_obpm_9peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_9bpm = at_least_1500_min_bpm.copy()\n",
        "sorted_9bpm.insert(6, \"OBPM\", at_least_1500_min_obpm['PeakValue'])\n",
        "sorted_9bpm = sorted_9bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_9bpm = sorted_9bpm.sort_values('BPM', ascending=False)\n",
        "sorted_9bpm = sorted_9bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_9bpm = sorted_9bpm.reindex(columns=columns_titles)\n",
        "sorted_9bpm = sorted_9bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_9bpm['BPM'] = sorted_9bpm['BPM'].round(2)\n",
        "sorted_9bpm['OBPM'] = sorted_9bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_9bpm = sorted_9bpm.dropna()\n",
        "\n",
        "\n",
        "print(sorted_9bpm)\n",
        "\n",
        "sorted_9bpm.to_csv(\"Nine_Year_BPM_Playoff_Peaks_1700min.csv\", index=False)\n",
        "\n",
        "#@title 10 year adjusted playoff scoring peaks (>=2000 min) Output File\n",
        "\n",
        "at_least_2000_min_bpm = import_bpm_10peaks_df[(import_bpm_10peaks_df['MP'] >= 300)]\n",
        "at_least_2000_min_obpm = import_obpm_10peaks_df[(import_obpm_10peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_10bpm = at_least_2000_min_bpm.copy()\n",
        "sorted_10bpm.insert(6, \"OBPM\", at_least_2000_min_obpm['PeakValue'])\n",
        "sorted_10bpm = sorted_10bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_10bpm = sorted_10bpm.sort_values('BPM', ascending=False)\n",
        "sorted_10bpm = sorted_10bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_10bpm = sorted_10bpm.reindex(columns=columns_titles)\n",
        "sorted_10bpm = sorted_10bpm.reset_index(drop=True)\n",
        "sorted_10bpm['BPM'] = sorted_10bpm['BPM'].round(2)\n",
        "sorted_10bpm['OBPM'] = sorted_10bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_10bpm = sorted_10bpm.dropna()\n",
        "\n",
        "print(sorted_10bpm)\n",
        "\n",
        "sorted_10bpm.to_csv(\"Ten_Year_BPM_Playoff_Peaks_2000min.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PBP PEAK FILES**"
      ],
      "metadata": {
        "id": "s1nOyA7_9oGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run PBP Peaks\n",
        "nineyearpeak(import_player_since74playoffs_playbyplay_df, 'OnCourt')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('nine_year_peak_OnCourt_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_OnCourt_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "nineyearpeak(import_player_since74playoffs_playbyplay_df, 'On-Off')\n",
        "import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_On-Off_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_On-Off_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "id": "vdNvzeQ39nct",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import PBP Peaks\n",
        "import_oncourt_9peaks_df = pd.read_csv('nine_year_peak_OnCourt_data.csv', encoding='utf8')\n",
        "import_oncourt_9peaks_df = import_oncourt_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_onoff_9peaks_df = pd.read_csv('nine_year_peak_On-Off_data.csv', encoding='utf8')\n",
        "import_onoff_9peaks_df = import_onoff_9peaks_df.assign(TeamColor=0)"
      ],
      "metadata": {
        "id": "KrW6tABC98im",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Output PBP Peaks\n",
        "\n",
        "at_least_400_min_oncourt = import_oncourt_9peaks_df[(import_oncourt_9peaks_df['MP'] >= 3000)]\n",
        "at_least_400_min_oncourt = at_least_400_min_oncourt.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_onoff = import_onoff_9peaks_df[(import_onoff_9peaks_df['MP'] >= 3000)]\n",
        "at_least_400_min_onoff = at_least_400_min_onoff.reset_index(drop=True)\n",
        "\n",
        "sorted_3bpm = at_least_400_min_oncourt.copy()\n",
        "sorted_3bpm.insert(6, \"On-Off\", at_least_400_min_onoff['PeakValue'])\n",
        "sorted_3bpm = sorted_3bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"OnCourt\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"On-Off\": \"On-Off\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.sort_values('On-Off', ascending=False)\n",
        "sorted_3bpm = sorted_3bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'On-Off', 'OnCourt', 'MP', 'G']\n",
        "sorted_3bpm = sorted_3bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3bpm['On-Off'] = sorted_3bpm['On-Off'].round(2)\n",
        "sorted_3bpm['OnCourt'] = sorted_3bpm['OnCourt'].round(2)\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.dropna()\n",
        "\n",
        "print(sorted_3bpm)\n",
        "\n",
        "sorted_3bpm.to_csv(\"Nine_Year_pbp_Playoff_Peaks_3000_min.csv\", index=False)"
      ],
      "metadata": {
        "id": "qa_aFfXc-Ts6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xD45xeb_1zE"
      },
      "source": [
        "**PEAK FUNCTION DEFINITIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "cellView": "form",
        "id": "WKanZbn6ABM9"
      },
      "outputs": [],
      "source": [
        "#@title 2 year peaks function\n",
        "\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '777' '15'\n",
        "def twoyearpeak(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = 0\n",
        "    prev_min = 0\n",
        "    prev_g = 0\n",
        "    prevYearTeam = 0\n",
        "    prevyear = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + prev_g\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back * (prev_min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prev_back = 0\n",
        "            prev_min = 0\n",
        "            prev_g = 0\n",
        "            prevYearTeam = 0\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 2 consecutive seasons\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear , present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+2 and len(indexlist) >=2:\n",
        "            two_seasons_count = player['Year']\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back = inner_row[valuestring]\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prev_min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "            prev_g = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            prev_back = inner_row[valuestring]\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prev_min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "            prev_g = inner_row['G']\n",
        "\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 2:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and prevYearTeam == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_two_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_two_year_peak_val, running_min, games]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "            outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "            two_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "cellView": "form",
        "id": "XTmZzNX7_UBG"
      },
      "outputs": [],
      "source": [
        "#@title 3 year peaks function\n",
        "\n",
        "# def threeyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 3 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 3 year stretches of 'valuestring' AND the listed years from each 3 year stretch + minutes played across the 3 seasons.\n",
        "# EX: threeyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-20', 'Kris Middleton', 'MIL' '23.32', '712' '22'\n",
        "def threeyearpeak(df, valuestring):\n",
        "  three_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 3 year peaks); begin as 0's\n",
        "    for i in range(0, 2):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    three_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_three_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_three_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[1]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 2):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons\n",
        "          if present_year >= original_year+2 and len(indexlist) >=3:\n",
        "            if (prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[1] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}'.format(prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if three_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            three_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 1\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 1\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          three_seasons_count = three_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 3:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_three_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_three_year_peak_val, running_min, games]], columns=cols)\n",
        "            three_year_peak = three_year_peak.append(df_temp)\n",
        "            outfile = f\"three_year_peak_{valuestring}_data.csv\"\n",
        "            three_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "cellView": "form",
        "id": "5Syc_qCO-cpI"
      },
      "outputs": [],
      "source": [
        "#@title 4 year peaks function\n",
        "\n",
        "# def fouryearpeak(df, valuestring):\n",
        "# returns a dataframe containing 4 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 4 year stretches of 'valuestring' AND the listed years from each 4 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fouryearpeak(import_player_since74_per100_df, 'PTS') returns 4 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-19', 'Kris Middleton', 'MIL' '22.11', '1213' '28'\n",
        "def fouryearpeak(df, valuestring):\n",
        "  four_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 4 year peaks); begin as 0's\n",
        "    for i in range(0, 3):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    four_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_four_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_four_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[2]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 3):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 4 consecutive seasons\n",
        "          if present_year >= original_year+3 and len(indexlist) >=4:\n",
        "            if (prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[2] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}'.format(prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if four_seasons_count == original_year+4 and len(indexlist) >=4:\n",
        "            four_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 2\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 2\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          four_seasons_count = four_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 4:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_four_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_four_year_peak_val, running_min, games]], columns=cols)\n",
        "            four_year_peak = four_year_peak.append(df_temp)\n",
        "            outfile = f\"four_year_peak_{valuestring}_data.csv\"\n",
        "            four_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "cellView": "form",
        "id": "iAmiC4OO9Ypf"
      },
      "outputs": [],
      "source": [
        "#@title 5 year peaks function\n",
        "\n",
        "# def fiveyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 5 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 5 year stretches of 'valuestring' AND the listed years from each 5 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 5 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-20', 'Kris Middleton', 'MIL' '22.11', '1639 '34'\n",
        "def fiveyearpeak(df, valuestring):\n",
        "  five_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 5 year peaks); begin as 0's\n",
        "    for i in range(0, 4):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    five_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_five_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_five_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[3]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 4):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 5 consecutive seasons\n",
        "          if present_year >= original_year+4 and len(indexlist) >=5:\n",
        "            if (prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[3] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}'.format(prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if five_seasons_count == original_year+5 and len(indexlist) >=5:\n",
        "            five_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 3\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 3\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          five_seasons_count = five_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 5:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_five_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_five_year_peak_val, running_min, games]], columns=cols)\n",
        "            five_year_peak = five_year_peak.append(df_temp)\n",
        "            outfile = f\"five_year_peak_{valuestring}_data.csv\"\n",
        "            five_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "cellView": "form",
        "id": "OdOIKhKi8z_t"
      },
      "outputs": [],
      "source": [
        "#@title 6 year peaks function\n",
        "\n",
        "# def sixyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 6 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 6 year stretches of 'valuestring' AND the listed years from each 6 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 6 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-21', 'Kris Middleton', 'MIL' '22.11', '1119' '46'\n",
        "def sixyearpeak(df, valuestring):\n",
        "  six_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 6 year peaks); begin as 0's\n",
        "    for i in range(0, 5):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    six_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_six_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_six_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[4]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 5):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 6 consecutive seasons\n",
        "          if present_year >= original_year+5 and len(indexlist) >=6:\n",
        "            if (prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[4] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}'.format(prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if six_seasons_count == original_year+6 and len(indexlist) >=6:\n",
        "            six_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 4\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 4\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          six_seasons_count = six_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 6:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_six_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_six_year_peak_val, running_min, games]], columns=cols)\n",
        "            six_year_peak = six_year_peak.append(df_temp)\n",
        "            outfile = f\"six_year_peak_{valuestring}_data.csv\"\n",
        "            six_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "cellView": "form",
        "id": "4rrbqSWm8Mvn"
      },
      "outputs": [],
      "source": [
        "#@title 7 year peaks function\n",
        "\n",
        "# def sevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 7 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 7 year stretches of 'valuestring' AND the listed years from each 7 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 7 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-22', 'Kris Middleton', 'MIL' '22.11', '1467' '66'\n",
        "def sevenyearpeak(df, valuestring):\n",
        "  seven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 7 year peaks); begin as 0's\n",
        "    for i in range(0, 6):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    seven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_seven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_seven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[5]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 6):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 7 consecutive seasons\n",
        "          if present_year >= original_year+6 and len(indexlist) >=7:\n",
        "            if (prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[5] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}'.format(prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if seven_seasons_count == original_year+7 and len(indexlist) >=7:\n",
        "            seven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 5\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 5\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          seven_seasons_count = seven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 7:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_seven_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_seven_year_peak_val, running_min, games]], columns=cols)\n",
        "            seven_year_peak = seven_year_peak.append(df_temp)\n",
        "            outfile = f\"seven_year_peak_{valuestring}_data.csv\"\n",
        "            seven_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "cellView": "form",
        "id": "A4a_yTqH7Z8f"
      },
      "outputs": [],
      "source": [
        "#@title 8 year peaks function\n",
        "\n",
        "# def eightyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 8 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 8 year stretches of 'valuestring' AND the listed years from each 8 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 8 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2013-20', 'Kris Middleton', 'MIL' '22.11', '2139' '66'\n",
        "def eightyearpeak(df, valuestring):\n",
        "  eight_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 8 year peaks); begin as 0's\n",
        "    for i in range(0, 7):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eight_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_eight_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_eight_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[6]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 7):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 8 consecutive seasons\n",
        "          if present_year >= original_year+7 and len(indexlist) >=8:\n",
        "            if (prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[6] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if eight_seasons_count == original_year+8 and len(indexlist) >=8:\n",
        "            eight_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 6\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 6\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          eight_seasons_count = eight_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 8:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_eight_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_eight_year_peak_val, running_min, games]], columns=cols)\n",
        "            eight_year_peak = eight_year_peak.append(df_temp)\n",
        "            outfile = f\"eight_year_peak_{valuestring}_data.csv\"\n",
        "            eight_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "cellView": "form",
        "id": "CTS30J-_32LS"
      },
      "outputs": [],
      "source": [
        "#@title 9 year peaks function\n",
        "\n",
        "# def nineyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 9 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 9 year stretches of 'valuestring' AND the listed years from each 9 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 9 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2012-20', 'Kris Middleton', 'MIL' '22.11', '2585' '66'\n",
        "def nineyearpeak(df, valuestring):\n",
        "  nine_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 9 year peaks); begin as 0's\n",
        "    for i in range(0, 8):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    nine_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_nine_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_nine_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)) + (prev_back[7] * (prev_min[7] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[7]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 8):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 9 consecutive seasons\n",
        "          if present_year >= original_year+8 and len(indexlist) >=9:\n",
        "            if (prevyear[7]  == (prevyear[6] - 1) and prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[7] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[7] , prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if nine_seasons_count == original_year+9 and len(indexlist) >=9:\n",
        "            nine_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 7\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 7\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          nine_seasons_count = nine_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 9:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[7] and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_nine_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_nine_year_peak_val, running_min, games]], columns=cols)\n",
        "            nine_year_peak = nine_year_peak.append(df_temp)\n",
        "            outfile = f\"nine_year_peak_{valuestring}_data.csv\"\n",
        "            nine_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "cellView": "form",
        "id": "wJUmrKQyZ7yv"
      },
      "outputs": [],
      "source": [
        "#@title 10 year peaks function\n",
        "\n",
        "# def tenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '2976', '76'\n",
        "def tenyearpeak(df, valuestring):\n",
        "  ten_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 10 year peaks); begin as 0's\n",
        "    for i in range(0, 9):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    ten_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_ten_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_ten_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)) + (prev_back[7] * (prev_min[7] / running_min)) + (prev_back[8] * (prev_min[8] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[8]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 9):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 10 consecutive seasons\n",
        "          if present_year >= original_year+9 and len(indexlist) >=10:\n",
        "            if (prevyear[8] == (prevyear[7] - 1) and prevyear[7]  == (prevyear[6] - 1) and prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[8] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[8] , prevyear[7] , prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if ten_seasons_count == original_year+10 and len(indexlist) >=10:\n",
        "            ten_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 8\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 8\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          ten_seasons_count = ten_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 10:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[7] and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_ten_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_ten_year_peak_val, running_min, games]], columns=cols)\n",
        "            ten_year_peak = ten_year_peak.append(df_temp)\n",
        "            outfile = f\"ten_year_peak_{valuestring}_data.csv\"\n",
        "            ten_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjnG8CpstskX"
      },
      "source": [
        "**SMALL USE CASE PEAK FUNCTION DEFINITIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oAcCFD7_sNPw"
      },
      "outputs": [],
      "source": [
        "#@title 2 year fragmented peaks function\n",
        "\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '4231'\n",
        "def fragtwoyearpeak(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes played\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = [0, 0]\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # store team player played on a season and 2 seasons ago in case they change teams during peak 3 years.\n",
        "    prevyear = 0\n",
        "    prevYearTeam = 0\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevYearTeam = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prevyear = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 2 consecutive seasons (not reached after 2 rows of a player is found)\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear, present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+2 and len(indexlist) >=2:\n",
        "            two_seasons_count = player['Year']\n",
        "\n",
        "          # move present value to previous year's value\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=2:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP']\n",
        "            if (old_team == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_two_year_peak_val, running_min]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_two_year_peak_val, running_min]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "            outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "            two_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jTUzLULMfPWF"
      },
      "outputs": [],
      "source": [
        "#@title Manual Data Peak Functions\n",
        "\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '4231'\n",
        "def twoyearpeak_manual_data(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # store the team a player played with 1 season and 2 seasons ago in case they change teams during peak 3 years.\n",
        "\n",
        "    prevyear = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear, present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            two_seasons_count = player['Year']\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=2:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_two_year_peak_val, running_min]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "            outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "            two_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 3 year peaks (manual data) function\n",
        "\n",
        "# def threeyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 3 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 3 year stretches of 'valuestring' AND the listed years from each 3 year stretch + minutes played across the 3 seasons.\n",
        "# EX: threeyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-20', 'Kris Middleton', 'MIL' '23.32', '7120'\n",
        "def threeyearpeak_manual_data(df, valuestring):\n",
        "  three_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue and minutes\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    three_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # previous two years; e.g. 2014, 2015 before 2016. 2016, 2019 if these were the two most recent seasons for a player before 2020.\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "\n",
        "    indexlist = []\n",
        "    running_three_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_three_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+2 and len(indexlist) >=3:\n",
        "            if (prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev2year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}'.format(prev2year, prevyear, present_year)\n",
        "\n",
        "          if three_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            three_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          three_seasons_count = three_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=3:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_three_year_peak_val, running_min]], columns=cols)\n",
        "            three_year_peak = three_year_peak.append(df_temp)\n",
        "            outfile = f\"three_year_peak_{valuestring}_data.csv\"\n",
        "            three_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 4 year peaks (manual data) function\n",
        "\n",
        "# returns a dataframe containing 4 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 4 year stretches of 'valuestring' AND the listed years from each 4 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 4 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-19', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def fouryearpeak_manual_data(df, valuestring):\n",
        "  four_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    four_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_four_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_four_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+3 and len(indexlist) >=4:\n",
        "            if (prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev3year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}'.format(prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if four_seasons_count == original_year+4 and len(indexlist) >=4:\n",
        "            four_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          four_seasons_count = four_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=4:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_four_year_peak_val, running_min]], columns=cols)\n",
        "            four_year_peak = four_year_peak.append(df_temp)\n",
        "            outfile = f\"four_year_peak_{valuestring}_data.csv\"\n",
        "            four_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 5 year peaks (manual data) function\n",
        "\n",
        "# def fiveyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 5 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 5 year stretches of 'valuestring' AND the listed years from each 5 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 5 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def fiveyearpeak_manual_data(df, valuestring):\n",
        "  five_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    five_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_five_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_five_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+4 and len(indexlist) >=5:\n",
        "            if (prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev4year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}'.format(prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if five_seasons_count == original_year+5 and len(indexlist) >=5:\n",
        "            five_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          five_seasons_count = five_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=5:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_five_year_peak_val, running_min]], columns=cols)\n",
        "            five_year_peak = five_year_peak.append(df_temp)\n",
        "            outfile = f\"five_year_peak_{valuestring}_data.csv\"\n",
        "            five_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 6 year peaks (manual data) function\n",
        "\n",
        "# def sixyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 6 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 6 year stretches of 'valuestring' AND the listed years from each 6 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 6 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-21', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def sixyearpeak_manual_data(df, valuestring):\n",
        "  six_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    six_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_six_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_six_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+5 and len(indexlist) >=6:\n",
        "            if (prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev5year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}'.format(prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if six_seasons_count == original_year+6 and len(indexlist) >=6:\n",
        "            six_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          six_seasons_count = six_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=6:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_six_year_peak_val, running_min]], columns=cols)\n",
        "            six_year_peak = six_year_peak.append(df_temp)\n",
        "            outfile = f\"six_year_peak_{valuestring}_data.csv\"\n",
        "            six_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 7 year peaks (manual data) function\n",
        "\n",
        "# def sevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def sevenyearpeak_manual_data(df, valuestring):\n",
        "  seven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    seven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_seven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_seven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+6 and len(indexlist) >=7:\n",
        "            if (prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev6year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}'.format(prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if seven_seasons_count == original_year+7 and len(indexlist) >=7:\n",
        "            seven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          seven_seasons_count = seven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=7:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_seven_year_peak_val, running_min]], columns=cols)\n",
        "            seven_year_peak = seven_year_peak.append(df_temp)\n",
        "            outfile = f\"seven_year_peak_{valuestring}_data.csv\"\n",
        "            seven_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 8 year peaks (manual data) function\n",
        "\n",
        "# def eightyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def eightyearpeak_manual_data(df, valuestring):\n",
        "  eight_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eight_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_eight_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_eight_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+7 and len(indexlist) >=8:\n",
        "            if (prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev7year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}'.format(prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if eight_seasons_count == original_year+8 and len(indexlist) >=8:\n",
        "            eight_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          eight_seasons_count = eight_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=8:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_eight_year_peak_val, running_min]], columns=cols)\n",
        "            eight_year_peak = eight_year_peak.append(df_temp)\n",
        "            outfile = f\"eight_year_peak_{valuestring}_data.csv\"\n",
        "            eight_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 9 year peaks (manual data) function\n",
        "\n",
        "# def nineyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 9 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 9 year stretches of 'valuestring' AND the listed years from each 9 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 9 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def nineyearpeak_manual_data(df, valuestring):\n",
        "  nine_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    nine_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_nine_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_nine_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+8 and len(indexlist) >=9:\n",
        "            if (prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev8year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if nine_seasons_count == original_year+9 and len(indexlist) >=9:\n",
        "            nine_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          nine_seasons_count = nine_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=9:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_nine_year_peak_val, running_min]], columns=cols)\n",
        "            nine_year_peak = nine_year_peak.append(df_temp)\n",
        "            outfile = f\"nine_year_peak_{valuestring}_data.csv\"\n",
        "            nine_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 10 year peaks (manual data) function\n",
        "\n",
        "# def tenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def tenyearpeak_manual_data(df, valuestring):\n",
        "  ten_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # 9 seasons ago's peakvalue\n",
        "    prev_9back = 0\n",
        "    prev_9min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    ten_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "    prev9year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_ten_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min + prev_9min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_ten_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)) + (prev_9back * (prev_9min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev9year = 0\n",
        "            prev_9back = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            prev_9min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+9 and len(indexlist) >=10:\n",
        "            if (prev9year == (prev8year-1) and prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev9year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev9year, prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if ten_seasons_count == original_year+10 and len(indexlist) >=10:\n",
        "            ten_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          ten_seasons_count = ten_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=10:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_ten_year_peak_val, running_min]], columns=cols)\n",
        "            ten_year_peak = ten_year_peak.append(df_temp)\n",
        "            outfile = f\"ten_year_peak_{valuestring}_data.csv\"\n",
        "            ten_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 11 year peaks (manual data) function\n",
        "\n",
        "# def elevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 11 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 11 year stretches of 'valuestring' AND the listed years from each 11 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 11 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-21', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def elevenyearpeak_manual_data(df, valuestring):\n",
        "  eleven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # 9 seasons ago's peakvalue\n",
        "    prev_9back = 0\n",
        "    prev_9min = 0\n",
        "\n",
        "    prev_10back = 0\n",
        "    prev_10min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eleven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "    prev9year = 0\n",
        "    prev10year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_eleven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min + prev_9min + prev_10min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_eleven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)) + (prev_9back * (prev_9min / running_min))+ (prev_10back * (prev_10min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev9year = 0\n",
        "            prev10year = 0\n",
        "            prev_10back = 0\n",
        "            prev_9back = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            prev_9min = 0\n",
        "            prev_10min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+10 and len(indexlist) >=11:\n",
        "            if (prev10year == (prev9year-1) and prev9year == (prev8year-1) and prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev10year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev10year, prev9year, prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if eleven_seasons_count == original_year+11 and len(indexlist) >=11:\n",
        "            eleven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_10back = prev_9back\n",
        "            prev_10min = prev_9min\n",
        "            prev10year = prev9year\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_10back = prev_9back\n",
        "            prev_10min = prev_9min\n",
        "            prev10year = prev9year\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          eleven_seasons_count = eleven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=11:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_eleven_year_peak_val, running_min]], columns=cols)\n",
        "            eleven_year_peak = eleven_year_peak.append(df_temp)\n",
        "            outfile = f\"eleven_year_peak_{valuestring}_data.csv\"\n",
        "            eleven_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXEdTPyqEUUH"
      },
      "source": [
        "**RUN YEAR MANUAL SUBSETS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2n5FivB9QcKn"
      },
      "outputs": [],
      "source": [
        "#@title Adjusted Playoff TS+ of Manual Subset\n",
        "def manual_adjust_scoring_efficiency(player_df, opp_ts_df, opp_defrtg_df, opp_literal_defrtg, player):\n",
        "\n",
        "      final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'PP75', 'TS+', 'NetRtg', 'rOffRtg', 'MP'])\n",
        "\n",
        "      years_list = []\n",
        "\n",
        "      player_df['PP75'] = player_df['PP75'].astype(float)\n",
        "      player_df['PP75'] = player_df['PP75'] * .75\n",
        "\n",
        "\n",
        "      player_df['TS%'] = player_df['TS%'].astype(float)\n",
        "\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(int)\n",
        "      opp_defrtg_df['Team'] = opp_defrtg_df['Team'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(int)\n",
        "      opp_literal_defrtg['Team'] = opp_literal_defrtg['Team'].astype(str)\n",
        "      opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "      player_df['Opp'] = player_df['Opp'].astype(str)\n",
        "      player_df['Year'] = player_df['Year'].astype(int)\n",
        "\n",
        "      for i, row in player_df.iterrows():\n",
        "\n",
        "        current_opp = player_df.loc[i, 'Opp']\n",
        "        current_year = player_df.loc[i, 'Year']\n",
        "\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & (opp_ts_df['Year'] == current_year)]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        opponent_literal_def = opp_literal_defrtg[(opp_literal_defrtg['Team'] == current_opp) & ((opp_literal_defrtg['Year'] == current_year))]\n",
        "        opp_def_rtg = float(opponent_literal_def['DefRtg'])\n",
        "\n",
        "        player_ts = player_df.loc[i, 'TS%']\n",
        "        tsplus = (float(player_ts) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        relOffRtg = float(row['OffRtg']) - opp_def_rtg\n",
        "\n",
        "        player_df.loc[i,'TS+'] = tsplus\n",
        "        player_df.loc[i,'PTS_coeff'] = pts_coeff\n",
        "        player_df.loc[i,'rOffRtg'] = relOffRtg\n",
        "\n",
        "\n",
        "        if player_df.loc[i, 'Year'] not in years_list:\n",
        "          years_list.append(player_df.loc[i, 'Year'])\n",
        "\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'TS%', 'PTS', 'PTS_coeff'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = player_df[(player_df['Year'] == year)]\n",
        "\n",
        "        total_pts = 0\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        total_net = 0\n",
        "        total_off = 0\n",
        "\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "         #PTS\n",
        "        iter = 0\n",
        "        for ind_pts in tmp_sub_df['PP75']:\n",
        "          ind_pts = float(ind_pts)\n",
        "          total_pts += float(ind_pts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        #coeff\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        total_pts = total_pts * total_coeff\n",
        "\n",
        "\n",
        "        # NetRtg\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['NetRtg']:\n",
        "          ind_net = float(ind_coeff)\n",
        "          total_net += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        # OffRtg\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['rOffRtg']:\n",
        "          ind_off = float(ind_coeff)\n",
        "          total_off += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "        total_off = '%.2f' % round(total_off, 2)\n",
        "        total_net = '%.2f' % round(total_net, 2)\n",
        "\n",
        "        new_row = {'Player':player, 'Year':year,  'PP75':total_pts, 'TS+':total_ts, 'NetRtg':total_net, 'rOffRtg': total_off, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "      print(final_season_df)\n",
        "      outfile = f\"NBA_Playoff_Manual_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QQT2n6FFd9pf"
      },
      "outputs": [],
      "source": [
        "#@title Print Manual Peaks\n",
        "def manu_tony_compare(player, sit):\n",
        "\n",
        "  manu_only_one_adjusted = pd.read_csv('/content/NBA_Playoff_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('two_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('two_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('two_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('two_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('three_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('four_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('four_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('four_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('four_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('five_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('five_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('five_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('five_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('six_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('six_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('six_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('six_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('seven_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('seven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('eight_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('eight_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('nine_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('nine_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('ten_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('ten_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('eleven_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eleven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('eleven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eleven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  import_pts_twopeaks_df = pd.read_csv('two_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_ts_twopeaks_df = pd.read_csv('two_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_peaks_df = pd.read_csv('two_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_peaks_df = pd.read_csv('two_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_peaks_df = pd.read_csv('three_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_peaks_df = pd.read_csv('three_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg3_peaks_df = pd.read_csv('three_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg3_peaks_df = pd.read_csv('three_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_4peaks_df = pd.read_csv('four_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_4peaks_df = pd.read_csv('four_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_4peaks_df = pd.read_csv('four_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_4peaks_df = pd.read_csv('four_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_5peaks_df = pd.read_csv('five_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_5peaks_df = pd.read_csv('five_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_5peaks_df = pd.read_csv('five_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_5peaks_df = pd.read_csv('five_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_6peaks_df = pd.read_csv('six_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_6peaks_df = pd.read_csv('six_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_6peaks_df = pd.read_csv('six_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_6peaks_df = pd.read_csv('six_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_7peaks_df = pd.read_csv('seven_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_7peaks_df = pd.read_csv('seven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_7peaks_df = pd.read_csv('seven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_7peaks_df = pd.read_csv('seven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_8peaks_df = pd.read_csv('eight_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_8peaks_df = pd.read_csv('eight_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_8peaks_df = pd.read_csv('eight_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_8peaks_df = pd.read_csv('eight_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_9peaks_df = pd.read_csv('nine_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_9peaks_df = pd.read_csv('nine_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_9peaks_df = pd.read_csv('nine_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_9peaks_df = pd.read_csv('nine_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_10peaks_df = pd.read_csv('ten_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_10peaks_df = pd.read_csv('ten_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_10peaks_df = pd.read_csv('ten_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_10peaks_df = pd.read_csv('ten_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_11peaks_df = pd.read_csv('eleven_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_11peaks_df = pd.read_csv('eleven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_11peaks_df = pd.read_csv('eleven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_11peaks_df = pd.read_csv('eleven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #2 year playoff scoring peaks Output File\n",
        "  peaks_df = import_pts_twopeaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_ts_twopeaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Two\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_2_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #3 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg3_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg3_peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Three\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_3_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #4 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_4peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_4peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_4peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_4peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Four\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_4_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #5 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_5peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_5peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_5peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_5peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Five\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_5_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #6 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_6peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_6peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_6peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_6peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Six\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_6_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #7 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_7peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_7peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_7peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_7peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Seven\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_7_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #8 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_8peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_8peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_8peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_8peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Eight\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_8_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #9 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_9peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_9peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_9peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_9peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Nine\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_9_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #10 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_10peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_10peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_10peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_10peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Ten\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_10_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  #11 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_11peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_11peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_11peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_11peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Eleven\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_11_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inflate Scoring for Manual Subset\n",
        "new_df = pd.DataFrame()\n",
        "per_75_coeff['Year'] = per_75_coeff['Year'].astype(int)\n",
        "manu_one_on['Year'] = manu_one_on['Year'].astype(float)\n",
        "manu_one_on['PP75'] = manu_one_on['PP75'].astype(float)\n",
        "for i, row in manu_one_on.iterrows():\n",
        "  sub_coeff = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PP75'] = float((row['PP75'] * sub_coeff['Coefficient']))\n",
        "  new_df = new_df.append(row)\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df['PP75'] = new_df['PP75'].astype(float)\n",
        "new_df['TS%'] = new_df['TS%'].astype(float)\n",
        "new_df['MP'] = new_df['MP'].astype(int)\n",
        "new_df['Opp'] = new_df['Opp'].astype(str)\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "team_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "team_ts_allowed_df['TS% Allowed'] = team_ts_allowed_df['TS% Allowed'].astype(float)\n",
        "team_ts_allowed_df['Year'] = team_ts_allowed_df['Year'].astype(int)\n",
        "\n",
        "opp_literal_defrtg = pd.read_csv('/content/NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "\n",
        "\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "\n",
        "manual_adjust_scoring_efficiency(new_df, team_ts_allowed_df, opponent_adj_pts_coeff, opp_literal_defrtg, 'Tim Duncan')\n",
        "\n",
        "#Manu Ginóbili"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TGTZh3uIM6lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrnCdHn6Z4hM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Output Year Percentiles\n",
        "from scipy import stats\n",
        "graph_data =  era_opponent_adj_playoff_per_75_df.copy()\n",
        "graph_data = graph_data[(graph_data['PTS'] >= 15)]\n",
        "graph_data = graph_data[(graph_data['MP'] >= 90)]\n",
        "\n",
        "final_season_df = pd.DataFrame(columns = ['Year', 'PP75', 'TS+', 'MP'])\n",
        "\n",
        "this_df = pd.read_csv('/content/NBA_Playoff_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "for idx, row in this_df.iterrows():\n",
        "  year = int(row['Year'])\n",
        "  pts = row['PP75']\n",
        "  ts = row['TS+']\n",
        "  mp = row['MP']\n",
        "  pts_percentile = stats.percentileofscore(graph_data['PTS'], pts)\n",
        "  ts_percentile = stats.percentileofscore(graph_data['TS%+'], ts)\n",
        "\n",
        "  \n",
        "  new_row = {'Year':year,  'PP75':pts_percentile, 'TS+':ts_percentile,'MP':int(mp)}\n",
        "  final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  outfile = f\"Percentiles.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "632Vlw2nH8ir"
      },
      "outputs": [],
      "source": [
        "manu_tony_compare(\"Tony\", \"Only_One\")\n",
        "# Manu Ginóbili"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN SERIES MANUAL SUBSETS**"
      ],
      "metadata": {
        "id": "X9dcEeQyVVWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Series) Adjusted Playoff TS+ of Manual Subset \n",
        "def manual_adjust_scoring_efficiency_series(player_df, opp_ts_df, opp_defrtg_df, opp_literal_defrtg, player):\n",
        "\n",
        "      final_season_df = pd.DataFrame(columns = ['Player', 'Series', 'PP75', 'TS+', 'NetRtg', 'rOffRtg', 'MP'])\n",
        "\n",
        "      series_list = []\n",
        "\n",
        "      player_df['PP75'] = player_df['PP75'].astype(float)\n",
        "      player_df['PP75'] = player_df['PP75'] * .75\n",
        "\n",
        "\n",
        "      player_df['TS%'] = player_df['TS%'].astype(float)\n",
        "\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(int)\n",
        "      opp_defrtg_df['Team'] = opp_defrtg_df['Team'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(int)\n",
        "      opp_literal_defrtg['Team'] = opp_literal_defrtg['Team'].astype(str)\n",
        "      opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "      player_df['Opp'] = player_df['Opp'].astype(str)\n",
        "      player_df['Year'] = player_df['Year'].astype(int)\n",
        "\n",
        "      for i, row in player_df.iterrows():\n",
        "\n",
        "        current_opp = player_df.loc[i, 'Opp']\n",
        "        current_year = player_df.loc[i, 'Year']\n",
        "\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & (opp_ts_df['Year'] == current_year)]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        opponent_literal_def = opp_literal_defrtg[(opp_literal_defrtg['Team'] == current_opp) & ((opp_literal_defrtg['Year'] == current_year))]\n",
        "        opp_def_rtg = float(opponent_literal_def['DefRtg'])\n",
        "\n",
        "        player_ts = player_df.loc[i, 'TS%']\n",
        "        tsplus = (float(player_ts) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        relOffRtg = float(row['OffRtg']) - opp_def_rtg\n",
        "\n",
        "        player_df.loc[i,'TS+'] = tsplus\n",
        "        player_df.loc[i,'PTS_coeff'] = pts_coeff\n",
        "        player_df.loc[i,'rOffRtg'] = relOffRtg\n",
        "\n",
        "\n",
        "      for idx, row in player_df.iterrows():\n",
        "        total_pts = 0\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        total_net = 0\n",
        "        total_off = 0\n",
        "\n",
        "        total_mp = int(row['MP'])\n",
        "        total_ts = float(row['TS+'])\n",
        "        total_pts = float(row['PP75'])\n",
        "        total_coeff = float(row['PTS_coeff'])\n",
        "        total_pts = total_pts * total_coeff\n",
        "\n",
        "\n",
        "        total_net = float(row['NetRtg'])\n",
        "        total_off = float(row['rOffRtg'])\n",
        "\n",
        "        total_pts = '%.2f' % round(total_pts, 2)\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "        total_off = '%.2f' % round(total_off, 2)\n",
        "        total_net = '%.2f' % round(total_net, 2)\n",
        "\n",
        "        series = str(row['Year'])\n",
        "        series = series + \" \"\n",
        "        series = series + str(row['Opp'])\n",
        "\n",
        "        new_row = {'Player':player, 'Series':series,  'PP75':total_pts, 'TS+':total_ts, 'NetRtg':total_net, 'rOffRtg': total_off, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "      print(final_season_df)\n",
        "      outfile = f\"NBA_Playoff_Series_Manual_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QGtEKaNlMyD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Series) Inflate Scoring for Manual Subset\n",
        "new_df = pd.DataFrame()\n",
        "per_75_coeff['Year'] = per_75_coeff['Year'].astype(int)\n",
        "manu_one_on['Year'] = manu_one_on['Year'].astype(float)\n",
        "manu_one_on['PP75'] = manu_one_on['PP75'].astype(float)\n",
        "for i, row in manu_one_on.iterrows():\n",
        "  sub_coeff = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PP75'] = float((row['PP75'] * sub_coeff['Coefficient']))\n",
        "  new_df = new_df.append(row)\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df['PP75'] = new_df['PP75'].astype(float)\n",
        "new_df['TS%'] = new_df['TS%'].astype(float)\n",
        "new_df['MP'] = new_df['MP'].astype(int)\n",
        "new_df['Opp'] = new_df['Opp'].astype(str)\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "team_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "team_ts_allowed_df['TS% Allowed'] = team_ts_allowed_df['TS% Allowed'].astype(float)\n",
        "team_ts_allowed_df['Year'] = team_ts_allowed_df['Year'].astype(int)\n",
        "\n",
        "opp_literal_defrtg = pd.read_csv('/content/NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "\n",
        "\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "\n",
        "manual_adjust_scoring_efficiency_series(new_df, team_ts_allowed_df, opponent_adj_pts_coeff, opp_literal_defrtg, 'Kobe')\n",
        "\n",
        "#Manu Ginóbili"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H0z9UzeePrxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Output Series Percentiles\n",
        "from scipy import stats\n",
        "graph_data =  era_opponent_adj_playoff_per_75_df.copy()\n",
        "graph_data = graph_data[(graph_data['PTS'] >= 15)]\n",
        "graph_data = graph_data[(graph_data['MP'] >= 90)]\n",
        "\n",
        "final_season_df = pd.DataFrame(columns = ['Series', 'PP75', 'TS+', 'MP'])\n",
        "\n",
        "this_df = pd.read_csv('/content/NBA_Playoff_Series_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "for idx, row in this_df.iterrows():\n",
        "  series = row['Series']\n",
        "  pts = row['PP75']\n",
        "  ts = row['TS+']\n",
        "  mp = row['MP']\n",
        "  pts_percentile = stats.percentileofscore(graph_data['PTS'], pts)\n",
        "  ts_percentile = stats.percentileofscore(graph_data['TS%+'], ts)\n",
        "\n",
        "  \n",
        "  new_row = {'Series':series,  'PP75':pts_percentile, 'TS+':ts_percentile,'MP':int(mp)}\n",
        "  final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  outfile = f\"Percentiles.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eS7gPS-sMjSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Output Series Approx_Scoring_Val\n",
        "from scipy import stats\n",
        "graph_data =  era_opponent_adj_playoff_per_75_df.copy()\n",
        "graph_data = graph_data[(graph_data['PTS'] >= 15)]\n",
        "graph_data = graph_data[(graph_data['MP'] >= 90)]\n",
        "graph_data['Approx_Scoring_Val'] = 0\n",
        "\n",
        "for idx, row in graph_data.iterrows():\n",
        "  pts = row['PTS']\n",
        "  ts = row['TS%+']\n",
        "  mp = row['MP']\n",
        "  pts_percentile = stats.percentileofscore(graph_data['PTS'], pts)\n",
        "  ts_percentile = stats.percentileofscore(graph_data['TS%+'], ts)\n",
        "  approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "  graph_data.at[idx, 'Approx_Scoring_Val'] = approx_scoring_val\n",
        "\n",
        "\n",
        "final_season_df = pd.DataFrame(columns = ['Series', 'Approx_Scoring_Val', 'MP'])\n",
        "\n",
        "this_df = pd.read_csv('/content/NBA_Playoff_Series_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "for idx, row in this_df.iterrows():\n",
        "  series = row['Series']\n",
        "  pts = row['PP75']\n",
        "  ts = row['TS+']\n",
        "  mp = row['MP']\n",
        "  pts_percentile = stats.percentileofscore(graph_data['PTS'], pts)\n",
        "  ts_percentile = stats.percentileofscore(graph_data['TS%+'], ts)\n",
        "  approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "  approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], approx_scoring_val)\n",
        "\n",
        "\n",
        "  \n",
        "  new_row = {'Series':series,  'Approx_Scoring_Val':approx_scoring_val,'MP':int(mp)}\n",
        "  final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  outfile = f\"Percentiles.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TQhwzqlCoCv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBcJHTYvdqJ9"
      },
      "source": [
        "**MANUAL SUBSETS**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape NBA playoffs series possession data\n",
        "def scrape_nba_player_series_data(url, player, player_ref):\n",
        "                       \n",
        "  wd.get(url)   \n",
        "  html = wd.page_source\n",
        "  soup = BeautifulSoup(html, features=\"lxml\")\n",
        "  time.sleep(10)\n",
        "\n",
        "  for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'div_other_scores'})\n",
        "          hrefs = second_div.findAll('td', attrs={'class': 'right gamelink'})\n",
        "          hrefs = str(hrefs)\n",
        "          ref_urls = re.findall(r'/\\d+\\w+\\D\\w+', hrefs)\n",
        "          urls = []\n",
        "          for ref_url in ref_urls:\n",
        "            ref_url = \"https://www.basketball-reference.com/boxscores/pbp\" + ref_url\n",
        "            urls.append(ref_url)\n",
        "  def_possessions = 0\n",
        "  missing_poss = 0\n",
        "  for game_url in urls:\n",
        "\n",
        "    wd.get(game_url)   \n",
        "    html = wd.page_source\n",
        "    soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "    for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'all_pbp'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'pbp'})\n",
        "            body = first_table.find('tbody')\n",
        "    # grab rows\n",
        "    rows = body.findAll('tr')[0:]\n",
        "\n",
        "    \n",
        "\n",
        "    total_poss = 0\n",
        "    player_out_wait = 0\n",
        "    beg_q = 0\n",
        "    extra_poss = 0\n",
        "    non_shooting = 0\n",
        "\n",
        "\n",
        "    possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "    fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "    player_out = [f'enters the game for <a href=\"{player_ref}\">{player}']\n",
        "    player_in = [f'{player}']\n",
        "\n",
        "    hes_back_but_subtly = [f'{player}</a> misses 2-pt']\n",
        "    for row in rows:\n",
        "      row = str(row)\n",
        "\n",
        "\n",
        "      if player_out_wait == 1:\n",
        "        if f'{player}</a> misses 2-pt' in row:\n",
        "          total_poss = total_poss + extra_poss\n",
        "          extra_poss = 0\n",
        "          player_out_wait = 0\n",
        "          beg_q = 0\n",
        "\n",
        "      if 'Q' in row:\n",
        "        beg_q = 1\n",
        "\n",
        "      if any(iny in row for iny in player_in):\n",
        "        player_out_wait = 0\n",
        "      if any(outy in row for outy in player_out):\n",
        "        player_out_wait = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in fts_no_shooting_foul) and player_out_wait == 0 and non_shooting == 1):\n",
        "        total_poss = total_poss + 1\n",
        "\n",
        "      if ('foul' in row and 'Shooting' not in row):\n",
        "        non_shooting = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "        total_poss = total_poss + 1\n",
        "        non_shooting = 0\n",
        "      \n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 1 and beg_q == 1):\n",
        "        extra_poss = extra_poss + 1\n",
        "        non_shooting = 0\n",
        "      \n",
        "    missing_poss = missing_poss + total_poss\n",
        "\n",
        "    #@title Default possessions\n",
        "\n",
        "    total_poss = 0\n",
        "    player_out_wait = 0\n",
        "    extra_poss = 0\n",
        "\n",
        "\n",
        "    possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "    fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "    player_out = [f'enters the game for <a href=\"{player_ref}\">{player}']\n",
        "    player_in = [f'{player}']\n",
        "\n",
        "    hes_back_but_subtly = [f'{player}</a> misses 2-pt']\n",
        "\n",
        "    for row in rows:\n",
        "      row = str(row)\n",
        "\n",
        "      if any(iny in row for iny in player_in):\n",
        "        player_out_wait = 0\n",
        "      if any(outy in row for outy in player_out):\n",
        "        player_out_wait = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "        total_poss = total_poss + 1\n",
        "    def_possessions = def_possessions + total_poss\n",
        "  print(\"Total Default:\")\n",
        "  print(def_possessions/2)\n",
        "  print(\"\\nTotal Missing:\")\n",
        "  print(missing_poss/2)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ij-9Pa2Tz-Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_nba_player_series_data(\"https://www.basketball-reference.com/playoffs/1998-nba-western-conference-finals-lakers-vs-jazz.html\", 'K. Bryant', '/players/b/bryanko01.html')"
      ],
      "metadata": {
        "id": "kgQg5nhsbpPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzgUworfEJgE"
      },
      "source": [
        "MANU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MS29cIwYJqdM"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with both of Tim and Tony on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['23.08', '.5938', '50', 'MEM', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.38', '.6081', '106', 'LAL', '2004', '6.16', '96.52']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['33.08', '.6719', '66', 'DEN', '2005', '13.0', '121.8']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.29', '.6705', '106', 'SEA', '2005', '21.34', '122.92']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.43', '.6327', '112', 'PHO', '2005', '2.40', '121.68']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.82', '.5593', '161', 'DET', '2005', '-0.93', '103.60']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['30.66', '.6154', '112', 'SAC', '2006', '20.24', '125.00']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.95', '.5859', '154', 'DAL', '2006', '7.45', '115.96']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['17.65', '.4194', '78', 'DEN', '2007', '-3.83', '108.50']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.76', '.5784', '114', 'PHO', '2007', '1.48', '108.30']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.58', '.6667', '79', 'UTA', '2007', '7.58', '122.15']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.61', '.6613', '65', 'CLE', '2007', '14.18', '108.20']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['19.51', '.5128', '105', 'PHO', '2008', '3.80', '109.27']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.31', '.5655', '169', 'NOH', '2008', '-10.07', '100.94']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.59', '.5484', '102', 'LAL', '2008', '-3.62', '98.99']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['43.83', '.6481', '91', 'DAL', '2010', '11.94', '123.46']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.02', '.7368', '89', 'PHO', '2010', '5.88', '119.10']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['26.70', '.5795', '102', 'MEM', '2011', '-1.04', '97.91']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.4375', '50', 'UTA', '2012', '-0.19', '109.18']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.20', '.7083', '67', 'LAC', '2012', '30.88', '116.0']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.79', '.6591', '117', 'OKC', '2012', '8.79', '110.08']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['14.47', '.6111', '41', 'LAL', '2013', '19.74', '119.74']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.95', '.3103', '73', 'GSW', '2013', '-13.80', '90.65']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.47', '.5500', '41', 'MEM', '2013', '-17.26', '101.32']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.93', '.6622', '98', 'MIA', '2013', '-1.84', '111.64']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['24.19', '.5375', '97', 'DAL', '2014', '12.92', '116.67']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.81', '.4483', '57', 'POR', '2014', '-2.40', '110.53']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.06', '.7321', '66', 'OKC', '2014', '6.0', '120.61']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.78', '.5469', '87', 'MIA', '2014', '27.22', '128.48']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "manu_one_on = manu_one_on.reset_index(drop=True)\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8IJyDJSH0uKl"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with both of Tim/Tony on (5+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['5.26', '.5000', '9', 'MEM', '2004']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.86', '.6667', '64', 'LAL', '2004']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['39.73', '.7250', '38', 'DEN', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['56.45', '1.1000', '38', 'SEA', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.6892', '79', 'PHO', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.14', '.6023', '116', 'DET', '2005']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['27.73', '.5333', '67', 'SAC', '2006']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['13.51', '.3462', '42', 'DAL', '2006']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['19.44', '.4762', '56', 'DEN', '2007']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.92', '.5500', '35', 'PHO', '2007']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.65', '.7083', '31', 'UTA', '2007']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.53', '.7727', '22', 'CLE', '2007']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['14.71', '.5000', '34', 'PHO', '2008']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.35', '.6048', '131', 'NOH', '2008']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.31', '.3889', '51', 'LAL', '2008']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['21.90', '.4792', '58', 'DAL', '2010']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.67', '.6500', '31', 'PHO', '2010']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['22.52', '.5435', '60', 'MEM', '2011']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['28.21', '.5500', '19', 'UTA', '2012']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.81', '.5000', '16', 'LAC', '2012']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['8.62', '.5000', '32', 'OKC', '2012']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '3', 'LAL', '2013']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['13.61', '.5000', '18', 'GSW', '2013']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '5', 'MEM', '2013']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.85', '.7333', '41', 'MIA', '2013']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['40.63', '1.0833', '16', 'DAL', '2014']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.00', '.5192', '46', 'POR', '2014']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.00', '.7500', '20', 'OKC', '2014']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['46.15', '.7500', '14', 'MIA', '2014']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "497kM8cObznH"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with only 1 of Tim/Tony on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['18.27', '.4048', '56', 'MEM', '2004', '15.14', '106.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.17', '.7000', '66', 'LAL', '2004', '0.0', '107.50']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '76', 'DEN', '2005', '18.88', '109.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '79', 'SEA', '2005', '7.79', '119.59']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '67', 'PHO', '2005', '12.23', '110.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '86', 'DET', '2005', '11.78', '108.97']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '46', 'SAC', '2006', '1.14', '110.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '81', 'DAL', '2006', '2.70', '110.81']\n",
        "\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['32.31', '.5263', '35', 'DEN', '2007', '7.74', '110.77']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.19', '.5167', '71', 'PHO', '2007', '-7.50', '108.70']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.21', '.5370', '54', 'UTA', '2007', '9.22', '104.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.51', '.5750', '36', 'CLE', '2007', '50.79', '123.81']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['42.05', '.5606', '42', 'PHO', '2008', '-0.21', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.72', '.7333', '60', 'NOH', '2008', '28.35', '120.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.72', '.5192', '55', 'LAL', '2008', '-7.09', '100.99']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4457', '102', 'DAL', '2010', '-5.21', '98.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.49', '.4444', '49', 'PHO', '2010', '-19.89', '94.85']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['51.95', '.7800', '38', 'MEM', '2011', '31.20', '128.57']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['16.67', '.4000', '13', 'UTA', '2012', '-43.30', '95.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '10', 'LAC', '2012', '-17.73', '55.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.95', '.6071', '18', 'OKC', '2012', '-49.03', '108.11']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['45.83', '.9167', '12', 'LAL', '2013', '29.17', '137.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.79', '.5256', '83', 'GSW', '2013', '46.44', '130.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.62', '.8889', '41', 'MEM', '2013', '35.38', '117.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.91', '.4444', '75', 'MIA', '2013', '-11.91', '102.99']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['48.39', '.6471', '44', 'DAL', '2014', '26.18', '120.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.97', '.4333', '29', 'POR', '2014', '30.05', '98.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.71', '.6842', '39', 'OKC', '2014', '24.56', '110.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.38', '.5000', '20', 'MIA', '2014', '14.76', '102.56']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SU6mtICYuRvm"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with only 1 of Tim/Tony on (3+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['17.65', '.4000', '29', 'MEM', '2004', '0.0', '90.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.4750', '42', 'LAL', '2004', '-2.26', '105.33']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['47.19', '.7000', '47', 'DEN', '2005', '26.97', '112.36']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['55.56', '.8125', '40', 'SEA', '2005', '14.38', '131.94']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '67', 'PHO', '2005', '12.23', '110.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.97', '.7250', '84', 'DET', '2005', '11.39', '109.22']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['8.70', '.3000', '36', 'SAC', '2006', '-21.74', '102.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.17', '.6528', '63', 'DAL', '2006', '3.42', '108.55']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['30.36', '.5333', '30', 'DEN', '2007', '-1.60', '108.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16', '.4167', '52', 'PHO', '2007', '-9.67', '107.0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.21', '.6667', '24', 'UTA', '2007', '16.59', '123.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.48', '.5000', '17', 'CLE', '2007', '72.41', '124.14']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['28.07', '.5000', '26', 'PHO', '2008', '-16.43', '101.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['44.00', '.7500', '42', 'NOH', '2008', '18.33', '113.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.55', '.5000', '25', 'LAL', '2008', '-21.28', '100.00']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['23.53', '.4872', '93', 'DAL', '2010', '-6.47', '98.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['10.53', '.3333', '28', 'PHO', '2010', '-34.31', '87.72']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['55.77', '.7250', '26', 'MEM', '2011', '17.31', '117.31']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.5000', '9', 'UTA', '2012', '-46.27', '106.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '6', 'LAC', '2012', '-24.18', '61.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['55.56', '.4545', '8', 'OKC', '2012', '-30.72', '122.22']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['60.00', '1.1250', '7', 'LAL', '2013', '40.00', '133.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.76', '.4444', '54', 'GSW', '2013', '44.55', '124.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['11.63', '.8333', '23', 'MEM', '2013', '61.60', '137.21']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['7.46', '.2083', '39', 'MIA', '2013', '-24.64', '94.03']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['62.22', '.6750', '21', 'DAL', '2014', '28.89', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.91', '.3889', '22', 'POR', '2014', '20.98', '97.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.89', '.7000', '26', 'OKC', '2014', '30.34', '111.11']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.05', '.6667', '12', 'MIA', '2014', '41.67', '100.00']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZMIRy4nnvI8E"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with only 1 of Tim/Tony on (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.000', '4', 'MEM', '2004', '6.94', '44.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.58', '.5667', '25', 'LAL', '2004', '8.67', '116.67']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['55.81', '.7059', '26', 'DEN', '2005', '16.90', '104.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['73.33', '1.2222', '16', 'SEA', '2005', '66.25', '160.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.47', '.5000', '44', 'PHO', '2005', '11.87', '114.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['49.25', '.8056', '42', 'DET', '2005', '28.14', '120.90']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['16.67', '.3333', '13', 'SAC', '2006', '-52.88', '62.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.7857', '11', 'DAL', '2006', '-9.09', '90.91']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.3889', '13', 'DEN', '2007', '-41.50', '96.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.25', '.5000', '27', 'PHO', '2007', '-30.22', '101.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '7', 'UTA', '2007', '33.33', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.2500', '6', 'CLE', '2007', '92.42', '109.09']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['22.71', '.5000', '10', 'PHO', '2008', '-19.26', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.46', '.7143', '29', 'NOH', '2008', '20.94', '117.31']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['13.33', '.2500', '8', 'LAL', '2008', '-37.92', '93.33']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['17.27', '.3800', '61', 'DAL', '2010', '-41.56', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['4.76', '.2500', '20', 'PHO', '2010', '-6.40', '91.82']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['56.25', '.7500', '14', 'MEM', '2011', '20.00', '100.00']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5000', '6', 'UTA', '2012', '-97.73', '75.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '3', 'LAC', '2012', '-66.67', '66.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.50', '.3750', '4', 'OKC', '2012', '-100.00', '100.00']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['75.00', '1.500', '4', 'LAL', '2013', '62.50', '162.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.4286', '16', 'GSW', '2013', '41.94', '106.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '14', 'MEM', '2013', '42.63', '138.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '19', 'MIA', '2013', '-49.88', '75.76']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['68.42', '.8571', '8', 'DAL', '2014', '2.79', '126.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.58', '.5000', '16', 'POR', '2014', '9.68', '90.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.43', '.6000', '18', 'OKC', '2014', '11.58', '97.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.6667', '8', 'MIA', '2014', '50.89', '107.14']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu Scoring numbers (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['18.75', '.5000', '16', 'MEM', '2004', '6.94', '44.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.6146', '121', 'LAL', '2004', '8.67', '116.67']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['35.62', '.6500', '77', 'DEN', '2005', '16.90', '104.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['46.72', '.9483', '69', 'SEA', '2005', '66.25', '160.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.28', '.5600', '149', 'PHO', '2005', '11.87', '114.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.03', '.6250', '171', 'DET', '2005', '28.14', '120.90']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['25.76', '.5435', '107', 'SAC', '2006', '-52.88', '62.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.03', '.5833', '102', 'DAL', '2006', '-9.09', '90.91']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['19.63', '.4306', '82', 'DEN', '2007', '-41.50', '96.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.42', '.5909', '112', 'PHO', '2007', '-30.22', '101.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.00', '.5893', '71', 'UTA', '2007', '33.33', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.5833', '42', 'CLE', '2007', '92.42', '109.09']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['13.10', '.4074', '85', 'PHO', '2008', '-19.26', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.23', '.6146', '180', 'NOH', '2008', '20.94', '117.31']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.86', '.4310', '89', 'LAL', '2008', '-37.92', '93.33']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['28.42', '.5098', '102', 'DAL', '2010', '-41.56', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.06', '.6618', '84', 'PHO', '2010', '-6.40', '91.82']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['32.11', '.6224', '98', 'MEM', '2011', '20.00', '100.00']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['21.88', '.5000', '49', 'UTA', '2012', '-97.73', '75.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.06', '.5909', '38', 'LAC', '2012', '-66.67', '66.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.25', '.5893', '80', 'OKC', '2012', '-100.00', '100.00']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['22.92', '.7857', '26', 'LAL', '2013', '62.50', '162.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.67', '.3913', '58', 'GSW', '2013', '41.94', '106.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['10.29', '.5000', '37', 'MEM', '2013', '42.63', '138.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.23', '.6857', '96', 'MIA', '2013', '-49.88', '75.76']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['35.54', '.6833', '63', 'DAL', '2014', '2.79', '126.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.68', '.4306', '70', 'POR', '2014', '9.68', '90.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.38', '.5893', '49', 'OKC', '2014', '11.58', '97.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.78', '.7273', '51', 'MIA', '2014', '50.89', '107.14']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H6Z3FD97Q_oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu Scoring numbers\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['12.96', '.4107', '182', 'PHO', '2003', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.31', '.6364', '149', 'LAL', '2003', '-24.93', '86.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.77', '.5472', '158', 'DAL', '2003', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.05', '.4643', '171', 'NJN', '2003', '-24.93', '86.63']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['21.32', '.5000', '106', 'MEM', '2004', '6.94', '44.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.24', '.5833', '173', 'LAL', '2004', '8.67', '116.67']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['38.13', '.6420', '154', 'DEN', '2005', '16.90', '104.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.76', '.7000', '187', 'SEA', '2005', '66.25', '160.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.41', '.6033', '183', 'PHO', '2005', '11.87', '114.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.39', '.6139', '252', 'DET', '2005', '28.14', '120.90']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['26.09', '.5779', '184', 'SAC', '2006', '-52.88', '62.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.48', '.6271', '243', 'DAL', '2006', '-9.09', '90.91']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['25.19', '.4710', '138', 'DEN', '2007', '-41.50', '96.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.37', '.5464', '197', 'PHO', '2007', '-30.22', '101.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.56', '.6143', '150', 'UTA', '2007', '33.33', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.81', '.5635', '117', 'CLE', '2007', '92.42', '109.09']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['29.35', '.5617', '155', 'PHO', '2008', '-19.26', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.04', '.6025', '244', 'NOH', '2008', '20.94', '117.31']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.72', '.5259', '160', 'LAL', '2008', '-37.92', '93.33']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['31.75', '.5550', '199', 'DAL', '2010', '-41.56', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.5735', '153', 'PHO', '2010', '-6.40', '91.82']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['31.21', '.5795', '174', 'MEM', '2011', '20.00', '100.00']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['17.71', '.4583', '99', 'UTA', '2012', '-97.73', '75.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.69', '.5490', '112', 'LAC', '2012', '-66.67', '66.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.25', '.6667', '180', 'OKC', '2012', '-100.00', '100.00']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.6250', '78', 'LAL', '2013', '62.50', '162.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.29', '.4471', '178', 'GSW', '2013', '41.94', '106.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.30', '.5714', '105', 'MEM', '2013', '42.63', '138.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.66', '.5548', '199', 'MIA', '2013', '-49.88', '75.76']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['32.89', '.6050', '192', 'DAL', '2014', '2.79', '126.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.38', '.3893', '113', 'POR', '2014', '9.68', '90.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.73', '.6567', '137', 'OKC', '2014', '11.58', '97.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.53', '.6574', '143', 'MIA', '2014', '50.89', '107.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.88', '.5283', '131', 'LAC', '2015', '-24.93', '86.63']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uJrNIC7PWILu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pIVKP6D6QBbO"
      },
      "outputs": [],
      "source": [
        "#@title Manu MISC numbers\n",
        "\n",
        "\n",
        "#@title Manu Finals Scoring numbers with only 1 of Tim/Tony on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.27', '.4750', '58', 'NJN', '2003', '31.94', '110.58']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '86', 'DET', '2005', '11.78', '108.97']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.51', '.5750', '36', 'CLE', '2007', '50.79', '123.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.91', '.4444', '75', 'MIA', '2013', '-11.91', '102.99']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.38', '.5000', '20', 'MIA', '2014', '14.76', '102.56']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "#@title Manu Scoring numbers when he starts (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['19.51', '.5714', '20', 'DEN', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['52.38', '.9118', '35', 'SEA', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.28', '.5600', '149', 'PHO', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.03', '.6250', '171', 'DET', '2005']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['25.76', '.5435', '107', 'SAC', '2006']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25', '.5758', '86', 'DAL', '2006']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5959', '143', 'NOH', '2008']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['4.35', '.1429', '23', 'LAL', '2008']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['28.42', '.5098', '102', 'DAL', '2010']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.06', '.6618', '84', 'PHO', '2010']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['32.11', '.6224', '98', 'MEM', '2011']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['40.26', '.6200', '39', 'OKC', '2012']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['26.72', '.7381', '60', 'MIA', '2013']\n",
        "\n",
        "# 2017\n",
        "tmp_df.loc[len(tmp_df)] = ['5.56', '.2000', '16', 'GSW', '2017']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu Finals Scoring numbers with only 1 of Tim/Tony on games 1 and 2\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['53.85', '.8750', '8', 'DET', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['83.33', '1.1667', '11', 'DET', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.9231', '32', 'DET', '2005']\n",
        "\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu Finals Scoring numbers with only 1 of Tim/Tony on (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['31.43', '.7857', '19', 'NJN', '2003']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['49.25', '.8056', '42', 'DET', '2005']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.2500', '6', 'CLE', '2007']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0', '19', 'MIA', '2013']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.6667', '8', 'MIA', '2014']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu 07 numbers\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['25.19', '.4710', '138', 'DEN', '2007', '2.84', '107.89']\n",
        "\n",
        "#g1-4\n",
        "tmp_df.loc[len(tmp_df)] = ['19.67', '.4123', '123', 'PHO', '2007', '-7.02', '105.33']\n",
        "\n",
        "#g5 1Q\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '6', 'PHO', '2007', '-100.00', '33.33']\n",
        "\n",
        "#g5 2Q\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.5000', '9', 'PHO', '2007', '0.00', '106.67']\n",
        "\n",
        "#g5 3Q\n",
        "tmp_df.loc[len(tmp_df)] = ['35.00', '.7000', '10', 'PHO', '2007', '25.00', '115.00']\n",
        "\n",
        "#g5 4Q\n",
        "tmp_df.loc[len(tmp_df)] = ['62.50', '1.0714', '12', 'PHO', '2007', '37.50', '133.33']\n",
        "\n",
        "#g6\n",
        "tmp_df.loc[len(tmp_df)] = ['43.42', '.7857', '36', 'PHO', '2007', '14.42', '118.42']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.56', '.6143', '150', 'UTA', '2007', '8.27', '112.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.81', '.5635', '117', 'CLE', '2007', '20.62', '110.48']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu 05 numbers\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['38.13', '.6420', '154', 'DEN', '2005', '15.39', '114.05']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.76', '.7000', '187', 'SEA', '2005', '13.25', '120.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.41', '.6033', '183', 'PHO', '2005', '9.20', '120.0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.39', '.6139', '252', 'DET', '2005', '2.71', '104.64']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu 07 numbers (3+ starters)\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "#g5 3Q\n",
        "tmp_df.loc[len(tmp_df)] = ['35.00', '.7000', '10', 'PHO', '2007', '25.00', '115.00']\n",
        "\n",
        "#g5 4Q\n",
        "tmp_df.loc[len(tmp_df)] = ['62.50', '1.0714', '12', 'PHO', '2007', '37.50', '133.33']\n",
        "\n",
        "#g6\n",
        "tmp_df.loc[len(tmp_df)] = ['37.93', '.7333', '27', 'PHO', '2007', '13.73', '117.24']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.05', '.6860', '106', 'UTA', '2007', '8.08', '123.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.00', '.5882', '68', 'CLE', '2007', '31.20', '111.20']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu 07 numbers (0-2 starters)\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "\n",
        "#g6\n",
        "tmp_df.loc[len(tmp_df)] = ['61.11', '.9167', '9', 'PHO', '2007', '16.67', '122.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.76', '.5000', '44', 'UTA', '2007', '8.50', '85.88']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.47', '.5345', '49', 'CLE', '2007', '5.96', '109.41']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "#@title Manu alone\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "#tmp_df.loc[len(tmp_df)] = ['17.74', '.4024', '105', 'NJN', '2003', '-14.96', '90.86']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['100.00', '1.000', '1', 'MEM', '2004', '-100.00', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['00.00', '.0000', '1', 'LAL', '2004', '00.00', '0.0']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['48.00', '.5000', '12', 'DEN', '2005', '3.70', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '2', 'SEA', '2005', '-175.00', '0.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['75.00', '.7500', '3', 'PHO', '2005', '150.00', '225.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['00.00', '.00', '5', 'DET', '2005', '-37.50', '62.50']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['31.11', '.5833', '25', 'SAC', '2006', '30.17', '108.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['80.00', '.8571', '8', 'DAL', '2006', '-28.72', '86.67']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['39.58', '.5000', '26', 'DEN', '2007', '17.64', '102.08']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['66.67', '.5000', '12', 'PHO', '2007', '11.11', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.6538', '17', 'UTA', '2007', '6.42', '88.24']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.2971', '16', 'CLE', '2007', '-23.11', '88.00']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['82.35', '.7778', '8', 'PHO', '2008', '-11.76', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.5000', '15', 'NOH', '2008', '26.29', '114.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.000', '3', 'LAL', '2008', '-87.50', '0.00']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.000', '6', 'DAL', '2010', '-40.00', '60.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.14', '.2500', '15', 'PHO', '2010', '-44.83', '68.97']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.3158', '31', 'MEM', '2011', '-8.06', '103.23']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['22.86', '.5000', '36', 'UTA', '2012', '47.14', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.14', '.4783', '35', 'LAC', '2012', '-36.99', '97.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.04', '.7147', '45', 'OKC', '2012', '-21.09', '108.70']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['43.50', '.5476', '25', 'LAL', '2013', '50.94', '126.42']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.53', '.5000', '22', 'GSW', '2013', '-0.05', '113.95']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.66', '.4063', '23', 'MEM', '2013', '8.51', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.69', '.4444', '27', 'MIA', '2013', '-38.22', '86.27']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['34.69', '.6538', '52', 'DAL', '2014', '-10.62', '109.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['6.90', '.1667', '28', 'POR', '2014', '31.88', '148.28']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.38', '.5250', '33', 'OKC', '2014', '-0.29', '118.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['46.88', '.9375', '36', 'MIA', '2014', '56.45', '143.75']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SQe3mtTEK-Y"
      },
      "source": [
        "Tony"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzdz_hyZHVns"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with both of Tim and Manu on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.6190', '50', 'MEM', '2004', '36.35', '128.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.88', '.4211', '106', 'LAL', '2004', '6.16', '96.52']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['24.06', '.4706', '66', 'DEN', '2005', '13.0', '121.8']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.34', '.4667', '106', 'SEA', '2005', '21.34', '122.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.43', '.4844', '112', 'PHO', '2005', '2.40', '121.68']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.82', '.5476', '161', 'DET', '2005', '-0.93', '103.60']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['25.94', '.5288', '112', 'SAC', '2006', '20.24', '125.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.47', '.5149', '154', 'DAL', '2006', '7.45', '115.96']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.5233', '78', 'DEN', '2007', '-3.83', '108.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.90', '.3942', '114', 'PHO', '2007', '1.48', '108.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.18', '.6136', '79', 'UTA', '2007', '7.58', '122.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.97', '.5735', '65', 'CLE', '2007', '14.18', '108.20']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['32.20', '.6000', '105', 'PHO', '2008', '3.80', '109.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.06', '.5746', '169', 'NOH', '2008', '-10.07', '100.94']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.03', '.5556', '102', 'LAL', '2008', '-3.62', '98.99']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['25.31', '.5125', '91', 'DAL', '2010', '11.94', '123.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.65', '.5930', '89', 'PHO', '2010', '5.88', '119.10']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['30.37', '.6042', '102', 'MEM', '2011', '-1.04', '97.91']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['43.88', '.6719', '50', 'UTA', '2012', '-0.19', '109.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.40', '.4583', '67', 'LAC', '2012', '30.88', '116.0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.09', '.5362', '117', 'OKC', '2012', '8.79', '110.08']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['44.74', '.5690', '41', 'LAL', '2013', '19.74', '119.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.90', '.4500', '73', 'GSW', '2013', '-13.80', '90.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.21', '.5652', '41', 'MEM', '2013', '-17.26', '101.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.93', '.5698', '98', 'MIA', '2013', '-1.84', '111.64']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.18', '.5179', '97', 'DAL', '2014', '12.92', '116.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.19', '.5741', '57', 'POR', '2014', '-2.40', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.95', '.6296', '66', 'OKC', '2014', '6.0', '120.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.28', '.6375', '87', 'MIA', '2014', '27.22', '128.48']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RYGsEEHwBoxW"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "#tmp_df.loc[len(tmp_df)] = ['17.74', '.4024', '105', 'NJN', '2003', '-14.96', '90.86']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['31.98', '.6875', '94', 'MEM', '2004', '15.11', '114.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.94', '.4310', '125', 'LAL', '2004', '-16.40', '89.91']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['28.65', '.5000', '105', 'DEN', '2005', '7.27', '105.21']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.31', '.5536', '108', 'SEA', '2005', '-0.51', '114.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '71', 'PHO', '2005', '-3.88', '106.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.97', '.3235', '95', 'DET', '2005', '-4.0', '113.61']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['48.18', '.6226', '73', 'SAC', '2006', '-3.09', '117.52']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.67', '.4648', '105', 'DAL', '2006', '-7.77', '109.41']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['23.08', '.4773', '102', 'DEN', '2007', '18.46', '110.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.63', '.5714', '121', 'PHO', '2007', '4.79', '108.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.65', '.4700', '94', 'UTA', '2007', '7.65', '107.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.67', '.6395', '80', 'CLE', '2007', '-3.12', '103.03']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['45.88', '.5821', '92', 'PHO', '2008', '1.69', '107.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.58', '.5000', '93', 'NOH', '2008', '12.40', '119.11']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.74', '.4674', '83', 'LAL', '2008', '-3.81', '101.29']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['42.32', '.5825', '149', 'DAL', '2009', '-0.65', '111.99']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['24.81', '.4714', '73', 'DAL', '2010', '-1.73', '108.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.55', '.4107', '53', 'PHO', '2010', '-24.51', '101.96']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['26.23', '.4898', '97', 'MEM', '2011', '-9.11', '107.65']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '73', 'UTA', '2012', '33.82', '116.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '73', 'LAC', '2012', '24.51', '119.40']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '92', 'OKC', '2012', '1.43', '111.83']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '82', 'LAL', '2013', '19.43', '111.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '141', 'GSW', '2013', '10.50', '111.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '97', 'MEM', '2013', '28.25', '112.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '135', 'MIA', '2013', '1.02', '107.11']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '126', 'DAL', '2014', '0.70', '111.21']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '81', 'POR', '2014', '15.54', '107.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '91', 'OKC', '2014', '2.39', '107.47']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '64', 'MIA', '2014', '4.57', '114.05']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Z9hQvfBWDyBp"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (3+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '63', 'MEM', '2004', '14.55', '114.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '121', 'LAL', '2004', '-20.18', '86.79']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '91', 'DEN', '2005', '11.90', '105.36']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '82', 'SEA', '2005', '-1.77', '116.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '71', 'PHO', '2005', '-3.88', '106.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '92', 'DET', '2005', '-0.56', '116.43']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '66', 'SAC', '2006', '-4.97', '115.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '93', 'DAL', '2006', '-10.43', '107.39']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '98', 'DEN', '2007', '18.18', '110.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '106', 'PHO', '2007', '7.08', '108.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '75', 'UTA', '2007', '8.45', '114.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '66', 'CLE', '2007', '7.62', '105.71']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '82', 'PHO', '2008', '1.31', '105.88']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.46', '.5313', '73', 'NOH', '2008', '14.04', '117.07']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.4848', '55', 'LAL', '2008', '-8.43', '107.92']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['33.60', '.5667', '139', 'DAL', '2009', '-1.93', '110.28']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['19.44', '.3889', '59', 'DAL', '2010', '0.0', '110.19']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.63', '.4063', '33', 'PHO', '2010', '-40.39', '98.41']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['28.29', '.5000', '79', 'MEM', '2011', '-19.63', '101.32']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['27.93', '.4844', '58', 'UTA', '2012', '42.16', '121.62']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.00', '.5000', '59', 'LAC', '2012', '23.17', '124.07']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.39', '.5750', '78', 'OKC', '2012', '2.34', '110.56']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['29.71', '.4750', '75', 'LAL', '2013', '22.39', '112.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.5462', '114', 'GSW', '2013', '0.0', '106.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.56', '.5875', '77', 'MEM', '2013', '26.94', '108.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.33', '.3700', '103', 'MIA', '2013', '-5.12', '103.30']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['30.81', '.4692', '108', 'DAL', '2014', '-0.25', '108.08']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.69', '.5000', '78', 'POR', '2014', '13.61', '106.80']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.94', '.4722', '74', 'OKC', '2014', '4.96', '107.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.02', '.4286', '60', 'MIA', '2014', '-4.70', '107.34']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PjFAAd14T4Pn"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['34.74', '.8684', '55', 'MEM', '2004', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.93', '.4186', '97', 'LAL', '2004', '-24.93', '86.63']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4714', '70', 'DEN', '2005', '1.50', '99.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.56', '.5893', '62', 'SEA', '2005', '6.83', '119.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4630', '59', 'PHO', '2005', '-2.49', '104.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.94', '.2895', '57', 'DET', '2005', '-5.75', '116.47']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['37.84', '.5385', '42', 'SAC', '2006', '5.06', '113.51']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25', '.4138', '49', 'DAL', '2006', '-3.75', '108.33']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['19.29', '.4091', '79', 'DEN', '2007', '13.25', '102.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.77', '.5938', '84', 'PHO', '2007', '4.01', '107.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.55', '.4107', '58', 'UTA', '2007', '11.88', '114.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['44.19', '.6129', '53', 'CLE', '2007', '12.67', '102.33']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['46.28', '.5600', '65', 'PHO', '2008', '4.92', '107.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.60', '.5128', '61', 'NOH', '2008', '0', '115.84']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.63', '.4800', '44', 'LAL', '2008', '-10.95', '102.47']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['46.03', '.6397', '103', 'DAL', '2009', '-0.84', '112.70']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['21.05', '.4444', '20', 'DAL', '2010', '21.34', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['10.34', '.2143', '14', 'PHO', '2010', '-68.86', '65.52']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['23.76', '.4286', '51', 'MEM', '2011', '-19.55', '99.01']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['28.44', '.4844', '56', 'UTA', '2012', '42.63', '119.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.73', '.5000', '51', 'LAC', '2012', '19.45', '127.96']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.06', '.5694', '68', 'OKC', '2012', '0', '108.87']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['23.14', '.3939', '66', 'LAL', '2013', '18.93', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.4286', '77', 'GSW', '2013', '-18.87', '95.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.02', '.5645', '60', 'MEM', '2013', '14.05', '102.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.44', '.3889', '77', 'MIA', '2013', '5.19', '107.30']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.61', '.4900', '84', 'DAL', '2014', '5.18', '107.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.45', '.4881', '65', 'POR', '2014', '8.36', '105.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.81', '.4848', '64', 'OKC', '2014', '2.47', '108.87']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.57', '.3600', '51', 'MIA', '2014', '-9.96', '106.52']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tony Scoring numbers (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['32.20', '.8261', '66', 'MEM', '2004', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.25', '.3906', '195', 'LAL', '2004', '-24.93', '86.63']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['23.25', '.4141', '123', 'DEN', '2005', '1.50', '99.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.79', '.5213', '118', 'SEA', '2005', '6.83', '119.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.40', '.5000', '169', 'PHO', '2005', '-2.49', '104.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.89', '.4394', '185', 'DET', '2005', '-5.75', '116.47']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['27.78', '.5282', '148', 'SAC', '2006', '5.06', '113.51']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.71', '.4516', '140', 'DAL', '2006', '-3.75', '108.33']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['24.30', '.4539', '152', 'DEN', '2007', '13.25', '102.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.48', '.5000', '169', 'PHO', '2007', '4.01', '107.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.33', '.5690', '120', 'UTA', '2007', '11.88', '114.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.40', '.5909', '92', 'CLE', '2007', '12.67', '102.33']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['38.15', '.5787', '141', 'PHO', '2008', '4.92', '107.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.51', '.5200', '208', 'NOH', '2008', '0', '115.84']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.97', '.5242', '124', 'LAL', '2008', '-10.95', '102.47']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['46.03', '.6397', '103', 'DAL', '2009', '-0.84', '112.70']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['19.66', '.4600', '64', 'DAL', '2010', '21.34', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.62', '.5395', '76', 'PHO', '2010', '-68.86', '65.52']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['29.43', '.5417', '139', 'MEM', '2011', '-19.55', '99.01']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.73', '.5636', '94', 'UTA', '2012', '42.63', '119.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.85', '.5000', '85', 'LAC', '2012', '19.45', '127.96']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.96', '.5333', '140', 'OKC', '2012', '0', '108.87']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.4327', '91', 'LAL', '2013', '18.93', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.20', '.4706', '127', 'GSW', '2013', '-18.87', '95.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.89', '.5000', '82', 'MEM', '2013', '14.05', '102.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.94', '.4603', '149', 'MIA', '2013', '5.19', '107.30']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['30.20', '.4744', '132', 'DAL', '2014', '5.18', '107.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.28', '.5379', '117', 'POR', '2014', '8.36', '105.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.86', '.5366', '92', 'OKC', '2014', '2.47', '108.87']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.00', '.3804', '95', 'MIA', '2014', '-9.96', '106.52']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JBiDmpuqYGEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tony Scoring numbers\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['32.21', '.5733', '147', 'SEA', '2002', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.77', '.4792', '194', 'LAL', '2002', '-24.93', '86.63']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['22.44', '.4355', '193', 'PHO', '2003', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.65', '.4731', '210', 'LAL', '2003', '-24.93', '86.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.31', '.4850', '199', 'DAL', '2003', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.43', '.4468', '212', 'NJN', '2003', '-24.93', '86.63']\n",
        "\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['31.00', '.6364', '148', 'MEM', '2004', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.09', '.4202', '238', 'LAL', '2004', '-24.93', '86.63']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['26.69', '.4840', '180', 'DEN', '2005', '1.50', '99.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.43', '.5096', '221', 'SEA', '2005', '6.83', '119.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.64', '.4904', '190', 'PHO', '2005', '-2.49', '104.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.95', '.4907', '265', 'DET', '2005', '-5.75', '116.47']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['34.28', '.5833', '207', 'SAC', '2006', '5.06', '113.51']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.03', '.4732', '268', 'DAL', '2006', '-3.75', '108.33']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['26.30', '.4892', '187', 'DEN', '2007', '13.25', '102.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.77', '.4921', '238', 'PHO', '2007', '4.01', '107.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.61', '.5372', '174', 'UTA', '2007', '11.88', '114.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.84', '.6049', '151', 'CLE', '2007', '12.67', '102.33']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['38.84', '.5781', '202', 'PHO', '2008', '4.92', '107.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.45', '.5397', '262', 'NOH', '2008', '0', '115.84']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.87', '.5160', '190', 'LAL', '2008', '-10.95', '102.47']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['43.07', '.5813', '181', 'DAL', '2009', '-0.84', '112.70']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['27.38', '.4948', '189', 'DAL', '2010', '21.34', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.99', '.5065', '147', 'PHO', '2010', '-68.86', '65.52']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['28.43', '.5221', '221', 'MEM', '2011', '-19.55', '99.01']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['33.07', '.5753', '131', 'UTA', '2012', '42.63', '119.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.09', '.4595', '149', 'LAC', '2012', '19.45', '127.96']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.45', '.5466', '226', 'OKC', '2012', '0', '108.87']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['37.55', '.5380', '127', 'LAL', '2013', '18.93', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.41', '.4963', '233', 'GSW', '2013', '-18.87', '95.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.22', '.5741', '153', 'MEM', '2013', '14.05', '102.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.02', '.4701', '246', 'MIA', '2013', '5.19', '107.30']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.81', '.5148', '231', 'DAL', '2014', '5.18', '107.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.17', '.5476', '145', 'POR', '2014', '8.36', '105.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.31', '.5197', '167', 'OKC', '2014', '2.47', '108.87']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.52', '.5422', '176', 'MIA', '2014', '-9.96', '106.52']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.00', '.3838', '210', 'LAC', '2015', '-9.96', '106.52']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IgddRQCebcJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tony Finals Scoring numbers with only 1 of Tim/Manu on (3+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['15.20', '.3714', '96', 'NJN', '2003', '-16.92', '89.47']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '92', 'DET', '2005', '-0.56', '116.43']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '66', 'CLE', '2007', '7.62', '105.71']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['20.33', '.3700', '103', 'MIA', '2013',  '-5.12', '103.30']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['22.02', '.4286', '60', 'MIA', '2014',  '-4.70', '107.34']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8OlSpxh_Tg_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tony Finals Scoring numbers\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['21.43', '.4468', '212', 'NJN', '2003', '-1.79', '96.68']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['21.95', '.4709', '265', 'DET', '2005', '-1.36', '107.24']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['36.84', '.6049', '151', 'CLE', '2007', '3.73', '104.89']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['24.02', '.4701', '246', 'MIA', '2013', '-0.36', '108.73']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['27.52', '.5422', '176', 'MIA', '2014', '11.22', '118.65']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e-8cvu-aTs2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tony MISC numbers\n",
        "\n",
        "\n",
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (At most 2 starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.5238', '40', 'MEM', '2004', '20.68', '116.88']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.43', '.4667', '28', 'LAL', '2004', '14.42', '102.17']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['30.99', '.5500', '36', 'DEN', '2005', '17.03', '115.49']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.22', '.5179', '47', 'SEA', '2005', '-9.46', '107.78']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.78', '.6667', '12', 'PHO', '2005', '-15.94', '117.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.74', '.3667', '38', 'DET', '2005', '-0.32', '109.68']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['60.32', '.7037', '31', 'SAC', '2006', '-12.78', '122.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.62', '.5000', '56', 'DAL', '2006', '-11.12', '110.38']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['35.77', '.6818', '24', 'DEN', '2007', '35.77', '138.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.26', '.5227', '37', 'PHO', '2007', '6.30', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '.5455', '36', 'UTA', '2007', '1.54', '97.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.96', '.7083', '28', 'CLE', '2007', '-35.19', '104.35']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['44.90', '.6471', '27', 'PHO', '2008', '-6.12', '108.16']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.93', '.4750', '32', 'NOH', '2008', '21.43', '125.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.68', '.4524', '40', 'LAL', '2008', '4.00', '100.00']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.4483', '46', 'DAL', '2009', '-0.13', '110.26']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4808', '53', 'DAL', '2010', '-10.91', '107.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.40', '.4762', '38', 'PHO', '2010', '-6.42', '116.44']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['29.27', '.5714', '46', 'MEM', '2011', '-3.66', '118.29']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['16.13', '.4167', '17', 'UTA', '2012', '3.23', '106.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.83', '.4583', '22', 'LAC', '2012', '34.88', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.5714', '24', 'OKC', '2012', '-0.97', '118.18']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['69.70', '.7857', '17', 'LAL', '2013', '21.21', '118.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.45', '.6923', '63', 'GSW', '2013', '46.15', '130.58']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.68', '.6250', '37', 'MEM', '2013', '51.43', '128.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.47', '.4091', '58', 'MIA', '2013', '-4.68', '106.86']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['32.47', '.5435', '42', 'DAL', '2014', '-7.43', '118.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.89', '.6364', '16', 'POR', '2014', '40.36', '113.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.00', '.3636', '27', 'OKC', '2014', '2.08', '104.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['51.72', '.8333', '14', 'MIA', '2014', '53.93', '137.93']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (Exactly 3 starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.3333', '8', 'MEM', '2004', '38.43', '126.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.00', '.5000', '23', 'LAL', '2004', '-0.60', '87.50']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['29.79', '.5833', '22', 'DEN', '2005', '41.79', '121.28']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.50', '.4231', '20', 'SEA', '2005', '-25.00', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.78', '.6667', '12', 'PHO', '2005', '-15.94', '117.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.36', '.3462', '35', 'DET', '2005', '8.96', '116.36']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['60.78', '.7750', '24', 'SAC', '2006', '-19.85', '117.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.00', '.5000', '44', 'DAL', '2006', '-17.85', '106.25']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['32.35', '.6875', '19', 'DEN', '2007', '38.49', '147.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.82', '.5833', '22', 'PHO', '2007', '18.29', '113.64']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.71', '.6667', '18', 'UTA', '2007', '-3.23', '112.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['52.63', '.6250', '13', 'CLE', '2007', '-17.84', '121.05']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['31.25', '.5000', '18', 'PHO', '2008', '-11.76', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.6111', '12', 'NOH', '2008', '43.56', '122.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.00', '.5000', '12', 'LAL', '2008', '-8.43', '130.00']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['28.13', '.4091', '36', 'DAL', '2009', '-4.94', '103.13']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['18.57', '.3611', '39', 'DAL', '2010', '-20.30', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.5556', '19', 'PHO', '2010', '-16.39', '126.47']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['37.25', '.6333', '28', 'MEM', '2011', '-19.61', '250.00']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['0.0', '.00', '2', 'UTA', '2012', '110.00', '121.62']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.5000', '9', 'LAC', '2012', '41.18', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.78', '.6250', '10', 'OKC', '2012', '7.22', '122.22']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['76.47', '.8571', '9', 'LAL', '2013', '47.06', '135.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.59', '.7308', '37', 'GSW', '2013', '45.59', '129.41']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.00', '.6667', '17', 'MEM', '2013', '71.94', '130.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.00', '.3214', '26', 'MIA', '2013', '-35.97', '91.11']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['27.91', '.4000', '24', 'DAL', '2014', '-17.78', '109.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.71', '.5556', '13', 'POR', '2014', '36.51', '114.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['11.11', '.3333', '10', 'OKC', '2014', '20.76', '94.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '1.000', '9', 'MIA', '2014', '23.53', '111.76']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Tony Finals Scoring numbers with only 1 of Tim/Manu on (3+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['15.20', '.3714', '96', 'NJN', '2003']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '92', 'DET', '2005']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '66', 'CLE', '2007']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['20.33', '.3700', '103', 'MIA', '2013']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['22.02', '.4286', '60', 'MIA', '2014']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Tony 07 numbers\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.30', '.4892', '187', 'DEN', '2007', '6.35', '108.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.77', '.4921', '238', 'PHO', '2007', '1.63', '107.49']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.61', '.5372', '174', 'UTA', '2007', '7.49', '114.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.84', '.6049', '151', 'CLE', '2007', '3.73', '104.89']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title Tony alone\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "#tmp_df.loc[len(tmp_df)] = ['17.74', '.4024', '105', 'NJN', '2003', '-14.96', '90.86']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['36.50', '.3000', '4', 'MEM', '2004', '33.93', '62.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.2500', '7', 'LAL', '2004', '-21.43', '85.71']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['25.00', '.4000', '8', 'DEN', '2005', '18.75', '27.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.3333', '7', 'SEA', '2005', '-99.39', '114.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.5000', '7', 'PHO', '2005', '-13.33', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '.5000', '9', 'DET', '2005', '22.88', '111.76']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['30.77', '.6667', '21', 'SAC', '2006', '-17.95', '102.56']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.58', '.2727', '9', 'DAL', '2006', '-90.16', '31.58']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '0.00', '7', 'DEN', '2007', '-63.64', '63.64']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['57.14', '.4000', '4', 'PHO', '2007', '-100.00', '57.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '0.000', '1', 'UTA', '2007', '-50.00', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5000', '6', 'CLE', '2007', '-23.72', '91.67']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['36.36', '.3333', '5', 'PHO', '2008', '11.69', '72.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['57.14', '.6667', '4', 'LAL', '2008', '-22.22', '100.00']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['46.15', '.5769', '32', 'DAL', '2009', '-25.06', '84.62']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['40.38', '.5000', '25', 'DAL', '2010', '-12.02', '94.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['44.44', '.3333', '5', 'PHO', '2010', '-31.31', '122.22']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['29.27', '.3750', '22', 'MEM', '2011', '-8.31', '78.05']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['31.25', '.8333', '8', 'UTA', '2012', '-37.50', '87.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.2500', '9', 'LAC', '2012', '-6.25', '93.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.5000', '17', 'OKC', '2012', '-49.68', '90.32']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['57.14', '.6667', '4', 'LAL', '2013', '10.71', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.3125', '20', 'GSW', '2013', '-15.52', '94.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.92', '.5000', '15', 'MEM', '2013', '-39.56', '96.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.00', '.6000', '14', 'MIA', '2013', '-4.07', '103.33']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['36.84', '.5833', '9', 'DAL', '2014', '15.17', '121.05']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '.7500', '8', 'POR', '2014', '17.65', '117.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.00', '.5000', '10', 'OKC', '2014', '20.00', '125.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.3333', '24', 'MIA', '2014', '-25.00', '97.92']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qEBKucfP2uUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TIM**"
      ],
      "metadata": {
        "id": "IuUt6BM79PS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tim\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "# 1998\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['26.6', '.5730', '163', 'PHO', '1998', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['29.6', '.5485', '210', 'UTA', '1998', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "\n",
        "# 1999\n",
        "tmp_df.loc[len(tmp_df)] = ['24.67', '.516', '171', 'MIN', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.2688331', '.600', '177', 'LAL', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.47', '.547', '157', 'POR', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.349469', '.5999', '228', 'NYK', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.47', '.512', '154', 'MIN', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['35.6', '.5400', '202', 'DAL', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.3', '.547', '169', 'LAL', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['37.73', '.5988', '156', 'SEA', '2002', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.07', '.486', '224', 'LAL', '2002', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['22.95', '.5773', '257', 'PHO', '2003', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "            \n",
        "tmp_df.loc[len(tmp_df)] = ['37', '.575', '241', 'LAL', '2003', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['33.4', '.5957', '260', 'DAL', '2003', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.71', '.5410', '264', 'NJN', '2003', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['35.66', '.5988', '153', 'MEM', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "            \n",
        "tmp_df.loc[len(tmp_df)] = ['27.25', '.534', '251', 'LAL', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['35.83', '.5140', '165', 'DEN', '2005', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['38.52', '.5393', '218', 'SEA', '2005', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['36.44', '.5855', '198', 'PHO', '2005', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.81', '.471', '285', 'DET', '2005', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['29.57', '.6471', '202', 'SAC', '2006', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.7221172', '.5938', '291', 'DAL', '2006', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['29.19', '.4856', '188', 'DEN', '2007', '13.25', '102.14']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.14', '.5919', '229', 'PHO', '2007', '4.01', '107.10']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.94', '.6193', '170', 'UTA', '2007', '11.88', '114.71']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.97', '.4803', '149', 'CLE', '2007', '12.67', '102.33']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['32.55', '.5167', '199', 'PHO', '2008', '4.92', '107.44']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.20', '.4820', '266', 'NOH', '2008', '0', '115.84']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.55', '.4628', '124', 'LAL', '2008', '-10.95', '102.47']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['33.79', '.5562', '164', 'DAL', '2009', '-0.84', '112.70']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['27.25', '.5142', '223', 'DAL', '2010', '21.34', '110.53']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.5473', '150', 'PHO', '2010', '-68.86', '65.52']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['19.05', '.4935', '212', 'MEM', '2011', '-19.55', '99.01']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['24.46', '.5278', '121', 'UTA', '2012', '42.63', '119.27']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.47', '.6176', '136', 'LAC', '2012', '19.45', '127.96']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.25', '.4766', '207', 'OKC', '2012', '0', '108.87']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['29.29', '.5556', '129', 'LAL', '2013', '18.93', '109.09']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.96', '.4916', '214', 'GSW', '2013', '-18.87', '95.89']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.90', '.4921', '138', 'MEM', '2013', '14.05', '102.83']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.03', '.5500', '254', 'MIA', '2013', '5.19', '107.30']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['25.80', '.6050', '244', 'DAL', '2014', '5.18', '107.74']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.90', '.4929', '162', 'POR', '2014', '8.36', '105.04']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.89', '.5515', '181', 'OKC', '2014', '2.47', '108.87']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.67', '.6111', '165', 'MIA', '2014', '-9.96', '106.52']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.88', '.5952', '250', 'LAC', '2015', '-9.96', '106.52']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "manu_one_on = manu_one_on.reset_index(drop=True)\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "b68i0m747x5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Kobe\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "#Kobe\n",
        "tmp_df.loc[len(tmp_df)] = ['25.57', '.4997', '149', 'HOU', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#Kobe\n",
        "tmp_df.loc[len(tmp_df)] = ['26.28', '.5201', '168', 'SAS', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#Kobe\n",
        "tmp_df.loc[len(tmp_df)] = ['37.72', '.5565', '193', 'SAC', '2000', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.89', '.5476', '187', 'PHO', '2000', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.38', '.5235', '303', 'POR', '2000', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.03', '.4112', '176', 'IND', '2000', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.94', '.5462', '119', 'POR', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.00', '.588', '173', 'SAC', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.36', '.571', '168', 'SAS', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.83', '.501', '234', 'PHI', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.45', '.4688', '131', 'POR', '2002', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.42', '.486', '218', 'SAS', '2002', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.89', '.491', '308', 'SAC', '2002', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "            \n",
        "tmp_df.loc[len(tmp_df)] = ['31.85', '.623', '174', 'NJN', '2002', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.77', '.5250', '270', 'MIN', '2003', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "            \n",
        "tmp_df.loc[len(tmp_df)] = ['39.27', '.533', '261', 'SAS', '2003', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "            \n",
        "tmp_df.loc[len(tmp_df)] = ['30.05', '.507', '233', 'HOU', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.64', '.534', '264', 'SAS', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.81', '.519', '255', 'MIN', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.49', '.456', '231', 'DET', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.45', '.5706', '314', 'PHO', '2006', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.95', '.5660', '215', 'PHO', '2007', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "          \n",
        "\n",
        "# Kobe rOffRtg\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.585', '157', 'DEN', '2008', '36.35', '118.75']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.585', '247', 'UTA', '2008', '36.35', '118.40']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.585', '201', 'SAS', '2008', '36.35', '106.05']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.56', '.505', '258', 'BOS', '2008', '36.35', '103.89']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '203', 'UTA', '2009', '36.35', '113.28']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '266', 'HOU', '2009', '36.35', '111.65']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '252', 'DEN', '2009', '36.35', '116.39']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '219', 'ORL', '2009', '36.35', '112.28']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '221', 'OKC', '2010', '36.35', '107.66']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '164', 'UTA', '2010', '36.35', '118.87']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '249', 'PHO', '2010', '36.35', '127.41']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.31', '.528', '288', 'BOS', '2010', '36.35', '104.02']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.10', '.5488', '206', 'NOH', '2011', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.44', '.5112', '148', 'DAL', '2011', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.5262', '282', 'DEN', '2012', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.62', '.5100', '194', 'OKC', '2012', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "manu_one_on = manu_one_on.reset_index(drop=True)\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Yc7Tw_746G0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Shaq\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "\n",
        "# Shaq\n",
        "tmp_df.loc[len(tmp_df)] = ['47.3967684', '.5792', '154', 'POR', '1997', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.606838', '.5226', '171', 'UTA', '1997', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.2391653', '.6205', '160', 'POR', '1998', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['46.363636', '.6413', '183', 'SEA', '1998', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['44.561404', '.5512', '157', 'UTA', '1998', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.419753', '.5218', '159', 'HOU', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.74443366', '.5062', '156', 'SAS', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.5478927', '.5343', '205', 'SAC', '2000', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.4223919', '.5584', '201', 'PHO', '2000', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.524708', '.5500', '320', 'POR', '2000', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['44.7497547', '.5760', '274', 'IND', '2000', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.40', '.5263', '131', 'POR', '2001', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.67', '.5885', '163', 'SAC', '2001', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.24', '.5455', '156', 'SAS', '2001', '22.70', '114.48']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.55', '.5651', '225', 'PHI', '2001', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.08', '.6111', '128', 'POR', '2002', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.48', '.4820', '196', 'SAS', '2002', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.52', '.5668', '287', 'SAC', '2002', '22.70', '114.48']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.55', '.5651', '166', 'NJN', '2002', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.68', '.5478', '251', 'MIN', '2003', '22.70', '114.48']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.19', '.5938', '230', 'SAS', '2003', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.37', '.4821', '210', 'HOU', '2004', '22.70', '114.48']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.67', '.6081', '249', 'SAS', '2004', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.74', '.5391', '248', 'MIN', '2004', '22.70', '114.48']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.46', '.6157', '213', 'DET', '2004', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.32', '.4932', '132', 'NJN', '2005', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.17', '.5833', '61', 'WAS', '2005', '22.70', '114.48']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.72', '.5714', '235', 'DET', '2005', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.15', '.5777', '186', 'CHI', '2006', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.42', '.5471', '155', 'NJN', '2006', '22.70', '114.48']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.81', '.6132', '207', 'DET', '2006', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.97', '.5325', '211', 'DAL', '2006', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "manu_one_on = manu_one_on.reset_index(drop=True)\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a8EsRGnBMhuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LeBron\n",
        "# LeBron\n",
        "tmp_df.loc[len(tmp_df)] = ['40.75', '.528', '288', 'SAS', '2014', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "b_2DXIRvy6iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tony/Manu On/Off numbers"
      ],
      "metadata": {
        "id": "HIYHokiV2-3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Peak rOffRtg On/Off\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# everything besides OffRtg and MP dummy values\n",
        "\n",
        "# Manu On\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '154', 'DEN', '2005', '18.88', '114.05']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '187', 'SEA', '2005', '7.79', '120.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '183', 'PHO', '2005', '12.23', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '252', 'DET', '2005', '11.78', '104.64']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '184', 'SAC', '2006', '1.14', '119.13']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '243', 'DAL', '2006', '2.70', '113.26']\n",
        "\n",
        "\n",
        "\n",
        "# Manu Off\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '91', 'DEN', '2005', '18.88', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '101', 'SEA', '2005', '7.79', '99.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '57', 'PHO', '2005', '12.23', '105.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '89', 'DET', '2005', '11.78', '98.62']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '109', 'SAC', '2006', '1.14', '114.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '103', 'DAL', '2006', '2.70', '98.98']\n",
        "\n",
        "\n",
        "\n",
        "# Manu On (no Bruce!)\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '57', 'DEN', '2005', '18.88', '108.70']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '61', 'SEA', '2005', '7.79', '124.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '69', 'PHO', '2005', '12.23', '128.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '59', 'DET', '2005', '11.78', '99.04']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '80', 'SAC', '2006', '1.14', '120.13']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '60', 'DAL', '2006', '2.70', '126.50']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tony On\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '131', 'UTA', '2012', '33.82', '111.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '149', 'LAC', '2012', '24.51', '116.36']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '226', 'OKC', '2012', '1.43', '109.36']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '127', 'LAL', '2013', '19.43', '113.08']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '233', 'GSW', '2013', '10.50', '103.60']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '153', 'MEM', '2013', '28.25', '107.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '246', 'MIA', '2013', '1.02', '108.73']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '231', 'DAL', '2014', '0.70', '113.96']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '145', 'POR', '2014', '15.54', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '167', 'OKC', '2014', '2.39', '113.85']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '176', 'MIA', '2014', '4.57', '118.65']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tony Off\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '61', 'UTA', '2012', '33.82', '107.86']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '43', 'LAC', '2012', '24.51', '101.11']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '62', 'OKC', '2012', '1.43', '102.38']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '65', 'LAL', '2013', '19.43', '114.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '70', 'GSW', '2013', '10.50', '112.59']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '49', 'MEM', '2013', '28.25', '107.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '95', 'MIA', '2013', '1.02', '106.29']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '105', 'DAL', '2014', '0.70', '107.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '95', 'POR', '2014', '15.54', '120.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '126', 'OKC', '2014', '2.39', '111.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '64', 'MIA', '2014', '4.57', '123.89']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Im8HJgCBZ-88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Peak rOffRtg On/Off 4+ starters\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# everything besides OffRtg dummy values\n",
        "\n",
        "# Manu On\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '77', 'DEN', '2005', '18.88', '110.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '69', 'SEA', '2005', '7.79', '140.16']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '149', 'PHO', '2005', '12.23', '120.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '171', 'DET', '2005', '11.78', '104.15']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '107', 'SAC', '2006', '1.14', '118.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '102', 'DAL', '2006', '2.70', '108.65']\n",
        "\n",
        "\n",
        "\n",
        "# Manu Off\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '56', 'DEN', '2005', '18.88', '91.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '56', 'SEA', '2005', '7.79', '94.85']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '42', 'PHO', '2005', '12.23', '102.78']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '53', 'DET', '2005', '11.78', '98.75']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '61', 'SAC', '2006', '1.14', '114.41']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '54', 'DAL', '2006', '2.70', '108.57']\n",
        "\n",
        "\n",
        "\n",
        "# Tony On\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '94', 'UTA', '2012', '33.82', '114.13']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '85', 'LAC', '2012', '24.51', '123.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '140', 'OKC', '2012', '1.43', '110.49']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '91', 'LAL', '2013', '19.43', '113.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '127', 'GSW', '2013', '10.50', '96.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '82', 'MEM', '2013', '28.25', '100.68']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '149', 'MIA', '2013', '1.02', '110.47']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '132', 'DAL', '2014', '0.70', '113.47']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '117', 'POR', '2014', '15.54', '109.25']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '92', 'OKC', '2014', '2.39', '112.99']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '95', 'MIA', '2014', '4.57', '112.57']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tony Off\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '15', 'UTA', '2012', '33.82', '103.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '2', 'LAC', '2012', '24.51', '0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '8', 'OKC', '2012', '1.43', '61.11']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '13', 'LAL', '2013', '19.43', '88.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '18', 'GSW', '2013', '10.50', '111.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '14', 'MEM', '2013', '28.25', '115.38']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '28', 'MIA', '2013', '1.02', '94.12']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '14', 'DAL', '2014', '0.70', '143.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '47', 'POR', '2014', '15.54', '122.34']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '32', 'OKC', '2014', '2.39', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '14', 'MIA', '2014', '4.57', '150.00']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c85_peEvlzaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title rOffRtg Tim/Tony On; Manu Off\n",
        "\n",
        "# PTS TS+ dummy values\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['31.98', '.6875', '68', 'MEM', '2004', '10.83', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.94', '.4310', '102', 'LAL', '2004', '-19.82', '86.36']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['24.06', '.4706', '56', 'DEN', '2005', '-3.99', '97.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.34', '.4667', '60', 'SEA', '2005', '-6.59', '105.56']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.43', '.4844', '40', 'PHO', '2005', '-13.28', '112.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.82', '.5476', '62', 'DET', '2005', '-11.47', '111.83']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['25.94', '.5288', '53', 'SAC', '2006', '-3.29', '114.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.47', '.5149', '71', 'DAL', '2006', '-9.72', '112.59']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.5233', '87', 'DEN', '2007', '18.27', '107.95']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.90', '.3942', '82', 'PHO', '2007', '5.23', '105.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.18', '.6136', '60', 'UTA', '2007', '10.51', '112.38']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.97', '.5735', '61', 'CLE', '2007', '-14.29', '97.96']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['32.20', '.6000', '72', 'PHO', '2008', '-3.80', '106.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.06', '.5746', '65', 'NOH', '2008', '7.53', '120.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.03', '.5556', '64', 'LAL', '2008', '2.59', '103.42']\n",
        "\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jUzUW7YluP6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sHrWJxvESTy"
      },
      "source": [
        "Klay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2NZwjbmh3GYh"
      },
      "outputs": [],
      "source": [
        "#@title Kobe Scoring numbers vs Spurs (Tim On)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2001\n",
        "tmp_df.loc[len(tmp_df)] = ['40.69', '.5673', '157', 'SAS', '2001', '15', '15']\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['32.80', '.4766', '209', 'SAS', '2002', '15', '15']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['38.90', '.5185', '232', 'SAS', '2003', '15', '15']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['32.30', '.5271', '232', 'SAS', '2004', '15', '15']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.5862', '188', 'SAS', '2008', '15', '15']\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NWwiLOog3IMM"
      },
      "outputs": [],
      "source": [
        "#@title Kobe Scoring numbers vs Spurs (Tim Off)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2001\n",
        "tmp_df.loc[len(tmp_df)] = ['62.5', '.5833', '11', 'SAS', '2001', '15', '15']\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['47.06', '.6667', '9', 'SAS', '2002', '15', '15']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['42.11', '.6000', '29', 'SAS', '2003', '15', '15']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['34.92', '.5526', '31', 'SAS', '2004', '15', '15']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['38.46', '.6250', '13', 'SAS', '2008', '15', '15']\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Klay Scoring numbers with Curry off\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2015\n",
        "tmp_df.loc[len(tmp_df)] = ['18.87', '.3571', '28', 'NOP', '2015', '-37.74', '90.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.43', '.7000', '41', 'MEM', '2015', '-1.62', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.90', '.6364', '32', 'HOU', '2015', '29.46', '126.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.86', '.5833', '27', 'CLE', '2015', '-24.29', '87.76']\n",
        "\n",
        "# 2016\n",
        "tmp_df.loc[len(tmp_df)] = ['34.26', '.5774', '141', 'HOU', '2016', '20.08', '115.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.32', '.5707', '133', 'POR', '2016', '4.83', '112.41']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.65', '.4524', '35', 'OKC', '2016', '-24.19', '90.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.8000', '56', 'CLE', '2016', '-4.22', '104.95']\n",
        "\n",
        "# 2017\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.4762', '37', 'POR', '2017', '4.14', '113.24']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.00', '.3333', '43', 'UTA', '2017', '-2.59', '90.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.05', '.5000', '37', 'SAS', '2017', '9.03', '115.79']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.69', '.3750', '44', 'CLE', '2017', '5.51', '95.40']\n",
        "\n",
        "# 2018\n",
        "tmp_df.loc[len(tmp_df)] = ['30.21', '.6348', '196', 'SAS', '2018', '8.54', '113.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.86', '.4821', '83', 'NOP', '2018', '-8.48', '99.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.62', '.5909', '32', 'HOU', '2018', '-17.20', '108.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.84', '.7000', '21', 'CLE', '2018', '44.93', '132.43']\n",
        "\n",
        "# 2019\n",
        "tmp_df.loc[len(tmp_df)] = ['30.22', '.7000', '68', 'LAC', '2019', '0.31', '121.58']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.71', '.6250', '53', 'HOU', '2019', '-7.48', '109.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.98', '.3542', '36', 'POR', '2019', '-12.55', '96.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.42', '.5769', '31', 'TOR', '2019', '-16.95', '106.78']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hOP-kp58D25z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Klay Scoring numbers with Curry on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2015\n",
        "tmp_df.loc[len(tmp_df)] = ['37.04', '.618', '124', 'NOP', '2015', '23.46', '123.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.42', '.5519', '183', 'MEM', '2015', '10.26', '101.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.02', '.4692', '126', 'HOU', '2015', '0', '106.79']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.22', '.4933', '200', 'CLE', '2015', '10.40', '109.61']\n",
        "\n",
        "# 2016\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.8182', '28', 'HOU', '2016', '35.81', '107.94']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.46', '.9259', '58', 'POR', '2016', '17.18', '133.85']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.90', '.5540', '207', 'OKC', '2016', '0.21', '110.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.07', '.5198', '191', 'CLE', '2016', '-9.82', '102.41']\n",
        "\n",
        "# 2017\n",
        "tmp_df.loc[len(tmp_df)] = ['24.09', '.4796', '101', 'POR', '2017', '33.15', '125.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.78', '.6111', '95', 'UTA', '2017', '18.23', '120.79']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.84', '.3889', '101', 'SAS', '2017', '20.22', '128.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.38', '.6413', '139', 'CLE', '2017', '6.64', '126.92']\n",
        "\n",
        "# 2018\n",
        "tmp_df.loc[len(tmp_df)] = ['30.40', '.4787', '100', 'NOP', '2018', '17.16', '111.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.71', '.6250', '234', 'HOU', '2018', '10.54', '112.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.75', '.5952', '127', 'CLE', '2018', '15.26', '126.56']\n",
        "\n",
        "# 2019\n",
        "tmp_df.loc[len(tmp_df)] = ['19.20', '.5083', '148', 'LAC', '2019', '0.38', '113.31']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.20', '.5263', '196', 'HOU', '2019', '5.11', '117.68']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.65', '.5074', '129', 'POR', '2019', '5.77', '117.84']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.16', '.7278', '157', 'TOR', '2019', '-0.31', '113.21']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JTLfqjB6MFIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce Off/Manu On (3+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '114', 'PHO', '2003', '23.51', '110.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '37', 'LAL', '2003', '-30.56', '84.51']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '77', 'DAL', '2003', '27.20', '115.79']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '75', 'NJN', '2003', '11.74', '102.01']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '27', 'MEM', '2004', '5.37', '84.62']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '74', 'LAL', '2004', '10.27', '103.42']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '23', 'DEN', '2005', '23.57', '104.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '31', 'SEA', '2005', '34.12', '144.64']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '69', 'PHO', '2005', '25.18', '128.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '57', 'DET', '2005', '8.70', '100.00']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '66', 'SAC', '2006', '3.59', '117.19']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '40', 'DAL', '2006', '12.58', '118.99']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '53', 'DEN', '2007', '3.05', '114.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '45', 'PHO', '2007', '2.04', '120.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '46', 'UTA', '2007', '17.44', '129.07']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '9', 'CLE', '2007', '27.78', '94.44']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '84', 'PHO', '2008', '2.56', '112.87']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '52', 'NOH', '2008', '10.62', '117.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '22', 'LAL', '2008', '-32.00', '102.04']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LmU_yGiEgfLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce On/Manu On (3+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '44', 'PHO', '2003', '-4.40', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '65', 'LAL', '2003', '19.53', '119.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '68', 'DAL', '2003', '0.15', '104.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '52', 'NJN', '2003', '13.38', '97.92']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '28', 'MEM', '2004', '34.69', '132.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '69', 'LAL', '2004', '-12.46', '90.00']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '86', 'DEN', '2005', '11.03', '117.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '95', 'SEA', '2005', '14.20', '120.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '114', 'PHO', '2005', '-0.17', '114.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '192', 'DET', '2005', '0.47', '106.13']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '97', 'SAC', '2006', '14.59', '117.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '92', 'DAL', '2006', '1.35', '109.64']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '66', 'DEN', '2007', '-10.57', '98.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '123', 'PHO', '2007', '-4.87', '101.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '59', 'UTA', '2007', '1.10', '118.80']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '59', 'CLE', '2007', '32.54', '114.02']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '43', 'PHO', '2008', '-16.51', '95.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.46', '.5313', '162', 'NOH', '2008', '-9.33', '99.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.4848', '98', 'LAL', '2008', '-3.86', '95.58']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3I39N3jAghOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce Off/Manu On (4+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '78', 'PHO', '2003', '24.00', '106.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '12', 'LAL', '2003', '0.38', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '42', 'DAL', '2003', '44.06', '114.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '49', 'NJN', '2003', '16.00', '112.87']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '11', 'MEM', '2004', '35.00', '95.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '61', 'LAL', '2004', '6.77', '105.04']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '12', 'DEN', '2005', '4.00', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '13', 'SEA', '2005', '60.87', '173.91']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '46', 'PHO', '2005', '20.56', '126.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '14', 'DET', '2005', '-32.39', '82.61']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '26', 'SAC', '2006', '9.80', '131.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '9', 'DAL', '2006', '0.0', '100.00']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '29', 'DEN', '2007', '-8.53', '112.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '19', 'PHO', '2007', '5.07', '137.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '29', 'UTA', '2007', '30.22', '133.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '6', 'CLE', '2007', '3.33', '83.33']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '56', 'PHO', '2008', '5.19', '111.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '35', 'NOH', '2008', '-14.50', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '10', 'LAL', '2008', '27.30', '136.00']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JxTKtAAdMxB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce On/Manu On (4+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '16', 'PHO', '2003', '-3.12', '81.25']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '40', 'LAL', '2003', '19.33', '123.08']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '21', 'DAL', '2003', '-8.93', '88.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '36', 'NJN', '2003', '-0.09', '93.85']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '5', 'MEM', '2004', '-1.28', '83.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '60', 'LAL', '2004', '-4.72', '95.28']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '65', 'DEN', '2005', '7.69', '112.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '55', 'SEA', '2005', '41.41', '132.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '102', 'PHO', '2005', '-3.00', '117.48']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '157', 'DET', '2005', '4.51', '106.02']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '81', 'SAC', '2006', '15.18', '113.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '92', 'DAL', '2006', '1.35', '109.64']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '53', 'DEN', '2007', '-17.15', '99.01']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '92', 'PHO', '2007', '-10.11', '100.56']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '42', 'UTA', '2007', '-1.60', '115.48']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '36', 'CLE', '2007', '62.97', '130.16']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '29', 'PHO', '2008', '-38.91', '82.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.46', '.5313', '145', 'NOH', '2008', '-8.64', '101.85']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.4848', '79', 'LAL', '2008', '-8.67', '91.33']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ni8QrCQ5MvTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce Off (4+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '20', 'SEA', '2002', '63.89', '152.78']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '15', 'LAL', '2002', '4.28', '93.94']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '80', 'PHO', '2003', '20.05', '104.03']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '12', 'LAL', '2003', '0.38', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '42', 'DAL', '2003', '44.66', '113.41']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '52', 'NJN', '2003', '11.16', '112.15']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '11', 'MEM', '2004', '30.48', '90.48']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '70', 'LAL', '2004', '2.23', '102.99']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '14', 'DEN', '2005', '4.29', '90.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '19', 'SEA', '2005', '45.36', '151.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '46', 'PHO', '2005', '20.56', '126.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '18', 'DET', '2005', '-48.89', '68.97']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '45', 'SAC', '2006', '0', '124.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '11', 'DAL', '2006', '3.70', '108.70']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '29', 'DEN', '2007', '-8.53', '112.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '21', 'PHO', '2007', '2.72', '129.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '34', 'UTA', '2007', '30.39', '136.36']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '11', 'CLE', '2007', '4.74', '110.00']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '68', 'PHO', '2008', '6.39', '117.16']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '43', 'NOH', '2008', '-19.05', '102.47']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '10', 'LAL', '2008', '27.30', '136.00']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4hutnyOS2ZpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce On (4+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '112', 'SEA', '2002', '10.78', '112.31']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '132', 'LAL', '2002', '0.01', '100.43']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '97', 'PHO', '2003', '-19.25', '84.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '148', 'LAL', '2003', '13.92', '112.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '106', 'DAL', '2003', '0', '103.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '122', 'NJN', '2003', '-4.59', '94.04']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '62', 'MEM', '2004', '8.21', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '131', 'LAL', '2004', '-22.28', '86.27']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '118', 'DEN', '2005', '-1.21', '104.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '106', 'SEA', '2005', '9.01', '114.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '144', 'PHO', '2005', '-5.13', '113.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '206', 'DET', '2005', '-1.85', '105.88']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '123', 'SAC', '2006', '13.19', '113.64']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '145', 'DAL', '2006', '-2.66', '108.61']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '136', 'DEN', '2007', '0.01', '100.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '163', 'PHO', '2007', '-6.44', '102.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '93', 'UTA', '2007', '1.75', '112.28']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '57', 'CLE', '2007', '24.78', '115.31']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '78', 'PHO', '2008', '-6.84', '95.86']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.46', '.5313', '184', 'NOH', '2008', '-5.69', '104.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.4848', '121', 'LAL', '2008', '-8.81', '95.57']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WZutUNEs2Xoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce Off (5+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '2', 'SEA', '2002', '140.00', '180.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '4', 'LAL', '2002', '-77.50', '60.00']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '10', 'PHO', '2003', '30.26', '125.00']\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '6', 'LAL', '2003', '-23.08', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '9', 'DAL', '2003', '66.11', '105.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '13', 'NJN', '2003', '16.67', '91.67']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '4', 'MEM', '2004', '96.43', '125.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '27', 'LAL', '2004', '39.87', '115.38']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '6', 'DEN', '2005', '55.24', '146.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '11', 'SEA', '2005', '64.74', '170.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '6', 'PHO', '2005', '39.39', '166.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '4', 'DET', '2005', '-114.29', '42.86']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '15', 'SAC', '2006', '-24.01', '124.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '2', 'DAL', '2006', '0', '75.00']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '16', 'DEN', '2007', '14.96', '121.21']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '10', 'PHO', '2007', '4.21', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '18', 'UTA', '2007', '38.05', '146.88']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '1', 'CLE', '2007', '-100.00', '0']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '21', 'PHO', '2008', '-4.29', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '18', 'NOH', '2008', '-39.78', '93.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '5', 'LAL', '2008', '55.56', '133.33']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1eRNPEgcyxM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce On (5+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '73', 'SEA', '2002', '24.83', '114.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '83', 'LAL', '2002', '-7.02', '93.66']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '51', 'PHO', '2003', '-9.48', '86.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '127', 'LAL', '2003', '14.10', '112.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '44', 'DAL', '2003', '9.30', '110.47']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '84', 'NJN', '2003', '-8.01', '87.42']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '59', 'MEM', '2004', '10.63', '112.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '104', 'LAL', '2004', '-26.55', '87.98']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '70', 'DEN', '2005', '-3.81', '104.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '54', 'SEA', '2005', '19.57', '117.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '85', 'PHO', '2005', '7.76', '130.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '137', 'DET', '2005', '-5.99', '100.88']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '75', 'SAC', '2006', '27.96', '118.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '60', 'DAL', '2006', '0', '102.75']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '103', 'DEN', '2007', '4.26', '100.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '72', 'PHO', '2007', '5.31', '106.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '60', 'UTA', '2007', '6.31', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '57', 'CLE', '2007', '24.78', '115.31']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '49', 'PHO', '2008', '-17.23', '84.95']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.46', '.5313', '133', 'NOH', '2008', '-16.19', '98.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.4848', '84', 'LAL', '2008', '-5.73', '95.57']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LeivjhypuOx1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}