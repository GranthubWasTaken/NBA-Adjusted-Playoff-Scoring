{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "KA1adZNvGkBH"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "pd.set_option('display.colheader_justify', 'center')\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "\n",
        "import scipy.stats\n",
        "from scipy import stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "\n",
        "from inspect import signature\n",
        "\n",
        "def someMethod(self, arg1, kwarg1=None):\n",
        "    pass\n",
        "\n",
        "possession_data_seasons = np.arange(1974, 2024, 1)\n",
        "play_by_play_data_seasons = np.arange(1997, 2024, 1)\n",
        "pre_possesson_data_seasons = np.arange(1952, 1974, 1)\n",
        "aba_seasons = np.arange(1974, 1977, 1)\n",
        "aba_pre_possession_seasons = np.arange(1968, 1974, 1)\n",
        "\n",
        "all_nba_seasons = np.arange(1952, 2024, 1)\n",
        "all_aba_seasons = np.arange(1968, 1977, 1)\n",
        "\n",
        "# plot\n",
        "import seaborn as sns\n",
        "import ast\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.pyplot import *\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as font_manager\n",
        "sns.set_style('darkgrid')        # darkgrid, white grid, dark, white and ticks\n",
        "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=14)     # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=13)    # legend fontsize\n",
        "plt.rc('font', size=13)          # controls default text sizes\n",
        "\n",
        "def label_point(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "      #if i % 2 == 0:  \n",
        "      ax.text(point['x']+0.12, point['y']+.25, str(point['val']))\n",
        "      #else:\n",
        "      #ax.text(point['x']+0.30, point['y'], str(point['val']))\n",
        "      #ax.text(point['x']+0.05, point['y'], str(point['val']))\n",
        "\n",
        "def label_point_year(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "      #if i % 2 == 0: \n",
        "      ax.text(point['x']+0.12, point['y'], int(point['val']))\n",
        "      #else:\n",
        "      #ax.text(point['x']+0.30, point['y'], str(point['val']))\n",
        "      #ax.text(point['x']+0.05, point['y'], str(point['val']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Selenium\n",
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install chromium chromium-driver\n",
        "\n",
        "# Install selenium\n",
        "pip install selenium"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cn6OcXIY66Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start Webdriver and VirtualDisplay\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "url = \"http://example.com\" \n",
        "options = Options()\n",
        "options.add_argument(\"--headless\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "\n",
        "options.headless = True\n",
        "\n",
        "wd = webdriver.Chrome(\"/usr/bin/chromedriver\", options=options)\n",
        "\n",
        "!pip install pyvirtualdisplay\n",
        "!apt-get install xvfb\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(800, 800))  \n",
        "display.start()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jozq2eJRHQHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NncsPba_zEg"
      },
      "source": [
        "**IMPORT RAW DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "u6CkVfCOGD-g"
      },
      "outputs": [],
      "source": [
        "#@title Manually add team abbrev, league_avg TS%, and teamcolors\n",
        "\n",
        "aba_league_avg = pd.DataFrame(columns=['Year','TS%'])\n",
        "\n",
        "aba_league_avg = pd.read_csv('/content/aba_player_ts_data.csv')\n",
        "\n",
        "league_avg_df = pd.read_csv('/content/nba_player_ts_data.csv')\n",
        "\n",
        "team_colors = {\"ATL\": \"#E03A3E\", \"BOS\": \"#007A33\", \"BRK\": \"#000000\", \"BUF\": \"#ff6314\", \"CAP\": \"#E31837\", \"CHA\": \"#00788C\", \n",
        "               \"CHI\": \"#CE1141\", \"CHO\": \"#f26631\", \"CLE\": \"#860038\", \"DAL\": \"#00538C\", \"DEN\": \"#0E2240\", \"DET\": \"#1D42BA\",\n",
        "               \"GSW\": \"#FFC72C\", \"HOU\": \"#CE1141\", \"IND\": \"#002D62\", \"KCO\": \"#5A2D81\", \"KCK\": \"#5A2D81\", \"LAC\": \"#C8102E\", \n",
        "               \"LAL\": \"#552583\", \"MEM\": \"#5D76A9\", \"MIA\": \"#98002E\", \"MIL\": \"#00471B\", \"MIN\": \"#78BE20\", \"NOH\": \"#008fc5\", \n",
        "               \"NOP\": \"#85714D\", \"NOJ\": \"#00471B\", \"NJN\": \"#00275d\", \"NYK\": \"#006BB6\", \"OKC\": \"#007AC1\", \"ORL\": \"#0077C0\", \n",
        "               \"PHI\": \"#006BB6\", \"PHO\": \"#1D1160\", \"POR\": \"#E03A3E\", \"SAC\": \"#5A2D81\", \"SAS\": \"#C4CED4\", \"SEA\": \"#00653A\", \n",
        "               \"TOR\": \"#CE1141\", \"TOT\": \"pink\", \"UTA\": \"#00471B\", \"WAS\": \"#E31837\", \"WSB\": \"#E31837\"}\n",
        "\n",
        "team_abbrev = {\"Atlanta Hawks\" : \"ATL\",       \"Boston Celtics\": \"BOS\",        \"Brooklyn Nets\": \"BRK\",         \"Charlotte Bobcats\": \"CHA\", \n",
        "               \"Chicago Bulls\": \"CHI\",      \"Charlotte Hornets\": \"CHO\",      \"Cleveland Cavaliers\": \"CLE\",     \"Dallas Mavericks\": \"DAL\",\n",
        "               \"Denver Nuggets\": \"DEN\",     \"Detroit Pistons\": \"DET\",       \"Golden State Warriors\": \"GSW\",     \"Houston Rockets\": \"HOU\",\n",
        "               \"Indiana Pacers\": \"IND\",     \"Los Angeles Clippers\": \"LAC\",  \"Los Angeles Lakers\": \"LAL\",      \"Memphis Grizzlies\": \"MEM\",\n",
        "               \"Miami Heat\": \"MIA\",         \"Milwaukee Bucks\": \"MIL\",     \"Minnesota Timberwolves\": \"MIN\",  \"New Orleans Hornets\": \"NOH\",\n",
        "               \"New Orleans Pelicans\": \"NOP\", \"New Jersey Nets\": \"NJN\",     \"New York Knicks\": \"NYK\",     \"Oklahoma City Thunder\": \"OKC\", \n",
        "               \"Orlando Magic\": \"ORL\",     \"Philadelphia 76ers\": \"PHI\",      \"Phoenix Suns\": \"PHO\",       \"Portland Trail Blazers\": \"POR\",\n",
        "               \"Sacramento Kings\": \"SAC\",    \"San Antonio Spurs\": \"SAS\",       \"Toronto Raptors\": \"TOR\",               \"Utah Jazz\": \"UTA\", \n",
        "               \"Washington Wizards\": \"WAS\", \"Capital Bullets\": \"CAP\", \"Buffalo Braves\": \"BUF\", \"Seattle SuperSonics\": \"SEA\", \"Washington Bullets\": \"WSB\",\n",
        "               \"Kansas City-Omaha Kings\": \"KCO\", \"Kansas City Kings\": \"KCK\", \"Charlotte Hornets\": \"CHH\"}\n",
        "\n",
        "\n",
        "aba_abbrev = {\"Denver Nuggets\": \"DNA\", \"Indiana Pacers\": \"INA\", \"New York Nets\": \"NYA\", \"San Antonio Spurs\": \"SAA\",\n",
        "              \"Virginia Squires\": \"VIR\", \"Carolina Cougars\": \"CAR\", \"San Diego Conquistadors\": \"SDA\", \"Kentucky Colonels\": \"KEN\",\n",
        "              \"Utah Stars\": \"UTS\", \"Carolina Cougars\": \"CAR\", \"San Diego Sails\": \"SDS\", \"Spirits of St. Louis\": \"SSL\",\n",
        "              \"Memphis Sounds\": \"MMS\", \"Denver Rockets\": \"DNR\", \"Memphis Tams\": \"MMT\"}\n",
        "\n",
        "aba_pre_poss_abbrev = {\"Denver Nuggets\": \"DNA\", \"Indiana Pacers\": \"INA\", \"New York Nets\": \"NYA\", \"San Antonio Spurs\": \"SAA\",\n",
        "              \"Virginia Squires\": \"VIR\", \"Carolina Cougars\": \"CAR\", \"San Diego Conquistadors\": \"SDA\", \"Kentucky Colonels\": \"KEN\",\n",
        "              \"Utah Stars\": \"UTS\", \"Carolina Cougars\": \"CAR\", \"San Diego Sails\": \"SDS\", \"Spirits of St. Louis\": \"SSL\",\n",
        "              \"Memphis Sounds\": \"MMS\", \"Denver Rockets\": \"DNR\", \"Pittsburgh Pipers\": \"PTP\", \"Minnesota Muskies\": \"MNM\",\n",
        "              \"New Orleans Buccaneers\": \"NOB\", \"Dallas Chaparrals\": \"DLC\", \"Texas Chaparrals\": \"TEX\", \"Houston Mavericks\": \"HSM\",\n",
        "              \"Oakland Oaks\": \"OAK\", \"Miami Floridians\": \"MMF\", \"Minnesota Pipers\": \"MNP\", \"Washington Capitols\": \"WSA\",\n",
        "              \"Los Angeles Stars\": \"LAS\", \"The Floridians\": \"FLO\", \"Memphis Pros\": \"MMP\", \"New Jersey Americans\": \"NJA\",\n",
        "              \"Anaheim Amigos\": \"ANA\", \"Pittsburgh Condors\": \"PTC\", \"Memphis Tams\": \"MMT\"}\n",
        "\n",
        "team_52_73_abbrev = {\"Milwaukee Hawks\" : \"MLH\",  \"Syracuse Nationals\": \"SYR\",        \"Minneapolis Lakers\": \"MNL\",         \"Rochester Royals\": \"ROC\", \n",
        "               \"Chicago Bulls\": \"CHI\",      \"Boston Celtics\": \"BOS\",      \"Cleveland Cavaliers\": \"CLE\",     \"Fort Wayne Pistons\": \"FTW\",\n",
        "               \"Indianapolis Olympians\": \"INO\",     \"Detroit Pistons\": \"DET\",       \"Golden State Warriors\": \"GSW\",     \"Houston Rockets\": \"HOU\",\n",
        "               \"St. Louis Hawks\": \"STL\",  \"Los Angeles Lakers\": \"LAL\",      \"Philadelphia Warriors\": \"PHW\",\n",
        "               \"Cincinnati Royals\": \"CIN\",         \"Milwaukee Bucks\": \"MIL\", \"San Diego Rockets\": \"SDR\",     \n",
        "               \"New York Knicks\": \"NYK\",   \"Philadelphia 76ers\": \"PHI\",      \"Phoenix Suns\": \"PHO\",       \"Portland Trail Blazers\": \"POR\",\n",
        "               \"Baltimore Bullets\": \"BAL\", \"Buffalo Braves\": \"BUF\", \"Seattle SuperSonics\": \"SEA\", \"Washington Bullets\": \"WSB\",\n",
        "               \"Kansas City-Omaha Kings\": \"KCO\", \"Kansas City Kings\": \"KCK\", \"San Francisco Warriors\": \"SFW\", \"Atlanta Hawks\": \"ATL\",\n",
        "               \"Chicago Packers\": \"CHP\", \"Chicago Zephyrs\": \"CHZ\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xTVOqjCkD24f",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import data and add team colors for advanced, play-by-play, per 100, and league avg data\n",
        "\n",
        "# per 100 posssessions\n",
        "#import_player_since74_per100_df = pd.read_csv('nba_player_since74_per100_data.csv')\n",
        "\n",
        "# add team color for per 100 posssessions\n",
        "#import_player_since74_per100_df['TeamColor'] = import_player_since74_per100_df['Tm'].map(team_colors)\n",
        "# per 100 playoff posssessions\n",
        "#import_player_since74playoffs_per100_df = pd.read_csv('nba_player_since74playoffs_per100_data.csv')\n",
        "# add team color for playoff per 100 posssessions\n",
        "#import_player_since74playoffs_per100_df['TeamColor'] = import_player_since74playoffs_per100_df['Tm'].map(team_colors)\n",
        "\n",
        "# advanced\n",
        "import_player_since74_advanced_df = pd.read_csv('nba_player_since74_advanced_data.csv', encoding='utf8')\n",
        "\n",
        "# advanced playoffs\n",
        "import_player_since74playoffs_advanced_df = pd.read_csv('nba_player_since74playoffs_advanced_data.csv', encoding='utf8')\n",
        "\n",
        "\n",
        "# play-by-play\n",
        "import_player_regular_playbyplay_df = pd.read_csv('nba_player_regular_playbyplay_data.csv', encoding='utf8')\n",
        "\n",
        "# add team color for play-by-play\n",
        "import_player_regular_playbyplay_df['TeamColor'] = import_player_regular_playbyplay_df['Tm'].map(team_colors)\n",
        "\n",
        "# play-by-play playoffs\n",
        "import_player_since74playoffs_playbyplay_df = pd.read_csv('nba_player_playoff_playbyplay_data.csv', encoding='utf8')\n",
        "\n",
        "# add team color for playoff play-by-play\n",
        "import_player_since74playoffs_playbyplay_df['TeamColor'] = import_player_since74playoffs_playbyplay_df['Tm'].map(team_colors)\n",
        "\n",
        "\n",
        "# import league avg data\n",
        "\n",
        "# league avg\n",
        "import_leagueavgsince74_df = pd.read_csv('nba_leaguestats_data.csv')\n",
        "\n",
        "# drop NBA seasons from inception of league until 1973 (final year without per possession data)\n",
        "import_leagueavgsince74_df.drop(import_leagueavgsince74_df.tail(26).index,inplace=True)\n",
        "\n",
        "# change from '2020-21' to '2021' and '2019-20' to '2020'... and so on\n",
        "for i, trial in import_leagueavgsince74_df.iterrows():\n",
        "   import_leagueavgsince74_df.loc[i, \"Season\"] = 2022-i\n",
        "\n",
        "league_avg_df['Year'] = league_avg_df['Year'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "b0yr4pEL4W7l"
      },
      "outputs": [],
      "source": [
        "#@title Import per 75 data (can be used in place of 'Calculate per 75' cells with necessitated imported data')\n",
        "\n",
        "# per 75 posssessions\n",
        "import_player_since74_per75_df = pd.read_csv('nba_player_since74_per75_data.csv')\n",
        "\n",
        "# add team color for per 75 posssessions\n",
        "import_player_since74_per75_df['TeamColor'] = import_player_since74_per75_df['Tm'].map(team_colors)\n",
        "\n",
        "# per 75 playoff posssessions\n",
        "import_player_since74playoffs_per75_df = pd.read_csv('nba_player_since74playoffs_per75_data.csv')\n",
        "\n",
        "# add team color for playoff per 75 posssessions\n",
        "import_player_since74playoffs_per75_df['TeamColor'] = import_player_since74playoffs_per75_df['Tm'].map(team_colors)\n",
        "\n",
        "# per 75 adjusted ts playoff posssessions\n",
        "#adjusted_playoff_per_75_df = pd.read_csv('/content/since74_adj_ts_playoffs_per75_data.csv')\n",
        "# add team color for playoff per 75 adjusted posssessions\n",
        "#adjusted_playoff_per_75_df['TeamColor'] = adjusted_playoff_per_75_df['Tm'].map(team_colors)\n",
        "\n",
        "# era/opponent adjusted scoring\n",
        "era_adj_reg_per_75_df = pd.read_csv('/content/era_adjusted_reg_per75_data.csv')\n",
        "era_opponent_adj_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "f4veohWtxhJh"
      },
      "outputs": [],
      "source": [
        "#@title Create scoring coefficients\n",
        "\n",
        "# era-adjust per game data\n",
        "per_game_coeff = pd.read_csv('/content/Avg_Reg_PTS_G.csv', index_col=False, encoding='utf8')\n",
        "per_game_coeff['Coefficient'] = per_game_coeff['Average PTS_G'].max() / per_game_coeff['Average PTS_G'] \n",
        "\n",
        "# era-adjust per 75 data\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "\n",
        "bpm_coeff = pd.read_csv('/content/Avg_Reg_BPM.csv', index_col=False, encoding='utf8')\n",
        "bpm_coeff['Average BPM'] = bpm_coeff['Average BPM'] +  1\n",
        "bpm_coeff['Average OBPM'] = bpm_coeff['Average OBPM'] + 1\n",
        "bpm_coeff['BPM_Coefficient'] = bpm_coeff['Average BPM'].max() / bpm_coeff['Average BPM']\n",
        "bpm_coeff['OBPM_Coefficient'] = bpm_coeff['Average OBPM'].max() / bpm_coeff['Average OBPM']\n",
        "\n",
        "try:\n",
        "  opponent_adj_pts_coeff = pd.DataFrame(columns = ['Year', 'Team', 'PTS_coeff'])\n",
        "\n",
        "  team_def_rtg = pd.read_csv('NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "  league_avg_def_rtg = pd.read_csv('/content/Avg_Def_Rtg.csv', index_col=False, encoding='utf8')\n",
        "  for idx, row in team_def_rtg.iterrows():\n",
        "          match_df = league_avg_def_rtg[(league_avg_def_rtg['Year'] == row['Year'])]\n",
        "          avg = match_df['Avg DefRtg']\n",
        "          avg = float(avg)\n",
        "          coeff = avg / row['DefRtg']\n",
        "\n",
        "          new_row = pd.DataFrame(np.array([[row['Year'], row['Team'], coeff]]), columns=['Year', 'Team', 'PTS_coeff'])\n",
        "          opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "          opponent_adj_pts_coeff = pd.concat([opponent_adj_pts_coeff, new_row], ignore_index=True)\n",
        "\n",
        "\n",
        "  outfile = f\"opponent_adj_pts_coeff.csv\"\n",
        "  opponent_adj_pts_coeff.to_csv(outfile, index=False)\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create ABA scoring coefficients\n",
        "aba_per75_coeff = pd.read_csv('/content/Avg_ABA_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "aba_per75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / aba_per75_coeff['Average PP75']\n",
        "\n",
        "opponent_adj_pts_coeff = pd.DataFrame(columns = ['Year', 'Team', 'PTS_coeff'])\n",
        "\n",
        "team_def_rtg = pd.read_csv('ABA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "league_avg_def_rtg = pd.read_csv('Avg_Def_Rtg_ABA_68-76.csv', index_col=False, encoding='utf8')\n",
        "for idx, row in team_def_rtg.iterrows():\n",
        "        match_df = league_avg_def_rtg[(league_avg_def_rtg['Year'] == row['Year'])]\n",
        "        avg = match_df['Avg DefRtg']\n",
        "        avg = float(avg)\n",
        "        coeff = avg / row['DefRtg']\n",
        "\n",
        "        new_row = pd.DataFrame(np.array([[row['Year'], row['Team'], coeff]]), columns=['Year', 'Team', 'PTS_coeff'])\n",
        "        opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "        opponent_adj_pts_coeff = pd.concat([opponent_adj_pts_coeff, new_row], ignore_index=True)\n",
        "        \n",
        "\n",
        "outfile = f\"aba_opponent_adj_pts_coeff.csv\"\n",
        "opponent_adj_pts_coeff.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vuhvc-NKzlTp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outputting Cells**"
      ],
      "metadata": {
        "id": "fdjvCUzH819P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Single Playoffs Import\n",
        "sing = era_opponent_adj_playoff_per_75_df.copy()\n",
        "#sing = sing.drop(['TeamColor', 'Pos', 'Age', 'GS', 'DRB', 'TRB', 'AST', 'STL', 'PF', 'FG', 'FGA', '3P', '3PA', 'TOV', '2P', '2PA', 'FG%', '3P%', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'BLK', 'Possessions','eFG%'], axis=1)\n",
        "\n",
        "#sing = era_opponent_adj_playoff_per_75_df.copy()\n",
        "sing = sing.drop(['TeamColor', 'Pos', 'Age', 'GS', 'DRB', 'TRB', 'AST', 'STL', 'PF', 'ORtg', 'DRtg', 'FG', 'FGA', '3P', '3PA', 'TOV', '2P', '2PA', 'FG%', '3P%', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'BLK'], axis=1)\n",
        "\n",
        "sing = sing.rename(columns={\"Year\": \"Year\", \"Player\": \"Player\", \"Tm\": \"Team\", \"TS%+\": \"TS+\", \"PTS\": \"PP75\"})\n",
        "\n",
        "columns_titles = ['Year', 'Player', 'Team', 'PP75', 'TS+', 'MP', 'G']\n",
        "sing = sing.reindex(columns=columns_titles)\n",
        "\n",
        "sing['PP75'] = sing['PP75'].round(2)\n",
        "sing['TS+'] = sing['TS+'].round(2)\n",
        "sing['MP'] = sing['MP'].astype(int)\n",
        "\n",
        "sing = sing.sort_values(by = ['Player', 'Year'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "print(sing)\n",
        "sing.to_csv(\"Single_Playoffs_Adjusted_Scoring.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TeBHK4mouJzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Single Playoffs Custom Dataframes\n",
        "sing = pd.read_csv('/content/52-22_Single_Playoffs_Adjusted_Scoring.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "sing['MP'] = sing['MP'].astype(int)\n",
        "sing['G'] = sing['G'].astype(int)\n",
        "\n",
        "sing = sing[(sing['MP'] >= 500)]\n",
        "sing = sing[(sing['PP75'] <= 10)]\n",
        "sing = sing[(sing['TS+'] <= 99)]\n",
        "\n",
        "sing = sing.sort_values(by = ['Year', 'Player'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "print(sing)\n",
        "#sing.to_csv(\"Single_Playoffs_Adjusted_Scoring.csv\", index=False)\n",
        "\n",
        "sim_score = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "\n",
        "sim_score = sim_score[(sim_score['PTS'] >= 20) & (sim_score['PTS'] <= 22)]\n",
        "sim_score = sim_score[(sim_score['MP'] >= 900) & (sim_score['MP'] <= 1100)]\n",
        "sim_score = sim_score[(sim_score['TS+'] >= 105) & (sim_score['TS+'] <= 107)]\n",
        "print(sim_score)\n",
        "\n",
        "sim_score = era_opponent_adj_playoff_per_75_df.copy()\n",
        "\n",
        "sim_score = sim_score[(sim_score['PTS'] >= 20) & (sim_score['PTS'] <= 22)]\n",
        "sim_score = sim_score[(sim_score['MP'] >= 600) & (sim_score['MP'] <= 1100)]\n",
        "sim_score = sim_score[(sim_score['TS%+'] >= 105) & (sim_score['TS%+'] <= 107)]\n",
        "print(sim_score)"
      ],
      "metadata": {
        "id": "-FZKHrYKP9MP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Edit Text\n",
        "with open('/content/tmpurllist.txt', 'r') as f, open('better_format', 'w') as f1:\n",
        "  Lines = f.readlines()\n",
        "  \n",
        "  count = 0\n",
        "  # Strips the newline character\n",
        "  for line in Lines:\n",
        "    if \"Player\" in line:\n",
        "      continue\n",
        "    else:\n",
        "      new_line = re.sub('/pla', r',/pla', line)\n",
        "      print(new_line)\n",
        "    f1.write(new_line)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OppF_CK9sXic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_xOBKntCacv6"
      },
      "outputs": [],
      "source": [
        "#@title NBA Scrape League Average TS% (1952 - 2023)\n",
        "def scrape_nba_ts_data(years):\n",
        "\n",
        "    league_avg_ts_df = pd.DataFrame(columns = ['Year', 'TS%'])\n",
        "\n",
        "    for year in years:\n",
        "        league_stats_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\"\n",
        "        \n",
        "        wd.get(league_stats_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_advanced_team'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'advanced-team'})\n",
        "          foot = first_table.find('tfoot')\n",
        "\n",
        "        headers = [th.getText() for th in first_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        rows = [td.getText() for td in foot.findAll('tr', limit=2)[0].findAll('td')]\n",
        "        rows.insert(0, year)\n",
        "\n",
        "        all_stats_frivolous_included_df = pd.DataFrame(np.array(rows).reshape(-1,len(rows)), columns = headers)\n",
        "        \n",
        "\n",
        "        tmp_year_and_ts_df = pd.DataFrame()\n",
        "\n",
        "        tmp_year_and_ts_df['Year'] = all_stats_frivolous_included_df['Rk']\n",
        "        tmp_year_and_ts_df['TS%'] = all_stats_frivolous_included_df['TS%']\n",
        "\n",
        "        league_avg_ts_df = pd.concat([league_avg_ts_df, tmp_year_and_ts_df], ignore_index=False)\n",
        "        league_avg_ts_df.to_csv(\"nba_player_ts_data.csv\", index=False)\n",
        "        \n",
        "    # print final_df\n",
        "    print(league_avg_ts_df.info)\n",
        "    \n",
        "scrape_nba_ts_data(all_nba_seasons)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA Scrape League Average TS% (1968 - 1976)\n",
        "def scrape_aba_ts_data(years):\n",
        "\n",
        "    league_avg_ts_df = pd.DataFrame(columns = ['Year', 'TS%'])\n",
        "\n",
        "    for year in years:\n",
        "        league_stats_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\"\n",
        "        \n",
        "        wd.get(league_stats_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_advanced_team'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'advanced-team'})\n",
        "          foot = first_table.find('tfoot')\n",
        "\n",
        "        headers = [th.getText() for th in first_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        rows = [td.getText() for td in foot.findAll('tr', limit=2)[0].findAll('td')]\n",
        "        rows.insert(0, year)\n",
        "\n",
        "        all_stats_frivolous_included_df = pd.DataFrame(np.array(rows).reshape(-1,len(rows)), columns = headers)\n",
        "        \n",
        "\n",
        "        tmp_year_and_ts_df = pd.DataFrame()\n",
        "\n",
        "        tmp_year_and_ts_df['Year'] = all_stats_frivolous_included_df['Rk']\n",
        "        tmp_year_and_ts_df['TS%'] = all_stats_frivolous_included_df['TS%']\n",
        "\n",
        "        league_avg_ts_df = pd.concat([league_avg_ts_df, tmp_year_and_ts_df], ignore_index=False)\n",
        "        league_avg_ts_df.to_csv(\"aba_player_ts_data.csv\", index=False)\n",
        "        \n",
        "    # print final_df\n",
        "    print(league_avg_ts_df.info)\n",
        "    \n",
        "scrape_aba_ts_data(all_aba_seasons)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "R53A6znwlqZU",
        "outputId": "3238082b-851d-4269-e3e1-fe9552403c89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method DataFrame.info of    Year  TS% \n",
            "0  1968  .483\n",
            "0  1969  .502\n",
            "0  1970  .506\n",
            "0  1971  .513\n",
            "0  1972  .519\n",
            "0  1973  .527\n",
            "0  1974  .509\n",
            "0  1975  .520\n",
            "0  1976  .517>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NBA 1952-73 (estimated) DATA**"
      ],
      "metadata": {
        "id": "9DTh1HKJ2cGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scrape_team_estimated_playoff_pace_data(pre_possesson_data_seasons)\n",
        "#scrape_nba_player_pergame_data(pre_possesson_data_seasons)\n",
        "#scrape_nba_player_advanced_data(pre_possesson_data_seasons)\n",
        "#scrape_nba_player_pergame_data(pre_possesson_data_seasons)\n",
        "#scrape_nba_player_total_mp_data(pre_possesson_data_seasons)\n",
        "#scrape_nba_player_changed_teams_per75_data(pre_possesson_data_seasons)"
      ],
      "metadata": {
        "id": "XlhmwilWyuBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA 1952-73 Scrape Functions\n",
        "\n",
        "# Scrape NBA Teams' Playoff Pace (1952-73 [estimated])\n",
        "# Grab Team and Opponent Total stats to estimate pace of play for each NBA team from 1952-73\n",
        "def scrape_team_estimated_playoff_pace_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'Pace/G', 'ORtg', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/playoffs/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "\n",
        "        #Find table body of team stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-team'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year and pace column to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "             team_allowed_stats[i].insert(1, 0) \n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"Pace/G\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        each_years_teams = each_years_teams.sort_values('Team', ascending=True)\n",
        "\n",
        "        # estimate pace\n",
        "        if year >= 1971:\n",
        "          ORB_percent = 0.319\n",
        "        else:\n",
        "          ORB_percent = 0.303\n",
        "        if year >= 1971:\n",
        "          TOV_percent = 0.158\n",
        "        else:\n",
        "          TOV_percent = 0.161\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FG'] = each_years_teams['FG'].astype(float)\n",
        "        each_years_teams['G'] = each_years_teams['G'].astype(float)\n",
        "        each_years_teams['Pace/G'] = (each_years_teams['FGA'] + (0.4 * each_years_teams['FTA']) - ORB_percent * (each_years_teams['FGA'] - each_years_teams['FG']) + (-TOV_percent * (each_years_teams['FGA'] + 0.44 * each_years_teams['FTA']) / (TOV_percent - 1)))\n",
        "        each_years_teams['Ortg'] = (each_years_teams['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'], axis=1, inplace=True)\n",
        "\n",
        "        \n",
        "\n",
        "        #Find table body of opponent stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each row\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        def_rtg_df = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        def_rtg_df = def_rtg_df.sort_values('Team', ascending=True)\n",
        "\n",
        "        def_rtg_df['PTS'] = def_rtg_df['PTS'].astype(float)\n",
        "        each_years_teams['Drtg'] = (def_rtg_df['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = pd.concat([final_team_data_df, each_years_teams], ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"NBA_Team_Estimated_Playoff_Pace_52-73_df.csv\", index=False)\n",
        "\n",
        "\n",
        "# Scrape NBA regular season per game (1952-73)\n",
        "def scrape_nba_player_changed_teams_per75_data(years):\n",
        "\n",
        "    fin_df = pd.DataFrame()\n",
        "    pace_sup = pd.read_csv('abbrev_52-73 reg pace ortg drtg.csv', encoding='utf8', index_col=False)\n",
        "    for year in years:\n",
        "\n",
        "        final_players_pergame_df = pd.DataFrame()\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
        "\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        time.sleep(5)\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(32, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(32, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = pd.concat([final_players_pergame_df, each_years_teams], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        #final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "        players_who_changed_teams = final_players_pergame_df[(final_players_pergame_df['Tm'] == 'TOT')]\n",
        "        player_names = players_who_changed_teams['Player'].tolist()\n",
        "        final_players_pergame_df = final_players_pergame_df[(final_players_pergame_df['Player'].isin(player_names))]\n",
        "        if year == 1955:\n",
        "          final_players_pergame_df = final_players_pergame_df[(final_players_pergame_df['Tm'] != 'BLB')]\n",
        "\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        final_players_pergame_df['PTS'] = final_players_pergame_df['PTS'].astype(float)\n",
        "        final_players_pergame_df['MP'] = final_players_pergame_df['MP'].astype(float)\n",
        "        pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "        final_players_pergame_df['G'] = final_players_pergame_df['G'].astype(int)\n",
        "        final_players_pergame_df['total_MP'] = final_players_pergame_df['MP'] * final_players_pergame_df['G']\n",
        "        final_players_pergame_df = final_players_pergame_df.reset_index(drop=True)\n",
        "\n",
        "        player_names = final_players_pergame_df['Player'].tolist()\n",
        "        player_names = list(set(player_names))\n",
        "\n",
        "        for player_name in player_names:\n",
        "          mp_list = []\n",
        "          player_teams_df = final_players_pergame_df[(final_players_pergame_df['Player'] == player_name) & (final_players_pergame_df['Tm'] != 'TOT')]\n",
        "          player_teams_df = player_teams_df.reset_index(drop=True)\n",
        "\n",
        "          for idx, row in player_teams_df.iterrows():\n",
        "            team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "            team_pace = float(team['Pace/G'])\n",
        "            # team folded and didn't play for another team that season.\n",
        "            teams_count = idx+1\n",
        "            player_teams_df.iat[idx, 32] = team_pace * (player_teams_df.iat[idx, 9]/48)\n",
        "            player_teams_df.iat[idx, 32] = player_teams_df.iat[idx, 32].astype(float)\n",
        "            ind_poss_coeff = player_teams_df.iat[idx, 32] / 75\n",
        "            player_teams_df.iat[idx, 31] = player_teams_df.iat[idx, 31]  / ind_poss_coeff\n",
        "            mp_list.append(row['total_MP'])\n",
        "          \n",
        "\n",
        "          player_tot_df = final_players_pergame_df[(final_players_pergame_df['Player'] == player_name) & (final_players_pergame_df['Tm'] == 'TOT')]\n",
        "          player_tot_df = player_tot_df.reset_index()\n",
        "\n",
        "          i = 0\n",
        "          total_per_75_pts = 0\n",
        "          total_pace = 0\n",
        "          total_mp = sum(mp_list)\n",
        "          while i < teams_count:\n",
        "            total_per_75_pts+= float(player_teams_df.iat[i, 31]) * (mp_list[i] / total_mp)\n",
        "            total_pace+= player_teams_df.iat[i, 32] * (mp_list[i] / total_mp)\n",
        "            i = i + 1\n",
        "          player_tot_df.iat[0, 32] = total_per_75_pts\n",
        "          player_tot_df.iat[0, 33] = total_pace\n",
        "          \n",
        "          fin_df = pd.concat([fin_df, player_tot_df], ignore_index=True)\n",
        "          fin_df= fin_df.reset_index(drop=True)\n",
        "    fin_df = fin_df.drop(columns=['total_MP', 'index'])\n",
        "    print(fin_df.info)\n",
        "    fin_df.to_csv(\"52-73_changed_teams_reg_per_75_data.csv\", index=False)\n",
        "\n",
        "    \n",
        "\n",
        "# Scrape NBA regular season per game (1952-73)\n",
        "def scrape_nba_player_reg_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame()\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        time.sleep(10)\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(32, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(32, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = pd.concat([final_players_pergame_df, player_tot_df], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "        if year == 1955:\n",
        "          final_players_pergame_df = final_players_pergame_df[(final_players_pergame_df['Tm'] != 'BLB')]\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"52-73_reg_pergame_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season advanced (1952-73)\n",
        "def scrape_nba_player_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame()\n",
        "\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        time.sleep(5)\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_advanced_df = pd.concat([final_players_advanced_df, player_tot_df], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "        if year == 1955:\n",
        "          final_players_advanced_df = final_players_advanced_df[(final_players_advanced_df['Tm'] != 'BLB')]\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"52-73_reg_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoff per game (1952-73)\n",
        "def scrape_nba_player_playoff_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        time.sleep(5)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = pd.concat([final_players_pergame_df, player_tot_df], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"52-73_playoff_pergame_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoff totals (1952-73)\n",
        "def scrape_nba_player_total_mp_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_totals.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        time.sleep(5)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = pd.concat([final_players_pergame_df, player_tot_df], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"52-73_total_mp_playoff_data.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "s9oi73XB3Uru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA 1952-73 Ancillary Calculations\n",
        "\n",
        "# NBA 1952-73 Calculate reg per 75 and TS+\n",
        "pergame = pd.read_csv('52-73_reg_pergame_data.csv', encoding='utf8', index_col=False)\n",
        "pace_sup = pd.read_csv('abbrev_52-73 reg pace ortg drtg.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "pergame['PTS'] = pergame['PTS'].astype(float)\n",
        "pergame['MP'] = pergame['MP'].astype(float)\n",
        "pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "pergame = pergame[(pergame['Tm'] != 'TOT')]\n",
        "pergame = pergame.reset_index(drop=True)\n",
        "\n",
        "\n",
        "for idx, row in pergame.iterrows():\n",
        "  team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "  team_pace = team['Pace/G']\n",
        "  # team folded and didn't play for another team that season.\n",
        "  if row['Tm'] == 'BLB' and row['Year'] == 1955:\n",
        "    continue\n",
        "  pergame.iat[idx, 32] = team_pace * (pergame.iat[idx, 9]/48)\n",
        "  pergame.iat[idx, 32] = pergame.iat[idx, 32].astype(float)\n",
        "  ind_poss_coeff = pergame.iat[idx, 32] / 75\n",
        "  pergame.iat[idx, 31] = pergame.iat[idx, 31]  / ind_poss_coeff\n",
        "pergame.to_csv(\"52-73_reg_per_75_data.csv\", index=False)\n",
        "\n",
        "# NBA 1952-73 Calculate playoff per 75\n",
        "pergame = pd.read_csv('52-73_playoff_pergame_data.csv', encoding='utf8', index_col=False)\n",
        "pace_sup = pd.read_csv('Abbrev_Playoff_Pace_52-73.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "pergame['PTS'] = pergame['PTS'].astype(float)\n",
        "pergame['MP'] = pergame['MP'].astype(float)\n",
        "pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "\n",
        "\n",
        "for idx, row in pergame.iterrows():\n",
        "  team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "  team_pace = team['Pace/G']\n",
        "  pergame.iat[idx, 31] = team_pace * (pergame.iat[idx, 9]/48)\n",
        "  pergame.iat[idx, 31] = pergame.iat[idx, 31].astype(float)\n",
        "  ind_poss_coeff = pergame.iat[idx, 31] / 75\n",
        "  pergame.iat[idx, 30] = pergame.iat[idx, 30]  / ind_poss_coeff\n",
        "pergame.to_csv(\"52-73_playoff_per_75_data.csv\", index=False)\n",
        "\n",
        "\n",
        "# Calculate average PTS per 75 (1952-73)\n",
        "# year by year find what the league average PTS per 75 possessions was. Each row (player)'s points scaled for minutes.\n",
        "avg_pts_per_75 = pd.read_csv('/content/52-73_reg_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "total_mp = 0\n",
        "running_pts_avg = []\n",
        "year_list = []\n",
        "final_df = pd.DataFrame()\n",
        "for year in pre_possesson_data_seasons:\n",
        "  year_list.append(year)\n",
        "  this_years_players = avg_pts_per_75[(avg_pts_per_75['Year']) == year]\n",
        "  this_years_players['MP'] = this_years_players['MP'].astype(float)\n",
        "  total_mp = this_years_players['MP'].sum()\n",
        "  this_years_players['AdjPts'] = (this_years_players['PTS'].astype(float)) * (this_years_players['MP'].astype(float) / total_mp)\n",
        "  running_pts_avg.append(this_years_players['AdjPts'].sum())\n",
        "\n",
        "final_df['Year'] = year_list\n",
        "final_df['Average PP75'] = running_pts_avg\n",
        "        \n",
        "final_df.to_csv(\"Avg_52-73_Reg_PP75.csv\", index=False)\n",
        "\n",
        "\n",
        "# Calculate average DefRtg (1952-73)\n",
        "# year by year find what the league average DefRtg was.\n",
        "avg_pts_per_75 = pd.read_csv('/content/abbrev_52-73 reg pace ortg drtg.csv', index_col=False, encoding='utf8')\n",
        "running_pts_avg = []\n",
        "year_list = []\n",
        "final_df = pd.DataFrame()\n",
        "for year in pre_possesson_data_seasons:\n",
        "  year_list.append(year)\n",
        "  this_years_players = avg_pts_per_75[(avg_pts_per_75['Year']) == year]\n",
        "  running_pts_avg.append(this_years_players['Drtg'].mean())\n",
        "\n",
        "final_df['Year'] = year_list\n",
        "final_df['Average DefRtg'] = running_pts_avg\n",
        "        \n",
        "final_df.to_csv(\"Avg_52-73_DefRtg.csv\", index=False)\n",
        "\n",
        "# Replace Per 75 'MPG' with total 'MP'\n",
        "per75 = pd.read_csv('52-73_playoff_per_75_data.csv', encoding='utf8', index_col=False)\n",
        "total_mp = pd.read_csv('52-73_total_mp_playoff_data.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "per75['MP'] = total_mp['MP'].astype(int)\n",
        "per75.to_csv(\"52-73_playoff_per_75_data.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4KlWoPonuSwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Era Adjust and add TS+ for reg data from 1952-73\n",
        "reg_per_75 = pd.read_csv('/content/52-73_reg_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "reg_ts = pd.read_csv('/content/52-73_reg_advanced_data.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "# Add TS+\n",
        "reg_per_75['Year'] = reg_per_75['Year'].astype(int)\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for yearloop in range(1952, 1974):\n",
        "  yearloop = int(yearloop)\n",
        "  league_avg_df['Year'] = league_avg_df['Year'].astype(int)\n",
        "\n",
        "  year_df = per_75_coeff[(per_75_coeff['Year'] == yearloop)]\n",
        "  tmp_reg_df = reg_per_75[(reg_per_75['Year'] == yearloop)]\n",
        "\n",
        "  year_league_avg_df = league_avg_df[(league_avg_df['Year'] == yearloop)]\n",
        "  year_league_avg_df = year_league_avg_df.reset_index(drop=True)\n",
        "  for idx, player_df in tmp_reg_df.iterrows():\n",
        "    player_ts_df = reg_ts[(reg_ts['Player'] == player_df['Player']) & (reg_ts['Year'] == player_df['Year'])]\n",
        "    player_ts_df = player_ts_df.reset_index(drop=True)\n",
        "    player_df['TS%+'] = float((player_ts_df['TS%'].astype(float) / year_league_avg_df['TS%'].astype(float)) * 100)\n",
        "    player_df['PTS'] = float(player_df['PTS'] * year_df['Coefficient'].astype(float))\n",
        "    #new_df = new_df.append(player_df)\n",
        "    new_df = pd.concat([new_df, player_df], ignore_index=True)\n",
        "  i = i - 1\n",
        "\n",
        "outfile = f\"52-73_era_adjusted_reg_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "r9MYNoPb_GSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ABA 1968-73 DATA**"
      ],
      "metadata": {
        "id": "rcQQeiXhYijl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA 1968-73 Scrape Functions\n",
        "def scrape_aba_team_estimated_playoff_pace_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'Pace/G', 'OffRtg', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/playoffs/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "\n",
        "        #Find table body of team stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-team'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year and pace column to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "             team_allowed_stats[i].insert(1, 0) \n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"Pace/G\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        each_years_teams = each_years_teams.sort_values('Team', ascending=True)\n",
        "\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FG'] = each_years_teams['FG'].astype(float)\n",
        "        each_years_teams['FG'] = each_years_teams['FG'].astype(float)\n",
        "        each_years_teams['G'] = each_years_teams['G'].astype(float)\n",
        "        \n",
        "\n",
        "        ORB_percent = 0.321\n",
        "        if year == 1971:\n",
        "          TOV_percent = 0.158\n",
        "          each_years_teams['Pace/G'] = (each_years_teams['FGA'] + (0.4 * each_years_teams['FTA']) - ORB_percent * (each_years_teams['FGA'] - each_years_teams['FG']) + (-TOV_percent * (each_years_teams['FGA'] + 0.44 * each_years_teams['FTA']) / (TOV_percent - 1)))\n",
        "          each_years_teams['OffRtg'] = (each_years_teams['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "        else:\n",
        "          each_years_teams['TOV'] = each_years_teams['TOV'].astype(float)\n",
        "          each_years_teams['Pace/G'] = (each_years_teams['FGA'] + (0.4 * each_years_teams['FTA']) - ORB_percent * (each_years_teams['FGA'] - each_years_teams['FG']) + each_years_teams['TOV'])\n",
        "          each_years_teams['OffRtg'] = (each_years_teams['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'], axis=1, inplace=True)\n",
        "\n",
        "        \n",
        "\n",
        "        #Find table body of opponent stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each row\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        def_rtg_df = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        def_rtg_df = def_rtg_df.sort_values('Team', ascending=True)\n",
        "\n",
        "        def_rtg_df['PTS'] = def_rtg_df['PTS'].astype(float)\n",
        "        each_years_teams['DefRtg'] = (def_rtg_df['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(aba_pre_poss_abbrev)\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = pd.concat([final_team_data_df, each_years_teams], ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"ABA_Team_Estimated_Playoff_Pace_68-73_df.csv\", index=False)\n",
        "\n",
        "# ABA Scrape reg pace \n",
        "def scrape_aba_team_estimated_pace_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'Pace/G', 'OffRtg', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "\n",
        "        #Find table body of team stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-team'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year and pace column to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "             team_allowed_stats[i].insert(1, 0) \n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"Pace/G\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        each_years_teams = each_years_teams.sort_values('Team', ascending=True)\n",
        "\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FG'] = each_years_teams['FG'].astype(float)\n",
        "        each_years_teams['FG'] = each_years_teams['FG'].astype(float)\n",
        "        each_years_teams['G'] = each_years_teams['G'].astype(float)\n",
        "        \n",
        "\n",
        "        ORB_percent = 0.321\n",
        "        each_years_teams['TOV'] = each_years_teams['TOV'].astype(float)\n",
        "        each_years_teams['Pace/G'] = (each_years_teams['FGA'] + (0.4 * each_years_teams['FTA']) - ORB_percent * (each_years_teams['FGA'] - each_years_teams['FG']) + each_years_teams['TOV'])\n",
        "        each_years_teams['OffRtg'] = (each_years_teams['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'], axis=1, inplace=True)\n",
        "\n",
        "        \n",
        "\n",
        "        #Find table body of opponent stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each row\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        def_rtg_df = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        def_rtg_df = def_rtg_df.sort_values('Team', ascending=True)\n",
        "\n",
        "        def_rtg_df['PTS'] = def_rtg_df['PTS'].astype(float)\n",
        "        each_years_teams['DefRtg'] = (def_rtg_df['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(aba_pre_poss_abbrev)\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = pd.concat([final_team_data_df, each_years_teams], ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"ABA_Team_Estimated_Pace_68-73_df.csv\", index=False)\n",
        "\n",
        "\n",
        "# Scrape ABA regular season per 75 (changed teams mid-season) (1968-73)\n",
        "def scrape_aba_player_changed_teams_per75_data(years):\n",
        "\n",
        "    fin_df = pd.DataFrame()\n",
        "    pace_sup = pd.read_csv('/content/ABA_Team_Estimated_Pace_68-73_df.csv', encoding='utf8', index_col=False)\n",
        "    for year in years:\n",
        "\n",
        "        final_players_pergame_df = pd.DataFrame()\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_per_game.html\"\n",
        "\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "        time.sleep(8)\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(33, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(33, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = pd.concat([final_players_pergame_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        #final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "        players_who_changed_teams = final_players_pergame_df[(final_players_pergame_df['Tm'] == 'TOT')]\n",
        "        player_names = players_who_changed_teams['Player'].tolist()\n",
        "        final_players_pergame_df = final_players_pergame_df[(final_players_pergame_df['Player'].isin(player_names))]\n",
        "\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        final_players_pergame_df['PTS'] = final_players_pergame_df['PTS'].astype(float)\n",
        "        final_players_pergame_df['MP'] = final_players_pergame_df['MP'].astype(float)\n",
        "        pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "        final_players_pergame_df['G'] = final_players_pergame_df['G'].astype(int)\n",
        "        final_players_pergame_df['total_MP'] = final_players_pergame_df['MP'] * final_players_pergame_df['G']\n",
        "        final_players_pergame_df = final_players_pergame_df.reset_index(drop=True)\n",
        "\n",
        "        player_names = final_players_pergame_df['Player'].tolist()\n",
        "        player_names = list(set(player_names))\n",
        "\n",
        "        for player_name in player_names:\n",
        "          mp_list = []\n",
        "          player_teams_df = final_players_pergame_df[(final_players_pergame_df['Player'] == player_name) & (final_players_pergame_df['Tm'] != 'TOT')]\n",
        "          player_teams_df = player_teams_df.reset_index(drop=True)\n",
        "\n",
        "          for idx, row in player_teams_df.iterrows():\n",
        "            team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "            team_pace = float(team['Pace/G'])\n",
        "            # team folded and didn't play for another team that season.\n",
        "            teams_count = idx+1\n",
        "            player_teams_df.iat[idx, 32] = team_pace * (player_teams_df.iat[idx, 9]/48)\n",
        "            player_teams_df.iat[idx, 32] = player_teams_df.iat[idx, 32].astype(float)\n",
        "            ind_poss_coeff = player_teams_df.iat[idx, 32] / 75\n",
        "            player_teams_df.iat[idx, 31] = player_teams_df.iat[idx, 31]  / ind_poss_coeff\n",
        "            mp_list.append(row['total_MP'])\n",
        "          \n",
        "\n",
        "          player_tot_df = final_players_pergame_df[(final_players_pergame_df['Player'] == player_name) & (final_players_pergame_df['Tm'] == 'TOT')]\n",
        "          player_tot_df = player_tot_df.reset_index()\n",
        "\n",
        "          i = 0\n",
        "          total_per_75_pts = 0\n",
        "          total_pace = 0\n",
        "          total_mp = sum(mp_list)\n",
        "          while i < teams_count:\n",
        "            total_per_75_pts+= float(player_teams_df.iat[i, 31]) * (mp_list[i] / total_mp)\n",
        "            total_pace+= player_teams_df.iat[i, 32] * (mp_list[i] / total_mp)\n",
        "            i = i + 1\n",
        "          player_tot_df.iat[0, 32] = total_per_75_pts\n",
        "          player_tot_df.iat[0, 33] = total_pace         \n",
        "          fin_df = fin_df.append(player_tot_df)\n",
        "          new_df = pd.concat([new_df, player_df], ignore_index=True)\n",
        "          fin_df= fin_df.reset_index(drop=True)\n",
        "    fin_df = fin_df.drop(columns=['total_MP', 'index'])\n",
        "    print(fin_df.info)\n",
        "    fin_df.to_csv(\"68-73_changed_teams_reg_per_75_data.csv\", index=False)\n",
        "\n",
        "\n",
        "# Scrape NBA regular season advanced (1968-73)\n",
        "def scrape_aba_player_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame()\n",
        "    for year in years:\n",
        "        print(year)\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        time.sleep(5)\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_advanced_df = pd.concat([final_players_advanced_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"68-73_reg_advanced_data.csv\", index=False)\n",
        "\n",
        "\n",
        "# Scrape ABA regular season per game (1968-73)\n",
        "def scrape_aba_player_reg_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame()\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "        time.sleep(8)\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(32, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(32, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = pd.concat([final_players_pergame_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"68-73_reg_pergame_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA playoff per game (1968-73)\n",
        "def scrape_aba_player_playoff_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        time.sleep(5)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = pd.concat([final_players_pergame_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"68-73_playoff_pergame_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA playoff totals (1968-73)\n",
        "def scrape_aba_player_total_mp_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_totals.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        time.sleep(5)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = pd.concat([final_players_pergame_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"68-73_total_mp_playoff_data.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JEfswM1KYPLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA 1968-73 Ancillary Calculations\n",
        "\n",
        "# ABA 1968-73 Calculate reg per 75\n",
        "pergame = pd.read_csv('68-73_reg_pergame_data.csv', encoding='utf8', index_col=False)\n",
        "pace_sup = pd.read_csv('ABA_Team_Estimated_Pace_68-73_df.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "pergame['PTS'] = pergame['PTS'].astype(float)\n",
        "pergame['MP'] = pergame['MP'].astype(float)\n",
        "pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "pergame = pergame[(pergame['Tm'] != 'TOT')]\n",
        "pergame = pergame.reset_index(drop=True)\n",
        "\n",
        "\n",
        "for idx, row in pergame.iterrows():\n",
        "  team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "  team_pace = team['Pace/G']\n",
        "  # changed team in middle of year. Two paces to account for.\n",
        "  pergame.iat[idx, 32] = team_pace * (pergame.iat[idx, 9]/48)\n",
        "  pergame.iat[idx, 32] = pergame.iat[idx, 32].astype(float)\n",
        "  ind_poss_coeff = pergame.iat[idx, 32] / 75\n",
        "  pergame.iat[idx, 31] = pergame.iat[idx, 31]  / ind_poss_coeff\n",
        "pergame.to_csv(\"68-73_reg_per_75_data.csv\", index=False)\n",
        "\n",
        "\n",
        "# Calculate average PTS per 75 (1968-73)\n",
        "# year by year find what the league average PTS per 75 possessions was. Each row (player)'s points scaled for minutes.\n",
        "avg_pts_per_75 = pd.read_csv('/content/68-73_reg_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "avg_pts_per_75 = avg_pts_per_75[(avg_pts_per_75['Tm'] != \"TOT\")]\n",
        "total_mp = 0\n",
        "running_pts_avg = []\n",
        "year_list = []\n",
        "final_df = pd.DataFrame()\n",
        "for year in pre_possesson_data_seasons:\n",
        "  year_list.append(year)\n",
        "  this_years_players = avg_pts_per_75[(avg_pts_per_75['Year']) == year]\n",
        "  this_years_players['MP'] = this_years_players['MP'].astype(float)\n",
        "  total_mp = this_years_players['MP'].sum()\n",
        "  this_years_players['AdjPts'] = (this_years_players['PTS'].astype(float)) * (this_years_players['MP'].astype(float) / total_mp)\n",
        "  running_pts_avg.append(this_years_players['AdjPts'].sum())\n",
        "\n",
        "final_df['Year'] = year_list\n",
        "final_df['Average PP75'] = running_pts_avg\n",
        "        \n",
        "final_df.to_csv(\"Avg_68-73_Reg_PP75.csv\", index=False)\n",
        "\n",
        "# ABA 1968-73 Calculate playoff per 75\n",
        "pergame = pd.read_csv('68-73_playoff_pergame_data.csv', encoding='utf8', index_col=False)\n",
        "pace_sup = pd.read_csv('ABA_Team_Estimated_Playoff_Pace_68-73_df.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "pergame['PTS'] = pergame['PTS'].astype(float)\n",
        "pergame['MP'] = pergame['MP'].astype(float)\n",
        "pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "\n",
        "\n",
        "for idx, row in pergame.iterrows():\n",
        "  team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "  team_pace = team['Pace/G']\n",
        "  pergame.iat[idx, 31] = team_pace * (pergame.iat[idx, 9]/48)\n",
        "  pergame.iat[idx, 31] = pergame.iat[idx, 31].astype(float)\n",
        "  ind_poss_coeff = pergame.iat[idx, 31] / 75\n",
        "  pergame.iat[idx, 30] = pergame.iat[idx, 30]  / ind_poss_coeff\n",
        "pergame.to_csv(\"68-73_playoff_per_75_data.csv\", index=False)\n",
        "\n",
        "\n",
        "# Calculate average DefRtg (1968-73)\n",
        "# year by year find what the league average DefRtg was.\n",
        "avg_pts_per_75 = pd.read_csv('ABA_Team_Estimated_Pace_68-73_df.csv', index_col=False, encoding='utf8')\n",
        "running_pts_avg = []\n",
        "year_list = []\n",
        "final_df = pd.DataFrame()\n",
        "for year in aba_pre_possession_seasons:\n",
        "  year_list.append(year)\n",
        "  this_years_players = avg_pts_per_75[(avg_pts_per_75['Year']) == year]\n",
        "  running_pts_avg.append(this_years_players['DefRtg'].mean())\n",
        "\n",
        "final_df['Year'] = year_list\n",
        "final_df['Average DefRtg'] = running_pts_avg\n",
        "        \n",
        "final_df.to_csv(\"Avg_68-73_DefRtg.csv\", index=False)\n",
        "\n",
        "# Replace Per 75 'MPG' with total 'MP'\n",
        "per75 = pd.read_csv('68-73_playoff_per_75_data.csv', encoding='utf8', index_col=False)\n",
        "total_mp = pd.read_csv('68-73_total_mp_playoff_data.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "per75['MP'] = total_mp['MP'].astype(int)\n",
        "per75.to_csv(\"68-73_playoff_per_75_data.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2pYxkLUbkWek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Era Adjust and add TS+ for reg data from 1968-73\n",
        "reg_per_75 = pd.read_csv('/content/68-73_reg_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "reg_ts = pd.read_csv('/content/68-73_reg_advanced_data.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "# Add TS+\n",
        "reg_per_75['Year'] = reg_per_75['Year'].astype(int)\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for yearloop in range(1968, 1974):\n",
        "  yearloop = int(yearloop)\n",
        "  aba_league_avg['Year'] = aba_league_avg['Year'].astype(int)\n",
        "\n",
        "  year_df = per_75_coeff[(per_75_coeff['Year'] == yearloop)]\n",
        "  tmp_reg_df = reg_per_75[(reg_per_75['Year'] == yearloop)]\n",
        "\n",
        "  year_league_avg_df = aba_league_avg[(aba_league_avg['Year'] == yearloop)]\n",
        "  year_league_avg_df = year_league_avg_df.reset_index(drop=True)\n",
        "  for idx, player_df in tmp_reg_df.iterrows():\n",
        "    player_ts_df = reg_ts[(reg_ts['Player'] == player_df['Player']) & (reg_ts['Year'] == player_df['Year'])]\n",
        "    player_ts_df = player_ts_df.reset_index(drop=True)\n",
        "    player_df['TS%+'] = float((player_ts_df['TS%'].astype(float) / year_league_avg_df['TS%'].astype(float)) * 100)\n",
        "    player_df['PTS'] = float(player_df['PTS'] * year_df['Coefficient'].astype(float))\n",
        "    #new_df = new_df.append(player_df)\n",
        "    new_df = pd.concat([new_df, player_df], ignore_index=True)\n",
        "  i = i - 1\n",
        "\n",
        "outfile = f\"68-73_era_adjusted_reg_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TwP_cLfQXGmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ABA 1974-76 DATA**"
      ],
      "metadata": {
        "id": "HtCLgfbO4rpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scrape_aba_player_per100_data(aba_seasons)\n",
        "#scrape_aba_advanced_data(aba_seasons)\n",
        "#scrape_nba_player_per100_aba_data(aba_seasons)\n",
        "#scrape_team_ts_allowed_data(aba_seasons)\n",
        "#scrape_nba_player_reg_avg_per_100(aba_seasons)\n",
        "#scrape_team_defrtg_allowed_data(aba_seasons)\n",
        "#scrape_nba_player_avg_defrtg(aba_seasons)"
      ],
      "metadata": {
        "id": "YvT4wDHZ5Ihd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA 1974-76 Scrape Functions\n",
        "# Scrape ABA regular season per 100\n",
        "def scrape_aba_player_per100_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = pd.concat([final_players_per100_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"aba_player_since74_per100_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA regular season advanced\n",
        "def scrape_aba_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP'\n",
        "                                                        ])\n",
        "    for year in years:\n",
        "        player_advanced_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_advanced_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_advanced_stats = [e for e in player_advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_advanced_stats)):\n",
        "             player_advanced_stats[i].insert(0, year)\n",
        "             player_advanced_stats[i].insert(5, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(5, \"TeamColor\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_advanced_df = pd.concat([final_players_advanced_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "        #final_players_advanced_df['Player'] = final_players_advanced_df['Player'].apply(ast.literal_eval).str.decode(\"utf-8\")\n",
        "        #final_players_advanced_df['Player'] = unidecode(final_players_advanced_df['Player'])\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"aba_player_since74_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA playoffs per 100\n",
        "def scrape_nba_player_per100_aba_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = pd.concat([final_players_per100_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"nba_player_since74playoffs_per100_aba_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA Teams' TS% Allowed\n",
        "def scrape_team_ts_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team' 'TS% Allowed'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_totals_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'totals-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['TS% Allowed'] = each_years_teams['PTS'] / ( ( (each_years_teams['FTA'] * .44) + (each_years_teams['FGA']) ) * 2)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(aba_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = pd.concat([final_team_data_df, each_years_teams], ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"ABA_Team_TS_Percentage_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape ABA Reg Avg Per 75 Scoring\n",
        "def scrape_nba_player_reg_avg_per_100(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PP75'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = (each_year['PTS'].astype(float) * .75) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        new_row = pd.DataFrame(np.array([[year, running_pts_avg]]), columns=['Year',  'Average PP75'])\n",
        "        final_df = pd.concat([final_df, new_row], ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_ABA_Reg_PP75.csv\", index=False)\n",
        "\n",
        "# Scrape ABA Teams' DefRtg \n",
        "def scrape_team_defrtg_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # add DefRTG allowed\n",
        "        each_years_teams['DefRtg'] = each_years_teams['PTS'].astype(float)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(aba_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = pd.concat([final_team_data_df, each_years_teams], ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"ABA_Team_defrtg_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape ABA League Avg DefRtg\n",
        "def scrape_nba_player_avg_defrtg(years):\n",
        "\n",
        "  final_team_data_df = pd.DataFrame(columns = ['Year', 'Avg DefRtg'])\n",
        "    \n",
        "  for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        avg_def_rtg = each_year['PTS'].mean()\n",
        "\n",
        "\n",
        "\n",
        "        new_row = pd.DataFrame(np.array([[year, avg_def_rtg]]), columns=['Year',  'Avg DefRtg'])\n",
        "        final_team_data_df = pd.concat([final_team_data_df, new_row], ignore_index=True)\n",
        "        final_team_data_df['Year'] = final_team_data_df['Year'].astype(int)\n",
        "        print(new_row)\n",
        "        \n",
        "  # print final_df\n",
        "  final_team_data_df.to_csv(\"Avg_ABA_Def_Rtg.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0ybCHOcAfCBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA 1974-76 Ancillary Calculations\n",
        "\n",
        "# Calculate ABA reg per 75 points\n",
        "aba_per100_reg_df = pd.read_csv('/content/aba_player_since74_per100_data.csv')\n",
        "aba_per100_reg_df['PTS'] = aba_per100_reg_df['PTS'] * .75\n",
        "aba_advanced_reg_df = pd.read_csv('/content/aba_player_since74_advanced_data.csv')\n",
        "\n",
        "\n",
        "# Add ABA reg TS+\n",
        "# TS% from advanced dataframge (aba_advanced_reg_df.iat[j, 9]) divided by league average TS% (aba_league_avg.iat[yearloop, 1])\n",
        "i = 1976\n",
        "for yearloop in range(49):\n",
        "  for j, row in aba_per100_reg_df.iterrows():\n",
        "    if row['Year'] == i:\n",
        "      aba_per100_reg_df.iat[j, 1] = (aba_advanced_reg_df.iat[j, 9] / aba_league_avg.iat[yearloop, 1]) * 100\n",
        "  i = i - 1\n",
        "\n",
        "aba_per100_reg_df = aba_per100_reg_df[import_player_since74_per75_df['TS%+'].notna()]\n",
        "outfile = f\"aba_per75_reg_data.csv\"\n",
        "aba_per100_reg_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OIcwUzC7Swym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ylkdaUS_rxK"
      },
      "source": [
        "**NBA 1974-2022 DATA**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scrape_nba_player_reg_per100_data(possession_data_seasons)\n",
        "#scrape_nba_player_post_per100_data(possession_data_seasons)\n",
        "#scrape_nba_reg_advanced_data(possession_data_seasons)\n",
        "#scrape_nba_advanced_post_data(possession_data_seasons)\n",
        "#scrape_nba_reg_playbyplay_data(play_by_play_data_seasons)\n",
        "#scrape_nba_post_playbyplay_data(play_by_play_data_seasons)\n",
        "#scrape_nba_leaguestats_data(possession_data_seasons)\n",
        "#scrape_nba_player_reg_avg_per_75(possession_data_seasons)\n",
        "#scrape_nba_player_playoff_avg_per_75(possession_data_seasons)\n",
        "#scrape_nba_player_reg_bpm_avg(possession_data_seasons)\n",
        "#scrape_team_ts_allowed_data(all_the_years)\n",
        "#scrape_team_defrtg_allowed_data(all_the_years)\n",
        "#scrape_nba_player_avg_defrtg(all_the_years)"
      ],
      "metadata": {
        "id": "VUlmu6LP6eAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "28WIXVx2GuiM"
      },
      "outputs": [],
      "source": [
        "#@title NBA 1974-2022 Scrape Functions\n",
        "\n",
        "# Scrape NBA regular season per 100\n",
        "def scrape_nba_player_reg_per100_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = pd.concat([final_players_per100_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"nba_player_since74_per100_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoffs per 100\n",
        "def scrape_nba_player_post_per100_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = pd.concat([final_players_per100_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"nba_player_since74playoffs_per100_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season advanced\n",
        "def scrape_nba_reg_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP'\n",
        "                                                        ])\n",
        "    for year in years:\n",
        "        player_advanced_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_advanced_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_advanced_stats = [e for e in player_advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_advanced_stats)):\n",
        "             player_advanced_stats[i].insert(0, year)\n",
        "             player_advanced_stats[i].insert(5, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(5, \"TeamColor\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_advanced_df = pd.concat([final_players_advanced_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "        #final_players_advanced_df['Player'] = final_players_advanced_df['Player'].apply(ast.literal_eval).str.decode(\"utf-8\")\n",
        "        #final_players_advanced_df['Player'] = unidecode(final_players_advanced_df['Player'])\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"nba_player_since74_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoffs advanced\n",
        "def scrape_nba_post_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP'\n",
        "                                                        ])\n",
        "    for year in years:\n",
        "        player_advanced_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_advanced_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_advanced_stats = [e for e in player_advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_advanced_stats)):\n",
        "             player_advanced_stats[i].insert(0, year)\n",
        "             player_advanced_stats[i].insert(5, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(5, \"TeamColor\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_advanced_df = pd.concat([final_players_advanced_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "        #final_players_advanced_df['Player'] = final_players_advanced_df['Player'].apply(ast.literal_eval).str.decode(\"utf-8\")\n",
        "        #final_players_advanced_df['Player'] = unidecode(final_players_advanced_df['Player'])\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"nba_player_since74playoffs_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season play-by-play\n",
        "def scrape_nba_reg_playbyplay_data(years):\n",
        " \n",
        "    final_players_playbyplay_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age',\n",
        "                                                          'Tm', 'G', 'MP','OnCourt', 'On-Off', 'BadPass', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1'\n",
        "                                                         ])\n",
        "    \n",
        "    for year in years:\n",
        "        player_playbyplay_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        html = urlopen(player_playbyplay_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        # grab tr[1], as tr[0] is populated with categorical headers. Not headers for each columns of data (which are in tr[1])\n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"Blkd\")+1]\n",
        "\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_playbyplay_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_playbyplay_stats = [e for e in player_playbyplay_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_playbyplay_stats)):\n",
        "             player_playbyplay_stats[i].insert(0, year)   \n",
        "        headers.insert(0, \"Year\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_playbyplay_stats, columns = headers)\n",
        "\n",
        "        #rename some columns for less ambiguity\n",
        "        each_year.columns=['Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'MP','PG%', 'SG%', 'SF%', 'PF%', 'C%',\n",
        "                            'OnCourt', 'On-Off', 'BadPass', 'LostBall', 'ShootCommit', 'OffCommit', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1', 'Blkd']\n",
        "        # drop irrelevant columns\n",
        "        each_year = each_year.drop(['PG%', 'SG%', 'SF%', 'PF%', 'C%', 'LostBall', 'ShootCommit', 'OffCommit', 'Blkd'], axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_playbyplay_df = pd.concat([final_players_playbyplay_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_playbyplay_df['Player'] = final_players_playbyplay_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_playbyplay_df.info)\n",
        "    final_players_playbyplay_df.to_csv(\"nba_player_regular_playbyplay_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoffs play-by-play\n",
        "# import needed libraries\n",
        "def scrape_nba_post_playbyplay_data(years):\n",
        " \n",
        "    final_players_playbyplay_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age',\n",
        "                                                          'Tm', 'G', 'MP','OnCourt', 'On-Off', 'BadPass', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1'\n",
        "                                                         ])\n",
        "    \n",
        "    for year in years:\n",
        "        player_playbyplay_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        html = urlopen(player_playbyplay_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        # grab tr[1], as tr[0] is populated with categorical headers. Not headers for each columns of data (which are in tr[1])\n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"Blkd\")+1]\n",
        "\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_playbyplay_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_playbyplay_stats = [e for e in player_playbyplay_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_playbyplay_stats)):\n",
        "             player_playbyplay_stats[i].insert(0, year)   \n",
        "        headers.insert(0, \"Year\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_playbyplay_stats, columns = headers)\n",
        "\n",
        "        #rename some columns for less ambiguity\n",
        "        each_year.columns=['Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'MP','PG%', 'SG%', 'SF%', 'PF%', 'C%',\n",
        "                            'OnCourt', 'On-Off', 'BadPass', 'LostBall', 'ShootCommit', 'OffCommit', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1', 'Blkd']\n",
        "        # drop irrelevant columns\n",
        "        each_year = each_year.drop(['PG%', 'SG%', 'SF%', 'PF%', 'C%', 'LostBall', 'ShootCommit', 'OffCommit', 'Blkd'], axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_playbyplay_df = pd.concat([final_players_playbyplay_df, each_year], ignore_index=True)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_playbyplay_df['Player'] = final_players_playbyplay_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_playbyplay_df.info)\n",
        "    final_players_playbyplay_df.to_csv(\"nba_player_playoff_playbyplay_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season league average\n",
        "def scrape_nba_leaguestats_data():\n",
        "\n",
        "        final_leaguestats_df = pd.DataFrame(columns = ['Year',\t'Lg',\t'Age',\t'Ht',\t'Wt',\t'G',\t'MP',\t'FG',\t'FGA',\t'3P',\n",
        "                                                      '3PA',\t'FT',\t'FTA',\t'ORB',\t'DRB',\t'TRB',\t'AST',\t'STL',\t'BLK',\t'TOV',\n",
        "                                                      'PF',\t'PTS',\t'FG%',\t'3P%',\t'FT%',\t'Pace',\t'eFG%',\t'TOV%',\t'ORB%',\n",
        "                                                      'FT/FGA',\t'ORtg', 'TS%'])\n",
        "        \n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_stats_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"ORtg\")+1]\n",
        "        headers.insert(32, \"TS%\")\n",
        "        print(headers)\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        #rows = soup.findAll('tr', class=None)[1:]\n",
        "        rows = soup.findAll('tr', class_=None)[1:]\n",
        "\n",
        "\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "          player_base_stats[i].insert(32, 0)\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        final_leaguestats_df = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        final_leaguestats_df = final_leaguestats_df.drop(['Lg'], axis=1)\n",
        "\n",
        "        final_leaguestats_df = final_leaguestats_df.iloc[1: , :]\n",
        "\n",
        "        final_leaguestats_df.drop(final_leaguestats_df.index[20])\n",
        "        final_leaguestats_df.drop(final_leaguestats_df.index[21])\n",
        "        \n",
        "        # print final_df\n",
        "        print(final_leaguestats_df.info)\n",
        "        final_leaguestats_df.to_csv(\"nba_leaguestats_data.csv\", index=False)\n",
        "\n",
        "# Scrape Reg Avg Per 75 Scoring\n",
        "def scrape_nba_player_reg_avg_per_75(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PP75'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = (each_year['PTS'].astype(float) * .75) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        new_row = pd.DataFrame(np.array([[year, running_pts_avg]]), columns=['Year',  'Average PP75'])\n",
        "        final_df = pd.concat([final_df, new_row], ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_Reg_PP75.csv\", index=False)\n",
        "\n",
        "# Scrape Playoff Avg Per 75 Scoring\n",
        "def scrape_nba_player_playoff_avg_per_75(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PP75'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = (each_year['PTS'].astype(float) * .75) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        year = year.astype(int)\n",
        "        new_row = pd.DataFrame(np.array([[year, running_pts_avg]]), columns=['Year',  'Average PP75'])\n",
        "        final_df = pd.concat([final_df, new_row], ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_Playoff_PP75.csv\", index=False)\n",
        "\n",
        "# Scrape Reg Avg BPM\n",
        "def scrape_nba_player_reg_bpm_avg(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average BPM', 'Average OBPM'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_bpm_avg = 0\n",
        "        running_obpm_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['BPM'] = each_year['BPM'].astype(float)\n",
        "        each_year['OBPM'] = each_year['OBPM'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['adjBPM'] = each_year['BPM'].astype(float) * (each_year['MP'].astype(float) / total_mp)\n",
        "        each_year['adjOBPM'] = each_year['OBPM'].astype(float) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_bpm_avg = each_year['adjBPM'].sum()\n",
        "        running_obpm_avg = each_year['adjOBPM'].sum()\n",
        "\n",
        "        running_bpm_avg = running_bpm_avg + 1\n",
        "        running_obpm_avg = running_obpm_avg + 1\n",
        "\n",
        "\n",
        "        new_row = {'Year':year, 'Average BPM':running_bpm_avg, 'Average OBPM':running_obpm_avg}\n",
        "        new_row = pd.DataFrame(np.array([[year, running_pts_avg]]), columns=['Year',  'Average PP75'])\n",
        "        final_df = pd.concat([final_df, new_row], ignore_index=True)\n",
        "        final_df['Year'] = final_df['Year'].astype(int)\n",
        "        \n",
        "    # print final_df\n",
        "    final_df.to_csv(\"Avg_Reg_BPM.csv\", index=False)\n",
        "\n",
        "# Scrape NBA Teams' TS% Allowed\n",
        "def scrape_team_ts_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team' 'TS% Allowed'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_totals_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'totals-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['TS% Allowed'] = each_years_teams['PTS'] / ( ( (each_years_teams['FTA'] * .44) + (each_years_teams['FGA']) ) * 2)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(team_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        final_players_per100_df = pd.concat([final_players_per100_df, each_year], ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"NBA_Team_TS_Percentage_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape NBA Teams' DefRtg \n",
        "def scrape_team_defrtg_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(team_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        final_players_per100_df = pd.concat([final_players_per100_df, each_year], ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"NBA_Team_defrtg_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape League Avg DefRtg\n",
        "def scrape_nba_player_avg_defrtg(years):\n",
        "\n",
        "  final_team_data_df = pd.DataFrame(columns = ['Year', 'Avg DefRtg'])\n",
        "    \n",
        "  for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        avg_def_rtg = each_year['PTS'].mean()\n",
        "\n",
        "\n",
        "\n",
        "        new_row = pd.DataFrame(np.array([[year, avg_def_rtg]]), columns=['Year',  'Avg DefRtg'])\n",
        "        final_team_data_df = pd.concat([final_team_data_df, new_row], ignore_index=True)\n",
        "        final_team_data_df['Year'] = final_team_data_df['Year'].astype(int)\n",
        "        print(new_row)\n",
        "        \n",
        "  # print final_df\n",
        "  final_team_data_df.to_csv(\"Avg_Def_Rtg.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA 1974-2022 Ancillary Calculations\n",
        "\n",
        "# Calculate NBA reg per 75 points\n",
        "#import_player_since74_per75_df = import_player_since74_per100_df.copy()\n",
        "#import_player_since74_per75_df['PTS'] = import_player_since74_per75_df['PTS'] * .75\n",
        "\n",
        "# Add NBA reg TS+\n",
        "# TS% from advanced dataframge (import_player_since74_advanced_df.iat[j, 9]) divided by league average TS% (league_avg_df.iat[yearloop, 1])\n",
        "i = 2022\n",
        "for yearloop in range(49):\n",
        "  for j, row in import_player_since74_per75_df.iterrows():\n",
        "    if row['Year'] == i:\n",
        "      import_player_since74_per75_df.iat[j, 1] = (import_player_since74_advanced_df.iat[j, 9] / league_avg_df.iat[yearloop, 1]) * 100\n",
        "  i = i - 1\n",
        "\n",
        "import_player_since74_per75_df = import_player_since74_per75_df[import_player_since74_per75_df['TS%+'].notna()]\n",
        "outfile = f\"nba_player_since74_per75_data.csv\"\n",
        "import_player_since74_per75_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate Playoffs per 75\n",
        "#import_player_since74playoffs_per75_df = import_player_since74playoffs_per100_df.copy()\n",
        "#import_player_since74playoffs_per75_df['PTS'] = import_player_since74playoffs_per75_df['PTS'] * .75\n",
        "\n",
        "aba_per75_pts = pd.read_csv('/content/aba_player_since74playoffs_per100_data.csv')\n",
        "aba_per75_pts['PTS'] = aba_per75_pts['PTS'] * .75\n",
        "\n",
        "outfile = f\"aba_player_since74playoffs_per75_data.csv\"\n",
        "aba_per75_pts.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_ntucsSc6SDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPo3JH7bZmrN"
      },
      "source": [
        "**SCRAPE URL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape NBA Player URL's (1952-73)\n",
        "# import needed libraries\n",
        "def scrape_url_data_52_73(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        wd.get(page_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_game_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = pd.concat([player_url_df, tmp_df], ignore_index=True)\n",
        "        \n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_52-73_URL_data.csv\", index=False)\n",
        "scrape_url_data_52_73(pre_possesson_data_seasons)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Vj0vFAsXBecy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape ABA Player URL's (1968-73)\n",
        "# import needed libraries\n",
        "def scrape_url_data_aba(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_per_game.html\"\n",
        "        \n",
        "        wd.get(page_url)       \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_game_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = pd.concat([player_url_df, tmp_df], ignore_index=True)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"aba_player_URL_data.csv\", index=False)\n",
        "scrape_url_data_aba(aba_pre_possession_seasons)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "U2QkVE4z66FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape ABA Player URL's (1974-76)\n",
        "# import needed libraries\n",
        "def scrape_url_data_aba(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        wd.get(page_url)       \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(15)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = pd.concat([player_url_df, tmp_df], ignore_index=True)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_aba_URL_data.csv\", index=False)\n",
        "scrape_url_data_aba([1974, 1975, 1976])"
      ],
      "metadata": {
        "id": "tl9YBqUF8T4H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gxLh3jVuAZe4"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA Player URL's (1974-2022)\n",
        "# import needed libraries\n",
        "def scrape_url_data_74(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        wd.get(page_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(15)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = pd.concat([player_url_df, tmp_df], ignore_index=True)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_since_74_URL_data.csv\", index=False)\n",
        "scrape_url_data_74(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1BJWc9nsob9K"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA Player URL's (1997-2022)\n",
        "# import needed libraries\n",
        "def scrape_url_data_97(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        print(year)\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        wd.get(page_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(15)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_pbp_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'pbp_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = pd.concat([player_url_df, tmp_df], ignore_index=True)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_URL_data.csv\", index=False)\n",
        "scrape_url_data_74(some_of_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4yATMvO-BkTW"
      },
      "outputs": [],
      "source": [
        "#@title Shorten URL list to only players with >x playoff minutes\n",
        "def nba_shorten_url_list_by_x(url_df, min_requirement):\n",
        "\n",
        "    new_df = pd.DataFrame(columns = ['Player', 'URL', 'MP'])\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      og_url = url\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      \n",
        "\n",
        "      wd.get(url)          \n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "      time.sleep(5)\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_advanced-playoffs_advanced'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs_advanced'})\n",
        "        foot = first_table.find('tfoot')\n",
        "\n",
        "      rows = foot.find('tr')\n",
        "      only_for_mp = [[td.getText() for td in rows.findAll('td')]]\n",
        "\n",
        "      # remove empty rows\n",
        "      only_for_mp = [e for e in only_for_mp if e != []]\n",
        "\n",
        "      url_data = pd.DataFrame(only_for_mp)\n",
        "\n",
        "      tmp_df = pd.DataFrame(columns = ['Player', 'URL', 'MP'])\n",
        "      \n",
        "\n",
        "      # took only long mid range FGA\n",
        "      if int(url_data[5]) <= min_requirement:\n",
        "        continue\n",
        "      else:\n",
        "        mp = int(url_data[5])\n",
        "\n",
        "      tmp_df.loc[len(tmp_df)] = [player, og_url, mp]\n",
        "      new_df = pd.concat([new_df, tmp_df], ignore_index=True)\n",
        "      outfile = f\"NBA_Player_68-73_URL_List_{min_requirement}_Min_df.csv\"\n",
        "      new_df.to_csv(outfile, index=False)\n",
        "      print(tmp_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLzLiVsSJUU2"
      },
      "outputs": [],
      "source": [
        "player_urls = pd.read_csv('/content/nba_player_URL_data_2023.csv', index_col=False, encoding='utf8')\n",
        "nba_shorten_url_list_by_x(player_urls, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhL-arWPFvb8"
      },
      "source": [
        "**NBA/ABA 1952-2022 ADJUSTED PLAYOFF TS+**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA/ABA 1952-2022 Adjusted Playoff TS+ (1954)\n",
        "def adjust_scoring_efficiency(url_df, nba_league_avg_df, aba_league_avg_df, nba_opp_ts_df, nba_opp_defrtg_df, aba_opp_ts_df, aba_opp_defrtg_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'TS+', 'PTS_coeff', 'MP'])\n",
        "    percent_iteration = 1\n",
        "\n",
        "    from itertools import chain\n",
        "\n",
        "    nba_league_avg_df['Year'] = nba_league_avg_df['Year'].astype(int)\n",
        "    nba_league_avg_df['Year'] = nba_league_avg_df['Year'].astype(str)\n",
        "\n",
        "    aba_league_avg_df['Year'] = aba_league_avg_df['Year'].astype(int)\n",
        "    aba_league_avg_df['Year'] = aba_league_avg_df['Year'].astype(str)\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      print(player)\n",
        "      time.sleep(5)\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        header = first_table.find('thead')\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "      series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "      #create df\n",
        "      series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      pts_count = 0\n",
        "      mp_count = 0\n",
        "      cols = []\n",
        "      for column in series_data.columns:\n",
        "        if column == 'MP':\n",
        "          if mp_count == 1:\n",
        "            cols.append(f'MPG')\n",
        "          else:\n",
        "            cols.append(f'MP')\n",
        "          mp_count+=1\n",
        "          continue\n",
        "        if column == 'PTS':\n",
        "          if pts_count == 1:\n",
        "            cols.append(f'PTS/G')\n",
        "          else:\n",
        "            cols.append(f'PTS')\n",
        "          pts_count+=1\n",
        "          continue\n",
        "        cols.append(column)\n",
        "      series_data.columns = cols\n",
        "\n",
        "\n",
        "      # remove seasons preceding 1952\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1951\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1950\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1949\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1948\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1947\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1946\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1945\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1944\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "      series_data = series_data.reset_index()\n",
        "\n",
        "      df_new1 = pd.DataFrame({'Year' : ['1954'], 'FGA': [6], 'FTA': [7], 'PTS': [14], 'Opp': ['ROC']})\n",
        "      tmp = pd.concat([df_new1, series_data], sort=False).reset_index(drop = True).fillna('')\n",
        "\n",
        "      df_new1 = pd.DataFrame({'Year' : ['1954'], 'FGA': [33], 'FTA': [15], 'PTS': [49], 'Opp': ['FTW']})\n",
        "      tmp_2 = pd.concat([df_new1, tmp], sort=False).reset_index(drop = True).fillna('')\n",
        "\n",
        "      series_data = tmp_2\n",
        "\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      nba_opp_ts_df['Team'] = nba_opp_ts_df['Team'].astype(str)\n",
        "      nba_opp_ts_df['Year'] = nba_opp_ts_df['Year'].astype(str)\n",
        "      nba_opp_defrtg_df['Year'] = nba_opp_defrtg_df['Year'].astype(str)\n",
        "      nba_opp_defrtg_df['Year'] = nba_opp_defrtg_df['Year'].astype(str)\n",
        "      aba_opp_ts_df['Team'] = aba_opp_ts_df['Team'].astype(str)\n",
        "      aba_opp_ts_df['Year'] = aba_opp_ts_df['Year'].astype(str)\n",
        "      aba_opp_defrtg_df['Year'] = aba_opp_defrtg_df['Year'].astype(str)\n",
        "      aba_opp_defrtg_df['Year'] = aba_opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['G'] = series_data['G'].astype(float)\n",
        "\n",
        "      \n",
        "      # may be missing MP data.\n",
        "      # divide the missing estimated total numbers equally among games w/o MP data.\n",
        "      missing_mp_data = series_data.copy()\n",
        "      missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      years_list = []\n",
        "      \n",
        "      remaining_mp = []\n",
        "      missing_index = 0\n",
        "      \n",
        "      \n",
        "      for mp_idx, row in missing_mp_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_mp_data.loc[mp_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which MP aren't accounted for\n",
        "          working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # MP accounted for \n",
        "          accounted_for_mp = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_mp['MP'] = accounted_for_mp['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_mp.dropna(inplace=True)\n",
        "          accounted_for_mp = (accounted_for_mp['MP'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total MP\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "\n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_mp = selected_year['MP'].astype(float)\n",
        "          \n",
        "\n",
        "          # remaining MP contains estimated MP for this year's series with missing MP\n",
        "          remaining_mp.append(total_mp - accounted_for_mp)\n",
        "\n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            idx = int(idx)\n",
        "            if working_missing_year.shape[0]  == 1:\n",
        "              series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index])\n",
        "            elif working_missing_year.shape[0]  == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0]  == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      # may be missing FGA data.\n",
        "      # divide the missing estimated total numbers equally among games w/o FGA data.\n",
        "      missing_fg_data = series_data.copy()\n",
        "      missing_fg_data = missing_fg_data[(missing_fg_data['FGA'] == '')]\n",
        "      years_list = []\n",
        "      remaining_fg = []\n",
        "      missing_index = 0\n",
        "\n",
        "      for fg_idx, row in missing_fg_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_fg_data.loc[fg_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which FGA aren't accounted for \n",
        "          working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # FGA accounted for \n",
        "          accounted_for_fg = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_fg['FGA'] = accounted_for_fg['FGA'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_fg.dropna(inplace=True)\n",
        "          accounted_for_fg = (accounted_for_fg['FGA'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total FGA\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          from itertools import chain\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_fg = selected_year['FGA'].astype(float)\n",
        "          selected_year['Tm'] = selected_year['Tm'].astype(str)\n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          # remaining FGA contains estimated FGA for this year's series with missing FGA\n",
        "          remaining_fg.append(total_fg - accounted_for_fg)\n",
        "          \n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            if working_missing_year.shape[0] == 1:\n",
        "              series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index])\n",
        "            elif working_missing_year.shape[0] == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0] == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data['FGA'].iat[idx] = float(remaining_fg[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      series_data['TS+'] = 0\n",
        "      years_list = []\n",
        "\n",
        "      aba_teams = [\"DNA\", \"INA\", \"NYA\", \"SAA\", \"VIR\", \"CAR\", \"SDA\", \"KEN\",\n",
        "             \"UTS\", \"CAR\", \"SDS\", \"SSL\", \"MMS\", \"DNR\", \"PTP\", \"MNM\",\n",
        "             \"NOB\", \"DLC\", \"TEX\", \"HSM\", \"OAK\", \"MMF\", \"MNP\", \"WSA\",\n",
        "             \"LAS\", \"FLO\", \"MMP\", \"NJA\", \"ANA\", \"PTC\", \"MMT\"]\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "\n",
        "        if current_opp in aba_teams:\n",
        "          if current_year <= '1973':\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = aba_opp_defrtg_df[(aba_opp_defrtg_df['Team'] == current_opp) & ((aba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            this_year = aba_league_avg_df[(aba_league_avg_df['Year'] == current_year)]\n",
        "            league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "            league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "            # estimate TS+ allowed\n",
        "            predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "            #find raw TS% compared to league average\n",
        "            raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed) * 100)\n",
        "            series_data.loc[i,'TS+'] = tsplus\n",
        "            series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "          else:\n",
        "            # get ts% allowed by opponent\n",
        "            opponent_ts = aba_opp_ts_df[(aba_opp_ts_df['Team'] == current_opp) & ((aba_opp_ts_df['Year'] == current_year))]\n",
        "            opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = aba_opp_defrtg_df[(aba_opp_defrtg_df['Team'] == current_opp) & ((aba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "            series_data.loc[i,'TS+'] = tsplus\n",
        "            series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "\n",
        "        else:\n",
        "          if current_year <= '1973':\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = nba_opp_defrtg_df[(nba_opp_defrtg_df['Team'] == current_opp) & ((nba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            this_year = nba_league_avg_df[(nba_league_avg_df['Year'] == current_year)]\n",
        "            league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "            league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "            # estimate TS+ allowed\n",
        "            predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "            #find raw TS% compared to league average\n",
        "            raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed) * 100)\n",
        "            series_data.loc[i,'TS+'] = tsplus\n",
        "            series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "          else:\n",
        "            # get ts% allowed by opponent\n",
        "            opponent_ts = nba_opp_ts_df[(nba_opp_ts_df['Team'] == current_opp) & ((nba_opp_ts_df['Year'] == current_year))]\n",
        "            opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = nba_opp_defrtg_df[(nba_opp_defrtg_df['Team'] == current_opp) & ((nba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "            series_data.loc[i,'TS+'] = tsplus\n",
        "            series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'FGA', 'FTA', 'PTS', 'MPG'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = series_data[(series_data['Year'] == year)]\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "\n",
        "        new_row = pd.DataFrame(np.array([[player, year, total_ts, total_coeff, int(total_mp)]]), columns=['Player', 'Year', 'TS+', 'PTS_coeff', 'MP'])\n",
        "        final_season_df = pd.concat([final_season_df, new_row], ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "      outfile = f\"Playoff_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)\n",
        "    print(final_season_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZPjt7SAG_XbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Remove round robin data\n",
        "       # remove round robin data\n",
        "          if current_year == '1954':\n",
        "            remove_rr_url = url + \"/gamelog/1954\"\n",
        "            time.sleep(5)\n",
        "            wd.get(remove_rr_url)\n",
        "            html = wd.page_source\n",
        "            soup = BeautifulSoup(html)\n",
        "            rr_df\n",
        "            selected_year = selected_year.sort_index(inplace=True)\n",
        "            rr_df = rr_df.sort_index(inplace=True)\n",
        "            print(selected_year['Tm'])\n",
        "\n",
        "            rr_df['Team'] = rr_df['Team'].astype(str)\n",
        "\n",
        "            selected_rr = rr_df[(rr_df['Team'] == selected_year['Tm'])]\n",
        "            rr_games = selected_rr['G']\n",
        "\n",
        "            # scrape Playoff shooting distribution data\n",
        "            for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "              second_div = first_div.find('div', attrs={'id': 'div_pgl_basic_playoffs'})\n",
        "              first_table = second_div.find('table', attrs={'id': 'pgl_basic_playoffs'})\n",
        "              header = first_table.find('thead')\n",
        "              body = first_table.find('tbody')\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "            print(headers)\n",
        "\n",
        "            # grab total stats\n",
        "            rows = body.findAll('tr')[0:]\n",
        "            player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "            player_total_stats = [e for e in player_total_stats if e != []]\n",
        "            #if player_total_stats[0, ]\n",
        "            print(player_total_stats)\n",
        "            print(total_fg)\n",
        "            total_fg = total_fg - (total_fg * (selected_year['G'] - rr_games))\n",
        "            print(total_fg)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0eOsSzoYechU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V5D3qCAUcglZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title NBA/ABA 1952-2022 Adjusted Playoff TS+\n",
        "def adjust_scoring_efficiency(url_df, nba_league_avg_df, aba_league_avg_df, nba_opp_ts_df, nba_opp_defrtg_df, aba_opp_ts_df, aba_opp_defrtg_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'TS+', 'PTS_coeff', 'MP'])\n",
        "    percent_iteration = 1\n",
        "\n",
        "    from itertools import chain\n",
        "\n",
        "    nba_league_avg_df['Year'] = nba_league_avg_df['Year'].astype(int)\n",
        "    nba_league_avg_df['Year'] = nba_league_avg_df['Year'].astype(str)\n",
        "\n",
        "    aba_league_avg_df['Year'] = aba_league_avg_df['Year'].astype(int)\n",
        "    aba_league_avg_df['Year'] = aba_league_avg_df['Year'].astype(str)\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      time.sleep(10)\n",
        "      print(player)\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        header = first_table.find('thead')\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "      series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "      #create df\n",
        "      series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      pts_count = 0\n",
        "      mp_count = 0\n",
        "      cols = []\n",
        "      for column in series_data.columns:\n",
        "        if column == 'MP':\n",
        "          if mp_count == 1:\n",
        "            cols.append(f'MPG')\n",
        "          else:\n",
        "            cols.append(f'MP')\n",
        "          mp_count+=1\n",
        "          continue\n",
        "        if column == 'PTS':\n",
        "          if pts_count == 1:\n",
        "            cols.append(f'PTS/G')\n",
        "          else:\n",
        "            cols.append(f'PTS')\n",
        "          pts_count+=1\n",
        "          continue\n",
        "        cols.append(column)\n",
        "      series_data.columns = cols\n",
        "\n",
        "\n",
        "      # remove seasons preceding 1952\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1954\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1951\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1950\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1949\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1948\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1947\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1946\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1945\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1944\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "      series_data = series_data.reset_index()\n",
        "\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      nba_opp_ts_df['Team'] = nba_opp_ts_df['Team'].astype(str)\n",
        "      nba_opp_ts_df['Year'] = nba_opp_ts_df['Year'].astype(str)\n",
        "      nba_opp_defrtg_df['Year'] = nba_opp_defrtg_df['Year'].astype(str)\n",
        "      nba_opp_defrtg_df['Year'] = nba_opp_defrtg_df['Year'].astype(str)\n",
        "      aba_opp_ts_df['Team'] = aba_opp_ts_df['Team'].astype(str)\n",
        "      aba_opp_ts_df['Year'] = aba_opp_ts_df['Year'].astype(str)\n",
        "      aba_opp_defrtg_df['Year'] = aba_opp_defrtg_df['Year'].astype(str)\n",
        "      aba_opp_defrtg_df['Year'] = aba_opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['G'] = series_data['G'].astype(float)\n",
        "\n",
        "      \n",
        "      # may be missing MP data.\n",
        "      # divide the missing estimated total numbers equally among games w/o MP data.\n",
        "      missing_mp_data = series_data.copy()\n",
        "      missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      years_list = []\n",
        "      \n",
        "      remaining_mp = []\n",
        "      missing_index = 0\n",
        "      \n",
        "      \n",
        "      for mp_idx, row in missing_mp_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_mp_data.loc[mp_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which MP aren't accounted for\n",
        "          working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # MP accounted for \n",
        "          accounted_for_mp = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_mp['MP'] = accounted_for_mp['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_mp.dropna(inplace=True)\n",
        "          accounted_for_mp = (accounted_for_mp['MP'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total MP\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "\n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_mp = selected_year['MP'].astype(float)\n",
        "          \n",
        "\n",
        "          # remaining MP contains estimated MP for this year's series with missing MP\n",
        "          remaining_mp.append(total_mp - accounted_for_mp)\n",
        "\n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            idx = int(idx)\n",
        "            if working_missing_year.shape[0]  == 1:\n",
        "              series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index])\n",
        "            elif working_missing_year.shape[0]  == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0]  == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      # may be missing FGA data.\n",
        "      # divide the missing estimated total numbers equally among games w/o FGA data.\n",
        "      missing_fg_data = series_data.copy()\n",
        "      missing_fg_data = missing_fg_data[(missing_fg_data['FGA'] == '')]\n",
        "      years_list = []\n",
        "      remaining_fg = []\n",
        "      missing_index = 0\n",
        "\n",
        "      for fg_idx, row in missing_fg_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_fg_data.loc[fg_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which FGA aren't accounted for \n",
        "          working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # FGA accounted for \n",
        "          accounted_for_fg = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_fg['FGA'] = accounted_for_fg['FGA'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_fg.dropna(inplace=True)\n",
        "          accounted_for_fg = (accounted_for_fg['FGA'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total FGA\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          from itertools import chain\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_fg = selected_year['FGA'].astype(float)\n",
        "          selected_year['Tm'] = selected_year['Tm'].astype(str)\n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          # remaining FGA contains estimated FGA for this year's series with missing FGA\n",
        "          remaining_fg.append(total_fg - accounted_for_fg)\n",
        "          \n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            if working_missing_year.shape[0] == 1:\n",
        "              series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index])\n",
        "            elif working_missing_year.shape[0] == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0] == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data['FGA'].iat[idx] = float(remaining_fg[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      series_data['TS+'] = 0\n",
        "      years_list = []\n",
        "\n",
        "      aba_teams = [\"DNA\", \"INA\", \"NYA\", \"SAA\", \"VIR\", \"CAR\", \"SDA\", \"KEN\",\n",
        "             \"UTS\", \"CAR\", \"SDS\", \"SSL\", \"MMS\", \"DNR\", \"PTP\", \"MNM\",\n",
        "             \"NOB\", \"DLC\", \"TEX\", \"HSM\", \"OAK\", \"MMF\", \"MNP\", \"WSA\",\n",
        "             \"LAS\", \"FLO\", \"MMP\", \"NJA\", \"ANA\", \"PTC\", \"MMT\"]\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "\n",
        "        if current_opp in aba_teams:\n",
        "          if current_year <= '1973':\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = aba_opp_defrtg_df[(aba_opp_defrtg_df['Team'] == current_opp) & ((aba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            this_year = aba_league_avg_df[(aba_league_avg_df['Year'] == current_year)]\n",
        "            league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "            league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "            # estimate TS+ allowed\n",
        "            predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "            #find raw TS% compared to league average\n",
        "            raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed) * 100)\n",
        "            series_data.loc[i,'TS+'] = tsplus\n",
        "            series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "          else:\n",
        "            # get ts% allowed by opponent\n",
        "            opponent_ts = aba_opp_ts_df[(aba_opp_ts_df['Team'] == current_opp) & ((aba_opp_ts_df['Year'] == current_year))]\n",
        "            opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = aba_opp_defrtg_df[(aba_opp_defrtg_df['Team'] == current_opp) & ((aba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "            series_data.loc[i,'TS+'] = tsplus\n",
        "            series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "\n",
        "        else:\n",
        "          if current_year <= '1973':\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = nba_opp_defrtg_df[(nba_opp_defrtg_df['Team'] == current_opp) & ((nba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            this_year = nba_league_avg_df[(nba_league_avg_df['Year'] == current_year)]\n",
        "            league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "            league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "            # estimate TS+ allowed\n",
        "            predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "            #find raw TS% compared to league average\n",
        "            raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed) * 100)\n",
        "            series_data.loc[i,'TS+'] = tsplus\n",
        "            series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "          else:\n",
        "            # get ts% allowed by opponent\n",
        "            opponent_ts = nba_opp_ts_df[(nba_opp_ts_df['Team'] == current_opp) & ((nba_opp_ts_df['Year'] == current_year))]\n",
        "            opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = nba_opp_defrtg_df[(nba_opp_defrtg_df['Team'] == current_opp) & ((nba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "            series_data.loc[i,'TS+'] = tsplus\n",
        "            series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'FGA', 'FTA', 'PTS', 'MPG'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = series_data[(series_data['Year'] == year)]\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "\n",
        "        new_row = pd.DataFrame(np.array([[player, year, total_ts, total_coeff, int(total_mp)]]), columns=['Player', 'Year', 'TS+', 'PTS_coeff', 'MP'])\n",
        "        final_season_df = pd.concat([final_season_df, new_row], ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "      outfile = f\"Playoff_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)\n",
        "    print(final_season_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPP2QwEUVAKq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run Adjusted Playoff TS+\n",
        "url_df = pd.read_csv('/content/tmp.csv', index_col=False, encoding='utf8')\n",
        "url_df = url_df.drop('MP', axis=1)\n",
        "\n",
        "nba_opp_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "nba_opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "aba_opp_ts_allowed_df = pd.read_csv('/content/ABA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "aba_opponent_adj_pts_coeff = pd.read_csv('/content/aba_opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "\n",
        "# correlation will be used to estimate TS%'s allowed by teams from 1952-1973\n",
        "rdRtg = pd.read_csv(\"/content/remove reg teams.csv\", index_col=False, encoding='utf8')\n",
        "rTS = pd.read_csv(\"/content/NBA_Team_TS_Percentage_Allowed_df.csv\", index_col=False, encoding='utf8')\n",
        "\n",
        "rTS['Year'] = rTS['Year'].astype(int)\n",
        "league_avg_df['Year'] = league_avg_df['Year'].astype(float)\n",
        "\n",
        "rTS['rTS'] = 0\n",
        "\n",
        "for idx, row in rTS.iterrows():     \n",
        "          match_df = league_avg_df[(league_avg_df['Year'] == row['Year'])]\n",
        "          rTS.iat[idx, 3] = float(rTS.iat[idx, 2] / (match_df['TS%']))\n",
        "          \n",
        "rTS = rTS.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "rdRtg = rdRtg.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "import scipy.stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "x_pred = rdRtg['PTS_coeff']\n",
        "x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "y_pred = rTS['rTS']\n",
        "\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(x_pred, y_pred)\n",
        "pred = lr.predict(x_pred)\n",
        "\n",
        "adjust_scoring_efficiency(url_df, league_avg_df, aba_league_avg, nba_opp_ts_allowed_df, nba_opponent_adj_pts_coeff, aba_opp_ts_allowed_df, aba_opponent_adj_pts_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dunca_ad = pd.read_csv('/content/adj_ts_74_22_playoffs_per75_data.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "hed = pd.DataFrame()\n",
        "\n",
        "hed['Player'] = dunca_ad['Player']\n",
        "hed['Playoffs'] = dunca_ad['Year']\n",
        "hed['PTS'] = dunca_ad['PTS']\n",
        "hed['TS+'] = dunca_ad['TS%+']\n",
        "hed['MP'] = dunca_ad['MP']\n",
        "\n",
        "hed['PTS'] = dunca_ad['PTS'].round(2)\n",
        "\n",
        "hed.to_csv('output.csv', index=False)\n",
        "\n",
        "print(hed)"
      ],
      "metadata": {
        "id": "vVoXGRlQTyiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uavrTm3rmdeb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Create DataFrame of Adjusted TS+ Data and Adjust for Era\n",
        "\n",
        "# NBA 1974-2022\n",
        "nba_74_23 = pd.read_csv('/content/nba_player_since74playoffs_per75_data.csv', index_col=False, encoding='utf8')\n",
        "adj_ts_list = pd.read_csv('/content/Playoff_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "# ABA 1974-76\n",
        "aba_74_76 = pd.read_csv('/content/aba_player_since74playoffs_per75_data.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "# ABA 1968-73\n",
        "aba_68_73 = pd.read_csv('/content/68-73_playoff_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "# NBA 1952-73\n",
        "nba_52_73 = pd.read_csv('/content/52-73_playoff_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# NBA 1974-2022\n",
        "names = [x for x in nba_74_22.columns]\n",
        "adjusted_playoff_per_75_df = pd.DataFrame(columns=names)\n",
        "\n",
        "for outer_index, adj_player_season in adj_ts_list.iterrows():\n",
        "\n",
        "  adj_player_season['Player'] = str(adj_player_season['Player'])\n",
        "  adj_player_season['Year'] = str(adj_player_season['Year'])\n",
        "  nba_74_22['Player'] = nba_74_22['Player'].astype(str)\n",
        "  nba_74_22['Year'] = nba_74_22['Year'].astype(str)\n",
        "\n",
        "  current_player = adj_player_season.loc['Player']\n",
        "  current_year = adj_player_season.loc['Year']\n",
        "  smaller_start_adj_list = nba_74_22[(nba_74_22['Player'] == current_player) & ((nba_74_22['Year'] == current_year))]\n",
        "  smaller_start_adj_list['TS%+'] = adj_player_season['TS+']\n",
        "  smaller_start_adj_list['PTS'] = smaller_start_adj_list['PTS'] * adj_player_season['PTS_coeff']\n",
        "  adjusted_playoff_per_75_df = pd.concat([adjusted_playoff_per_75_df, smaller_start_adj_list], ignore_index=True)\n",
        "\n",
        "print(adjusted_playoff_per_75_df)\n",
        "outfile = f\"adj_ts_74_22_playoffs_per75_data.csv\"\n",
        "adjusted_playoff_per_75_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# NBA 1952-73\n",
        "names = [x for x in nba_52_73.columns]\n",
        "adjusted_playoff_per_75_df = pd.DataFrame(columns=names)\n",
        "\n",
        "for outer_index, adj_player_season in adj_ts_list.iterrows():\n",
        "\n",
        "  adj_player_season['Player'] = str(adj_player_season['Player'])\n",
        "  adj_player_season['Year'] = str(adj_player_season['Year'])\n",
        "  nba_52_73['Player'] = nba_52_73['Player'].astype(str)\n",
        "  nba_52_73['Year'] = nba_52_73['Year'].astype(str)\n",
        "\n",
        "  current_player = adj_player_season.loc['Player']\n",
        "  current_year = adj_player_season.loc['Year']\n",
        "  smaller_start_adj_list = nba_52_73[(nba_52_73['Player'] == current_player) & ((nba_52_73['Year'] == current_year))]\n",
        "  smaller_start_adj_list['TS%+'] = adj_player_season['TS+']\n",
        "  smaller_start_adj_list['PTS'] = smaller_start_adj_list['PTS'] * adj_player_season['PTS_coeff']\n",
        "  adjusted_playoff_per_75_df = pd.concat([adjusted_playoff_per_75_df, smaller_start_adj_list], ignore_index=True)\n",
        "print(adjusted_playoff_per_75_df)\n",
        "outfile = f\"adj_ts_52_73_playoffs_per75_data.csv\"\n",
        "adjusted_playoff_per_75_df.to_csv(outfile, index=False)\n",
        "\n",
        "# ABA 1968-73\n",
        "names = [x for x in aba_68_73.columns]\n",
        "adjusted_playoff_per_75_df = pd.DataFrame(columns=names)\n",
        "\n",
        "for outer_index, adj_player_season in adj_ts_list.iterrows():\n",
        "\n",
        "  adj_player_season['Player'] = str(adj_player_season['Player'])\n",
        "  adj_player_season['Year'] = str(adj_player_season['Year'])\n",
        "  aba_68_73['Player'] = aba_68_73['Player'].astype(str)\n",
        "  aba_68_73['Year'] = aba_68_73['Year'].astype(str)\n",
        "\n",
        "  current_player = adj_player_season.loc['Player']\n",
        "  current_year = adj_player_season.loc['Year']\n",
        "  smaller_start_adj_list = aba_68_73[(aba_68_73['Player'] == current_player) & ((aba_68_73['Year'] == current_year))]\n",
        "  smaller_start_adj_list['TS%+'] = adj_player_season['TS+']\n",
        "  smaller_start_adj_list['PTS'] = smaller_start_adj_list['PTS'] * adj_player_season['PTS_coeff']\n",
        "  adjusted_playoff_per_75_df = pd.concat([adjusted_playoff_per_75_df, smaller_start_adj_list], ignore_index=True)\n",
        "print(adjusted_playoff_per_75_df)\n",
        "outfile = f\"adj_ts_68_73_playoffs_per75_data.csv\"\n",
        "adjusted_playoff_per_75_df.to_csv(outfile, index=False)\n",
        "\n",
        "# ABA 1974-76\n",
        "names = [x for x in aba_74_76.columns]\n",
        "adjusted_playoff_per_75_df = pd.DataFrame(columns=names)\n",
        "\n",
        "for outer_index, adj_player_season in adj_ts_list.iterrows():\n",
        "\n",
        "  adj_player_season['Player'] = str(adj_player_season['Player'])\n",
        "  adj_player_season['Year'] = str(adj_player_season['Year'])\n",
        "  aba_74_76['Player'] = aba_74_76['Player'].astype(str)\n",
        "  aba_74_76['Year'] = aba_74_76['Year'].astype(str)\n",
        "\n",
        "  current_player = adj_player_season.loc['Player']\n",
        "  current_year = adj_player_season.loc['Year']\n",
        "  smaller_start_adj_list = aba_74_76[(aba_74_76['Player'] == current_player) & ((aba_74_76['Year'] == current_year))]\n",
        "  smaller_start_adj_list['TS%+'] = adj_player_season['TS+']\n",
        "  smaller_start_adj_list['PTS'] = smaller_start_adj_list['PTS'] * adj_player_season['PTS_coeff']\n",
        "  adjusted_playoff_per_75_df = pd.concat([adjusted_playoff_per_75_df, smaller_start_adj_list], ignore_index=True)\n",
        "print(adjusted_playoff_per_75_df)\n",
        "outfile = f\"adj_ts_74_76_playoffs_per75_data.csv\"\n",
        "adjusted_playoff_per_75_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Era Adjustment\n",
        "playoff_75_data = pd.read_csv('/content/adj_ts_52_73_playoffs_per75_data.csv')\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in playoff_75_data.iterrows():\n",
        "  era_adj = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PTS'] = float(row['PTS']) * float(era_adj['Coefficient'])\n",
        "  new_df = pd.concat([new_df, row], ignore_index=True)\n",
        "outfile = f\"52_73_era_opponent_adjusted_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# Era Adjustment\n",
        "playoff_75_data = pd.read_csv('/content/adj_ts_68_73_playoffs_per75_data.csv')\n",
        "\n",
        "per_75_coeff = pd.read_csv('/content/Avg_ABA_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in playoff_75_data.iterrows():\n",
        "  era_adj = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PTS'] = float(row['PTS']) * float(era_adj['Coefficient'])\n",
        "  new_df = pd.concat([new_df, row], ignore_index=True)\n",
        "outfile = f\"68_73_era_opponent_adjusted_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# Era Adjustment\n",
        "playoff_75_data = pd.read_csv('adj_ts_74_76_playoffs_per75_data.csv')\n",
        "\n",
        "per_75_coeff = pd.read_csv('/content/Avg_ABA_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in playoff_75_data.iterrows():\n",
        "  era_adj = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PTS'] = float(row['PTS']) * float(era_adj['Coefficient'])\n",
        "  new_df = pd.concat([new_df, row], ignore_index=True)\n",
        "outfile = f\"74_76_era_opponent_adjusted_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# Era Adjustment\n",
        "playoff_75_data = pd.read_csv('adj_ts_74_22_playoffs_per75_data.csv')\n",
        "\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in playoff_75_data.iterrows():\n",
        "  era_adj = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PTS'] = float(row['PTS']) * float(era_adj['Coefficient'])\n",
        "  new_df = pd.concat([new_df, row], ignore_index=True)\n",
        "outfile = f\"74_22_era_opponent_adjusted_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(SERIES) NBA/ABA 1952-2022 ADJUSTED PLAYOFF TS+**"
      ],
      "metadata": {
        "id": "cN597LQBcjLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (SERIES) NBA/ABA 1952-2022 Adjusted Playoff TS+\n",
        "def adjust_scoring_efficiency_series(url_df, nba_league_avg_df, aba_league_avg_df, nba_opp_ts_df, nba_opp_defrtg_df, aba_opp_ts_df, aba_opp_defrtg_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'Opp', 'PTS/G', 'TS+', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    from itertools import chain\n",
        "\n",
        "    nba_league_avg_df['Year'] = nba_league_avg_df['Year'].astype(int)\n",
        "    nba_league_avg_df['Year'] = nba_league_avg_df['Year'].astype(str)\n",
        "\n",
        "    aba_league_avg_df['Year'] = aba_league_avg_df['Year'].astype(int)\n",
        "    aba_league_avg_df['Year'] = aba_league_avg_df['Year'].astype(str)\n",
        "\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      time.sleep(5)\n",
        "      print(player)\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        header = first_table.find('thead')\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "      series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "      #create df\n",
        "      series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      pts_count = 0\n",
        "      mp_count = 0\n",
        "      cols = []\n",
        "      # replace second PTS column with PTS/G\n",
        "      # same for MP and MPG\n",
        "      for column in series_data.columns:\n",
        "        if column == 'MP':\n",
        "          if mp_count == 1:\n",
        "            cols.append(f'MPG')\n",
        "          else:\n",
        "            cols.append(f'MP')\n",
        "          mp_count+=1\n",
        "          continue\n",
        "        if column == 'PTS':\n",
        "          if pts_count == 1:\n",
        "            cols.append(f'PTS/G')\n",
        "          else:\n",
        "            cols.append(f'PTS')\n",
        "          pts_count+=1\n",
        "          continue\n",
        "        cols.append(column)\n",
        "      series_data.columns = cols\n",
        "\n",
        "      # remove seasons preceding 1952\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1954\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1951\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1950\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1949\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1948\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1947\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1946\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1945\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1944\", float('NaN'))\n",
        "\n",
        "      missing_mp_data = series_data.copy()\n",
        "      missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      \n",
        "      # if age column is blank then replace with NaN to it's easy to drop\n",
        "      # these are rows from missed playoffs\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "      series_data = series_data.reset_index()\n",
        "      series_data['G'] = series_data['G'].astype(float)\n",
        "\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['PTS/G'] = series_data['PTS/G'].astype(float)\n",
        "      nba_opp_ts_df['Team'] = nba_opp_ts_df['Team'].astype(str)\n",
        "      nba_opp_ts_df['Year'] = nba_opp_ts_df['Year'].astype(str)\n",
        "      nba_opp_defrtg_df['Year'] = nba_opp_defrtg_df['Year'].astype(str)\n",
        "      nba_opp_defrtg_df['Year'] = nba_opp_defrtg_df['Year'].astype(str)\n",
        "      aba_opp_ts_df['Team'] = aba_opp_ts_df['Team'].astype(str)\n",
        "      aba_opp_ts_df['Year'] = aba_opp_ts_df['Year'].astype(str)\n",
        "      aba_opp_defrtg_df['Year'] = aba_opp_defrtg_df['Year'].astype(str)\n",
        "      aba_opp_defrtg_df['Year'] = aba_opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "      # may be missing MP data.\n",
        "      # divide the missing estimated total numbers equally among games w/o MP data.\n",
        "      missing_mp_data = series_data.copy()\n",
        "      missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      years_list = []\n",
        "      \n",
        "      remaining_mp = []\n",
        "      missing_index = 0\n",
        "      for mp_idx, row in missing_mp_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_mp_data.loc[mp_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which MP aren't accounted for\n",
        "          working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # MP accounted for \n",
        "          accounted_for_mp = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_mp['MP'] = accounted_for_mp['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_mp.dropna(inplace=True)\n",
        "          accounted_for_mp = (accounted_for_mp['MP'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total MP\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "\n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_mp = selected_year['MP'].astype(float)\n",
        "        \n",
        "          # remaining MP contains estimated MP for this year's series with missing MP\n",
        "          remaining_mp.append(total_mp - accounted_for_mp)\n",
        "\n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            idx = int(idx)\n",
        "            if working_missing_year.shape[0]  == 1:\n",
        "              series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index])\n",
        "            elif working_missing_year.shape[0]  == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0]  == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # may be missing FGA data.\n",
        "      # divide the missing estimated total numbers equally among games w/o FGA data.\n",
        "      missing_fg_data = series_data.copy()\n",
        "      missing_fg_data = missing_fg_data[(missing_fg_data['FGA'] == '')]\n",
        "      years_list = []\n",
        "      remaining_fg = []\n",
        "      missing_index = 0\n",
        "\n",
        "      for fg_idx, row in missing_fg_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_fg_data.loc[fg_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which FGA aren't accounted for \n",
        "          working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # FGA accounted for \n",
        "          accounted_for_fg = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_fg['FGA'] = accounted_for_fg['FGA'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_fg.dropna(inplace=True)\n",
        "          accounted_for_fg = (accounted_for_fg['FGA'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total FGA\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          from itertools import chain\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_fg = selected_year['FGA'].astype(float)\n",
        "          selected_year['Tm'] = selected_year['Tm'].astype(str)\n",
        "\n",
        "          # remaining FGA contains estimated FGA for this year's series with missing FGA\n",
        "          remaining_fg.append(total_fg - accounted_for_fg)\n",
        "          \n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            if working_missing_year.shape[0] == 1:\n",
        "              series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index])\n",
        "            elif working_missing_year.shape[0] == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0] == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "\n",
        "      # may be missing FTA data.\n",
        "      # divide the missing estimated total numbers equally among games w/o FTA data.\n",
        "      missing_ft_data = series_data.copy()\n",
        "      missing_ft_data = missing_ft_data[(missing_ft_data['FTA'] == '')]\n",
        "      years_list = []\n",
        "      remaining_ft = []\n",
        "      missing_index = 0\n",
        "\n",
        "      for fg_idx, row in missing_ft_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_ft_data.loc[fg_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_ft_data[(missing_ft_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which FTA aren't accounted for \n",
        "          working_missing_year = missing_ft_data[(missing_ft_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # FTA accounted for \n",
        "          accounted_for_ft = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_ft['FTA'] = accounted_for_ft['FTA'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_ft.dropna(inplace=True)\n",
        "          accounted_for_ft = (accounted_for_ft['FTA'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total FTA\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          from itertools import chain\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_ft = selected_year['FTA'].astype(float)\n",
        "          selected_year['Tm'] = selected_year['Tm'].astype(str)\n",
        "\n",
        "          # remaining FTA contains estimated FTA for this year's series with missing FTA\n",
        "          remaining_ft.append(total_ft - accounted_for_ft)\n",
        "          \n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            if working_missing_year.shape[0] == 1:\n",
        "              print(remaining_ft)\n",
        "              print(missing_index)\n",
        "              series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index])\n",
        "            elif working_missing_year.shape[0] == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0] == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      series_data['MP'] = series_data['MP'].astype(int)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['TS+'] = 0\n",
        "      years_list = []\n",
        "\n",
        "      aba_teams = [\"DNA\", \"INA\", \"NYA\", \"SAA\", \"VIR\", \"CAR\", \"SDA\", \"KEN\",\n",
        "             \"UTS\", \"CAR\", \"SDS\", \"SSL\", \"MMS\", \"DNR\", \"PTP\", \"MNM\",\n",
        "             \"NOB\", \"DLC\", \"TEX\", \"HSM\", \"OAK\", \"MMF\", \"MNP\", \"WSA\",\n",
        "             \"LAS\", \"FLO\", \"MMP\", \"NJA\", \"ANA\", \"PTC\", \"MMT\"]\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "\n",
        "        if current_opp in aba_teams:\n",
        "          if current_year <= '1973':\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = aba_opp_defrtg_df[(aba_opp_defrtg_df['Team'] == current_opp) & ((aba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            this_year = aba_league_avg_df[(aba_league_avg_df['Year'] == current_year)]\n",
        "            league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "            league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "            # estimate TS+ allowed\n",
        "            predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "            #find raw TS% compared to league average\n",
        "            raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed)) * 100\n",
        "            pts = row['PTS/G']\n",
        "            tsplus = '%.2f' % round(tsplus, 2)\n",
        "            pts = pts * pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "            new_row = pd.DataFrame(np.array([[player, current_year, current_opp, pts, tsplus, int(total_mp)]]), columns=['Player', 'Year', 'Opp', 'PTS/G', 'TS+', 'MP'])\n",
        "            final_season_df = pd.concat([final_season_df, new_row], ignore_index=True)\n",
        "          else:\n",
        "            # get ts% allowed by opponent\n",
        "            opponent_ts = aba_opp_ts_df[(aba_opp_ts_df['Team'] == current_opp) & ((aba_opp_ts_df['Year'] == current_year))]\n",
        "            opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = aba_opp_defrtg_df[(aba_opp_defrtg_df['Team'] == current_opp) & ((aba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            if row['PTS/G'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "            pts = row['PTS/G']\n",
        "            tsplus = '%.2f' % round(tsplus, 2)\n",
        "            pts = pts * pts_coeff\n",
        "\n",
        "            new_row = pd.DataFrame(np.array([[player, current_year, current_opp, pts, tsplus, int(total_mp)]]), columns=['Player', 'Year', 'Opp', 'PTS/G', 'TS+', 'MP'])\n",
        "            final_season_df = pd.concat([final_season_df, new_row], ignore_index=True)\n",
        "\n",
        "        else:\n",
        "          if current_year <= '1973':\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = nba_opp_defrtg_df[(nba_opp_defrtg_df['Team'] == current_opp) & ((nba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            this_year = nba_league_avg_df[(nba_league_avg_df['Year'] == current_year)]\n",
        "            league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "            league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "            # estimate TS+ allowed\n",
        "            predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "            #find raw TS% compared to league average\n",
        "            raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed)) * 100\n",
        "            pts = row['PTS/G']\n",
        "            tsplus = '%.2f' % round(tsplus, 2)\n",
        "            pts = pts * pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "            new_row = pd.DataFrame(np.array([[player, current_year, current_opp, pts, tsplus, int(total_mp)]]), columns=['Player', 'Year', 'Opp', 'PTS/G', 'TS+', 'MP'])\n",
        "            final_season_df = pd.concat([final_season_df, new_row], ignore_index=True)\n",
        "          else:\n",
        "            # get ts% allowed by opponent\n",
        "            opponent_ts = nba_opp_ts_df[(nba_opp_ts_df['Team'] == current_opp) & ((nba_opp_ts_df['Year'] == current_year))]\n",
        "            opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = nba_opp_defrtg_df[(nba_opp_defrtg_df['Team'] == current_opp) & ((nba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            if row['PTS/G'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "            pts = row['PTS/G']\n",
        "            tsplus = '%.2f' % round(tsplus, 2)\n",
        "            pts = pts * pts_coeff\n",
        "\n",
        "            new_row = pd.DataFrame(np.array([[player, current_year, current_opp, pts, tsplus, int(total_mp)]]), columns=['Player', 'Year', 'Opp', 'PTS/G', 'TS+', 'MP'])\n",
        "            final_season_df = pd.concat([final_season_df, new_row], ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "      outfile = f\"Playoff_Series_Adjusted_Scoring_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "x3hfZs8iYZIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (SERIES) NBA/ABA 1952-2022 Adjusted Playoff TS+ (w/ MPG and round)\n",
        "def adjust_scoring_efficiency_series(url_df, nba_league_avg_df, aba_league_avg_df, nba_opp_ts_df, nba_opp_defrtg_df, aba_opp_ts_df, aba_opp_defrtg_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'Opp', 'Round', 'PTS/G', 'TS+', 'MP', 'MPG'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    from itertools import chain\n",
        "\n",
        "    nba_league_avg_df['Year'] = nba_league_avg_df['Year'].astype(int)\n",
        "    nba_league_avg_df['Year'] = nba_league_avg_df['Year'].astype(str)\n",
        "\n",
        "    aba_league_avg_df['Year'] = aba_league_avg_df['Year'].astype(int)\n",
        "    aba_league_avg_df['Year'] = aba_league_avg_df['Year'].astype(str)\n",
        "\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      time.sleep(5)\n",
        "      print(player)\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        header = first_table.find('thead')\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "      series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "      #create df\n",
        "      series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      pts_count = 0\n",
        "      mp_count = 0\n",
        "      cols = []\n",
        "      # replace second PTS column with PTS/G\n",
        "      # same for MP and MPG\n",
        "      for column in series_data.columns:\n",
        "        if column == 'MP':\n",
        "          if mp_count == 1:\n",
        "            cols.append(f'MPG')\n",
        "          else:\n",
        "            cols.append(f'MP')\n",
        "          mp_count+=1\n",
        "          continue\n",
        "        if column == 'PTS':\n",
        "          if pts_count == 1:\n",
        "            cols.append(f'PTS/G')\n",
        "          else:\n",
        "            cols.append(f'PTS')\n",
        "          pts_count+=1\n",
        "          continue\n",
        "        cols.append(column)\n",
        "      series_data.columns = cols\n",
        "\n",
        "      # remove seasons preceding 1952\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1954\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1951\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1950\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1949\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1948\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1947\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1946\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1945\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1944\", float('NaN'))\n",
        "\n",
        "      missing_mp_data = series_data.copy()\n",
        "      missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      \n",
        "      # if age column is blank then replace with NaN to it's easy to drop\n",
        "      # these are rows from missed playoffs\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "      series_data = series_data.reset_index()\n",
        "      series_data['G'] = series_data['G'].astype(float)\n",
        "\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['PTS/G'] = series_data['PTS/G'].astype(float)\n",
        "      nba_opp_ts_df['Team'] = nba_opp_ts_df['Team'].astype(str)\n",
        "      nba_opp_ts_df['Year'] = nba_opp_ts_df['Year'].astype(str)\n",
        "      nba_opp_defrtg_df['Year'] = nba_opp_defrtg_df['Year'].astype(str)\n",
        "      nba_opp_defrtg_df['Year'] = nba_opp_defrtg_df['Year'].astype(str)\n",
        "      aba_opp_ts_df['Team'] = aba_opp_ts_df['Team'].astype(str)\n",
        "      aba_opp_ts_df['Year'] = aba_opp_ts_df['Year'].astype(str)\n",
        "      aba_opp_defrtg_df['Year'] = aba_opp_defrtg_df['Year'].astype(str)\n",
        "      aba_opp_defrtg_df['Year'] = aba_opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['Round'] = series_data['Round'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "      # may be missing MP data.\n",
        "      # divide the missing estimated total numbers equally among games w/o MP data.\n",
        "      missing_mp_data = series_data.copy()\n",
        "      missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      years_list = []\n",
        "      \n",
        "      remaining_mp = []\n",
        "      missing_index = 0\n",
        "      for mp_idx, row in missing_mp_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_mp_data.loc[mp_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which MP aren't accounted for\n",
        "          working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # MP accounted for \n",
        "          accounted_for_mp = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_mp['MP'] = accounted_for_mp['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_mp.dropna(inplace=True)\n",
        "          accounted_for_mp = (accounted_for_mp['MP'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total MP\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "\n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_mp = selected_year['MP'].astype(float)\n",
        "        \n",
        "          # remaining MP contains estimated MP for this year's series with missing MP\n",
        "          remaining_mp.append(total_mp - accounted_for_mp)\n",
        "\n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            idx = int(idx)\n",
        "            if working_missing_year.shape[0]  == 1:\n",
        "              series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index])\n",
        "            elif working_missing_year.shape[0]  == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0]  == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # may be missing FGA data.\n",
        "      # divide the missing estimated total numbers equally among games w/o FGA data.\n",
        "      missing_fg_data = series_data.copy()\n",
        "      missing_fg_data = missing_fg_data[(missing_fg_data['FGA'] == '')]\n",
        "      years_list = []\n",
        "      remaining_fg = []\n",
        "      missing_index = 0\n",
        "\n",
        "      for fg_idx, row in missing_fg_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_fg_data.loc[fg_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which FGA aren't accounted for \n",
        "          working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # FGA accounted for \n",
        "          accounted_for_fg = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_fg['FGA'] = accounted_for_fg['FGA'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_fg.dropna(inplace=True)\n",
        "          accounted_for_fg = (accounted_for_fg['FGA'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total FGA\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          from itertools import chain\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_fg = selected_year['FGA'].astype(float)\n",
        "          selected_year['Tm'] = selected_year['Tm'].astype(str)\n",
        "\n",
        "          # remaining FGA contains estimated FGA for this year's series with missing FGA\n",
        "          remaining_fg.append(total_fg - accounted_for_fg)\n",
        "          \n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            if working_missing_year.shape[0] == 1:\n",
        "              series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index])\n",
        "            elif working_missing_year.shape[0] == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0] == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "\n",
        "      # may be missing FTA data.\n",
        "      # divide the missing estimated total numbers equally among games w/o FTA data.\n",
        "      missing_ft_data = series_data.copy()\n",
        "      missing_ft_data = missing_ft_data[(missing_ft_data['FTA'] == '')]\n",
        "      years_list = []\n",
        "      remaining_ft = []\n",
        "      missing_index = 0\n",
        "\n",
        "      for ft_idx, row in missing_ft_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_ft_data.loc[ft_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_ft_data[(missing_ft_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which FTA aren't accounted for \n",
        "          working_missing_year = missing_ft_data[(missing_ft_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # FTA accounted for \n",
        "          accounted_for_ft = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_ft['FTA'] = accounted_for_ft['FTA'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_ft.dropna(inplace=True)\n",
        "          accounted_for_ft = (accounted_for_ft['FTA'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total FTA\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          from itertools import chain\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_ft = selected_year['FTA'].astype(float)\n",
        "          selected_year['Tm'] = selected_year['Tm'].astype(str)\n",
        "\n",
        "          # remaining FTA contains estimated FTA for this year's series with missing FTA\n",
        "          remaining_ft.append(total_ft - accounted_for_ft)\n",
        "          \n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            if working_missing_year.shape[0] == 1:\n",
        "              series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index])\n",
        "            elif working_missing_year.shape[0] == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0] == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FTA\"] ] = float(remaining_ft[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "\n",
        "      \n",
        "\n",
        "      # may be missing MPG data.\n",
        "      # divide the missing estimated total numbers equally among games w/o MPG data.\n",
        "      missing_mpg_data = series_data.copy()\n",
        "      missing_mpg_data = missing_mpg_data[(missing_mpg_data['MPG'] == '')]\n",
        "      years_list = []\n",
        "      remaining_mpg = []\n",
        "      missing_index = 0\n",
        "\n",
        "      for mpg_idx, row in missing_mpg_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_mpg_data.loc[mpg_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_mpg_data[(missing_mpg_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which MPG aren't accounted for \n",
        "          working_missing_year = missing_mpg_data[(missing_mpg_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # MPG accounted for \n",
        "          accounted_for_mpg = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_mpg['MPG'] = accounted_for_mpg['MPG'].replace(r'[^<>]+', float('NaN'), regex = True)\n",
        "          accounted_for_mpg.dropna(inplace=True)\n",
        "          accounted_for_mpg = (accounted_for_mpg['MP'].astype(float)).sum() \n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          remaining_mpg.append(accounted_for_mpg)\n",
        "          \n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            if working_missing_year.shape[0] == 1:\n",
        "              series_data.loc[idx, [\"MPG\"] ] = float(remaining_mpg[missing_index]) / series_data.loc[idx, [\"G\"] ].values\n",
        "            elif working_missing_year.shape[0] == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MPG\"] ] = (float(remaining_mpg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))) / series_data.loc[idx, [\"G\"] ].values\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MPG\"] ] = (float(remaining_mpg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))) / series_data.loc[idx, [\"G\"] ].values\n",
        "            elif working_missing_year.shape[0] == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MPG\"] ] = (float(remaining_mpg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))) / series_data.loc[idx, [\"G\"] ].values\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"MPG\"] ] = (float(remaining_mpg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))) / series_data.loc[idx, [\"G\"] ].values\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MPG\"] ] = (float(remaining_mpg[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))) / series_data.loc[idx, [\"G\"] ].values\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      series_data['MP'] = series_data['MP'].astype(int)\n",
        "      series_data['MPG'] = series_data['MPG'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['TS+'] = 0\n",
        "      years_list = []\n",
        "\n",
        "      aba_teams = [\"DNA\", \"INA\", \"NYA\", \"SAA\", \"VIR\", \"CAR\", \"SDA\", \"KEN\",\n",
        "             \"UTS\", \"CAR\", \"SDS\", \"SSL\", \"MMS\", \"DNR\", \"PTP\", \"MNM\",\n",
        "             \"NOB\", \"DLC\", \"TEX\", \"HSM\", \"OAK\", \"MMF\", \"MNP\", \"WSA\",\n",
        "             \"LAS\", \"FLO\", \"MMP\", \"NJA\", \"ANA\", \"PTC\", \"MMT\"]\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "\n",
        "        if current_opp in aba_teams:\n",
        "          if current_year <= '1973':\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = aba_opp_defrtg_df[(aba_opp_defrtg_df['Team'] == current_opp) & ((aba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            this_year = aba_league_avg_df[(aba_league_avg_df['Year'] == current_year)]\n",
        "            league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "            league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "            # estimate TS+ allowed\n",
        "            predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "            #find raw TS% compared to league average\n",
        "            raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed)) * 100\n",
        "            pts = row['PTS/G']\n",
        "            tsplus = '%.2f' % round(tsplus, 2)\n",
        "            pts = pts * pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "            new_row = pd.DataFrame(np.array([[player, current_year, current_opp, row['Round'], pts, tsplus, int(total_mp), float(row['MPG'])]]), columns=['Player', 'Year', 'Opp', 'Round', 'PTS/G', 'TS+', 'MP', 'MPG'])\n",
        "            final_season_df = pd.concat([final_season_df, new_row], ignore_index=True)\n",
        "          else:\n",
        "            # get ts% allowed by opponent\n",
        "            opponent_ts = aba_opp_ts_df[(aba_opp_ts_df['Team'] == current_opp) & ((aba_opp_ts_df['Year'] == current_year))]\n",
        "            opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = aba_opp_defrtg_df[(aba_opp_defrtg_df['Team'] == current_opp) & ((aba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            if row['PTS/G'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "            pts = row['PTS/G']\n",
        "            tsplus = '%.2f' % round(tsplus, 2)\n",
        "            pts = pts * pts_coeff\n",
        "\n",
        "            new_row = pd.DataFrame(np.array([[player, current_year, current_opp, row['Round'], pts, tsplus, int(total_mp), float(row['MPG'])]]), columns=['Player', 'Year', 'Opp', 'Round', 'PTS/G', 'TS+', 'MP', 'MPG'])\n",
        "            final_season_df = pd.concat([final_season_df, new_row], ignore_index=True)\n",
        "\n",
        "        else:\n",
        "          if current_year <= '1973':\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = nba_opp_defrtg_df[(nba_opp_defrtg_df['Team'] == current_opp) & ((nba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            this_year = nba_league_avg_df[(nba_league_avg_df['Year'] == current_year)]\n",
        "            league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "            league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "            # estimate TS+ allowed\n",
        "            predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "            #find raw TS% compared to league average\n",
        "            raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed)) * 100\n",
        "            pts = row['PTS/G']\n",
        "            tsplus = '%.2f' % round(tsplus, 2)\n",
        "            pts = pts * pts_coeff\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "            new_row = pd.DataFrame(np.array([[player, current_year, current_opp, row['Round'], pts, tsplus, int(total_mp), float(row['MPG'])]]), columns=['Player', 'Year', 'Opp', 'Round', 'PTS/G', 'TS+', 'MP', 'MPG'])\n",
        "            final_season_df = pd.concat([final_season_df, new_row], ignore_index=True)\n",
        "          else:\n",
        "            # get ts% allowed by opponent\n",
        "            opponent_ts = nba_opp_ts_df[(nba_opp_ts_df['Team'] == current_opp) & ((nba_opp_ts_df['Year'] == current_year))]\n",
        "            opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = nba_opp_defrtg_df[(nba_opp_defrtg_df['Team'] == current_opp) & ((nba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            if row['PTS/G'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "            pts = row['PTS/G']\n",
        "            tsplus = '%.2f' % round(tsplus, 2)\n",
        "            pts = pts * pts_coeff\n",
        "\n",
        "            new_row = pd.DataFrame(np.array([[player, current_year, current_opp, row['Round'], pts, tsplus, int(total_mp), float(row['MPG'])]]), columns=['Player', 'Year', 'Opp', 'Round', 'PTS/G', 'TS+', 'MP', 'MPG'])\n",
        "            final_season_df = pd.concat([final_season_df, new_row], ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "      outfile = f\"Playoff_Series_Adjusted_Scoring_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "id": "w0lf9f8n8ePb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (SERIES) Run Adjusted Playoff TS+ Series by Series\n",
        "\n",
        "# /content/NBA_Player_52_22_URL_List_1000_Min_df.csv\n",
        "url_df = pd.read_csv('/content/NBA_Player_52_22_URL_List_1000_Min_df.csv', index_col=False, encoding='utf8')\n",
        "url_df = url_df.drop('MP', axis=1)\n",
        "\n",
        "nba_opp_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "nba_opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "aba_opp_ts_allowed_df = pd.read_csv('/content/ABA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "aba_opponent_adj_pts_coeff = pd.read_csv('/content/aba_opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "\n",
        "# correlation will be used to estimate TS%'s allowed by teams from 1952-1973\n",
        "rdRtg = pd.read_csv(\"/content/remove reg teams.csv\", index_col=False, encoding='utf8')\n",
        "rTS = pd.read_csv(\"/content/NBA_Team_TS_Percentage_Allowed_df.csv\", index_col=False, encoding='utf8')\n",
        "\n",
        "rTS['Year'] = rTS['Year'].astype(int)\n",
        "league_avg_df['Year'] = league_avg_df['Year'].astype(float)\n",
        "\n",
        "rTS['rTS'] = 0\n",
        "\n",
        "for idx, row in rTS.iterrows():     \n",
        "          match_df = league_avg_df[(league_avg_df['Year'] == row['Year'])]\n",
        "          rTS.iat[idx, 3] = float(rTS.iat[idx, 2] / (match_df['TS%']))\n",
        "          \n",
        "rTS = rTS.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "rdRtg = rdRtg.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "import scipy.stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "x_pred = rdRtg['PTS_coeff']\n",
        "x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "y_pred = rTS['rTS']\n",
        "\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(x_pred, y_pred)\n",
        "pred = lr.predict(x_pred)\n",
        "\n",
        "adjust_scoring_efficiency_series(url_df, league_avg_df, aba_league_avg, nba_opp_ts_allowed_df, nba_opponent_adj_pts_coeff, aba_opp_ts_allowed_df, aba_opponent_adj_pts_coeff)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cbOuDuodchWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WEAK/HARD DEFENSE SCORING SEPERATION**"
      ],
      "metadata": {
        "id": "kybgv6wxTV0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA/ABA 1952-2022 Adjusted Playoff TS+ (vs Hard/Weak Defense)\n",
        "def adjust_scoring_efficiency_hard_soft(url_df, nba_league_avg_df, aba_league_avg_df, nba_opp_ts_df, nba_opp_defrtg_df, aba_opp_ts_df, aba_opp_defrtg_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'PTS/G v Great Def', 'TS+ v Great Def', 'MP v Great Def', 'PTS/G v Weak Def', 'TS+ v Weak Def', 'MP v Weak Def'])\n",
        "    percent_iteration = 1\n",
        "\n",
        "    from itertools import chain\n",
        "\n",
        "    nba_league_avg_df['Year'] = nba_league_avg_df['Year'].astype(int)\n",
        "    nba_league_avg_df['Year'] = nba_league_avg_df['Year'].astype(str)\n",
        "\n",
        "    aba_league_avg_df['Year'] = aba_league_avg_df['Year'].astype(int)\n",
        "    aba_league_avg_df['Year'] = aba_league_avg_df['Year'].astype(str)\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      time.sleep(15)\n",
        "      print(player)\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        header = first_table.find('thead')\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "      series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "\n",
        "      #create df\n",
        "      series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      pts_count = 0\n",
        "      mp_count = 0\n",
        "      cols = []\n",
        "      for column in series_data.columns:\n",
        "        if column == 'MP':\n",
        "          if mp_count == 1:\n",
        "            cols.append(f'MPG')\n",
        "          else:\n",
        "            cols.append(f'MP')\n",
        "          mp_count+=1\n",
        "          continue\n",
        "        if column == 'PTS':\n",
        "          if pts_count == 1:\n",
        "            cols.append(f'PTS/G')\n",
        "          else:\n",
        "            cols.append(f'PTS')\n",
        "          pts_count+=1\n",
        "          continue\n",
        "        cols.append(column)\n",
        "      series_data.columns = cols\n",
        "\n",
        "\n",
        "      # remove seasons preceding 1952\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1954\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1951\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1950\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1949\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1948\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1947\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1946\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1945\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1944\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "      series_data = series_data.reset_index()\n",
        "\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      nba_opp_ts_df['Team'] = nba_opp_ts_df['Team'].astype(str)\n",
        "      nba_opp_ts_df['Year'] = nba_opp_ts_df['Year'].astype(str)\n",
        "      nba_opp_defrtg_df['Year'] = nba_opp_defrtg_df['Year'].astype(str)\n",
        "      nba_opp_defrtg_df['Year'] = nba_opp_defrtg_df['Year'].astype(str)\n",
        "      aba_opp_ts_df['Team'] = aba_opp_ts_df['Team'].astype(str)\n",
        "      aba_opp_ts_df['Year'] = aba_opp_ts_df['Year'].astype(str)\n",
        "      aba_opp_defrtg_df['Year'] = aba_opp_defrtg_df['Year'].astype(str)\n",
        "      aba_opp_defrtg_df['Year'] = aba_opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['G'] = series_data['G'].astype(float)\n",
        "\n",
        "      \n",
        "      # may be missing MP data.\n",
        "      # divide the missing estimated total numbers equally among games w/o MP data.\n",
        "      missing_mp_data = series_data.copy()\n",
        "      missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      years_list = []\n",
        "      \n",
        "      remaining_mp = []\n",
        "      missing_index = 0\n",
        "      \n",
        "      \n",
        "      for mp_idx, row in missing_mp_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_mp_data.loc[mp_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which MP aren't accounted for\n",
        "          working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # MP accounted for \n",
        "          accounted_for_mp = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_mp['MP'] = accounted_for_mp['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_mp.dropna(inplace=True)\n",
        "          accounted_for_mp = (accounted_for_mp['MP'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total MP\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "\n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_mp = selected_year['MP'].astype(float)\n",
        "          \n",
        "\n",
        "          # remaining MP contains estimated MP for this year's series with missing MP\n",
        "          remaining_mp.append(total_mp - accounted_for_mp)\n",
        "\n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            idx = int(idx)\n",
        "            if working_missing_year.shape[0]  == 1:\n",
        "              series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index])\n",
        "            elif working_missing_year.shape[0]  == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0]  == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      # may be missing FGA data.\n",
        "      # divide the missing estimated total numbers equally among games w/o FGA data.\n",
        "      missing_fg_data = series_data.copy()\n",
        "      missing_fg_data = missing_fg_data[(missing_fg_data['FGA'] == '')]\n",
        "      years_list = []\n",
        "      remaining_fg = []\n",
        "      missing_index = 0\n",
        "\n",
        "      for fg_idx, row in missing_fg_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_fg_data.loc[fg_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which FGA aren't accounted for \n",
        "          working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # FGA accounted for \n",
        "          accounted_for_fg = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_fg['FGA'] = accounted_for_fg['FGA'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_fg.dropna(inplace=True)\n",
        "          accounted_for_fg = (accounted_for_fg['FGA'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total FGA\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          from itertools import chain\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_fg = selected_year['FGA'].astype(float)\n",
        "          selected_year['Tm'] = selected_year['Tm'].astype(str)\n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          # remaining FGA contains estimated FGA for this year's series with missing FGA\n",
        "          remaining_fg.append(total_fg - accounted_for_fg)\n",
        "          \n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            if working_missing_year.shape[0] == 1:\n",
        "              series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index])\n",
        "            elif working_missing_year.shape[0] == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0] == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data['FGA'].iat[idx] = float(remaining_fg[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      series_data['PTS/G'] = series_data['PTS/G'].astype(float)\n",
        "      years_list = []\n",
        "\n",
        "      aba_teams = [\"DNA\", \"INA\", \"NYA\", \"SAA\", \"VIR\", \"CAR\", \"SDA\", \"KEN\",\n",
        "             \"UTS\", \"CAR\", \"SDS\", \"SSL\", \"MMS\", \"DNR\", \"PTP\", \"MNM\",\n",
        "             \"NOB\", \"DLC\", \"TEX\", \"HSM\", \"OAK\", \"MMF\", \"MNP\", \"WSA\",\n",
        "             \"LAS\", \"FLO\", \"MMP\", \"NJA\", \"ANA\", \"PTC\", \"MMT\"]\n",
        "\n",
        "      series_data['PTS/G v Great Def'] = 0\n",
        "      series_data['TS+ v Great Def'] = 0\n",
        "      series_data['MP v Great Def'] = 0\n",
        "      series_data['PTS/G v Weak Def'] = 0\n",
        "      series_data['TS+ v Weak Def'] = 0\n",
        "      series_data['MP v Weak Def'] = 0\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "\n",
        "        if current_opp in aba_teams:\n",
        "          if current_year <= '1973':\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = aba_opp_defrtg_df[(aba_opp_defrtg_df['Team'] == current_opp) & ((aba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "\n",
        "            this_year = aba_league_avg_df[(aba_league_avg_df['Year'] == current_year)]\n",
        "            league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "            league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "            # estimate TS+ allowed\n",
        "            predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "            #find raw TS% compared to league average\n",
        "            raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed) * 100)\n",
        "            if pts_coeff >= 1.04:\n",
        "              series_data.loc[i,'TS+ v Great Def'] = tsplus\n",
        "              series_data.loc[i, 'PTS/G v Great Def'] = series_data.loc[i, 'PTS/G'] * pts_coeff\n",
        "              series_data.loc[i,'MP v Great Def'] =  series_data.loc[i,'MP']\n",
        "            elif pts_coeff <= 1.01:\n",
        "              series_data.loc[i,'TS+ v Weak Def'] = tsplus\n",
        "              series_data.loc[i, 'PTS/G v Weak Def'] = series_data.loc[i, 'PTS/G'] * pts_coeff\n",
        "              series_data.loc[i,'MP v Weak Def'] =  series_data.loc[i,'MP']\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "          else:\n",
        "            # get ts% allowed by opponent\n",
        "            opponent_ts = aba_opp_ts_df[(aba_opp_ts_df['Team'] == current_opp) & ((aba_opp_ts_df['Year'] == current_year))]\n",
        "            opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = aba_opp_defrtg_df[(aba_opp_defrtg_df['Team'] == current_opp) & ((aba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "            if pts_coeff >= 1.04:\n",
        "              series_data.loc[i,'TS+ v Great Def'] = tsplus\n",
        "              series_data.loc[i, 'PTS/G v Great Def'] = series_data.loc[i, 'PTS/G'] * pts_coeff\n",
        "              series_data.loc[i,'MP v Great Def'] =  series_data.loc[i,'MP']\n",
        "            elif pts_coeff <= 1.01:\n",
        "              series_data.loc[i,'TS+ v Weak Def'] = tsplus\n",
        "              series_data.loc[i, 'PTS/G v Weak Def'] = series_data.loc[i, 'PTS/G'] * pts_coeff\n",
        "              series_data.loc[i,'MP v Weak Def'] =  series_data.loc[i,'MP']\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "\n",
        "        else:\n",
        "          if current_year <= '1973':\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = nba_opp_defrtg_df[(nba_opp_defrtg_df['Team'] == current_opp) & ((nba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            this_year = nba_league_avg_df[(nba_league_avg_df['Year'] == current_year)]\n",
        "            league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "            league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "            # estimate TS+ allowed\n",
        "            predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "            #find raw TS% compared to league average\n",
        "            raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed) * 100)\n",
        "            if pts_coeff >= 1.04:\n",
        "              series_data.loc[i,'TS+ v Great Def'] = tsplus\n",
        "              series_data.loc[i, 'PTS/G v Great Def'] = series_data.loc[i, 'PTS/G'] * pts_coeff\n",
        "              series_data.loc[i,'MP v Great Def'] =  series_data.loc[i,'MP']\n",
        "            elif pts_coeff <= 1.01:\n",
        "              series_data.loc[i,'TS+ v Weak Def'] = tsplus\n",
        "              series_data.loc[i, 'PTS/G v Weak Def'] = series_data.loc[i, 'PTS/G'] * pts_coeff\n",
        "              series_data.loc[i,'MP v Weak Def'] =  series_data.loc[i,'MP']\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "          else:\n",
        "            # get ts% allowed by opponent\n",
        "            opponent_ts = nba_opp_ts_df[(nba_opp_ts_df['Team'] == current_opp) & ((nba_opp_ts_df['Year'] == current_year))]\n",
        "            opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "            # get defrtg allowed by opponent\n",
        "            opponent_def = nba_opp_defrtg_df[(nba_opp_defrtg_df['Team'] == current_opp) & ((nba_opp_defrtg_df['Year'] == current_year))]\n",
        "            pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "            if row['PTS'] == 0:\n",
        "              tsplus = 0\n",
        "            else:\n",
        "              tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "            if pts_coeff >= 1.04:\n",
        "              series_data.loc[i,'TS+ v Great Def'] = tsplus\n",
        "              series_data.loc[i, 'PTS/G v Great Def'] = series_data.loc[i, 'PTS/G'] * pts_coeff\n",
        "              series_data.loc[i,'MP v Great Def'] =  series_data.loc[i,'MP']\n",
        "            elif pts_coeff <= 1.01:\n",
        "              series_data.loc[i,'TS+ v Weak Def'] = tsplus\n",
        "              series_data.loc[i, 'PTS/G v Weak Def'] = series_data.loc[i, 'PTS/G'] * pts_coeff\n",
        "              series_data.loc[i,'MP v Weak Def'] =  series_data.loc[i,'MP']\n",
        "            if series_data.loc[i,'Year'] not in years_list:\n",
        "              years_list.append(series_data.loc[i,'Year'])\n",
        "\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = series_data[(series_data['Year'] == year)]\n",
        "        tough_ts = 0\n",
        "        weak_ts = 0\n",
        "        tough_mp = 0\n",
        "        weak_mp = 0\n",
        "        tough_pts = 0\n",
        "        weak_pts = 0\n",
        "\n",
        "        tough_mp_list = []\n",
        "        weak_mp_list = []\n",
        "\n",
        "        for ind_mp in tmp_sub_df['MP v Great Def']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          if ind_mp == 0:\n",
        "            continue\n",
        "          tough_mp_list.append(ind_mp)\n",
        "          tough_mp += ind_mp\n",
        "\n",
        "        for ind_mp in tmp_sub_df['MP v Weak Def']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          if ind_mp == 0:\n",
        "            continue\n",
        "          weak_mp_list.append(ind_mp)\n",
        "          weak_mp += ind_mp\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+ v Great Def']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          if ind_ts == 0:\n",
        "            continue\n",
        "          tough_ts += float(ind_ts) * (float(tough_mp_list[iter])) / float(tough_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+ v Weak Def']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          if ind_ts == 0:\n",
        "            continue\n",
        "          weak_ts += float(ind_ts) * (float(weak_mp_list[iter])) / float(weak_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for pts in tmp_sub_df['PTS/G v Great Def']:\n",
        "          pts = float(pts)\n",
        "          if pts == 0:\n",
        "            continue\n",
        "          tough_pts += float(pts) * (float(tough_mp_list[iter])) / float(tough_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for pts in tmp_sub_df['PTS/G v Weak Def']:\n",
        "          pts = float(pts)\n",
        "          if pts == 0:\n",
        "            continue\n",
        "          weak_pts += float(pts) * (float(weak_mp_list[iter])) / float(weak_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        weak_ts = '%.2f' % round(weak_ts, 2)\n",
        "        tough_ts = '%.2f' % round(tough_ts, 2)\n",
        "        tough_pts = '%.2f' % round(tough_pts, 2)\n",
        "        weak_pts = '%.2f' % round(weak_pts, 2)\n",
        "\n",
        "        new_row = {'Player':player, 'Year':year, 'PTS/G v Great Def': tough_pts, 'TS+ v Great Def': tough_ts, 'MP v Great Def':int(tough_mp), 'PTS/G v Weak Def': weak_pts, 'TS+ v Weak Def': weak_ts, 'MP v Weak Def':int(weak_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "      outfile = f\"Tough_Weak_Playoff_Scoring_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)\n",
        "    print(final_season_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3-QA-EajYYIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Adjusted Playoff TS+ Series by Series (vs Hard/Weak Defense)\n",
        "url_df = pd.read_csv('/content/test.csv', index_col=False, encoding='utf8')\n",
        "url_df = url_df.drop('MP', axis=1)\n",
        "\n",
        "nba_opp_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "nba_opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "aba_opp_ts_allowed_df = pd.read_csv('/content/ABA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "aba_opponent_adj_pts_coeff = pd.read_csv('/content/aba_opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "\n",
        "# correlation will be used to estimate TS%'s allowed by teams from 1952-1973\n",
        "rdRtg = pd.read_csv(\"/content/remove reg teams.csv\", index_col=False, encoding='utf8')\n",
        "rTS = pd.read_csv(\"/content/NBA_Team_TS_Percentage_Allowed_df.csv\", index_col=False, encoding='utf8')\n",
        "\n",
        "rTS['Year'] = rTS['Year'].astype(int)\n",
        "league_avg_df['Year'] = league_avg_df['Year'].astype(float)\n",
        "\n",
        "rTS['rTS'] = 0\n",
        "\n",
        "for idx, row in rTS.iterrows():     \n",
        "          match_df = league_avg_df[(league_avg_df['Year'] == row['Year'])]\n",
        "          rTS.iat[idx, 3] = float(rTS.iat[idx, 2] / (match_df['TS%']))\n",
        "          \n",
        "rTS = rTS.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "rdRtg = rdRtg.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "import scipy.stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "x_pred = rdRtg['PTS_coeff']\n",
        "x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "y_pred = rTS['rTS']\n",
        "\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(x_pred, y_pred)\n",
        "pred = lr.predict(x_pred)\n",
        "\n",
        "adjust_scoring_efficiency_hard_soft(url_df, league_avg_df, aba_league_avg, nba_opp_ts_allowed_df, nba_opponent_adj_pts_coeff, aba_opp_ts_allowed_df, aba_opponent_adj_pts_coeff)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5titAcnajiMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X7wa6qNOjrd"
      },
      "source": [
        "**REG TO PLAYOFFS SCORING CHANGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cvk_rdRbrv7P"
      },
      "outputs": [],
      "source": [
        "#@title Calculation Functions\n",
        "\n",
        "# print the change in scoring rate and effieciency for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoffs_functional_use(a, dfa, dfb):\n",
        "\n",
        "  player_reg = dfa[(dfa.Player == a)]\n",
        "  player_playoff = dfb[(dfb.Player == a)]\n",
        "\n",
        "  total_mp_reg = 0\n",
        "  pts_list_reg = []\n",
        "  ts_list_reg = []\n",
        "\n",
        "  total_mp_playoff = 0\n",
        "  pts_list_playoff = []\n",
        "  ts_list_playoff = []\n",
        "\n",
        "  mp_list_reg = []\n",
        "  mp_list_playoff = []\n",
        "\n",
        "  total_pts_change = 0\n",
        "  total_ts_change = 0\n",
        "  total_pts = 0\n",
        "  total_ts = 0\n",
        "\n",
        "  # find total reg PTS\n",
        "  i = 0\n",
        "  for row in player_reg['PTS']:\n",
        "    pts_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total reg TS+\n",
        "  i = 0\n",
        "  for row in player_reg['TS%+']:\n",
        "    ts_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff minutes\n",
        "  for row in player_playoff['MP']:\n",
        "    mp_list_playoff.append(row)\n",
        "    total_mp_playoff += row\n",
        "\n",
        "  # find total playoff PTS\n",
        "  i = 0\n",
        "  for row in player_playoff['PTS']:\n",
        "    pts_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff TS+\n",
        "  i = 0\n",
        "  for row in player_playoff['TS%+']:\n",
        "    ts_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "  if len(pts_list_reg) != len(pts_list_playoff):\n",
        "    j = j-1\n",
        "\n",
        "  i = 0\n",
        "  while i <= j-1:\n",
        "    total_pts_change += ((pts_list_playoff[i] - pts_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_ts_change += ((ts_list_playoff[i] - ts_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_pts += (pts_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_ts += (ts_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    i = i + 1\n",
        "  return (a, total_pts, total_ts, total_pts_change, total_ts_change, total_mp_playoff)\n",
        "\n",
        "\n",
        "# print the change in BPM and OBPM for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoffs_functional_use_bpm(a, dfa, dfb):\n",
        "\n",
        "  player_reg = dfa[(dfa.Player == a)]\n",
        "  player_playoff = dfb[(dfb.Player == a)]\n",
        "\n",
        "  total_mp_reg = 0\n",
        "  bpm_list_reg = []\n",
        "  obpm_list_reg = []\n",
        "\n",
        "  total_mp_playoff = 0\n",
        "  bpm_list_playoff = []\n",
        "  obpm_list_playoff = []\n",
        "\n",
        "  mp_list_reg = []\n",
        "  mp_list_playoff = []\n",
        "\n",
        "  total_bpm_change = 0\n",
        "  total_obpm_change = 0\n",
        "  total_bpm = 0\n",
        "  total_obpm = 0\n",
        "\n",
        "  # find total reg PTS\n",
        "  i = 0\n",
        "  for row in player_reg['BPM']:\n",
        "    bpm_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total reg TS+\n",
        "  i = 0\n",
        "  for row in player_reg['OBPM']:\n",
        "    obpm_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff minutes\n",
        "  for row in player_playoff['MP']:\n",
        "    mp_list_playoff.append(row)\n",
        "    total_mp_playoff += row\n",
        "\n",
        "  # find total playoff PTS\n",
        "  i = 0\n",
        "  for row in player_playoff['BPM']:\n",
        "    bpm_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff TS+\n",
        "  i = 0\n",
        "  for row in player_playoff['OBPM']:\n",
        "    obpm_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "  if len(bpm_list_reg) != len(bpm_list_playoff):\n",
        "    j = j-1\n",
        "\n",
        "  i = 0\n",
        "  while i <= j-1:\n",
        "    total_bpm_change += ((bpm_list_playoff[i] - bpm_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_obpm_change += ((obpm_list_playoff[i] - obpm_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_bpm += (bpm_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_obpm += (obpm_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    i = i + 1\n",
        "  return (a, total_bpm, total_obpm, total_bpm_change, total_obpm_change, total_mp_playoff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "74v74ArIIZdT"
      },
      "outputs": [],
      "source": [
        "#@title Functional declaration of playoff scoring changes (x year stretches)\n",
        "\n",
        "# def twoYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every two year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def twoYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year2 = int(year2)\n",
        "        season_list = '{} - {}'.format(year1, year2)\n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = int(year2)\n",
        "        season_list = '{}, {}'.format(year1, year2)\n",
        "\n",
        "      \n",
        "\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Two_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def threeYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every three year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def threeYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-1\n",
        "        year3 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year3 = int(year3)\n",
        "        season_list = '{} - {}'.format(year1, year3)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "        year3 = years.split()[2]\n",
        "        year3 = int(year3)\n",
        "        season_list = '{}, {}, {}'.format(year1, year2, year3)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Three_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def fourYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every four year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def fourYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-2\n",
        "        year3 = int(years.split()[2])-1\n",
        "        year4 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year4)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}'.format(year1, year2, year3, year4)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Four_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def fiveYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every five year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def fiveYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-3\n",
        "        year3 = int(years.split()[2])-2\n",
        "        year4 = int(years.split()[2])-1\n",
        "        year5 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year5)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Five_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def sixYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def sixYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-4\n",
        "        year3 = int(years.split()[2])-3\n",
        "        year4 = int(years.split()[2])-2\n",
        "        year5 = int(years.split()[2])-1\n",
        "        year6 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year6)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Six_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def sevenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def sevenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-5\n",
        "        year3 = int(years.split()[2])-4\n",
        "        year4 = int(years.split()[2])-3\n",
        "        year5 = int(years.split()[2])-2\n",
        "        year6 = int(years.split()[2])-1\n",
        "        year7 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year7)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Seven_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def eightYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every eight year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def eightYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-6\n",
        "        year3 = int(years.split()[2])-5\n",
        "        year4 = int(years.split()[2])-4\n",
        "        year5 = int(years.split()[2])-3\n",
        "        year6 = int(years.split()[2])-2\n",
        "        year7 = int(years.split()[2])-1\n",
        "        year8 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year8)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Eight_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def nineYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every nine year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def nineYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year9)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8) | (adjusted_playoff_per_75_df.Year == year9))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Nine_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def tenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every ten year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def tenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = int(years.split()[2])-1\n",
        "        year10 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year10)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = year9.replace(',', '')\n",
        "        year9 = int(year9)\n",
        "\n",
        "        year10 = years.split()[9]\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9, year10)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9) | (reg_df.Year == year10))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8) | (adjusted_playoff_per_75_df.Year == year9) | (adjusted_playoff_per_75_df.Year == year10))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Ten_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eb96uEuGsGDN"
      },
      "outputs": [],
      "source": [
        "#@title Functional declaration of playoff scoring changes (career)  \n",
        "# output file containing change in scoring rate and efficiency from regular season to playoffs (Entire Career)\n",
        "# use only regular seasons in which a player made the playoffs\n",
        "def regToPlayoffsProductionTightScope(reg_df, playoff_db):\n",
        "\n",
        "  new_df = pd.DataFrame(columns = ['Player','PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  headers_list = ['Player', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post']\n",
        "  players_finished = []\n",
        "  used_years = []\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "    used_years = []\n",
        "    if row['Player'] not in players_finished:\n",
        "      player_playoff_db = playoff_db[(playoff_db.Player == row[\"Player\"])]\n",
        "      for use_idx, use_row in player_playoff_db.iterrows():\n",
        "        used_years.append(use_row['Year'])\n",
        "      player_reg_db = reg_df[reg_df['Year'].isin(used_years)]\n",
        "      player_reg_db = player_reg_db[(player_reg_db.Player == row[\"Player\"])]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "      players_finished.append(row['Player'])\n",
        "  outfile = f\"Career_Playoff_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  \n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ85A5uLjDIJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff scoring changes (x year stretches)\n",
        "import_player_pts_playoff10peaks_df = pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "tenYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff10peaks_df)\n",
        "\n",
        "import_player_pts_playoff9peaks_df = pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "nineYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff9peaks_df)\n",
        "\n",
        "import_player_pts_playoff8peaks_df = pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "eightYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff8peaks_df)\n",
        "\n",
        "import_player_pts_playoff7peaks_df = pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "sevenYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff7peaks_df)\n",
        "\n",
        "import_player_pts_playoff6peaks_df = pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "sixYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff6peaks_df)\n",
        "\n",
        "import_player_pts_playoff5peaks_df = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "fiveYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff5peaks_df)\n",
        "\n",
        "import_player_pts_playoff4peaks_df = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "fourYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff4peaks_df)\n",
        "\n",
        "import_player_pts_playoff3peaks_df = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "threeYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff3peaks_df)\n",
        "\n",
        "import_player_pts_playoff2peaks_df = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "twoYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff2peaks_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaAVm7LcZedf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff scoring changes (career)\n",
        "# CAREER\n",
        "\n",
        " \n",
        "\n",
        "regToPlayoffsProductionTightScope(era_adj_reg_per_75_df, era_opponent_adj_playoff_per_75_df)\n",
        "import_player_scoring_changes_df = pd.read_csv('Career_Playoff_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_scoring_changes_df = import_player_scoring_changes_df.dropna()\n",
        "\n",
        "\n",
        "\n",
        "one_thousand_min_filter = import_player_scoring_changes_df[(import_player_scoring_changes_df['MP_post'] >= 2000)]\n",
        "outfile_1000 = f\"Career_Playoff_Scoring_Change_2000min.csv\"\n",
        "one_thousand_min_filter.to_csv(outfile_1000, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Functional declaration of playoff scoring (career)\n",
        "def PlayoffsCareer(playoff_db):\n",
        "\n",
        "  new_df = pd.DataFrame(columns = ['Player','PTS per 75_post', 'TS+_post', 'MP_post'])\n",
        "  headers_list = ['Player', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  players_finished = []\n",
        "  used_years = []\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "    used_years = []\n",
        "    if row['Player'] not in players_finished:\n",
        "      player_playoff_db = playoff_db[(playoff_db.Player == row[\"Player\"])]\n",
        "      for use_idx, use_row in player_playoff_db.iterrows():\n",
        "        used_years.append(use_row['Year'])\n",
        "      (name, pts_post, ts_post, mp_post) = playoffs_functional_use(row[\"Player\"], player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, pts_post, ts_post, mp_post]\n",
        "      players_finished.append(row['Player'])\n",
        "  outfile = f\"Career_Playoff_Scoring.csv\"\n",
        "  columns_titles = ['Player','PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('TS+_post', ascending=False)\n",
        "\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  \n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "  # print the change in scoring rate and effieciency for player from regular season, dfa, to postseason, dfb\n",
        "def playoffs_functional_use(a, dfa):\n",
        "\n",
        "  player_playoff = dfa[(dfa.Player == a)]\n",
        "\n",
        "\n",
        "  total_mp_playoff = 0\n",
        "  pts_list_playoff = []\n",
        "  ts_list_playoff = []\n",
        "\n",
        "  mp_list_playoff = []\n",
        "\n",
        "  total_pts = 0\n",
        "  total_ts = 0\n",
        "\n",
        "  # find total playoff minutes\n",
        "  for row in player_playoff['MP']:\n",
        "    mp_list_playoff.append(row)\n",
        "    total_mp_playoff += row\n",
        "\n",
        "  # find total playoff PTS\n",
        "  i = 0\n",
        "  for row in player_playoff['PTS']:\n",
        "    pts_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff TS+\n",
        "  i = 0\n",
        "  for row in player_playoff['TS%+']:\n",
        "    ts_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "\n",
        "  i = 0\n",
        "  while i <= j-1:\n",
        "    if total_mp_playoff == 0:\n",
        "      total_mp_playoff = 1\n",
        "    total_pts += (pts_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_ts += (ts_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    i = i + 1\n",
        "  return (a, total_pts, total_ts, total_mp_playoff)\n",
        "\n",
        "#@title Functional declaration of playoff scoring (career)\n",
        "def PlayoffsCareer(playoff_db):\n",
        "\n",
        "  playoff_db = playoff_db[(playoff_db['Tm'] == 'HOU')]\n",
        "\n",
        "  new_df = pd.DataFrame(columns = ['Player','PTS per 75_post', 'TS+_post', 'MP_post'])\n",
        "  headers_list = ['Player', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  players_finished = []\n",
        "  used_years = []\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "    used_years = []\n",
        "    if row['Player'] not in players_finished:\n",
        "      player_playoff_db = playoff_db[(playoff_db.Player == row[\"Player\"])]\n",
        "      for use_idx, use_row in player_playoff_db.iterrows():\n",
        "        used_years.append(use_row['Year'])\n",
        "      (name, pts_post, ts_post, mp_post) = playoffs_functional_use(row[\"Player\"], player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, pts_post, ts_post, mp_post]\n",
        "      players_finished.append(row['Player'])\n",
        "  outfile = f\"Career_Playoff_Scoring.csv\"\n",
        "  columns_titles = ['Player','PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('TS+_post', ascending=False)\n",
        "\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  \n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "  # print the change in scoring rate and effieciency for player from regular season, dfa, to postseason, dfb"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vm8VfdRlxo0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PlayoffsCareer(era_opponent_adj_playoff_per_75_df)"
      ],
      "metadata": {
        "id": "sYTeGHr5yR73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REG TO PLAYOFFS BPM CHANGES**"
      ],
      "metadata": {
        "id": "k9F-ko-AtZj7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cXgIpAWbAXC1"
      },
      "outputs": [],
      "source": [
        "#@title Functional declaration of playoff BPM changes (x year stretches)\n",
        "\n",
        "# def twoYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every two year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def twoYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year2 = int(year2)\n",
        "        season_list = '{} - {}'.format(year1, year2)\n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = int(year2)\n",
        "        season_list = '{}, {}'.format(year1, year2)\n",
        "\n",
        "      \n",
        "\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2))]\n",
        "      player_playoff_db = playoff_bpm_data[(playoff_bpm_data.Player == row[\"Player\"]) & ((playoff_bpm_data.Year == year1) | (playoff_bpm_data.Year == year2))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Two_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def threeYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every three year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def threeYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-1\n",
        "        year3 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year3 = int(year3)\n",
        "        season_list = '{} - {}'.format(year1, year3)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "        year3 = years.split()[2]\n",
        "        year3 = int(year3)\n",
        "        season_list = '{}, {}, {}'.format(year1, year2, year3)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Three_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def fourYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every four year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def fourYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-2\n",
        "        year3 = int(years.split()[2])-1\n",
        "        year4 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year4)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}'.format(year1, year2, year3, year4)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Four_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def fiveYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every five year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def fiveYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-3\n",
        "        year3 = int(years.split()[2])-2\n",
        "        year4 = int(years.split()[2])-1\n",
        "        year5 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year5)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Five_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def sixYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def sixYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-4\n",
        "        year3 = int(years.split()[2])-3\n",
        "        year4 = int(years.split()[2])-2\n",
        "        year5 = int(years.split()[2])-1\n",
        "        year6 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year6)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Six_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def sevenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def sevenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-5\n",
        "        year3 = int(years.split()[2])-4\n",
        "        year4 = int(years.split()[2])-3\n",
        "        year5 = int(years.split()[2])-2\n",
        "        year6 = int(years.split()[2])-1\n",
        "        year7 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year7)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Seven_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def eightYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every eight year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def eightYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-6\n",
        "        year3 = int(years.split()[2])-5\n",
        "        year4 = int(years.split()[2])-4\n",
        "        year5 = int(years.split()[2])-3\n",
        "        year6 = int(years.split()[2])-2\n",
        "        year7 = int(years.split()[2])-1\n",
        "        year8 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year8)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Eight_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def nineYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every nine year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def nineYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year9)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8) | (playoff_bpm_data .Year == year9))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Nine_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def tenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every ten year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def tenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = int(years.split()[2])-1\n",
        "        year10 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year10)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = year9.replace(',', '')\n",
        "        year9 = int(year9)\n",
        "\n",
        "        year10 = years.split()[9]\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9, year10)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9) | (reg_df.Year == year10))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8) | (playoff_bpm_data .Year == year9) | (playoff_bpm_data .Year == year10))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Ten_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PpVhZVsYcV0E"
      },
      "outputs": [],
      "source": [
        "#@title Function declaration of playoff BPM changes (career)  \n",
        "# output file containing change in scoring rate and efficiency from regular season to playoffs (Entire Career)\n",
        "# use only regular seasons in which a player made the playoffs\n",
        "def regToPlayoffsProductionTightScopeBPM(reg_df, playoff_db):\n",
        "\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "  players_finished = []\n",
        "  used_years = []\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "    used_years = []\n",
        "    if row['Player'] not in players_finished:\n",
        "      player_playoff_db = playoff_db[(playoff_db.Player == row[\"Player\"])]\n",
        "      for use_idx, use_row in player_playoff_db.iterrows():\n",
        "        used_years.append(use_row['Year'])\n",
        "      player_reg_db = reg_df[reg_df['Year'].isin(used_years)]\n",
        "      player_reg_db = player_reg_db[(player_reg_db.Player == row[\"Player\"])]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "      players_finished.append(row['Player'])\n",
        "  outfile = f\"Career_Playoff_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "  \n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  \n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Me79i0gHKVE3"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff bpm changes (x year stretches)\n",
        "import_player_bpm_playoff10peaks_df = pd.read_csv('/content/Ten_Year_BPM_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "tenYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff10peaks_df)\n",
        "\n",
        "import_player_bpm_playoff9peaks_df = pd.read_csv('/content/Nine_Year_BPM_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "nineYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff9peaks_df)\n",
        "\n",
        "import_player_bpm_playoff8peaks_df = pd.read_csv('/content/Eight_Year_BPM_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "eightYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff8peaks_df)\n",
        "\n",
        "import_player_bpm_playoff7peaks_df = pd.read_csv('/content/Seven_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "sevenYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff7peaks_df)\n",
        "\n",
        "import_player_bpm_playoff6peaks_df = pd.read_csv('/content/Six_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "sixYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff6peaks_df)\n",
        "\n",
        "import_player_bpm_playoff5peaks_df = pd.read_csv('/content/Five_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "fiveYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff5peaks_df)\n",
        "\n",
        "import_player_bpm_playoff4peaks_df = pd.read_csv('/content/Four_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "fourYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff4peaks_df)\n",
        "\n",
        "import_player_bpm_playoff3peaks_df = pd.read_csv('/content/Three_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "threeYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff3peaks_df)\n",
        "\n",
        "import_player_bpm_playoff2peaks_df = pd.read_csv('/content/Two_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "twoYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff2peaks_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q3UBqs5tb-Ea"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff BPM changes (career)\n",
        "# CAREER\n",
        "\n",
        " \n",
        "\n",
        "regToPlayoffsProductionTightScopeBPM(era_adj_reg_per_75_df, era_opponent_adj_playoff_per_75_df)\n",
        "import_player_scoring_changes_df = pd.read_csv('Career_Playoff_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_scoring_changes_df = import_player_scoring_changes_df.dropna()\n",
        "\n",
        "\n",
        "\n",
        "one_thousand_min_filter = import_player_scoring_changes_df[(import_player_scoring_changes_df['MP_post'] >= 2000)]\n",
        "outfile_1000 = f\"Career_Playoff_Scoring_Change_2000min.csv\"\n",
        "one_thousand_min_filter.to_csv(outfile_1000, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu-iOQT7Rpj5"
      },
      "source": [
        "**SCORING PLOT FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wJ_wS861o8eV"
      },
      "outputs": [],
      "source": [
        "#@title Single Plot Scoring Template\n",
        "def plotOneScoring(p1, c1, pts_floor, ts_floor, ts_ceiling, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f'Multi-Year Playoff Scoring Stretches (1952 - 2022) [min. {mp_floor} MP]'\n",
        "  ax.set(title=titlestring, xlabel='PTS per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def plotTwoScoring(p1, p2, c1, c2,  pts_floor, ts_floor, ts_ceiling, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f'Multi-Year Playoff Scoring Stretches (1952 - 2022) [min. {mp_floor} MP]'\n",
        "  ax.set(title=titlestring, xlabel='PTS per 75 (era/opponent adjusted', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def plotThreeScoring(p1, p2, p3, c1, c2, c3,  pts_floor, ts_floor, ts_ceiling, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f'Multi-Year Playoff Scoring Stretches (1952 - 2022) [min. {mp_floor} MP]'\n",
        "  ax.set(title=titlestring, xlabel='PTS per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nhc4VYkV2Zq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Multiple Plots Scoring Template\n",
        "def plotOneScoring(p1, c1, pts_floor, ts_floor, ts_ceiling):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(35,18), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted) (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(35,18), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [>500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 600)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(35,18), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [>600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1000)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [>1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1200)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [>1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [>1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [>1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Peaks', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title 2 Guys Scoring Plot Template\n",
        "def plotTwoScoring(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling):\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(115)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [>500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 600)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [>600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1000)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [>1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1200)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [>1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [>1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [>1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[9].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Peaks', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title 3 Guys Scoring Plot Template\n",
        "def plotThreeScoring(p1, p2, p3, c1, c2, c3, pts_floor, ts_floor, ts_ceiling):\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [> 300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [> 500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 600]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [> 600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [> 1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1200]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [> 1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1400]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [> 1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [> 1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 2000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [> 2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[9].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring_Peaks', bbox_inches='tight')\n",
        "\n",
        "#@title 4 Guys Scoring Plot Template\n",
        "def plotFourScoring(p1, p2, p3, p4, c1, c2, c3, c4, pts_floor, ts_floor, ts_ceiling):\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [> 300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [> 500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 600]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [> 600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [> 1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1200]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [> 1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1400]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [> 1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [> 1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 2000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [> 2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(40,20), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[9].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_{p4}_Scoring_Peaks', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gys3Jbx0NXFW",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Multiple Plots PBP Template\n",
        "def plotOnePBP(p1, c1):\n",
        "  fig, axis = plt.subplots(8)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_pbp_Peaks_NBA_Playoffs_300_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='3 Year Playoff PBP (1997-2022) [>500 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_pbp_Peaks_NBA_Playoffs_600_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='4 Year Playoff PBP (1997-2022) [>600 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_pbp_Peaks_NBA_Playoffs_1000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='5 Year Playoff PBP (1997-2022) [>1000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_pbp_Peaks_NBA_Playoffs_1400_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='6 Year Playoff PBP (1997-2022) [>1400 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_pbp_Peaks_NBA_Playoffs_2000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='7 Year Playoff PBP (1997-2022) [>2000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='8 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Nine_Year_pbp_Playoff_Peaks_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='9 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='10 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  fig.savefig(f'{p1}_PBP_Peaks', bbox_inches='tight')\n",
        "\n",
        "def plotTwoPBP(p1, p2, c1, c2):\n",
        "  fig, axis = plt.subplots(8)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_pbp_Peaks_NBA_Playoffs_300_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='3 Year Playoff PBP (1997-2022) [>500 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_pbp_Peaks_NBA_Playoffs_600_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='4 Year Playoff PBP (1997-2022) [>600 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_pbp_Peaks_NBA_Playoffs_1000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='5 Year Playoff PBP (1997-2022) [>1000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_pbp_Peaks_NBA_Playoffs_1400_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='6 Year Playoff PBP (1997-2022) [>1400 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_pbp_Peaks_NBA_Playoffs_2000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='7 Year Playoff PBP (1997-2022) [>2000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='8 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Nine_Year_pbp_Playoff_Peaks_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='9 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*13, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='10 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_PBP_Peaks', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plotTwoScoring(\"Kevin Durant\", \"Kawhi Leonard\", \"y\", \"k\", 20, 80, 130, 800)"
      ],
      "metadata": {
        "id": "ZkirMMdt7TCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotThreeScoring(\"Kobe Bryant\", \"Dwyane Wade\", \"Jerry West\", \"m\", \"r\", \"y\", 20, 90, 130, 1000)"
      ],
      "metadata": {
        "id": "Qlanat4gPTuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sy_RXsh-Ctf"
      },
      "source": [
        "**REG->PLAYOFF SCORING CHANGE PLOTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6B5fddTe-Mbr"
      },
      "outputs": [],
      "source": [
        "#@title Single Plot Scoring Change Template\n",
        "def p_plotOneScoringChange(p1, c1, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP_post']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1952 - 2022) [min. {pts_floor} Pts per 75 Postseason; min. {mp_floor} MP]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChange(p1, p2, c1, c2, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP_post']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1952 - 2022) [min. {pts_floor} Pts per 75 Postseason; min. {mp_floor} MP]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChange(p1, p2, p3, c1, c2, c3, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP_post']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1952 - 2022) [min. {pts_floor} Pts per 75 Postseason; min. {mp_floor} MP]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "  \n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title 2 Guys Scoring Change Single Plot Template (TS+ above below league avg)\n",
        "def p_plotOneScoringChange_ab(p1, c1, pts_floor, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['TS+_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PTS_change\": \"PTS_change\", \"TS+_change\": \"TS+_change\", \"PTS per 75_reg\": \"PTS per 75_reg\", \"PTS per 75_post\": \"PTS per 75_post\", \"TS+_reg\": \"TS+_reg\", \"TS+_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1952 - 2022) [min. {threshold} TS+ postseason]\"\n",
        "  ax.set(title=title_string, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys Scoring Change Single Plot Template (TS+ above below league avg)\n",
        "def p_plotTwoScoringChange_ab(p1, p2, c1, c2, pts_floor, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['TS+_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PTS_change\": \"PTS_change\", \"TS+_change\": \"TS+_change\", \"PTS per 75_reg\": \"PTS per 75_reg\", \"PTS per 75_post\": \"PTS per 75_post\", \"TS+_reg\": \"TS+_reg\", \"TS+_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.TSpost >= threshold),c2, graph_data.color)\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.TSpost <= threshold),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1952 - 2022) [min. {threshold} TS+ postseason]\"\n",
        "  ax.set(title=title_string, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xxGUbQIlBFL6"
      },
      "outputs": [],
      "source": [
        "#@title Multiple Plots Scoring Change (with lines) Template\n",
        "def p_plotOneScoringChangeWithLines(p1, c1, pts_floor, ts_floor, ts_ceiling, label, mp_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChangeWithLines(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling, label, mp_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChangeWithLines(p1, p2, p3, c1, c2, c3, pts_floor, ts_floor, ts_ceiling, label, mp_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[0])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[1])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[2])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff Scoring Change from Reg->Post (1952-2022) [>{mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[3])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ihbDWbHaHO-S"
      },
      "outputs": [],
      "source": [
        "#@title Single Plot Career Scoring Change (with lines) Template\n",
        "def p_plotOneScoringChangeWithLinesCareer(p1, c1, pts_floor, ts_floor, ts_ceiling):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <= ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChangeWithLinesCareer(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling):\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <= ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChangeWithLinesCareer(p1, p2, p3, c1, c2, c3, pts_floor, ts_floor, ts_ceiling):\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <= ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c3, linestyle=\"--\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plotTwoScoring(\"Stephen Curry\", \"Nikola Joki\", \"y\", \"r\", 20, 80, 120, 300)"
      ],
      "metadata": {
        "id": "sTuvrkN57PL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r597HycnNfI4"
      },
      "outputs": [],
      "source": [
        "# Single Plot Scoring Template\n",
        "  # plotNumScoring(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling, mp_floor)\n",
        "# Multiple Plots Scoring Template\n",
        "  # plotNumScoring(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling)\n",
        "#  Multiple Plots PBP Template\n",
        "  # plotTwoPBP(p1, p2, c1, c2)\n",
        "#  Single Plot Scoring Change Template\n",
        "  # p_plotNumScoringChange(p1, p2, c1, c2, pts_floor, mp_floor)\n",
        "#  Multiple Plots Scoring Change w Lines Template\n",
        "  # p_plotNumScoringChangeWithLines(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling, 1or0, [mp_2year, mp_3year, mp_4year, mp_5year])\n",
        "#  Single Plot Scoring Change w Lines Template\n",
        "  # p_plotNumScoringChangeWithLinesCareer(p1, c1, pts_floor, ts_floor, ts_ceiling):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plotTwoPBP(\"Tony Parker\", \"Manu Ginbili\", \"#EF426F\", \"#FF8200\")\n",
        "#p_plotTwoScoringChangeWithLines(\"Tony Parker\", \"Manu Ginbili\", \"#EF426F\", \"#FF8200\", 10, 80, 130, 0, [300, 500, 800, 1000])\n",
        "#p_plotOneScoringChange(\"DeMar DeRozan\", \"r\", 20, 300)\n",
        "p_plotTwoScoringChangeWithLines(\"Klay Thompson\", \"Reggie Miller\", \"r\", \"y\", 15, 80, 130, 0, [300, 500, 800, 1000])\n",
        "#p_plotTwoScoringChange(\"Tony Parker\", \"Manu Ginbili\", \"#EF426F\", \"#FF8200\", 10, 300)\n",
        "#plotThreeScoring(\"Kobe Bryant\", \"Stephen Curry\", \"Jerry West\", \"m\", \"y\", \"r\", 20, 90, 126)"
      ],
      "metadata": {
        "id": "q_M7VGXk7lGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_plotTwoScoringChange(\"Jamal Murray\", \"Reggie Miller\", \"r\", \"y\", 20, 500)"
      ],
      "metadata": {
        "id": "0RJRAGSQn64O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot a Team's Scoring\n",
        "def plotTeamScoring(first_year, last_year, team, c1, pts_floor, ts_floor, ts_ceiling, mp_floor, label):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/52-22_Single_Playoffs_Adjusted_Scoring.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PP75']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= mp_floor]\n",
        "\n",
        "  graph_data['Year'] = graph_data['Year'].astype(int)\n",
        "  graph_data = graph_data[(graph_data['Player'] != 'Jerry West')]\n",
        "\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Team\"] != team])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Team'] == team)]\n",
        "  no_first = no_first[(no_first['Year'] >= first_year)]\n",
        "  no_first = no_first[(no_first['Year'] <= last_year)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Team']== team)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  size = 100 * ((graph_data['MPG'] - (graph_data['MPG'].min() - 150)) / (graph_data['MPG'].max() - (graph_data['MPG'].min() - 150)))\n",
        "  fig = plt.figure(figsize=(40,24), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PP75\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Single Playoff Scoring Peaks (1952 - 2022) [min. {mp_floor} MP]\"\n",
        "  ax.set(title=titlestring, xlabel='PTS per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=f\"{team} {first_year} - {last_year}\", markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "  \n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PP75']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  ax.plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point_year(no_first['PP75'], no_first['TS+'], no_first['Year'], ax)\n",
        "    label_point(no_first['PP75'], no_first['TS+']+0.15, no_first['Player'], ax)\n",
        "\n",
        "  fig.savefig(f'{team}_Scoring', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "s1ERZr-Ym-mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotTeamScoring(1957, 1969, \"BOS\", \"g\", 10, 80, 140, 300, 1)"
      ],
      "metadata": {
        "id": "OSxExiq8oDps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SERIES PERCENTILES**"
      ],
      "metadata": {
        "id": "QT5we2Kmgy8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "players = ['Kareem Abdul-Jabbar', 'Jerry West', 'LeBron James', 'Wilt Chamberlain', 'Michael Jordan',\n",
        "           'Kevin McHale', 'Kevin Durant', 'Reggie Miller', 'Stephen Curry', 'Walt Frazier', 'Oscar Robertson',\n",
        "           'Kawhi Leonard', \"Shaquille O'Neal\", 'Elgin Baylor', 'Julius Erving', 'Terry Porter', 'Dirk Nowitzki',\n",
        "           'Charles Barkley', 'George Gervin', 'Bob Pettit', 'Rick Barry', 'Larry Bird', 'Cliff Hagan', 'Dwyane Wade',\n",
        "           'Kobe Bryant', 'James Harden', 'Artis Gilmore', 'Hakeem Olajuwon', 'Zelmo Beaty', 'Tim Duncan', 'James Worthy',\n",
        "           'Magic Johnson', 'Karl Malone', 'Steve Nash', 'Adrian Dantley', \"Amar'e Stoudemire\", 'Jimmy Jones', 'Dwight Howard',\n",
        "           'Chris Paul', 'John Havlicek', 'Sam Jones', 'Giannis Antetokounmpo', 'Moses Malone', 'Roger Brown', 'Ray Allen', 'Clyde Drexler',\n",
        "           'Pau Gasol', 'Jeff Hornacek', 'Manu Ginbili', 'Deron Williams', 'Dolph Schayes', 'Bob Lanier', 'Willie Wise', 'Kyrie Irving', 'Shawn Kemp',\n",
        "           'Kevin Johnson', 'Chauncey Billups', 'Elvin Hayes', 'Paul Pierce', 'Dan Issel']\n",
        "\n",
        "series_data_df = pd.read_csv('/content/series_data_52_22.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "series_data_df = series_data_df[(series_data_df.Player.isin(players))]\n",
        "print(series_data_df)\n",
        "series_data_df.to_csv('good_scorers.csv', index=False)"
      ],
      "metadata": {
        "id": "KY__LCkKEWlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Print Single Series\n",
        "series_data_52_22_df = pd.read_csv('/content/series_data_52_22.csv', encoding='utf8', index_col=False)\n",
        "tmp = series_data_52_22_df[(series_data_52_22_df['PTS/G']) >= 33]\n",
        "tmp = tmp.sort_values('Year', ascending=True)\n",
        "\n",
        "tmp = tmp[(tmp['Year']) >= 1976]\n",
        "tmp = tmp[(tmp['TS+']) >= 110]\n",
        "tmp = tmp[(tmp['MP']) >= 100]\n",
        "#tmp = tmp[(tmp['Player'] == 'Manu Ginbili')]\n",
        "print(tmp)"
      ],
      "metadata": {
        "id": "iYC4ASoQpzmv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Print PTS/TS+ percentiles for a players' series\n",
        "series_data_52_22_df = pd.read_csv('/content/series_data_52_22.csv', encoding='utf8', index_col=False) \n",
        "def printSeries_PTS_TS_Percentiles(p1, mp_min, pts_min):\n",
        "  graph_data =  series_data_52_22_df.copy()\n",
        "  graph_data = graph_data[(graph_data['PTS/G'] >= pts_min)]\n",
        "  graph_data = graph_data[(graph_data['MP'] >= mp_min)]\n",
        "  graph_data['Approx_Scoring_Val'] = 0\n",
        "\n",
        "  for idx, row in graph_data.iterrows():\n",
        "    pts = row['PTS/G']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "    approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    graph_data.at[idx, 'Approx_Scoring_Val'] = approx_scoring_val\n",
        "\n",
        "\n",
        "  final_season_df = pd.DataFrame(columns = ['Series', f\"{p1} PTS percentile\", f\"{p1} TS+ percentile\", f\"{p1} Approx_Scoring_Val\",f\"{p1} MP\"])\n",
        "\n",
        "  players_df = series_data_52_22_df[(series_data_52_22_df['Player'] == p1)]\n",
        "  players_df['index'] = players_df.index\n",
        "  players_df = players_df.sort_values(by = ['Year', 'index'], ascending = [True, True])\n",
        "\n",
        "  for idx, row in players_df.iterrows():\n",
        "    pts = row['PTS/G']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "    p1_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    p1_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p1_approx_scoring_val)\n",
        "    series = str(row['Year']) + \" \" + row['Opp']\n",
        "    new_row = {'Series':series,  f\"{p1} PTS percentile\":pts_percentile, f\"{p1} TS+ percentile\": ts_percentile, f\"{p1} Approx_Scoring_Val\":p1_approx_scoring_val, f\"{p1} MP\":int(mp)}\n",
        "    final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  print(final_season_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "beVRKD32E0aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Print PTS/TS+ percentiles for mutli players' series\n",
        "series_data_52_22_df = pd.read_csv('/content/series_data_52_22.csv', encoding='utf8', index_col=False) \n",
        "def printMultiSeries_PTS_TS_Percentiles(mp_min, pts_min):\n",
        "  graph_data =  series_data_52_22_df.copy()\n",
        "  graph_data = graph_data[(graph_data['PTS/G'] >= pts_min)]\n",
        "  graph_data = graph_data[(graph_data['MP'] >= mp_min)]\n",
        "  graph_data['Approx_Scoring_Val'] = 0\n",
        "\n",
        "  for idx, row in graph_data.iterrows():\n",
        "    pts = row['PTS/G']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "    approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    graph_data.at[idx, 'Approx_Scoring_Val'] = approx_scoring_val\n",
        "\n",
        "\n",
        "  final_season_df = pd.DataFrame(columns = ['Player', 'Series', f\"PTS percentile\", f\"TS+ percentile\", f\"Approx_Scoring_Val\",f\"MP\"])\n",
        "\n",
        "  players_df = pd.read_csv('/content/Finals.csv', encoding='utf8')\n",
        "  players_df['index'] = players_df.index\n",
        "  players_df = players_df.sort_values(by = ['Year', 'index'], ascending = [True, True])\n",
        "\n",
        "  for idx, row in players_df.iterrows():\n",
        "    pts = row['PTS/G']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "    p1_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    p1_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p1_approx_scoring_val)\n",
        "    series = str(row['Year']) + \" \" + row['Opp']\n",
        "    player = row['Player']\n",
        "    new_row = {'Player': player, 'Series':series,  f\"PTS percentile\":pts_percentile, f\"TS+ percentile\": ts_percentile, f\"Approx_Scoring_Val\":p1_approx_scoring_val, f\"MP\":int(mp)}\n",
        "    final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  final_season_df = final_season_df.sort_values('Approx_Scoring_Val', ascending=False)\n",
        "  final_season_df['PTS percentile'] = final_season_df['PTS percentile'].round(2)\n",
        "  final_season_df['TS+ percentile'] = final_season_df['TS+ percentile'].round(2)\n",
        "  final_season_df['Approx_Scoring_Val'] = final_season_df['Approx_Scoring_Val'].round(2)\n",
        "  final_season_df = final_season_df.reset_index()\n",
        "  final_season_df = final_season_df.drop(columns='index')\n",
        "  print(final_season_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fa79BJoIrrp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "printMultiSeries_PTS_TS_Percentiles(75, 0)"
      ],
      "metadata": {
        "id": "35HYDZzgrfDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manually Find Stretch of Approx_Scoring_Val\n",
        "def stretchesApproxScoringVal(p1, p2, file):\n",
        "  series_data_df = pd.read_csv(file, encoding='utf8', index_col=False)\n",
        "\n",
        "  total_mp_a = 0\n",
        "  total_pts_a = 0\n",
        "  total_ts_a = 0\n",
        "\n",
        "  total_mp_b = 0\n",
        "  total_pts_b = 0\n",
        "  total_ts_b = 0\n",
        "  mp_list_a = []\n",
        "  mp_list_b = []\n",
        "\n",
        "  # find total minutes a\n",
        "  for mp in series_data_df[f'{p1} MP']:\n",
        "    mp_list_a.append(mp)\n",
        "    total_mp_a += mp\n",
        "\n",
        "  # find total approx_scoring_val\n",
        "  i = 0\n",
        "  for approx_scoring_val in series_data_df[f'{p1} Approx_Scoring_Val']:\n",
        "    total_pts_a += approx_scoring_val * (mp_list_a[i] / total_mp_a)\n",
        "    i = i + 1\n",
        "\n",
        "  print(p1)\n",
        "  print(\"Approx_Scoring_Val: \", total_pts_a)\n",
        "  print(\"MP: \",total_mp_a)\n",
        "\n",
        "  # find total minutes\n",
        "  for mp in series_data_df[f'{p2} MP']:\n",
        "    mp_list_b.append(mp)\n",
        "    total_mp_b += mp\n",
        "  print(\"\\n\")\n",
        "\n",
        "  # find total PTS\n",
        "  i = 0\n",
        "  for approx_scoring_val in series_data_df[f'{p2} Approx_Scoring_Val']:\n",
        "    total_pts_b += approx_scoring_val * (mp_list_b[i] / total_mp_b)\n",
        "    i = i + 1\n",
        "\n",
        "  print(p2)\n",
        "  print(\"Approx_Scoring_Cal: \", total_pts_b)\n",
        "  print(\"MP: \",total_mp_b)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Cyfp7J-dNKRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title allStretchesApproxScoringVal\n",
        "def allStretchesApproxScoringVal(file, min_series_stretch):\n",
        "  series_data_df = pd.read_csv(file, encoding='utf8', index_col=False)\n",
        "\n",
        "  # create Approx_Scoring_Val for each series\n",
        "  for idx, row in series_data_df.iterrows():\n",
        "    pts = row['PTS/G']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    pts_percentile = stats.percentileofscore(series_data_df['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(series_data_df['TS+'], ts)\n",
        "    approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    series_data_df.at[idx, 'Approx_Scoring_Val'] = approx_scoring_val\n",
        "\n",
        "  final_series_df = pd.DataFrame(columns = ['Player', 'First Series', 'Last Series', \"Approx_Scoring_Val\", \"PTS/G\", \"TS+\", \"MP\"])\n",
        "\n",
        "  players_list = series_data_df['Player']\n",
        "  players_list = players_list.drop_duplicates()\n",
        "\n",
        "  for player in players_list:\n",
        "\n",
        "    single_player_df = series_data_df[(series_data_df['Player'] == player)]\n",
        "\n",
        "    new_first_series_index = 0\n",
        "    num_of_series = single_player_df.shape[0]\n",
        "    how_many_passes = num_of_series - min_series_stretch\n",
        "    while new_first_series_index <= how_many_passes:\n",
        "      tmp = single_player_df.iloc[new_first_series_index:]\n",
        "      tmp = tmp.reset_index(drop=True)\n",
        "      num_of_series = tmp.shape[0]\n",
        "      if num_of_series < min_series_stretch:\n",
        "        continue\n",
        "    \n",
        "      for series_stretch in range(min_series_stretch, num_of_series+1):\n",
        "\n",
        "        total_mp = 0\n",
        "        total_approx_scoring_val = 0\n",
        "        total_pts = 0\n",
        "        total_ts = 0\n",
        "        mp_list = []\n",
        "\n",
        "        idx_find_first_series = 0\n",
        "\n",
        "        # find total minutes\n",
        "        i = 0\n",
        "        for mp in tmp['MP']:\n",
        "          if i >= series_stretch:\n",
        "            continue\n",
        "          if idx_find_first_series == 0:\n",
        "            first_series = str(tmp.loc[i, 'Year']) + \" \" + tmp.loc[i, 'Opp']\n",
        "            idx_find_first_series = 1\n",
        "\n",
        "          mp_list.append(mp)\n",
        "          total_mp += mp\n",
        "          last_series = str(tmp.loc[i, 'Year']) + \" \" + tmp.loc[i, 'Opp']\n",
        "          i = i + 1\n",
        "\n",
        "        i = 0\n",
        "        for approx_scoring_val in tmp['Approx_Scoring_Val']:\n",
        "          if i >= series_stretch:\n",
        "            continue\n",
        "          total_approx_scoring_val += approx_scoring_val * (mp_list[i] / total_mp)\n",
        "          i = i + 1\n",
        "        i = 0\n",
        "        for pts in tmp['PTS/G']:\n",
        "          if i >= series_stretch:\n",
        "            continue\n",
        "          total_pts += pts * (mp_list[i] / total_mp)\n",
        "          i = i + 1\n",
        "        i = 0\n",
        "        for ts in tmp['TS+']:\n",
        "          if i >= series_stretch:\n",
        "            continue\n",
        "          total_ts += ts * (mp_list[i] / total_mp)\n",
        "          i = i + 1\n",
        "\n",
        "        total_approx_scoring_val = '%.2f' % round(total_approx_scoring_val, 2)\n",
        "        total_pts = '%.2f' % round(total_pts, 2)\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "        new_row = {'Player':player, 'First Series':first_series, 'Last Series':last_series, \"PTS/G\":total_pts, \"TS+\":total_ts, \"Approx_Scoring_Val\":total_approx_scoring_val, \"MP\":total_mp}\n",
        "        new_df = pd.DataFrame(data=new_row, index = [0])\n",
        "        final_series_df = pd.concat([final_series_df, new_df], axis=0)\n",
        "        outfile = f\"Stretches_Of_Series_Percentiles.csv\"\n",
        "        final_series_df.to_csv(outfile, index=False)\n",
        "      new_first_series_index = new_first_series_index + 1"
      ],
      "metadata": {
        "id": "L9xey6Mwkfld",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allStretchesApproxScoringVal('/content/series_data_52_22.csv', 5)"
      ],
      "metadata": {
        "id": "TFqHA2zvc2Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Print Single Player stretch\n",
        "def printSinglePlayerStretch(series_stretches_file, mp_min, mp_max, unique_players, best_or_worst, first_or_last, player):\n",
        "\n",
        "  series_data_df = pd.read_csv(series_stretches_file, encoding='utf8', index_col=False)\n",
        "  series_data_df = series_data_df[(series_data_df['MP'] >= mp_min)]\n",
        "  series_data_df = series_data_df[(series_data_df['MP'] <= mp_max)]\n",
        "\n",
        "  if best_or_worst == 'best':\n",
        "    series_data_df = series_data_df.sort_values('Approx_Scoring_Val', ascending=False)\n",
        "  elif best_or_worst == 'worst':\n",
        "    series_data_df = series_data_df.sort_values('Approx_Scoring_Val', ascending=True)\n",
        "  series_data_df['Approx_Scoring_Val'] = series_data_df['Approx_Scoring_Val'].round(2)\n",
        "  \n",
        "\n",
        "  if unique_players == 1:\n",
        "    if first_or_last == 'first':\n",
        "      series_data_df = series_data_df.drop_duplicates('Player', keep='first')\n",
        "    elif first_or_last == 'last':\n",
        "      series_data_df = series_data_df.drop_duplicates('Player', keep='last')\n",
        "  series_data_df = series_data_df.reset_index(drop=True)\n",
        "  series_data_df['Historical Player Rank'] = series_data_df.index\n",
        "  #print(series_data_df.shape[0])\n",
        "  series_data_df = series_data_df[(series_data_df['Player'] == player)]\n",
        "  series_data_df = series_data_df.drop(columns='Historical Player Rank')\n",
        "  \n",
        "\n",
        "  \n",
        "  titlestring = f\"\\tBest Playoff Scoring Stretches (max 1 per player)\\n\\t\\t\\t\\t Minimum {mp_min} MP\\n\"\n",
        "\n",
        "  print(titlestring)\n",
        "  \n",
        "  print(series_data_df)\n",
        "\n",
        "  print(\"\\n\\t'Approx_Scoring_Val' = Historical percentile of opponent adjusted PTS/G (1952-2022) * 0.5 + \\n\\t\\t\\t\\tHistorical percentile of TS+ (1952-2022)* 0.5\\n\\n\\tPTS/G adjusted based on regular season rDefRtg of playoff opponents\\n\\tTS+ adjusted based on opponents' TS% allowed in regular season\\n\\t1952-73 pace & TS% allowed both estimated\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ohw3Pm5mW8CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "printSinglePlayerStretch('/content/Stretches_Of_Series_Percentiles.csv', 2000, 11305, 1, \"best\", \"first\", \"Damian Lillard\")"
      ],
      "metadata": {
        "id": "JTwjbFo9XIbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Print Top Stretches of Series Stretch Lengths\n",
        "def printTopSeriesStretches(series_stretches_file, mp_min, mp_max, list_length, unique_players, best_or_worst, first_or_last):\n",
        "\n",
        "  series_data_df = pd.read_csv(series_stretches_file, encoding='utf8', index_col=False)\n",
        "  series_data_df = series_data_df[(series_data_df['MP'] >= mp_min)]\n",
        "  series_data_df = series_data_df[(series_data_df['MP'] <= mp_max)]\n",
        "\n",
        "  if best_or_worst == 'best':\n",
        "    series_data_df = series_data_df.sort_values('Approx_Scoring_Val', ascending=False)\n",
        "  elif best_or_worst == 'worst':\n",
        "    series_data_df = series_data_df.sort_values('Approx_Scoring_Val', ascending=True)\n",
        "  series_data_df['Approx_Scoring_Val'] = series_data_df['Approx_Scoring_Val'].round(2)\n",
        "  \n",
        "\n",
        "  if unique_players == 1:\n",
        "    if first_or_last == 'first':\n",
        "      series_data_df = series_data_df.drop_duplicates('Player', keep='first')\n",
        "    elif first_or_last == 'last':\n",
        "      series_data_df = series_data_df.drop_duplicates('Player', keep='last')\n",
        "  series_data_df = series_data_df.reset_index(drop=True)\n",
        "  series_data_df['Historical Player Rank'] = series_data_df.index\n",
        "  #print(series_data_df.shape[0])\n",
        "  #series_data_df = series_data_df[(series_data_df['Player'] == 'James Harden') | (series_data_df['Player'] == 'Bruce Bowen') | (series_data_df['Historical Player Rank'] == 0) | (series_data_df['Historical Player Rank'] == 681)]\n",
        "  #series_data_df = series_data_df[(series_data_df['Player'] == 'Manu Ginbili') | (series_data_df['Player'] == 'Kyrie Irving') | (series_data_df['Player'] == 'Tim Duncan')]\n",
        "  series_data_df = series_data_df[(series_data_df['Historical Player Rank'] <= list_length-1)]\n",
        "  series_data_df = series_data_df.drop(columns='Historical Player Rank')\n",
        "  #col_list = series_data_df.Player.values.tolist()\n",
        "  #print(col_list)\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "  titlestring = f\"\\tBest Playoff Scoring Stretches (max 1 per player)\\n\\t\\t\\t\\t Minimum {mp_min} MP\\n\"\n",
        "\n",
        "  print(titlestring)\n",
        "  \n",
        "  print(series_data_df)\n",
        "\n",
        "  series_data_df.to_csv('Top 2000 MP scoring stretches.csv',index=False)\n",
        "\n",
        "  print(\"\\n\\t'Approx_Scoring_Val' = Historical percentile of opponent adjusted PTS/G (1952-2022) * 0.5 + \\n\\t\\t\\t\\tHistorical percentile of TS+ (1952-2022)* 0.5\\n\\n\\tPTS/G adjusted based on regular season rDefRtg of playoff opponents\\n\\tTS+ adjusted based on opponents' TS% allowed in regular season\\n\\t1952-73 pace & TS% allowed both estimated\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9C8e_xOWZLAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title tmp approx_val_unique_stretches\n",
        "def printTopSeriesStretches(series_stretches_file, mp_min, mp_max, list_length, unique_players, best_or_worst, first_or_last):\n",
        "\n",
        "  series_data_df = pd.read_csv(series_stretches_file, encoding='utf8', index_col=False)\n",
        "  series_data_df = series_data_df[(series_data_df['MP'] >= mp_min)]\n",
        "  series_data_df = series_data_df[(series_data_df['MP'] <= mp_max)]\n",
        "\n",
        "  series = pd.read_csv('/content/series_data_52_22.csv', encoding='utf8', index_col=False)\n",
        "  series = series[(series['MP'] >= 100)]\n",
        "\n",
        "\n",
        "  # create Approx_Scoring_Val for each series\n",
        "  for idx, row in series_data_df.iterrows():\n",
        "    pts = row['PTS']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    pts_percentile = stats.percentileofscore(series['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(series['TS+'], ts)\n",
        "    s_color = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    series_data_df.at[idx, 'Color'] = s_color\n",
        "\n",
        "  series_data_df = series_data_df.sort_values('Color', ascending=False)\n",
        "  series_data_df['Color'] = series_data_df['Color'].round(2)\n",
        "  \n",
        "\n",
        "  if unique_players == 1:\n",
        "    series_data_df = series_data_df.drop_duplicates('Player', keep='first')\n",
        "  series_data_df = series_data_df.reset_index(drop=True)\n",
        "  #series_data_df['Historical Player Rank'] = series_data_df.index\n",
        "  #print(series_data_df.shape[0])\n",
        "  series_data_df = series_data_df[(series_data_df['PTS'] >= 20)]\n",
        "  #series_data_df = series_data_df.drop(columns='Historical Player Rank')\n",
        "  #col_list = series_data_df.Player.values.tolist()\n",
        "  #print(col_list)\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "  titlestring = f\"\\tBest Playoff Scoring Stretches (max 1 per player)\\n\\t\\t\\t\\t Minimum {mp_min} MP\\n\"\n",
        "\n",
        "  print(titlestring)\n",
        "  \n",
        "  print(series_data_df)\n",
        "\n",
        "  series_data_df.to_csv('Top 2500 MP scoring stretches.csv',index=False)\n",
        "\n",
        "  print(\"\\n\\t'Approx_Scoring_Val' = Historical percentile of opponent adjusted PTS/G (1952-2022) * 0.5 + \\n\\t\\t\\t\\tHistorical percentile of TS+ (1952-2022)* 0.5\\n\\n\\tPTS/G adjusted based on regular season rDefRtg of playoff opponents\\n\\tTS+ adjusted based on opponents' TS% allowed in regular season\\n\\t1952-73 pace & TS% allowed both estimated\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HGlP4ZCJoDpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "printTopSeriesStretches('/content/All_Scoring_Stretches_500min.csv', 1500, 11305, 60, 1, \"best\", \"first\")"
      ],
      "metadata": {
        "id": "yVxW57qII5qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Print Percentiles of Custom Playoff Series Stretches\n",
        "def trimStretchesPrintPercentile(series_stretches_file, player, first_opp, last_opp, mp_min, mp_max):\n",
        "\n",
        "  series_data_df = pd.read_csv(series_stretches_file, encoding='utf8', index_col=False)\n",
        "  series_data_df = series_data_df[(series_data_df['MP'] >= mp_min)]\n",
        "  series_data_df = series_data_df[(series_data_df['MP'] <= mp_max)]\n",
        "\n",
        "  player_df = series_data_df[(series_data_df['Player'] == player) & (series_data_df['First Series'] == first_opp) & (series_data_df['Last Series'] == last_opp)]\n",
        "  approx_scoring_val = float(player_df['Approx_Scoring_Val'])\n",
        "  print(\"Approx Scoring Val\")\n",
        "  print(approx_scoring_val)\n",
        "  approx_scoring_val_perc = stats.percentileofscore(series_data_df['Approx_Scoring_Val'], approx_scoring_val)\n",
        "  print(\"Percentile\")\n",
        "  print(approx_scoring_val_perc)"
      ],
      "metadata": {
        "id": "A6DIi7kJQd1r",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trimStretchesPrintPercentile('/content/Stretches_Of_Series_Percentiles.csv', 'Manu Ginbili', '2005 DEN', '2006 DAL', 1200, 12000)"
      ],
      "metadata": {
        "id": "25d8_9nMQhN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title printSeriesScoringPercentiles\n",
        "\n",
        "# plots the approx_scoring_percentile of two players in bar graph form\n",
        "series_data_52_22_df = pd.read_csv('/content/series_data_52_22.csv', encoding='utf8', index_col=False) \n",
        "def printTwoSeriesScoringPercentiles(p1, p2, c1, c2, mp_min, pts_min):\n",
        "  graph_data =  series_data_52_22_df.copy()\n",
        "  graph_data = graph_data[(graph_data['PTS/G'] >= pts_min)]\n",
        "  graph_data = graph_data[(graph_data['MP'] >= mp_min)]\n",
        "  graph_data['Approx_Scoring_Val'] = 0\n",
        "\n",
        "  for idx, row in graph_data.iterrows():\n",
        "    pts = row['PTS/G']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "    approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    graph_data.at[idx, 'Approx_Scoring_Val'] = approx_scoring_val\n",
        "\n",
        "\n",
        "  final_season_df = pd.DataFrame(columns = ['Series', f\"{p1} Approx_Scoring_Val\", f\"{p1} MP\", f\"{p2} Approx_Scoring_Val\", f\"{p2} MP\"])\n",
        "\n",
        "  players_df = series_data_52_22_df[(series_data_52_22_df['Player'] == p1) | (series_data_52_22_df['Player'] == p2)]\n",
        "  players_df['index'] = players_df.index\n",
        "  players_df = players_df.sort_values(by = ['Year', 'index'], ascending = [True, True])\n",
        "  p1_df = players_df[(players_df['Player'] == p1)]\n",
        "  p2_df = players_df[(players_df['Player'] == p2)]\n",
        "  p2_df = p2_df.reset_index()\n",
        "  p1_df = p1_df.reset_index()\n",
        "\n",
        "  series_done = []\n",
        "\n",
        "  recent_year = 1951\n",
        "  round_count = 1\n",
        "  for idx, row in players_df.iterrows():\n",
        "\n",
        "    display_series_opponent = 0\n",
        "\n",
        "    selected_series = str(row['Player']) + str(row['Year']) + row['Opp']\n",
        "    if selected_series not in series_done:\n",
        "      if row['Year'] == recent_year:\n",
        "        round_count+= 1\n",
        "      elif row['Year'] > recent_year:\n",
        "        round_count = 1\n",
        "        recent_year = row['Year']\n",
        "      if row['Player'] == p1:\n",
        "        if row['Year'] in p2_df.values:\n",
        "          if round_count == 1:\n",
        "            other_player_year = p2_df[(p2_df['Year'] == row['Year'])]\n",
        "            other_player_year = other_player_year.reset_index(drop=True)\n",
        "            pts = other_player_year.loc[round_count-1,'PTS/G']\n",
        "            ts = other_player_year.loc[round_count-1,'TS+']\n",
        "            mp_2 = other_player_year.loc[round_count-1,'MP']\n",
        "            pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "            ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "            p2_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "            p2_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p2_approx_scoring_val)\n",
        "            this_series = str(other_player_year.loc[round_count-1,'Player']) + str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])\n",
        "            series_done.append(this_series)\n",
        "            this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "            series_done.append(this_series)\n",
        "\n",
        "            if (str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])) == str(row['Year']) + row['Opp']:\n",
        "              display_series_opponent = 1\n",
        "\n",
        "          elif round_count == 2:\n",
        "            try:\n",
        "              other_player_year = p2_df[(p2_df['Year'] == row['Year'])]\n",
        "              other_player_year = other_player_year.reset_index(drop=True)\n",
        "              pts = other_player_year.loc[round_count-1,'PTS/G']\n",
        "              ts = other_player_year.loc[round_count-1,'TS+']\n",
        "              mp_2 = other_player_year.loc[round_count-1,'MP']\n",
        "              pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "              ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "              p2_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "              p2_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p2_approx_scoring_val)\n",
        "              this_series = str(other_player_year.loc[round_count-1,'Player']) + str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])\n",
        "              series_done.append(this_series)\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "\n",
        "              if (str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])) == str(row['Year']) + row['Opp']:\n",
        "                display_series_opponent = 1\n",
        "              \n",
        "            except:\n",
        "              p2_approx_scoring_val = 0\n",
        "              mp_2 = 0\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "              display_series_opponent = 1\n",
        "          elif round_count == 3:\n",
        "            try:\n",
        "              other_player_year = p2_df[(p2_df['Year'] == row['Year'])]\n",
        "              other_player_year = other_player_year.reset_index(drop=True)\n",
        "              pts = other_player_year.loc[round_count-1,'PTS/G']\n",
        "              ts = other_player_year.loc[round_count-1,'TS+']\n",
        "              mp_2 = other_player_year.loc[round_count-1,'MP']\n",
        "              pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "              ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "              p2_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "              p2_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p2_approx_scoring_val)\n",
        "              this_series = str(other_player_year.loc[round_count-1,'Player']) + str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])\n",
        "              series_done.append(this_series)\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "\n",
        "              if (str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])) == str(row['Year']) + row['Opp']:\n",
        "                display_series_opponent = 1\n",
        "            except:\n",
        "              p2_approx_scoring_val = 0\n",
        "              mp_2 = 0\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "              display_series_opponent = 1\n",
        "\n",
        "          elif round_count == 4:\n",
        "            try:\n",
        "              other_player_year = p2_df[(p2_df['Year'] == row['Year'])]\n",
        "              other_player_year = other_player_year.reset_index(drop=True)\n",
        "              pts = other_player_year.loc[round_count-1,'PTS/G']\n",
        "              ts = other_player_year.loc[round_count-1,'TS+']\n",
        "              mp_2 = other_player_year.loc[round_count-1,'MP']\n",
        "              pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "              ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "              p2_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "              p2_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p2_approx_scoring_val)\n",
        "              this_series = str(other_player_year.loc[round_count-1,'Player']) + str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])\n",
        "              series_done.append(this_series)\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "\n",
        "              if (str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])) == str(row['Year']) + row['Opp']:\n",
        "                display_series_opponent = 1\n",
        "            except:\n",
        "              p2_approx_scoring_val = 0\n",
        "              mp_2 = 0\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "              display_series_opponent = 1\n",
        "        else:\n",
        "          p2_approx_scoring_val = 0\n",
        "          mp_2 = 0\n",
        "          display_series_opponent = 1\n",
        "      if row['Player'] == p2:\n",
        "        if row['Year'] in p1_df.values:\n",
        "          if round_count == 1:\n",
        "            other_player_year = p1_df[(p1_df['Year'] == row['Year'])]\n",
        "            other_player_year = other_player_year.reset_index(drop=True)\n",
        "            pts = other_player_year.loc[round_count-1,'PTS/G']\n",
        "            ts = other_player_year.loc[round_count-1,'TS+']\n",
        "            mp_1 = other_player_year.loc[round_count-1,'MP']\n",
        "            pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "            ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "            p1_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "            p1_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p1_approx_scoring_val)\n",
        "            this_series = str(other_player_year.loc[round_count-1,'Player']) + str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])\n",
        "            series_done.append(this_series)\n",
        "            this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "            series_done.append(this_series)\n",
        "\n",
        "            if (str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])) == str(row['Year']) + row['Opp']:\n",
        "              display_series_opponent = 1\n",
        "          elif round_count == 2:\n",
        "            try:\n",
        "              other_player_year = p1_df[(p1_df['Year'] == row['Year'])]\n",
        "              other_player_year = other_player_year.reset_index(drop=True)\n",
        "              pts = other_player_year.loc[round_count-1,'PTS/G']\n",
        "              ts = other_player_year.loc[round_count-1,'TS+']\n",
        "              mp_1 = other_player_year.loc[round_count-1,'MP']\n",
        "              pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "              ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "              p1_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "              p1_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p1_approx_scoring_val)\n",
        "              this_series = str(other_player_year.loc[round_count-1,'Player']) + str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])\n",
        "              series_done.append(this_series)\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "\n",
        "              if (str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])) == str(row['Year']) + row['Opp']:\n",
        "                display_series_opponent = 1\n",
        "            except:\n",
        "              p1_approx_scoring_val = 0\n",
        "              mp_1 = 0\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "              display_series_opponent = 1\n",
        "          elif round_count == 3:\n",
        "            try:\n",
        "              other_player_year = p1_df[(p1_df['Year'] == row['Year'])]\n",
        "              other_player_year = other_player_year.reset_index(drop=True)\n",
        "              pts = other_player_year.loc[round_count-1,'PTS/G']\n",
        "              ts = other_player_year.loc[round_count-1,'TS+']\n",
        "              mp_1 = other_player_year.loc[round_count-1,'MP']\n",
        "              pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "              ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "              p1_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "              p1_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p1_approx_scoring_val)\n",
        "              this_series = str(other_player_year.loc[round_count-1,'Player']) + str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])\n",
        "              series_done.append(this_series)\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "\n",
        "              if (str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])) == str(row['Year']) + row['Opp']:\n",
        "                display_series_opponent = 1\n",
        "            except:\n",
        "              p1_approx_scoring_val = 0\n",
        "              mp_1 = 0\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "              display_series_opponent = 1\n",
        "          elif round_count == 4:\n",
        "            try:\n",
        "              other_player_year = p1_df[(p1_df['Year'] == row['Year'])]\n",
        "              other_player_year = other_player_year.reset_index(drop=True)\n",
        "              pts = other_player_year.loc[round_count-1,'PTS/G']\n",
        "              ts = other_player_year.loc[round_count-1,'TS+']\n",
        "              mp_1 = other_player_year.loc[round_count-1,'MP']\n",
        "              pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "              ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "              p1_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "              p1_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p1_approx_scoring_val)\n",
        "              this_series = str(other_player_year.loc[round_count-1,'Player']) + str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])\n",
        "              series_done.append(this_series)\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "\n",
        "              if (str(other_player_year.loc[round_count-1,'Year']) + str(other_player_year.loc[round_count-1,'Opp'])) == str(row['Year']) + row['Opp']:\n",
        "                display_series_opponent = 1\n",
        "            except:\n",
        "              p1_approx_scoring_val = 0\n",
        "              mp_1 = 0\n",
        "              this_series = row['Player'] + str(row['Year']) + row['Opp']\n",
        "              series_done.append(this_series)\n",
        "              display_series_opponent = 1\n",
        "        else:\n",
        "          p1_approx_scoring_val = 0\n",
        "          mp_1 = 0\n",
        "          display_series_opponent = 1\n",
        "\n",
        "      year = row['Year']\n",
        "      year = int(str(year)[2:])\n",
        "      opp = row['Opp']\n",
        "      year = int(year)\n",
        "      if year < 10:\n",
        "        year = \"0\" + str(year)\n",
        "      else:\n",
        "        year = str(year)\n",
        "      if round_count == 1:\n",
        "        series = year + \" 1st\"\n",
        "        series = str(series)\n",
        "      elif round_count == 2:\n",
        "        series = year + \" 2nd\"\n",
        "        series = str(series)\n",
        "      elif round_count == 3:\n",
        "        series = year + \" CON\"\n",
        "        series = str(series)\n",
        "      else:\n",
        "        series = year + \" FIN\"\n",
        "        series = str(series)\n",
        "      if display_series_opponent == 1:\n",
        "        series = year + \" \" + opp\n",
        "\n",
        "      if row['Player'] == p1:\n",
        "        pts = row['PTS/G']\n",
        "        ts = row['TS+']\n",
        "        mp_1 = row['MP']\n",
        "        pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "        ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "        p1_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "        p1_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p1_approx_scoring_val)\n",
        "        this_series = str(row['Player']) + str(row['Year']) + row['Opp']\n",
        "        series_done.append(this_series)\n",
        "      else:\n",
        "        pts = row['PTS/G']\n",
        "        ts = row['TS+']\n",
        "        mp_2 = row['MP']\n",
        "        pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "        ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "        p2_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "        p2_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p2_approx_scoring_val)\n",
        "        this_series = str(row['Player']) + str(row['Year']) + row['Opp']\n",
        "        series_done.append(this_series)\n",
        "      new_row = {'Series':series,  f\"{p1} Approx_Scoring_Val\":p1_approx_scoring_val, f\"{p1} MP\":int(mp_1), f\"{p2} Approx_Scoring_Val\":p2_approx_scoring_val, f\"{p2} MP\":int(mp_2)}\n",
        "      final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "      outfile = f\"{p1}_{p2}_Series_Percentiles.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(40)\n",
        "  fig.set_figwidth(45)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "  axis[0].tick_params(axis='x', which='major', labelsize=10)\n",
        "  axis[1].tick_params(axis='x', which='major', labelsize=10)\n",
        "  \n",
        "  perc_file_name = f\"{p1}_{p2}_Series_Percentiles.csv\"\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f\"{p1} MP\", f\"{p2} MP\"])\n",
        "  columns_titles = ['Series', f'{p1} Approx_Scoring_Val', f'{p2} Approx_Scoring_Val']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=[f'{p1} Approx_Scoring_Val', f'{p2} Approx_Scoring_Val'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[c1, c2], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Series Scoring [min. {pts_min} PP75; {mp_min} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile (1952 - 2022) *1954 not included*')\n",
        "\n",
        "  outfile = f\"{p1}_{p2}_Series_Percentiles_Output.csv\"\n",
        "  graph_data.to_csv(outfile, index=False)\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f'{p1} Approx_Scoring_Val', f'{p2} Approx_Scoring_Val'])\n",
        "  columns_titles = ['Series', f'{p1} MP', f'{p2} MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=[f'{p1} MP', f'{p2} MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[c1, c2], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "  \n",
        "\n",
        "  fig.savefig(f'/content/Graph_{p1}_{p2}_Series_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title printSeriesScoringPercentiles\n",
        "\n",
        "# plots the approx_scoring_percentile of one player in bar graph form\n",
        "series_data_52_22_df = pd.read_csv('/content/series_data_52_22.csv', encoding='utf8', index_col=False) \n",
        "def printSeriesScoringPercentiles(p1, c1, mp_min, pts_min):\n",
        "  graph_data =  series_data_52_22_df.copy()\n",
        "  graph_data = graph_data[(graph_data['PTS/G'] >= pts_min)]\n",
        "  graph_data = graph_data[(graph_data['MP'] >= mp_min)]\n",
        "  graph_data['Approx_Scoring_Val'] = 0\n",
        "\n",
        "  for idx, row in graph_data.iterrows():\n",
        "    pts = row['PTS/G']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "    approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    graph_data.at[idx, 'Approx_Scoring_Val'] = approx_scoring_val\n",
        "\n",
        "\n",
        "  final_season_df = pd.DataFrame(columns = ['Series', f\"{p1} Approx_Scoring_Val\", f\"{p1} MP\"])\n",
        "\n",
        "  players_df = series_data_52_22_df[(series_data_52_22_df['Player'] == p1)]\n",
        "  players_df['index'] = players_df.index\n",
        "  players_df = players_df.sort_values(by = ['Year', 'index'], ascending = [True, True])\n",
        "\n",
        "\n",
        " \n",
        "  for idx, row in players_df.iterrows():\n",
        "\n",
        "      pts = row['PTS/G']\n",
        "      ts = row['TS+']\n",
        "      mp_1 = row['MP']\n",
        "      pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "      ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "      p1_approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "      p1_approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], p1_approx_scoring_val)\n",
        "\n",
        "      year = str(row['Year'])\n",
        "      year = int(str(year)[2:])\n",
        "      opp = row['Opp']\n",
        "      year = str(year)\n",
        "      series = year + \" \" + opp\n",
        "\n",
        "      new_row = {'Series':series,  f\"{p1} Approx_Scoring_Val\":p1_approx_scoring_val, f\"{p1} MP\":int(mp_1)}\n",
        "      final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "      outfile = f\"{p1}_Series_Percentiles.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(40)\n",
        "  fig.set_figwidth(45)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "  axis[0].tick_params(axis='x', which='major', labelsize=10)\n",
        "  axis[1].tick_params(axis='x', which='major', labelsize=10)\n",
        "  \n",
        "  perc_file_name = f\"{p1}_Series_Percentiles.csv\"\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f\"{p1} MP\"])\n",
        "  columns_titles = ['Series', f'{p1} Approx_Scoring_Val']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=[f'{p1} Approx_Scoring_Val'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[c1], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Series Scoring [min. {pts_min} PP75; {mp_min} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile (1952 - 2022) *1954 not included*')\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=[f'{p1} Approx_Scoring_Val'])\n",
        "  columns_titles = ['Series', f'{p1} MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=[f'{p1} MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[c1], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "  \n",
        "\n",
        "  fig.savefig(f'/content/Graph_{p1}_Series_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "OhvwQVgEPN9O",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printSeriesScoringPercentiles(\"Shaquille O\\'Neal\", \"m\", 75, 0)\n",
        "printTwoSeriesScoringPercentiles(\"Manu Ginbili\", \"Tony Parker\", \"#FF8200\", \"#00B2A9\", 75, 0)\n",
        "#printTopSeriesStretches('/content/Stretches_Of_Series_Percentiles.csv', 2000, 11305, 60, 1, \"best\", \"first\")"
      ],
      "metadata": {
        "id": "Gt7WCeaGVPzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title printOrderedSeriesScoringPercentiles\n",
        "\n",
        "# plots the approx_scoring_percentile of two players in bar graph form\n",
        "series_data_52_22_df = pd.read_csv('/content/series_data_52_22.csv', encoding='utf8', index_col=False) \n",
        "def printOrderedSeriesScoringPercentiles(p1, p2, c1, c2, mp_min, pts_min):\n",
        "  graph_data =  series_data_52_22_df.copy()\n",
        "  graph_data = graph_data[(graph_data['PTS/G'] >= pts_min)]\n",
        "  graph_data = graph_data[(graph_data['MP'] >= mp_min)]\n",
        "  graph_data['Approx_Scoring_Val'] = 0\n",
        "\n",
        "  for idx, row in graph_data.iterrows():\n",
        "    pts = row['PTS/G']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "    approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    graph_data.at[idx, 'Approx_Scoring_Val'] = approx_scoring_val\n",
        "\n",
        "\n",
        "  final_season_df = pd.DataFrame(columns = ['Series', 'Player', \"Approx_Scoring_Val\", \"MP\"])\n",
        "\n",
        "  players_df = series_data_52_22_df[(series_data_52_22_df['Player'] == p1) | (series_data_52_22_df['Player'] == p2)]\n",
        "\n",
        "  for idx, row in players_df.iterrows():\n",
        "    year = row['Year']\n",
        "    year = int(str(year)[2:])\n",
        "    opp = row['Opp']\n",
        "    year = int(year)\n",
        "    if year < 10:\n",
        "      year = \"0\" + str(year)\n",
        "    else:\n",
        "      year = str(year)\n",
        "    series = year + \" \" + opp\n",
        "    pts = row['PTS/G']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "    approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], approx_scoring_val)\n",
        "    new_row = {'Series':series,  'Player': row['Player'], \"Approx_Scoring_Val\": approx_scoring_val, \"MP\":int(mp)}\n",
        "    final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  outfile = f\"{p1}_{p2}_Ordered_Series_Percentiles.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(40)\n",
        "  fig.set_figwidth(45)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "  axis[0].tick_params(axis='x', which='major', labelsize=10)\n",
        "  axis[1].tick_params(axis='x', which='major', labelsize=10)\n",
        "  \n",
        "  perc_file_name = f\"{p1}_{p2}_Ordered_Series_Percentiles.csv\"\n",
        "\n",
        "  graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "  graph_data\n",
        "  first_cond = (graph_data['Player'] == p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2), c2, graph_data.color)\n",
        "  graph_data = graph_data.sort_values('Approx_Scoring_Val', ascending = False)\n",
        "  graph_data = graph_data.reset_index()\n",
        "  sns.set(font_scale=2.5)\n",
        "\n",
        "  sns.barplot(data=graph_data, x=graph_data.index, y='Approx_Scoring_Val', palette=graph_data.color, ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Series Scoring [min. {pts_min} PP75; {mp_min} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile (1952 - 2022) *1954 not included*')\n",
        "  axis[0].set(xticklabels=[])  \n",
        "  axis[0].set(xlabel=None)\n",
        "  axis[0].tick_params(bottom=False)  # remove the ticks\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='$\\u25A0$', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=20),\n",
        "                    Line2D([0], [0], marker='$\\u25A0$', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=20)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "\n",
        "  sns.barplot(data=graph_data, x=graph_data.index, y='MP', palette=graph_data.color, ax=axis[1])\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "  axis[1].set(xticklabels=[])  \n",
        "  axis[1].set(xlabel=None)\n",
        "  axis[1].tick_params(bottom=False)  # remove the ticks\n",
        "\n",
        "  axis[1].legend(handles=legend_elements, loc='upper right')\n",
        "  \n",
        "\n",
        "  fig.savefig(f'/content/Graph_{p1}_{p2}_Ordered_Series_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "\n",
        "  # Downward Single Plot\n",
        "  #perc_file_name = f\"{p1}_{p2}_Ordered_Series_Percentiles.csv\"\n",
        "  #graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "\n",
        "  #first_cond = (graph_data['Player'] == p1)\n",
        "  #graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  #graph_data['color'] = np.where((graph_data.Player == p2), c2, graph_data.color)\n",
        "  #graph_data['MP'] = graph_data['MP'] * -1\n",
        "  #graph_data = graph_data.sort_values('MP', ascending = False)\n",
        "  #graph_data = graph_data.reset_index()\n",
        "\n",
        "  #fig = plt.figure(figsize=(40,45), tight_layout=True)\n",
        "  \n",
        "\n",
        "  #ax = sns.barplot(data=graph_data, x=graph_data.index, y='Approx_Scoring_Val', palette=graph_data.color)\n",
        "  #ax = sns.barplot(data=graph_data, x=graph_data.index, y='MP', palette=[\"k\", \"k\"])\n",
        "  #ax.tick_params(axis='x', which='major', labelsize=10)\n",
        "\n",
        "  #titlestring = f\"Playoff Series Scoring [min. {pts_min} PP75; {mp_min} MP]\"\n",
        "  #ax.set(title=titlestring, xlabel='Series', ylabel='Historical Percentile (1952 - 2022) *1954 not included*')\n",
        "  \n",
        "\n",
        "  #fig.savefig(f'/content/Graph_{p1}_{p2}_Ordered_Series_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xvEm2DWcvJRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title printOrderedSeriesScoringPercentiles (MPG)\n",
        "\n",
        "# plots the approx_scoring_percentile of two players in bar graph form\n",
        "def printMPGOrderedSeriesScoringPercentiles(p1, p2, c1, c2, mp_min, pts_min, option):\n",
        "  graph_data = pd.read_csv('/content/series_data_52_22.csv', encoding='utf8', index_col=False) \n",
        "  from scipy import stats\n",
        "  graph_data = graph_data[(graph_data['PTS/G'] >= pts_min)]\n",
        "  graph_data = graph_data[(graph_data['MP'] >= mp_min)]\n",
        "  graph_data['Approx_Scoring_Val'] = 0\n",
        "\n",
        "  for idx, row in graph_data.iterrows():\n",
        "    pts = row['PTS/G']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "    approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    graph_data.at[idx, 'Approx_Scoring_Val'] = approx_scoring_val\n",
        "\n",
        "\n",
        "  final_season_df = pd.DataFrame(columns = ['Series', 'Player', \"Approx_Scoring_Val\", \"MP\", \"MPG\", \"index\"])\n",
        "\n",
        "\n",
        "  players_df = pd.read_csv('/content/MPG_data.csv', encoding='utf8', index_col=False) \n",
        "  players_df['index'] = players_df.index\n",
        "  players_df = players_df.sort_values(by = ['Year', 'index'], ascending = [True, True])\n",
        "\n",
        "  for idx, row in players_df.iterrows():\n",
        "    index = row['index']\n",
        "    year = row['Year']\n",
        "    year = int(str(year)[2:])\n",
        "    opp = row['Opp']\n",
        "    year = int(year)\n",
        "    if year < 10:\n",
        "      year = \"0\" + str(year)\n",
        "    else:\n",
        "      year = str(year)\n",
        "    series = year + \" \" + opp\n",
        "    pts = row['PTS/G']\n",
        "    ts = row['TS+']\n",
        "    mp = row['MP']\n",
        "    mpg = row['MPG']\n",
        "    pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "    ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "    approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "    approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], approx_scoring_val)\n",
        "    new_row = {'Series':series,  'Player': row['Player'], \"Approx_Scoring_Val\": approx_scoring_val, \"MP\":int(mp), \"MPG\":float(mpg), \"index\": index}\n",
        "    final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  outfile = f\"{p1}_{p2}_Ordered_Series_Percentiles.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)\n",
        "\n",
        "  if option == 3:\n",
        "    fig, axis = plt.subplots(3)\n",
        "    fig.set_figheight(40)\n",
        "    fig.set_figwidth(45)\n",
        "\n",
        "    plt.subplots_adjust(left=0.1,\n",
        "                        bottom=0.1, \n",
        "                        right=0.9, \n",
        "                        top=0.9, \n",
        "                        wspace=0.4, \n",
        "                        hspace=0.4)\n",
        "    \n",
        "    axis[0].tick_params(axis='x', which='major', labelsize=10)\n",
        "    axis[1].tick_params(axis='x', which='major', labelsize=10)\n",
        "    \n",
        "    perc_file_name = f\"{p1}_{p2}_Ordered_Series_Percentiles.csv\"\n",
        "\n",
        "    graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "    graph_data\n",
        "    first_cond = (graph_data['Player'] == p1)\n",
        "    graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2), c2, graph_data.color)\n",
        "    graph_data = graph_data.sort_values('Approx_Scoring_Val', ascending = False)\n",
        "    graph_data = graph_data.reset_index()\n",
        "    sns.set(font_scale=2.5)\n",
        "\n",
        "    sns.barplot(data=graph_data, x=graph_data.index, y='Approx_Scoring_Val', palette=graph_data.color, ax=axis[0])\n",
        "\n",
        "    titlestring = f\"Playoff Series Scoring [min. {pts_min} PP75; {mp_min} MP]\"\n",
        "    axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile (1952 - 2022) *1954 not included*')\n",
        "    axis[0].set(xticklabels=[])  \n",
        "    axis[0].set(xlabel=None)\n",
        "    axis[0].tick_params(bottom=False)  # remove the ticks\n",
        "\n",
        "    legend_elements = [Line2D([0], [0], marker='$\\u25A0$', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=20),\n",
        "                      Line2D([0], [0], marker='$\\u25A0$', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=20)]\n",
        "    axis[0].legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "    sns.barplot(data=graph_data, x=graph_data.index, y='MPG', palette=graph_data.color, ax=axis[1])\n",
        "    titlestring = f\"Playoff MPG\"\n",
        "    axis[1].set(title=titlestring, xlabel='Series', ylabel='MPG')\n",
        "    axis[1].set(xticklabels=[])  \n",
        "    axis[1].set(xlabel=None)\n",
        "    axis[1].tick_params(bottom=False)  # remove the ticks\n",
        "\n",
        "    axis[1].legend(handles=legend_elements, loc='upper right')\n",
        "    \n",
        "\n",
        "    fig.savefig(f'/content/Graph_{p1}_{p2}_Ordered_Series_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "    sns.barplot(data=graph_data, x=graph_data.index, y='MP', palette=graph_data.color, ax=axis[2])\n",
        "    titlestring = f\"Playoff MP\"\n",
        "    axis[2].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "    axis[2].set(xticklabels=[])  \n",
        "    axis[2].set(xlabel=None)\n",
        "    axis[2].tick_params(bottom=False)  # remove the ticks\n",
        "\n",
        "    axis[2].legend(handles=legend_elements, loc='upper right')\n",
        "    \n",
        "\n",
        "    fig.savefig(f'/content/Graph_{p1}_{p2}_Ordered_Series_Percentiles', bbox_inches='tight')\n",
        "  else:\n",
        "    perc_file_name = f\"{p1}_{p2}_Ordered_Series_Percentiles.csv\"\n",
        "    graph_data = pd.read_csv(perc_file_name, encoding='utf8', index_col=False)\n",
        "\n",
        "    first_cond = (graph_data['Player'] == p1)\n",
        "    graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2), c2, graph_data.color)\n",
        "    graph_data['MPG'] = graph_data['MPG'] * -1\n",
        "    graph_data = graph_data.sort_values('Approx_Scoring_Val', ascending = False)\n",
        "    graph_data = graph_data.reset_index()\n",
        "\n",
        "    fig = plt.figure(figsize=(20,8), tight_layout=True)\n",
        "    sns.set(font_scale=1.0)\n",
        "\n",
        "    ax = sns.barplot(data=graph_data, x=graph_data.index, y='Approx_Scoring_Val', palette=graph_data.color)\n",
        "    ax = sns.barplot(data=graph_data, x=graph_data.index, y='MPG', palette=[\"k\", \"k\"])\n",
        "    ax.tick_params(axis='x', which='major', labelsize=10)\n",
        "\n",
        "    titlestring = f\"Playoff Series Scoring [min. {pts_min} PP75; {mp_min} MP]\"\n",
        "    ax.set(title=titlestring, xlabel='Series', ylabel='Historical Percentile (1952 - 2022) *1954 not included*')\n",
        "    ax.set(xticklabels=[])  \n",
        "    ax.set(xlabel=None)\n",
        "    ax.tick_params(bottom=False)  # remove the ticks\n",
        "    legend_elements = [Line2D([0], [0], marker='$\\u25A0$', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=8),\n",
        "                      Line2D([0], [0], marker='$\\u25A0$', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=8)]\n",
        "    ax.legend(handles=legend_elements, loc='upper right')\n",
        "    ticks =  ax.get_yticks()\n",
        "    ax.set_yticklabels([int(abs(tick)) for tick in ticks])\n",
        "    \n",
        "\n",
        "    fig.savefig(f'/content/Graph_{p1}_{p2}_Ordered_Series_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uAXtkoJb9XJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIWuoavMiG_r"
      },
      "source": [
        "**ERA ADJUSTED BPM CHANGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ax9wp0mPgnBr"
      },
      "outputs": [],
      "source": [
        "#@title Era Adjust BPM\n",
        "reg_playoff_per_75_df = import_player_since74_advanced_df.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in reg_playoff_per_75_df.iterrows():\n",
        "  sub_mess = bpm_coeff[(bpm_coeff['Year'] == row['Year'])]\n",
        "  row['BPM'] = float(row['BPM'] * sub_mess['BPM_Coefficient'])\n",
        "  row['OBPM'] = float(row['OBPM'] * sub_mess['OBPM_Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"inflation_adjusted_reg_bpm_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wlYv7A_Iexa8"
      },
      "outputs": [],
      "source": [
        "#@title (Era-Adjusted) p_plot_X_BPMChange (Single Plot)\n",
        "def p_plotOneBPMChange(p1, c1, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys BPM Change Single Plot Template (OBPM above below league avg)\n",
        "def p_plotOneBPMChange_ab(p1, c1, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  \n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['OBPM_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"bpm_change\": \"bpm_change\", \"OBPM_change\": \"OBPM_change\", \"BPM_reg\": \"BPM_reg\", \"BPM_post\": \"BPM_post\", \"OBPM_reg\": \"OBPM_reg\", \"OBPM_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"bpm_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [min. {threshold} OBPM postseason]\"\n",
        "  ax.set(title=title_string, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['bpm_change'].max()\n",
        "  x_min = graph_data['bpm_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "def p_plotTwoBPMChange(p1, p2, c1, c2, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys BPM Change Single Plot Template (OBPM above below league avg)\n",
        "def p_plotTwoBPMChange_ab(p1, p2, c1, c2, above_below, threshold, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  \n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['OBPM_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.BPM_post >= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.BPM_post >= threshold),c2, graph_data.color)\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.BPM_post <= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.BPM_post <= threshold),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [min. {threshold} BPM postseason; [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "def p_plotThreeBPMChange(p1, p2, p3, c1, c2, c3, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data =  pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_BPM_Changes', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pHiJYdZueZoR"
      },
      "outputs": [],
      "source": [
        "#@title (Era-Adjusted) p_plot_X_BPMChangeWithLines (Multiple Plots)\n",
        "def p_plotOneBPMChangeWithLines(p1, c1, pts_floor, mp_floor, label):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}__BPM_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoBPMChangeWithLines(p1, p2, c1, c2, pts_floor, mp_floor, label):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}__BPM_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeBPMChangeWithLines(p1, p2, p3, c1, c2, c3, pts_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_BPM_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B-Yy-4czj7Qc"
      },
      "outputs": [],
      "source": [
        "#@title Space labels (not working)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "np.random.seed(2016)\n",
        "\n",
        "N = 20\n",
        "scatter_data = np.random.rand(N, 3)*10\n",
        "\n",
        "\n",
        "def repel_labels(ax, x, y, labels, k=0.01):\n",
        "    G = nx.DiGraph()\n",
        "    data_nodes = []\n",
        "    init_pos = {}\n",
        "    for xi, yi, label in zip(x, y, labels):\n",
        "        data_str = 'data_{0}'.format(label)\n",
        "        G.add_node(data_str)\n",
        "        G.add_node(label)\n",
        "        G.add_edge(label, data_str)\n",
        "        data_nodes.append(data_str)\n",
        "        init_pos[data_str] = (xi, yi)\n",
        "        init_pos[label] = (xi, yi)\n",
        "\n",
        "    pos = nx.spring_layout(G, pos=init_pos, fixed=data_nodes, k=k)\n",
        "\n",
        "    # undo spring_layout's rescaling\n",
        "    pos_after = np.vstack([pos[d] for d in data_nodes])\n",
        "    pos_before = np.vstack([init_pos[d] for d in data_nodes])\n",
        "    scale, shift_x = np.polyfit(pos_after[:,0], pos_before[:,0], 1)\n",
        "    scale, shift_y = np.polyfit(pos_after[:,1], pos_before[:,1], 1)\n",
        "    shift = np.array([shift_x, shift_y])\n",
        "    for key, val in pos.items():\n",
        "        pos[key] = (val*scale) + shift\n",
        "\n",
        "    for label, data_str in G.edges():\n",
        "        ax.annotate(label,\n",
        "                    xy=pos[data_str], xycoords='data',\n",
        "                    xytext=pos[label], textcoords='data',\n",
        "                    arrowprops=dict(arrowstyle=\"->\",\n",
        "                                    shrinkA=0, shrinkB=0,\n",
        "                                    connectionstyle=\"arc3\", \n",
        "                                    color='red'), )\n",
        "    # expand limits\n",
        "    all_pos = np.vstack(pos.values())\n",
        "    x_span, y_span = np.ptp(all_pos, axis=0)\n",
        "    mins = np.min(all_pos-x_span*0.15, 0)\n",
        "    maxs = np.max(all_pos+y_span*0.15, 0)\n",
        "    ax.set_xlim([mins[0], maxs[0]])\n",
        "    ax.set_ylim([mins[1], maxs[1]])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(scatter_data[:, 0], scatter_data[:, 1],\n",
        "           c=scatter_data[:, 2], s=scatter_data[:, 2] * 150)\n",
        "labels = ['ano_{}'.format(i) for i in range(N)]\n",
        "repel_labels(ax, scatter_data[:, 0], scatter_data[:, 1], labels, k=0.008)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TONY MANU MULTIPLE LINE DRAWN SITUATIONAL CHANGES**"
      ],
      "metadata": {
        "id": "A1FZBFWLaGXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-Bgnirj0wYoA"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu Many changes from Big 3 -> 2/3 (2/3/4/5)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_2_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_3_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='3 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data = pd.read_csv('/content/Combined_4_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='4 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_5_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='5 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5oM4_4esYh2N"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu Many changes from Big 3 -> 2/3  +/- (2/3/4/5)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_2_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[0])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_3_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "  axis[1].set(title='3 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[1])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data = pd.read_csv('/content/Combined_4_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='4 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[2])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_5_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='5 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[3])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zgZ3-e7EQzRl"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu First to Later Rounds (+/-)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_NET\", y=\"Later_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Playoff +/- Change from First Round to Later Rounds (2004-14)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_NET'], graph_data['First_OFF']]\n",
        "  point2 = [graph_data['Later_NET'], graph_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_NET'], p2_data['First_OFF']]\n",
        "  point2 = [p2_data['Later_NET'], p2_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_NET'], graph_data['Later_OFF'], graph_data['Later_Years'], axis[0])\n",
        "    label_point(p2_data['Later_NET'], p2_data['Later_OFF'], p2_data['Later_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_NET\", y=\"Later_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Playoff +/- Change from First Round to Later Rounds (2004-14) [3+ opposing starters]', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_NET'], graph_data['First_OFF']]\n",
        "  point2 = [graph_data['Later_NET'], graph_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_NET'], p2_data['First_OFF']]\n",
        "  point2 = [p2_data['Later_NET'], p2_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_NET'], graph_data['Later_OFF'], graph_data['Later_Years'], axis[1])\n",
        "    label_point(p2_data['Later_NET'], p2_data['Later_OFF'], p2_data['Later_Years'], axis[1])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_NET_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loBdpFyEEaxA"
      },
      "source": [
        "**TONY MANU SITUATIONAL CHANGES FROM BIG 3 TO 2/3 BIG 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qw6gPZ85jYOp"
      },
      "outputs": [],
      "source": [
        "#@title Big 3 to Two Thirds\\2004-14\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O8X_Qca_iBDF"
      },
      "outputs": [],
      "source": [
        "#@title Big 3 to Two Thirds\\5 Year\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_5_Year_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Edki8wjYbKWz"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu 2004-14 change from Big 3 -> 2/3 (Tony Only 3 Opposing starters)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # NET\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [Manu 3+ opposing starters; Tony max 2 opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [Manu 3+ opposing starters; Tony max 2 opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0q8D6_zN2C5"
      },
      "source": [
        "**FROM FIRST TO LATER ROUNDS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xZ2si_VlN5mM"
      },
      "outputs": [],
      "source": [
        "#@title First Round to Later Rounds\\2004-14\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EP83nxE0UKmh"
      },
      "outputs": [],
      "source": [
        "#@title First Round to Later Rounds\\5 Year Later Peaks\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_5_Year_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UGlPvsNNcac7"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu 2004-14 change from first to later rounds (Tony Only 3 Opposing starters)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus_Round.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [Manu 3+ opposing starters; Tony max 2 opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus_Round.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [Manu 3+ opposing starters; Tony max 2 opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYaoLW0ASXvx"
      },
      "outputs": [],
      "source": [
        "plotTonyManuSituationalChange(\"Manu Ginbili\", \"Tony Parker\", \"#FF8200\", \"#EF426F\", 5, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KLAY/MANU GRAPHS"
      ],
      "metadata": {
        "id": "rxviYp2iQyeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Klay/Manu 5 Year Change\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Klay_Manu_5_Year_Change.png', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XisSl6juQ0fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Klay/Manu 3 Year Change\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (3 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (3 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (3 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (3 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Klay_Manu_3_Year_Change.png', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "br-VNioYT6LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotTonyManuSituationalChange(\"Manu Ginbili\", \"Klay Thompson\", \"k\", \"y\", 5, 1)"
      ],
      "metadata": {
        "id": "Wj6lgLfbRRG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MISC**"
      ],
      "metadata": {
        "id": "1BUC_calmAZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-AWQpDM9zWF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Append into one\n",
        "two = pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "three = pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', index_col=False, encoding='utf8')\n",
        "four = pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', index_col=False, encoding='utf8')\n",
        "five = pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "six = pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "seven = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "eight = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "nine = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "ten = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "two = two.append(three)\n",
        "two = two.append(four)\n",
        "two = two.append(five)\n",
        "two = two.append(six)\n",
        "two = two.append(seven)\n",
        "two = two.append(eight)\n",
        "two = two.append(nine)\n",
        "two = two.append(ten)\n",
        "two = two[(two['MP'] >= 500)]\n",
        "two = two.sort_values(by = ['PTS', 'MP'], ascending = [False, False], na_position = 'first')\n",
        "print(two)\n",
        "\n",
        "outfile = f\"All_Scoring_Stretches_500min.csv\"\n",
        "two.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3bBmu92gXOiE"
      },
      "outputs": [],
      "source": [
        "#@title 'Combine x year scoring and bpm changes' Function\n",
        "def combine_scoring_bpm_changes(scoring_df, bpm_df, year):\n",
        "  final_season_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_Change', 'TS+_Change', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  for idx, row in scoring_df.iterrows():\n",
        "    sub_second_df = bpm_df[(bpm_df['Player'] == row['Player'])]\n",
        "    for jdx, inner_row in sub_second_df.iterrows():\n",
        "      if inner_row['Player'] == row['Player'] and inner_row['Years'] == row['Years']:\n",
        "        new_row = {'Player':inner_row['Player'], 'Years':inner_row['Years'], 'PTS per 75_post':row['PTS per 75_post'], 'TS+_post':row['TS+_post'], 'PTS_Change':row['PTS_change'], 'TS+_Change':row['TS+_change'], 'BPM_post':inner_row['BPM_post'], 'OBPM_post':inner_row['OBPM_post'], 'BPM_change':inner_row['BPM_change'], 'OBPM_change':inner_row['OBPM_change'], 'MP_post':int(inner_row['MP_post'])}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  final_season_df = final_season_df[(final_season_df['MP_post'] >= 300)]\n",
        "  outfile = f\"{year}_Year_Scoring_BPM_Changes_300min.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3VNf4cGdXn40"
      },
      "outputs": [],
      "source": [
        "#@title Run 'Combine x year scoring and bpm changes'\n",
        "scoring = pd.read_csv('/content/Two_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Two_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Two\")\n",
        "\n",
        "scoring = pd.read_csv('/content/Three_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Three_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Three\")\n",
        "\n",
        "\n",
        "scoring = pd.read_csv('/content/Four_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Four_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Four\")\n",
        "\n",
        "\n",
        "scoring = pd.read_csv('/content/Five_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Five_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Five\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HISTORICAL PERCENTILES**"
      ],
      "metadata": {
        "id": "Ti-kIv9qTcdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Year Percentiles\n",
        "def Spurs_Playoff_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu PP75', 'Tony PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu PP75', 'Tony PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu TS+', 'Tony TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu TS+', 'Tony TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Year', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title Spurs '2/3' Percentiles\n",
        "def Spurs_Playoff_2_3_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_2-3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu PP75', 'Tony PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu PP75', 'Tony PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 70 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_2-3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu TS+', 'Tony TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu TS+', 'Tony TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 70 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_2-3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Year', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 70 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title Spurs '2/3' Percentiles\n",
        "def Spurs_Playoff_4_Plus_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_4plus_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)', 'Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)'])\n",
        "  columns_titles = ['Year', 'Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_4plus_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)', 'Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)'])\n",
        "  columns_titles = ['Year', 'Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_4plus_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)', 'Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)'])\n",
        "  columns_titles = ['Year', 'Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "BcoxF8ymi6Pf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Series Percentiles\n",
        "def Spurs_Playoff_Series_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_series_percentile.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu PP75', 'Tony PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu PP75', 'Tony PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_series_percentile.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu TS+', 'Tony TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu TS+', 'Tony TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_series_percentile.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[2].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title Spurs Series Percentiles\n",
        "def Spurs_Playoff_Series_Percentile_Approx():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Approx_Scoring_Val_Tony_Manu.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu Approx_Scoring_Val', 'Tony Approx_Scoring_Val']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu Approx_Scoring_Val', 'Tony Approx_Scoring_Val'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile (1952 - 2022) *1954 not included*')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Approx_Scoring_Val_Tony_Manu.csv', encoding='utf8', index_col=False)\n",
        "  graph_data = graph_data.drop(columns=['Manu Approx_Scoring_Val', 'Tony Approx_Scoring_Val'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "#@title Spurs Series Percentiles\n",
        "def Spurs_Playoff_Series_Percentile_No_First():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_No_First_Manu_Tony_series_percentile.csv', encoding='utf8')\n",
        "  graph_data['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Manu PP75']) + (0.5 * graph_data['Manu TS+'])\n",
        "  graph_data['Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tony PP75']) + (0.5 * graph_data['Tony TS+'])\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_No_First_Manu_Tony_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "C7xD2Y3KU0Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0unXklbF571"
      },
      "source": [
        "**PLOT SHOOTING DISTRIBUTION DATA/PRINT MANUAL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FIVy6IDJYfP2"
      },
      "outputs": [],
      "source": [
        "#@title Print Medians\n",
        "def printmedians(pts_floor):\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"2 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"2 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"3 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"3 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 800)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"4 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"4 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1000)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"5 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"5 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1200)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"6 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"6 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1400)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"7 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"7 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1500)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"8 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"8 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 2000)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"10 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"10 Year Median TS+ decline\")\n",
        "  print(med_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-xXRuU0mbJ-g"
      },
      "outputs": [],
      "source": [
        "#@title Print Distribution of Scoring Changes\n",
        "def printTSdistribution(all_some, pts_floor):\n",
        "  if all_some == 0:\n",
        "    # 2 year\n",
        "    graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "\n",
        "    # 3 year\n",
        "    tmp_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 4 year\n",
        "    tmp_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 5 year\n",
        "    tmp_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 6 year\n",
        "    tmp_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 7 year\n",
        "    tmp_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 8 year\n",
        "    tmp_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 10 year\n",
        "    tmp_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "  else:\n",
        "    graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data['PTS_change'] = graph_data['PTS_change'].round(1)\n",
        "  graph_data['TS+_change'] = graph_data['TS+_change'].round(1)\n",
        "\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "\n",
        "  pd.cut(graph_data['TS+_change'], \n",
        "       bins=[-17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8], \n",
        "       labels = ['-17% or worse', '-16%', '-15%', '-14%', '-13%', '-12%', '-11%', '-10%', '-9%', '-8%', '-7%', '-6%', '-5%', '-4%',\n",
        "                 '-3%', '-2%', '-1%', '0%', '+1%', '+2%', '+3%', '+4%', '+5%', '+6%',\n",
        "                 '+7% or better'])\\\n",
        "  .value_counts(sort=False).plot.bar()\n",
        "  title_string = f\"Reg->Post Scoring Change; Multi Year Playoff Stretches; >= {pts_floor} PP75 Post (1974-2022)\"\n",
        "  plt.title(title_string)\n",
        "  plt.xlabel('Change in TS+')\n",
        "  plt.ylabel('Count')\n",
        "  plt.show()\n",
        "  print(graph_data['TS+_change'].quantile(0.98))\n",
        "\n",
        "def printPTSdistribution(all_some, pts_floor):\n",
        "  if all_some == 0:\n",
        "    # 2 year\n",
        "    graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "\n",
        "    # 3 year\n",
        "    tmp_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 4 year\n",
        "    tmp_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 5 year\n",
        "    tmp_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 6 year\n",
        "    tmp_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 7 year\n",
        "    tmp_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 8 year\n",
        "    tmp_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 10 year\n",
        "    tmp_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "  else:\n",
        "    graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data['PTS_change'] = graph_data['PTS_change'].round(1)\n",
        "  graph_data['TS+_change'] = graph_data['TS+_change'].round(1)\n",
        "\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "\n",
        "  pd.cut(graph_data['PTS_change'], \n",
        "       bins=[-6, -5.5, -5, -4.5, -4, -3.5, -3, -2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5], \n",
        "       labels = ['-6 PTS or worse', '-5.5', '-5', '-4.5', '-4', '-3.5', '-3', '-2.5', '-2', '-1.5', '-1', '-0.5', '0', '+0.5', '+1', '+1.5', '+2', '+2.5', '+3', '+3.5', '+4', '+4.5% or better'])\\\n",
        "  .value_counts(sort=False).plot.bar()\n",
        "  title_string = f\"Reg->Post Scoring Change; Multi Year Playoff Stretches; >= {pts_floor} PP75 Post (1974-2022)\"\n",
        "  plt.title(title_string)\n",
        "  plt.xlabel('Change in PTS per 75')\n",
        "  plt.ylabel('Count')\n",
        "  plt.show()\n",
        "  print(graph_data['PTS_change'].quantile(0.8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CnygkJdO3VSy"
      },
      "outputs": [],
      "source": [
        "#@title Round Format\n",
        "player_change_file['TS+_change'] = player_change_file['TS+_change'].round(2)\n",
        "player_change_file['PTS_change'] = player_change_file['PTS_change'].round(2)\n",
        "player_change_file['PTS per 75_post'] = player_change_file['PTS per 75_post'].round(2)\n",
        "player_change_file['TS+_post'] = player_change_file['TS+_post'].round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1KNOV-aK5JdN"
      },
      "outputs": [],
      "source": [
        "#@title Manual comparisons function\n",
        "sorted_playoffs_pts = era_opponent_adj_playoff_per_75_df.copy()\n",
        "sorted_reg_pts = import_player_since74_per75_df.copy()\n",
        "\n",
        "player_a = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Kawhi Leonard\") & ((sorted_playoffs_pts.Year == 2017) | (sorted_playoffs_pts.Year == 2019)  | (sorted_playoffs_pts.Year == 2021))]\n",
        "player_b = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Kevin Durant\") & ((sorted_playoffs_pts.Year == 2012) | (sorted_playoffs_pts.Year == 2017)  | (sorted_playoffs_pts.Year == 2018) | (sorted_playoffs_pts.Year == 2019) | (sorted_playoffs_pts.Year == 2021))]\n",
        "\n",
        "#player_b = sorted_reg_pts[(sorted_reg_pts.Player == \"Damian Lillard\") & ((sorted_reg_pts.Year == 2014) | (sorted_reg_pts.Year == 2015)  | (sorted_reg_pts.Year == 2016) | (sorted_reg_pts.Year == 2016) | (sorted_reg_pts.Year == 2017) | (sorted_reg_pts.Year == 2019) | (sorted_reg_pts.Year == 2020) | (sorted_reg_pts.Year == 2021))]\n",
        "\n",
        "#player_a = sorted_pts[(sorted_pts.Player == \"Kawhi Leonard\") & ((sorted_pts.Year == 2012) | (sorted_pts.Year == 2014)  | (sorted_pts.Year == 2019) | (sorted_pts.Year == 2016) | (sorted_pts.Year == 2015) | (sorted_pts.Year == 2017) | (sorted_pts.Year == 2020) | (sorted_pts.Year == 2021))]\n",
        "\n",
        "#player_a = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Klay Thompson\") & ((sorted_playoffs_pts.Year == 2013) | (sorted_playoffs_pts.Year == 2014)  | (sorted_playoffs_pts.Year == 2015) | (sorted_playoffs_pts.Year == 2016) | (sorted_playoffs_pts.Year == 2017) | (sorted_playoffs_pts.Year == 2018) | (sorted_playoffs_pts.Year == 2019))]\n",
        "#player_b = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Kobe Bryant\")]\n",
        "#player_a = df[(df.Player == a)]\n",
        "#player_b = df[(df.Player == b)]\n",
        "total_mp_a = 0\n",
        "total_pts_a = 0\n",
        "total_ts_a = 0\n",
        "\n",
        "total_mp_b = 0\n",
        "total_pts_b = 0\n",
        "total_ts_b = 0\n",
        "mp_list_a = []\n",
        "mp_list_b = []\n",
        "\n",
        "# find total minutes a\n",
        "for row in player_a['MP']:\n",
        "  mp_list_a.append(row)\n",
        "  total_mp_a += row\n",
        "print(player_a.iat[0, 3], \"\\nminutes: \", total_mp_a)\n",
        "\n",
        "# find total PTS a\n",
        "i = 0\n",
        "for row in player_a['PTS']:\n",
        "  total_pts_a += row * (mp_list_a[i] / total_mp_a)\n",
        "  i = i + 1\n",
        "\n",
        "# find total TS+ a\n",
        "i = 0\n",
        "for row in player_a['TS%+']:\n",
        "  total_ts_a += row * (mp_list_a[i] / total_mp_a)\n",
        "  i = i + 1\n",
        "\n",
        "print(\"PTS per 75: \", total_pts_a)\n",
        "print(\"TS+: \",total_ts_a)\n",
        "\n",
        "# find total minutes\n",
        "for row in player_b['MP']:\n",
        "  mp_list_b.append(row)\n",
        "  total_mp_b += row\n",
        "print(\"\\n\")\n",
        "print(player_b.iat[0, 3], \"\\nminutes: \", total_mp_b)\n",
        "\n",
        "# find total PTS\n",
        "i = 0\n",
        "for row in player_b['PTS']:\n",
        "  total_pts_b += row * (mp_list_b[i] / total_mp_b)\n",
        "  i = i + 1\n",
        "\n",
        "# find total TS+\n",
        "i = 0\n",
        "for row in player_b['TS%+']:\n",
        "  total_ts_b += row * (mp_list_b[i] / total_mp_b)\n",
        "  i = i + 1\n",
        "\n",
        "print(\"PTS per 75: \", total_pts_b)\n",
        "print(\"TS+: \",total_ts_b)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M8yAW7WASwDX"
      },
      "outputs": [],
      "source": [
        "#@title def reg_playoff_comp(a, dfa, dfb) \n",
        "# def reg_playoff_comp(a, dfa, dfb) \n",
        "# print the change in scoring rate and effieciency for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoff_comp(a, dfa, dfb):\n",
        "\n",
        "  player_a = dfa[(dfa.Player == a)]\n",
        "  player_b = dfb[(dfb.Player == a)]\n",
        "  total_mp_a = 0\n",
        "  pts_list_a = []\n",
        "  ts_list_a = []\n",
        "\n",
        "  total_mp_b = 0\n",
        "  pts_list_b = []\n",
        "  ts_list_b = []\n",
        "\n",
        "  mp_list_a = []\n",
        "  mp_list_b = []\n",
        "\n",
        "\n",
        "  # find total PTS a\n",
        "  i = 0\n",
        "  for row in player_a['PTS']:\n",
        "    pts_list_a.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+ a\n",
        "  i = 0\n",
        "  for row in player_a['TS%+']:\n",
        "    ts_list_a.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total minutes\n",
        "  for row in player_b['MP']:\n",
        "    mp_list_b.append(row)\n",
        "    total_mp_b += row\n",
        "  print(\"\\n\")\n",
        "  print(player_b.iat[0, 3], \"\\nPlayoffs\\n\\nminutes: \", total_mp_b)\n",
        "\n",
        "  # find total PTS\n",
        "  i = 0\n",
        "  for row in player_b['PTS']:\n",
        "    pts_list_b.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+\n",
        "  i = 0\n",
        "  for row in player_b['TS%+']:\n",
        "    ts_list_b.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  total_pts = 0\n",
        "  total_ts = 0\n",
        "  while i <= j-1:\n",
        "    total_pts += ((pts_list_b[i] - pts_list_a[i]) * (mp_list_b[i] / total_mp_b))\n",
        "    print(pts_list_b[i] - pts_list_a[i])\n",
        "    print(((pts_list_b[i] - pts_list_a[i]) * (mp_list_b[i] / total_mp_b)))\n",
        "    total_ts += ((ts_list_b[i] - ts_list_a[i]) * (mp_list_b[i] / total_mp_b))\n",
        "    i = i + 1\n",
        "\n",
        "  print(\"\\n\\nRegular Season to Playoffs Change\\n\")\n",
        "  if total_pts > 0:\n",
        "    form_string = \"PTS per 75: +{}\".format(total_pts)\n",
        "    print(form_string)\n",
        "  else: \n",
        "    print(\"PTS per 75: \", total_pts)\n",
        "  if total_ts > 0:\n",
        "    form_string = \"TS+ {}\".format(total_ts)\n",
        "    print(form_string)\n",
        "  else:\n",
        "    print(\"TS+: \",total_ts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spurs = era_opponent_adj_playoff_per_75_df[(era_opponent_adj_playoff_per_75_df['Tm'] == 'SAS') | (era_opponent_adj_playoff_per_75_df['Tm'] == 'SAA')]\n",
        "spurs = spurs[(spurs['MP'] >= 80)]\n",
        "spurs = spurs.drop(columns= ['TeamColor', 'Age', 'Tm', 'G', 'GS', 'Pos', '2P', 'DRB','TRB','AST','STL','BLK','TOV','PF', '3P%','2PA','2P%','FT','FTA','FT%','ORB', 'FG','FGA','FG%','3P','3PA', 'ORtg','DRtg'])\n",
        "spurs['MP'] = spurs ['MP'].astype(int)\n",
        "spurs['PTS'] = spurs['PTS'].round(2)\n",
        "print(spurs)\n",
        "spurs.to_csv('Spurs_Single_Playoffs.csv', index=False)\n",
        "\n",
        "#@title Tableau Work\n",
        "\n",
        "#@title Tableau Work\n",
        "og = pd.read_csv('/content/series_data_52_22.csv')\n",
        "top_ts = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv')\n",
        "\n",
        "top_ts = top_ts[(top_ts['MP'] >= 2000)]\n",
        "top_ts = top_ts[(top_ts['MP'] <= 12000)]\n",
        "top_ts = top_ts[(top_ts['PTS']) >= 15]\n",
        "top_ts['MP'] = top_ts['MP'].astype(int)\n",
        "\n",
        "top_ts['Color'] = 0\n",
        "\n",
        "for idx, row in top_ts.iterrows():\n",
        "  pts = row['PTS']\n",
        "  ts = row['TS+']\n",
        "  mp = row['MP']\n",
        "  pts_percentile = stats.percentileofscore(og['PTS/G'], pts)\n",
        "  ts_percentile = stats.percentileofscore(og['TS+'], ts)\n",
        "  approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "  top_ts.at[idx, 'Approx_Scoring_Val'] = approx_scoring_val\n",
        "\n",
        "top_ts = top_ts.sort_values('Approx_Scoring_Val', ascending=False)\n",
        "top_ts = top_ts.drop_duplicates('Player', keep='first')\n",
        "top_ts = top_ts.drop(columns=['G', 'Approx_Scoring_Val', 'Team'])\n",
        "print(top_ts)\n",
        "top_ts.to_csv(\"Scorers.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# plots the approx_scoring_percentile of two players in bar graph form\n",
        "graph_data = pd.read_csv('/content/series_data_52_22.csv', encoding='utf8', index_col=False) \n",
        "graph_data = graph_data[(graph_data['PTS/G'] >= 0)]\n",
        "graph_data = graph_data[(graph_data['MP'] >= 80)]\n",
        "graph_data['Approx_Scoring_Val'] = 0\n",
        "\n",
        "for idx, row in graph_data.iterrows():\n",
        "  pts = row['PTS/G']\n",
        "  ts = row['TS+']\n",
        "  mp = row['MP']\n",
        "  pts_percentile = stats.percentileofscore(graph_data['PTS/G'], pts)\n",
        "  ts_percentile = stats.percentileofscore(graph_data['TS+'], ts)\n",
        "  approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "  graph_data.at[idx, 'Approx_Scoring_Val'] = approx_scoring_val\n",
        "tmp_graph_data = graph_data.sort_values('Approx_Scoring_Val', ascending=False)\n",
        "tmp_graph_data = tmp_graph_data.drop_duplicates('Player', keep='first')\n",
        "tmp_graph_data = tmp_graph_data.drop(columns=['Approx_Scoring_Val'])\n",
        "print(tmp_graph_data)\n",
        "\n",
        "tmp_graph_data = graph_data.sort_values('Approx_Scoring_Val', ascending=False)\n",
        "tmp_graph_data = tmp_graph_data.drop(columns=['Approx_Scoring_Val'])\n",
        "tmp_graph_data = tmp_graph_data[(tmp_graph_data['PTS/G'] >= 20)]\n",
        "tmp_graph_data = tmp_graph_data[(tmp_graph_data['MP'] >= 100)]\n",
        "print(tmp_graph_data)\n",
        "tmp_graph_data.to_csv(\"Series.csv\", index=False)\n",
        "\n",
        "#og = pd.read_csv('/content/series_data_52_22.csv')\n",
        "top_ts = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv')\n",
        "\n",
        "top_ts = top_ts[(top_ts['MP_post'] >= 2000)]\n",
        "#top_ts = top_ts[(top_ts['MP_post'] <= 12000)]\n",
        "top_ts = top_ts[(top_ts['PTS per 75_post']) >= 15]\n",
        "top_ts['MP_post'] = top_ts['MP_post'].astype(int)\n",
        "\n",
        "top_ts['Color'] = 0\n",
        "\n",
        "for idx, row in top_ts.iterrows():\n",
        "  pts = row['PTS_change']\n",
        "  ts = row['TS+_change']\n",
        "  mp = row['MP_post']\n",
        "  pts_percentile = stats.percentileofscore(top_ts['PTS_change'], pts)\n",
        "  ts_percentile = stats.percentileofscore(top_ts['TS+_change'], ts)\n",
        "  approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "  top_ts.at[idx, 'Color'] = approx_scoring_val*100\n",
        "\n",
        "#top_ts = top_ts.sort_values('Approx_Scoring_Val', ascending=False)\n",
        "#top_ts = top_ts.drop_duplicates('Player', keep='first')\n",
        "#top_ts = top_ts.drop(columns=['G', 'Approx_Scoring_Val', 'Team'])\n",
        "print(top_ts)\n",
        "top_ts.to_csv(\"Scorers.csv\", index=False)"
      ],
      "metadata": {
        "id": "M7-Oka0fhqxV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ1Q1Vf25HB8"
      },
      "source": [
        "**SCORING PEAK FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NXifsLAWa2m_"
      },
      "outputs": [],
      "source": [
        "#@title Run Scoring Peaks\n",
        "\n",
        "# 2\n",
        "twoyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "twoyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('two_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 3 \n",
        "threeyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "threeyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('three_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 4 \n",
        "fouryearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "fouryearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('four_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 5 \n",
        "fiveyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "fiveyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('five_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 6 \n",
        "sixyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "sixyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('six_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 7 \n",
        "sevenyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "sevenyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('seven_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 8 \n",
        "eightyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "eightyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('eight_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 9 \n",
        "nineyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "nineyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('nine_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 10 \n",
        "tenyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "tenyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('ten_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "18EL_SvjcEnR"
      },
      "outputs": [],
      "source": [
        "#@title Import Scoring Peaks\n",
        "\n",
        "# 2\n",
        "import_adjpts_twopeaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_twopeaks_df = import_adjpts_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_twopeaks_df = pd.read_csv('two_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_twopeaks_df = import_adjts_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_twopeaks_df['TeamColor'] = import_adjpts_twopeaks_df['Team'].map(team_colors)\n",
        "import_adjts_twopeaks_df['TeamColor'] = import_adjts_twopeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_threepeaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_threepeaks_df = import_adjpts_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_threepeaks_df = pd.read_csv('three_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_threepeaks_df = import_adjts_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_threepeaks_df['TeamColor'] = import_adjpts_threepeaks_df['Team'].map(team_colors)\n",
        "import_adjts_threepeaks_df['TeamColor'] = import_adjts_threepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_4peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_4peaks_df = import_adjpts_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_4peaks_df = pd.read_csv('four_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_4peaks_df = import_adjts_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_4peaks_df['TeamColor'] = import_adjpts_4peaks_df['Team'].map(team_colors)\n",
        "import_adjts_4peaks_df['TeamColor'] = import_adjts_4peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_fivepeaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_fivepeaks_df = import_adjpts_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_fivepeaks_df = pd.read_csv('five_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_fivepeaks_df = import_adjts_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_fivepeaks_df['TeamColor'] = import_adjpts_fivepeaks_df['Team'].map(team_colors)\n",
        "import_adjts_fivepeaks_df['TeamColor'] = import_adjts_fivepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_6peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_6peaks_df = import_adjpts_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_6peaks_df = pd.read_csv('six_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_6peaks_df = import_adjts_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjts_6peaks_df['TeamColor'] = import_adjts_6peaks_df['Team'].map(team_colors)\n",
        "import_adjpts_6peaks_df['TeamColor'] = import_adjpts_6peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_7peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_7peaks_df = import_adjpts_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_7peaks_df = pd.read_csv('seven_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_7peaks_df = import_adjts_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjts_7peaks_df['TeamColor'] = import_adjts_7peaks_df['Team'].map(team_colors)\n",
        "import_adjpts_7peaks_df['TeamColor'] = import_adjpts_7peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_eightpeaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_eightpeaks_df = import_adjpts_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_eightpeaks_df = pd.read_csv('eight_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_eightpeaks_df = import_adjts_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_eightpeaks_df['TeamColor'] = import_adjpts_eightpeaks_df['Team'].map(team_colors)\n",
        "import_adjts_eightpeaks_df['TeamColor'] = import_adjts_eightpeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_9peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_9peaks_df = import_adjpts_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_9peaks_df = pd.read_csv('nine_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_9peaks_df = import_adjts_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_9peaks_df['TeamColor'] = import_adjpts_9peaks_df['Team'].map(team_colors)\n",
        "import_adjts_9peaks_df['TeamColor'] = import_adjts_9peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_10peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_10peaks_df = import_adjpts_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_10peaks_df = pd.read_csv('ten_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_10peaks_df = import_adjts_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_10peaks_df['TeamColor'] = import_adjpts_10peaks_df['Team'].map(team_colors)\n",
        "import_adjts_10peaks_df['TeamColor'] = import_adjts_10peaks_df['Team'].map(team_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Fo8KJtggdtZC"
      },
      "outputs": [],
      "source": [
        "#@title Output Scoring Peaks\n",
        "\n",
        "# 2\n",
        "at_least_300_min_2pts = import_adjpts_twopeaks_df[(import_adjpts_twopeaks_df['MP'] >= 300)]\n",
        "at_least_300_min_2pts = at_least_300_min_2pts.reset_index(drop=True)\n",
        "\n",
        "at_least_300_min_2ts = import_adjts_twopeaks_df[(import_adjts_twopeaks_df['MP'] >= 300)]\n",
        "at_least_300_min_2ts = at_least_300_min_2ts.reset_index(drop=True)\n",
        "\n",
        "sorted_pts_peak = at_least_300_min_2pts.copy()\n",
        "sorted_pts_peak.insert(6, \"TS+\", at_least_300_min_2ts['PeakValue'])\n",
        "sorted_pts_peak = sorted_pts_peak.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.sort_values('PTS', ascending=False)\n",
        "sorted_pts_peak = sorted_pts_peak.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_pts_peak = sorted_pts_peak.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_pts_peak['PTS'] = sorted_pts_peak['PTS'].round(2)\n",
        "sorted_pts_peak['TS+'] = sorted_pts_peak['TS+'].round(2)\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.dropna()\n",
        "\n",
        "print(sorted_pts_peak)\n",
        "\n",
        "sorted_pts_peak.to_csv(\"Two_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 3\n",
        "at_least_300_min_pts = import_adjpts_threepeaks_df[(import_adjpts_threepeaks_df['MP'] >= 300)]\n",
        "at_least_300_min_pts = at_least_300_min_pts.reset_index(drop=True)\n",
        "\n",
        "at_least_300_min_ts = import_adjts_threepeaks_df[(import_adjts_threepeaks_df['MP'] >= 300)]\n",
        "at_least_300_min_ts = at_least_300_min_ts.reset_index(drop=True)\n",
        "\n",
        "sorted_pts_peak = at_least_300_min_pts.copy()\n",
        "sorted_pts_peak.insert(6, \"TS+\", at_least_300_min_ts['PeakValue'])\n",
        "sorted_pts_peak = sorted_pts_peak.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.sort_values('PTS', ascending=False)\n",
        "sorted_pts_peak = sorted_pts_peak.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_pts_peak = sorted_pts_peak.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_pts_peak['PTS'] = sorted_pts_peak['PTS'].round(2)\n",
        "sorted_pts_peak['TS+'] = sorted_pts_peak['TS+'].round(2)\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.dropna()\n",
        "\n",
        "print(sorted_pts_peak)\n",
        "\n",
        "sorted_pts_peak.to_csv(\"Three_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 4\n",
        "at_least_600_min_pts = import_adjpts_4peaks_df[(import_adjpts_4peaks_df['MP'] >= 600)]\n",
        "at_least_600_min_pts = at_least_600_min_pts.reset_index(drop=True)\n",
        "\n",
        "at_least_600_min_ts = import_adjts_4peaks_df[(import_adjts_4peaks_df['MP'] >= 600)]\n",
        "at_least_600_min_ts = at_least_600_min_ts.reset_index(drop=True)\n",
        "\n",
        "sorted_pts_peak = at_least_600_min_pts.copy()\n",
        "sorted_pts_peak.insert(6, \"TS+\", at_least_600_min_ts['PeakValue'])\n",
        "sorted_pts_peak = sorted_pts_peak.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.sort_values('PTS', ascending=False)\n",
        "sorted_pts_peak = sorted_pts_peak.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_pts_peak = sorted_pts_peak.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_pts_peak['PTS'] = sorted_pts_peak['PTS'].round(2)\n",
        "sorted_pts_peak['TS+'] = sorted_pts_peak['TS+'].round(2)\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.dropna()\n",
        "\n",
        "print(sorted_pts_peak)\n",
        "\n",
        "sorted_pts_peak.to_csv(\"Four_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 5\n",
        "at_least_1000_min_pts = import_adjpts_fivepeaks_df[(import_adjpts_fivepeaks_df['MP'] >= 1000)]\n",
        "at_least_1000_min_ts = import_adjts_fivepeaks_df[(import_adjts_fivepeaks_df['MP'] >= 1000)]\n",
        "\n",
        "\n",
        "sorted_pts_peak = at_least_1000_min_pts.copy()\n",
        "sorted_pts_peak.insert(6, \"TS+\", at_least_1000_min_ts['PeakValue'])\n",
        "sorted_pts_peak = sorted_pts_peak.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.sort_values('PTS', ascending=False)\n",
        "sorted_pts_peak = sorted_pts_peak.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_pts_peak = sorted_pts_peak.reindex(columns=columns_titles)\n",
        "sorted_pts_peak = sorted_pts_peak.reset_index(drop=True)\n",
        "\n",
        "sorted_pts_peak['PTS'] = sorted_pts_peak['PTS'].round(2)\n",
        "sorted_pts_peak['TS+'] = sorted_pts_peak['TS+'].round(2)\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.dropna()\n",
        "\n",
        "print(sorted_pts_peak)\n",
        "\n",
        "sorted_pts_peak.to_csv(\"Five_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 6\n",
        "at_least_1200_min_pts = import_adjpts_6peaks_df[(import_adjpts_6peaks_df['MP'] >= 1200)]\n",
        "at_least_1200_min_ts = import_adjts_6peaks_df[(import_adjts_6peaks_df['MP'] >= 1200)]\n",
        "\n",
        "\n",
        "sorted_pts_peak = at_least_1200_min_pts.copy()\n",
        "sorted_pts_peak.insert(6, \"TS+\", at_least_1200_min_ts['PeakValue'])\n",
        "sorted_pts_peak = sorted_pts_peak.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.sort_values('PTS', ascending=False)\n",
        "sorted_pts_peak = sorted_pts_peak.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_pts_peak = sorted_pts_peak.reindex(columns=columns_titles)\n",
        "sorted_pts_peak = sorted_pts_peak.reset_index(drop=True)\n",
        "\n",
        "sorted_pts_peak['PTS'] = sorted_pts_peak['PTS'].round(2)\n",
        "sorted_pts_peak['TS+'] = sorted_pts_peak['TS+'].round(2)\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.dropna()\n",
        "\n",
        "print(sorted_pts_peak)\n",
        "\n",
        "sorted_pts_peak.to_csv(\"Six_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 7\n",
        "at_least_1400_min_pts = import_adjpts_7peaks_df[(import_adjpts_7peaks_df['MP'] >= 1400)]\n",
        "at_least_1400_min_ts = import_adjts_7peaks_df[(import_adjts_7peaks_df['MP'] >= 1400)]\n",
        "\n",
        "\n",
        "sorted_pts_peak = at_least_1400_min_pts.copy()\n",
        "sorted_pts_peak.insert(6, \"TS+\", at_least_1400_min_ts['PeakValue'])\n",
        "sorted_pts_peak = sorted_pts_peak.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.sort_values('PTS', ascending=False)\n",
        "sorted_pts_peak = sorted_pts_peak.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_pts_peak = sorted_pts_peak.reindex(columns=columns_titles)\n",
        "sorted_pts_peak = sorted_pts_peak.reset_index(drop=True)\n",
        "\n",
        "sorted_pts_peak['PTS'] = sorted_pts_peak['PTS'].round(2)\n",
        "sorted_pts_peak['TS+'] = sorted_pts_peak['TS+'].round(2)\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.dropna()\n",
        "\n",
        "print(sorted_pts_peak)\n",
        "\n",
        "sorted_pts_peak.to_csv(\"Seven_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 8\n",
        "at_least_1800_min_pts = import_adjpts_eightpeaks_df[(import_adjpts_eightpeaks_df['MP'] >= 1500)]\n",
        "at_least_1800_min_ts = import_adjts_eightpeaks_df[(import_adjts_eightpeaks_df['MP'] >= 1500)]\n",
        "\n",
        "\n",
        "sorted_pts_peak = at_least_1800_min_pts.copy()\n",
        "sorted_pts_peak.insert(6, \"TS+\", at_least_1800_min_ts['PeakValue'])\n",
        "sorted_pts_peak = sorted_pts_peak.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.sort_values('PTS', ascending=False)\n",
        "sorted_pts_peak = sorted_pts_peak.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_pts_peak = sorted_pts_peak.reindex(columns=columns_titles)\n",
        "sorted_pts_peak = sorted_pts_peak.reset_index(drop=True)\n",
        "\n",
        "sorted_pts_peak['PTS'] = sorted_pts_peak['PTS'].round(2)\n",
        "sorted_pts_peak['TS+'] = sorted_pts_peak['TS+'].round(2)\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.dropna()\n",
        "\n",
        "\n",
        "print(sorted_pts_peak)\n",
        "\n",
        "sorted_pts_peak.to_csv(\"Eight_Year_scoring_Playoff_Peaks_1500min.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 9\n",
        "at_least_1700_min_pts = import_adjpts_9peaks_df[(import_adjpts_9peaks_df['MP'] >= 1700)]\n",
        "at_least_1700_min_ts = import_adjts_9peaks_df[(import_adjts_9peaks_df['MP'] >= 1700)]\n",
        "\n",
        "\n",
        "sorted_pts_peak = at_least_1700_min_pts.copy()\n",
        "sorted_pts_peak.insert(6, \"TS+\", at_least_1700_min_ts['PeakValue'])\n",
        "sorted_pts_peak = sorted_pts_peak.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.sort_values('PTS', ascending=False)\n",
        "sorted_pts_peak = sorted_pts_peak.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_pts_peak = sorted_pts_peak.reindex(columns=columns_titles)\n",
        "sorted_pts_peak = sorted_pts_peak.reset_index(drop=True)\n",
        "\n",
        "sorted_pts_peak['PTS'] = sorted_pts_peak['PTS'].round(2)\n",
        "sorted_pts_peak['TS+'] = sorted_pts_peak['TS+'].round(2)\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.dropna()\n",
        "\n",
        "\n",
        "print(sorted_pts_peak)\n",
        "\n",
        "sorted_pts_peak.to_csv(\"Nine_Year_scoring_Playoff_Peaks_1700min.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 10\n",
        "at_least_2000_min_pts = import_adjpts_10peaks_df[(import_adjpts_10peaks_df['MP'] >= 2000)]\n",
        "at_least_2000_min_ts = import_adjts_10peaks_df[(import_adjts_10peaks_df['MP'] >= 2000)]\n",
        "\n",
        "\n",
        "sorted_pts_peak = at_least_2000_min_pts.copy()\n",
        "sorted_pts_peak.insert(6, \"TS+\", at_least_2000_min_ts['PeakValue'])\n",
        "sorted_pts_peak = sorted_pts_peak.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.sort_values('PTS', ascending=False)\n",
        "sorted_pts_peak = sorted_pts_peak.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_pts_peak = sorted_pts_peak.reindex(columns=columns_titles)\n",
        "sorted_pts_peak = sorted_pts_peak.reset_index(drop=True)\n",
        "sorted_pts_peak['PTS'] = sorted_pts_peak['PTS'].round(2)\n",
        "sorted_pts_peak['TS+'] = sorted_pts_peak['TS+'].round(2)\n",
        "\n",
        "sorted_pts_peak = sorted_pts_peak.dropna()\n",
        "\n",
        "print(sorted_pts_peak)\n",
        "\n",
        "sorted_pts_peak.to_csv(\"Ten_Year_scoring_Playoff_Peaks_2000min.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Append into one\n",
        "two = pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "three = pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', index_col=False, encoding='utf8')\n",
        "four = pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', index_col=False, encoding='utf8')\n",
        "five = pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "six = pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "seven = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "eight = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "nine = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "ten = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "two = two.append(three)\n",
        "two = two.append(four)\n",
        "two = two.append(five)\n",
        "two = two.append(six)\n",
        "two = two.append(seven)\n",
        "two = two.append(eight)\n",
        "two = two.append(nine)\n",
        "two = two.append(ten)\n",
        "two = two[(two['MP'] >= 500)]\n",
        "two = two.sort_values(by = ['PTS', 'MP'], ascending = [False, False], na_position = 'first')\n",
        "print(two)\n",
        "\n",
        "outfile = f\"All_Spurs_Stretches_500min.csv\"\n",
        "two.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CHxE-hAf4Hne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9leRo7p78g-t"
      },
      "source": [
        "**BPM PEAK FILES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w_maV6Oy-7B1"
      },
      "outputs": [],
      "source": [
        "#@title Run BPM Peaks\n",
        "twoyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('two_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "twoyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('two_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "# 3\n",
        "threeyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('three_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "threeyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('three_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#4\n",
        "fouryearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('four_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "fouryearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('four_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#5\n",
        "fiveyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('five_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "fiveyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('five_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#6\n",
        "sixyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('six_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "sixyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('six_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#7\n",
        "sevenyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('seven_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "sevenyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#\n",
        "eightyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('eight_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "eightyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#9\n",
        "nineyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('nine_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "nineyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#10\n",
        "tenyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('ten_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "tenyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XMGgOIAq70p1"
      },
      "outputs": [],
      "source": [
        "#@title Import BPM Peaks\n",
        "import_bpm_twopeaks_df = pd.read_csv('two_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_twopeaks_df = import_bpm_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_twopeaks_df = pd.read_csv('two_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_twopeaks_df = import_obpm_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_twopeaks_df['TeamColor'] = import_bpm_twopeaks_df['Team'].map(team_colors)\n",
        "import_obpm_twopeaks_df['TeamColor'] = import_obpm_twopeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_threepeaks_df = pd.read_csv('three_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_threepeaks_df = import_bpm_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_threepeaks_df = pd.read_csv('three_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_threepeaks_df = import_obpm_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_threepeaks_df['TeamColor'] = import_bpm_threepeaks_df['Team'].map(team_colors)\n",
        "import_obpm_threepeaks_df['TeamColor'] = import_obpm_threepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_4peaks_df = pd.read_csv('four_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_4peaks_df = import_bpm_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_4peaks_df = pd.read_csv('four_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_4peaks_df = import_obpm_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_4peaks_df['TeamColor'] = import_bpm_4peaks_df['Team'].map(team_colors)\n",
        "import_obpm_4peaks_df['TeamColor'] = import_obpm_4peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_fivepeaks_df = pd.read_csv('five_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_fivepeaks_df = import_bpm_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_fivepeaks_df = pd.read_csv('five_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_fivepeaks_df = import_obpm_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_fivepeaks_df['TeamColor'] = import_bpm_fivepeaks_df['Team'].map(team_colors)\n",
        "import_obpm_fivepeaks_df['TeamColor'] = import_obpm_fivepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_6peaks_df = pd.read_csv('six_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_6peaks_df = import_bpm_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_6peaks_df = pd.read_csv('six_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_6peaks_df = import_obpm_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_obpm_6peaks_df['TeamColor'] = import_obpm_6peaks_df['Team'].map(team_colors)\n",
        "import_bpm_6peaks_df['TeamColor'] = import_bpm_6peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_7peaks_df = pd.read_csv('seven_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_7peaks_df = import_bpm_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_7peaks_df = pd.read_csv('seven_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_7peaks_df = import_obpm_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_obpm_7peaks_df['TeamColor'] = import_obpm_7peaks_df['Team'].map(team_colors)\n",
        "import_bpm_7peaks_df['TeamColor'] = import_bpm_7peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_eightpeaks_df = pd.read_csv('eight_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_eightpeaks_df = import_bpm_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_eightpeaks_df = pd.read_csv('eight_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_eightpeaks_df = import_obpm_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_eightpeaks_df['TeamColor'] = import_bpm_eightpeaks_df['Team'].map(team_colors)\n",
        "import_obpm_eightpeaks_df['TeamColor'] = import_obpm_eightpeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_9peaks_df = pd.read_csv('nine_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_9peaks_df = import_bpm_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_9peaks_df = pd.read_csv('nine_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_9peaks_df = import_obpm_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_9peaks_df['TeamColor'] = import_bpm_9peaks_df['Team'].map(team_colors)\n",
        "import_obpm_9peaks_df['TeamColor'] = import_obpm_9peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_10peaks_df = pd.read_csv('ten_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_10peaks_df = import_bpm_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_10peaks_df = pd.read_csv('ten_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_10peaks_df = import_obpm_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_10peaks_df['TeamColor'] = import_bpm_10peaks_df['Team'].map(team_colors)\n",
        "import_obpm_10peaks_df['TeamColor'] = import_obpm_10peaks_df['Team'].map(team_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7g56Mu1U8gL7"
      },
      "outputs": [],
      "source": [
        "#@title Output BPM Peaks\n",
        "\n",
        "at_least_400_min_2bpm = import_bpm_twopeaks_df[(import_bpm_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2bpm = at_least_400_min_2bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_2obpm = import_obpm_twopeaks_df[(import_obpm_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2obpm = at_least_400_min_2obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_2bpm = at_least_400_min_2bpm.copy()\n",
        "sorted_2bpm.insert(6, \"OBPM\", at_least_400_min_2obpm['PeakValue'])\n",
        "sorted_2bpm = sorted_2bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_2bpm = sorted_2bpm.sort_values('BPM', ascending=False)\n",
        "sorted_2bpm = sorted_2bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_2bpm = sorted_2bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_2bpm['BPM'] = sorted_2bpm['BPM'].round(2)\n",
        "sorted_2bpm['OBPM'] = sorted_2bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_2bpm = sorted_2bpm.dropna()\n",
        "\n",
        "print(sorted_2bpm)\n",
        "\n",
        "sorted_2bpm.to_csv(\"Two_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 3 year adjusted playoff scoring peaks (>= 400 min) Output File\n",
        "\n",
        "# 400 minutes filter\n",
        "at_least_400_min_bpm = import_bpm_threepeaks_df[(import_bpm_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_bpm = at_least_400_min_bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_obpm = import_obpm_threepeaks_df[(import_obpm_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_obpm = at_least_400_min_obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_3bpm = at_least_400_min_bpm.copy()\n",
        "sorted_3bpm.insert(6, \"OBPM\", at_least_400_min_obpm['PeakValue'])\n",
        "sorted_3bpm = sorted_3bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.sort_values('BPM', ascending=False)\n",
        "sorted_3bpm = sorted_3bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_3bpm = sorted_3bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3bpm['BPM'] = sorted_3bpm['BPM'].round(2)\n",
        "sorted_3bpm['OBPM'] = sorted_3bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.dropna()\n",
        "\n",
        "print(sorted_3bpm)\n",
        "\n",
        "sorted_3bpm.to_csv(\"Three_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 4 year adjusted playoff scoring peaks (>= 600 min) Output File\n",
        "\n",
        "# 400 minutes filter\n",
        "at_least_400_min_bpm = import_bpm_4peaks_df[(import_bpm_4peaks_df['MP'] >= 300)]\n",
        "at_least_400_min_bpm = at_least_400_min_bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_obpm = import_obpm_4peaks_df[(import_obpm_4peaks_df['MP'] >= 300)]\n",
        "at_least_400_min_obpm = at_least_400_min_obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_3bpm = at_least_400_min_bpm.copy()\n",
        "sorted_3bpm.insert(6, \"OBPM\", at_least_400_min_obpm['PeakValue'])\n",
        "sorted_3bpm = sorted_3bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.sort_values('BPM', ascending=False)\n",
        "sorted_3bpm = sorted_3bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_3bpm = sorted_3bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3bpm['BPM'] = sorted_3bpm['BPM'].round(2)\n",
        "sorted_3bpm['OBPM'] = sorted_3bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.dropna()\n",
        "\n",
        "print(sorted_3bpm)\n",
        "\n",
        "sorted_3bpm.to_csv(\"Four_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 5 year adjusted playoff scoring peaks (>=800 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_fivepeaks_df[(import_bpm_fivepeaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_fivepeaks_df[(import_obpm_fivepeaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Five_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 6 year adjusted playoff scoring peaks (>=1000 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_6peaks_df[(import_bpm_6peaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_6peaks_df[(import_obpm_6peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Six_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 7 year adjusted playoff scoring peaks (>=1200 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_7peaks_df[(import_bpm_7peaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_7peaks_df[(import_obpm_7peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Seven_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 8 year adjusted playoff scoring peaks (>=1500 min) Output File\n",
        "\n",
        "at_least_1500_min_bpm = import_bpm_eightpeaks_df[(import_bpm_eightpeaks_df['MP'] >= 300)]\n",
        "at_least_1500_min_obpm = import_obpm_eightpeaks_df[(import_obpm_eightpeaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_8bpm = at_least_1500_min_bpm.copy()\n",
        "sorted_8bpm.insert(6, \"OBPM\", at_least_1500_min_obpm['PeakValue'])\n",
        "sorted_8bpm = sorted_8bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_8bpm = sorted_8bpm.sort_values('BPM', ascending=False)\n",
        "sorted_8bpm = sorted_8bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_8bpm = sorted_8bpm.reindex(columns=columns_titles)\n",
        "sorted_8bpm = sorted_8bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_8bpm['BPM'] = sorted_8bpm['BPM'].round(2)\n",
        "sorted_8bpm['OBPM'] = sorted_8bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_8bpm = sorted_8bpm.dropna()\n",
        "\n",
        "\n",
        "print(sorted_8bpm)\n",
        "\n",
        "sorted_8bpm.to_csv(\"Eight_Year_BPM_Playoff_Peaks_1500min.csv\", index=False)\n",
        "\n",
        "#@title 9 year adjusted playoff scoring peaks (>=1700 min) Output File\n",
        "\n",
        "at_least_1500_min_bpm = import_bpm_9peaks_df[(import_bpm_9peaks_df['MP'] >= 300)]\n",
        "at_least_1500_min_obpm = import_obpm_9peaks_df[(import_obpm_9peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_9bpm = at_least_1500_min_bpm.copy()\n",
        "sorted_9bpm.insert(6, \"OBPM\", at_least_1500_min_obpm['PeakValue'])\n",
        "sorted_9bpm = sorted_9bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_9bpm = sorted_9bpm.sort_values('BPM', ascending=False)\n",
        "sorted_9bpm = sorted_9bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_9bpm = sorted_9bpm.reindex(columns=columns_titles)\n",
        "sorted_9bpm = sorted_9bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_9bpm['BPM'] = sorted_9bpm['BPM'].round(2)\n",
        "sorted_9bpm['OBPM'] = sorted_9bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_9bpm = sorted_9bpm.dropna()\n",
        "\n",
        "\n",
        "print(sorted_9bpm)\n",
        "\n",
        "sorted_9bpm.to_csv(\"Nine_Year_BPM_Playoff_Peaks_1700min.csv\", index=False)\n",
        "\n",
        "#@title 10 year adjusted playoff scoring peaks (>=2000 min) Output File\n",
        "\n",
        "at_least_2000_min_bpm = import_bpm_10peaks_df[(import_bpm_10peaks_df['MP'] >= 300)]\n",
        "at_least_2000_min_obpm = import_obpm_10peaks_df[(import_obpm_10peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_10bpm = at_least_2000_min_bpm.copy()\n",
        "sorted_10bpm.insert(6, \"OBPM\", at_least_2000_min_obpm['PeakValue'])\n",
        "sorted_10bpm = sorted_10bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_10bpm = sorted_10bpm.sort_values('BPM', ascending=False)\n",
        "sorted_10bpm = sorted_10bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_10bpm = sorted_10bpm.reindex(columns=columns_titles)\n",
        "sorted_10bpm = sorted_10bpm.reset_index(drop=True)\n",
        "sorted_10bpm['BPM'] = sorted_10bpm['BPM'].round(2)\n",
        "sorted_10bpm['OBPM'] = sorted_10bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_10bpm = sorted_10bpm.dropna()\n",
        "\n",
        "print(sorted_10bpm)\n",
        "\n",
        "sorted_10bpm.to_csv(\"Ten_Year_BPM_Playoff_Peaks_2000min.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PBP PEAK FILES**"
      ],
      "metadata": {
        "id": "s1nOyA7_9oGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run PBP Peaks\n",
        "nineyearpeak(import_player_since74playoffs_playbyplay_df, 'OnCourt')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('nine_year_peak_OnCourt_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_OnCourt_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "nineyearpeak(import_player_since74playoffs_playbyplay_df, 'On-Off')\n",
        "import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_On-Off_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_On-Off_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "id": "vdNvzeQ39nct",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import PBP Peaks\n",
        "import_oncourt_9peaks_df = pd.read_csv('nine_year_peak_OnCourt_data.csv', encoding='utf8')\n",
        "import_oncourt_9peaks_df = import_oncourt_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_onoff_9peaks_df = pd.read_csv('nine_year_peak_On-Off_data.csv', encoding='utf8')\n",
        "import_onoff_9peaks_df = import_onoff_9peaks_df.assign(TeamColor=0)"
      ],
      "metadata": {
        "id": "KrW6tABC98im",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Output PBP Peaks\n",
        "\n",
        "at_least_400_min_oncourt = import_oncourt_9peaks_df[(import_oncourt_9peaks_df['MP'] >= 3000)]\n",
        "at_least_400_min_oncourt = at_least_400_min_oncourt.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_onoff = import_onoff_9peaks_df[(import_onoff_9peaks_df['MP'] >= 3000)]\n",
        "at_least_400_min_onoff = at_least_400_min_onoff.reset_index(drop=True)\n",
        "\n",
        "sorted_3bpm = at_least_400_min_oncourt.copy()\n",
        "sorted_3bpm.insert(6, \"On-Off\", at_least_400_min_onoff['PeakValue'])\n",
        "sorted_3bpm = sorted_3bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"OnCourt\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"On-Off\": \"On-Off\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.sort_values('On-Off', ascending=False)\n",
        "sorted_3bpm = sorted_3bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'On-Off', 'OnCourt', 'MP', 'G']\n",
        "sorted_3bpm = sorted_3bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3bpm['On-Off'] = sorted_3bpm['On-Off'].round(2)\n",
        "sorted_3bpm['OnCourt'] = sorted_3bpm['OnCourt'].round(2)\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.dropna()\n",
        "\n",
        "print(sorted_3bpm)\n",
        "\n",
        "sorted_3bpm.to_csv(\"Nine_Year_pbp_Playoff_Peaks_3000_min.csv\", index=False)"
      ],
      "metadata": {
        "id": "qa_aFfXc-Ts6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xD45xeb_1zE"
      },
      "source": [
        "**PEAK FUNCTION DEFINITIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WKanZbn6ABM9"
      },
      "outputs": [],
      "source": [
        "#@title X Year Peaks Functions\n",
        "\n",
        "\n",
        "#@title 2 year peaks function\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '777' '15'\n",
        "def twoyearpeak(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = 0\n",
        "    prev_min = 0\n",
        "    prev_g = 0\n",
        "    prevYearTeam = 0\n",
        "    prevyear = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + prev_g\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back * (prev_min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prev_back = 0\n",
        "            prev_min = 0\n",
        "            prev_g = 0\n",
        "            prevYearTeam = 0\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 2 consecutive seasons\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear , present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+2 and len(indexlist) >=2:\n",
        "            two_seasons_count = player['Year']\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back = inner_row[valuestring]\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prev_min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "            prev_g = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            prev_back = inner_row[valuestring]\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prev_min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "            prev_g = inner_row['G']\n",
        "\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 2:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and prevYearTeam == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_two_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_two_year_peak_val, running_min, games]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "            outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "            two_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "\n",
        "#@title 3 year peaks function\n",
        "\n",
        "# def threeyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 3 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 3 year stretches of 'valuestring' AND the listed years from each 3 year stretch + minutes played across the 3 seasons.\n",
        "# EX: threeyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-20', 'Kris Middleton', 'MIL' '23.32', '712' '22'\n",
        "def threeyearpeak(df, valuestring):\n",
        "  three_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 3 year peaks); begin as 0's\n",
        "    for i in range(0, 2):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    three_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_three_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_three_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[1]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 2):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons\n",
        "          if present_year >= original_year+2 and len(indexlist) >=3:\n",
        "            if (prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[1] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}'.format(prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if three_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            three_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 1\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 1\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          three_seasons_count = three_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 3:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_three_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_three_year_peak_val, running_min, games]], columns=cols)\n",
        "            three_year_peak = three_year_peak.append(df_temp)\n",
        "            outfile = f\"three_year_peak_{valuestring}_data.csv\"\n",
        "            three_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "\n",
        "#@title 4 year peaks function\n",
        "\n",
        "# def fouryearpeak(df, valuestring):\n",
        "# returns a dataframe containing 4 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 4 year stretches of 'valuestring' AND the listed years from each 4 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fouryearpeak(import_player_since74_per100_df, 'PTS') returns 4 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-19', 'Kris Middleton', 'MIL' '22.11', '1213' '28'\n",
        "def fouryearpeak(df, valuestring):\n",
        "  four_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 4 year peaks); begin as 0's\n",
        "    for i in range(0, 3):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    four_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_four_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_four_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[2]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 3):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 4 consecutive seasons\n",
        "          if present_year >= original_year+3 and len(indexlist) >=4:\n",
        "            if (prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[2] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}'.format(prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if four_seasons_count == original_year+4 and len(indexlist) >=4:\n",
        "            four_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 2\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 2\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          four_seasons_count = four_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 4:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_four_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_four_year_peak_val, running_min, games]], columns=cols)\n",
        "            four_year_peak = four_year_peak.append(df_temp)\n",
        "            outfile = f\"four_year_peak_{valuestring}_data.csv\"\n",
        "            four_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "\n",
        "#@title 5 year peaks function\n",
        "\n",
        "# def fiveyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 5 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 5 year stretches of 'valuestring' AND the listed years from each 5 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 5 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-20', 'Kris Middleton', 'MIL' '22.11', '1639 '34'\n",
        "def fiveyearpeak(df, valuestring):\n",
        "  five_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 5 year peaks); begin as 0's\n",
        "    for i in range(0, 4):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    five_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_five_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_five_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[3]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 4):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 5 consecutive seasons\n",
        "          if present_year >= original_year+4 and len(indexlist) >=5:\n",
        "            if (prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[3] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}'.format(prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if five_seasons_count == original_year+5 and len(indexlist) >=5:\n",
        "            five_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 3\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 3\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          five_seasons_count = five_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 5:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_five_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_five_year_peak_val, running_min, games]], columns=cols)\n",
        "            five_year_peak = five_year_peak.append(df_temp)\n",
        "            outfile = f\"five_year_peak_{valuestring}_data.csv\"\n",
        "            five_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "\n",
        "#@title 6 year peaks function\n",
        "\n",
        "# def sixyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 6 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 6 year stretches of 'valuestring' AND the listed years from each 6 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 6 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-21', 'Kris Middleton', 'MIL' '22.11', '1119' '46'\n",
        "def sixyearpeak(df, valuestring):\n",
        "  six_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 6 year peaks); begin as 0's\n",
        "    for i in range(0, 5):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    six_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_six_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_six_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[4]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 5):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 6 consecutive seasons\n",
        "          if present_year >= original_year+5 and len(indexlist) >=6:\n",
        "            if (prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[4] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}'.format(prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if six_seasons_count == original_year+6 and len(indexlist) >=6:\n",
        "            six_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 4\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 4\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          six_seasons_count = six_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 6:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_six_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_six_year_peak_val, running_min, games]], columns=cols)\n",
        "            six_year_peak = six_year_peak.append(df_temp)\n",
        "            outfile = f\"six_year_peak_{valuestring}_data.csv\"\n",
        "            six_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "\n",
        "#@title 7 year peaks function\n",
        "\n",
        "# def sevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 7 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 7 year stretches of 'valuestring' AND the listed years from each 7 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 7 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-22', 'Kris Middleton', 'MIL' '22.11', '1467' '66'\n",
        "def sevenyearpeak(df, valuestring):\n",
        "  seven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 7 year peaks); begin as 0's\n",
        "    for i in range(0, 6):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    seven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_seven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_seven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[5]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 6):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 7 consecutive seasons\n",
        "          if present_year >= original_year+6 and len(indexlist) >=7:\n",
        "            if (prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[5] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}'.format(prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if seven_seasons_count == original_year+7 and len(indexlist) >=7:\n",
        "            seven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 5\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 5\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          seven_seasons_count = seven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 7:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_seven_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_seven_year_peak_val, running_min, games]], columns=cols)\n",
        "            seven_year_peak = seven_year_peak.append(df_temp)\n",
        "            outfile = f\"seven_year_peak_{valuestring}_data.csv\"\n",
        "            seven_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "\n",
        "#@title 8 year peaks function\n",
        "\n",
        "# def eightyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 8 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 8 year stretches of 'valuestring' AND the listed years from each 8 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 8 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2013-20', 'Kris Middleton', 'MIL' '22.11', '2139' '66'\n",
        "def eightyearpeak(df, valuestring):\n",
        "  eight_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 8 year peaks); begin as 0's\n",
        "    for i in range(0, 7):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eight_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_eight_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_eight_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[6]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 7):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 8 consecutive seasons\n",
        "          if present_year >= original_year+7 and len(indexlist) >=8:\n",
        "            if (prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[6] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if eight_seasons_count == original_year+8 and len(indexlist) >=8:\n",
        "            eight_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 6\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 6\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          eight_seasons_count = eight_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 8:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_eight_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_eight_year_peak_val, running_min, games]], columns=cols)\n",
        "            eight_year_peak = eight_year_peak.append(df_temp)\n",
        "            outfile = f\"eight_year_peak_{valuestring}_data.csv\"\n",
        "            eight_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "\n",
        "#@title 9 year peaks function\n",
        "\n",
        "# def nineyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 9 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 9 year stretches of 'valuestring' AND the listed years from each 9 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 9 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2012-20', 'Kris Middleton', 'MIL' '22.11', '2585' '66'\n",
        "def nineyearpeak(df, valuestring):\n",
        "  nine_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 9 year peaks); begin as 0's\n",
        "    for i in range(0, 8):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    nine_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_nine_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_nine_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)) + (prev_back[7] * (prev_min[7] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[7]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 8):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 9 consecutive seasons\n",
        "          if present_year >= original_year+8 and len(indexlist) >=9:\n",
        "            if (prevyear[7]  == (prevyear[6] - 1) and prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[7] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[7] , prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if nine_seasons_count == original_year+9 and len(indexlist) >=9:\n",
        "            nine_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 7\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 7\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          nine_seasons_count = nine_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 9:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[7] and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_nine_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_nine_year_peak_val, running_min, games]], columns=cols)\n",
        "            nine_year_peak = nine_year_peak.append(df_temp)\n",
        "            outfile = f\"nine_year_peak_{valuestring}_data.csv\"\n",
        "            nine_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "\n",
        "#@title 10 year peaks function\n",
        "\n",
        "# def tenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '2976', '76'\n",
        "def tenyearpeak(df, valuestring):\n",
        "  ten_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 10 year peaks); begin as 0's\n",
        "    for i in range(0, 9):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    ten_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_ten_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_ten_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)) + (prev_back[7] * (prev_min[7] / running_min)) + (prev_back[8] * (prev_min[8] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[8]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 9):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 10 consecutive seasons\n",
        "          if present_year >= original_year+9 and len(indexlist) >=10:\n",
        "            if (prevyear[8] == (prevyear[7] - 1) and prevyear[7]  == (prevyear[6] - 1) and prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[8] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[8] , prevyear[7] , prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if ten_seasons_count == original_year+10 and len(indexlist) >=10:\n",
        "            ten_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 8\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 8\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          ten_seasons_count = ten_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 10:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[7] and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_ten_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_ten_year_peak_val, running_min, games]], columns=cols)\n",
        "            ten_year_peak = ten_year_peak.append(df_temp)\n",
        "            outfile = f\"ten_year_peak_{valuestring}_data.csv\"\n",
        "            ten_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oAcCFD7_sNPw"
      },
      "outputs": [],
      "source": [
        "#@title 2 year fragmented peaks function\n",
        "\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '4231'\n",
        "def fragtwoyearpeak(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes played\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = [0, 0]\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # store team player played on a season and 2 seasons ago in case they change teams during peak 3 years.\n",
        "    prevyear = 0\n",
        "    prevYearTeam = 0\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevYearTeam = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prevyear = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 2 consecutive seasons (not reached after 2 rows of a player is found)\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear, present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+2 and len(indexlist) >=2:\n",
        "            two_seasons_count = player['Year']\n",
        "\n",
        "          # move present value to previous year's value\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=2:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP']\n",
        "            if (old_team == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_two_year_peak_val, running_min]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_two_year_peak_val, running_min]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "            outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "            two_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jTUzLULMfPWF"
      },
      "outputs": [],
      "source": [
        "#@title Manual Data Peak Functions\n",
        "\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '4231'\n",
        "def twoyearpeak_manual_data(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # store the team a player played with 1 season and 2 seasons ago in case they change teams during peak 3 years.\n",
        "\n",
        "    prevyear = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear, present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            two_seasons_count = player['Year']\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=2:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_two_year_peak_val, running_min]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "      outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "      two_year_peak = two_year_peak.drop_duplicates()\n",
        "      two_year_peak.to_csv(outfile, index=False)\n",
        "      player_finished.append(inner_row['Player'])\n",
        "#@title 3 year peaks (manual data) function\n",
        "\n",
        "# def threeyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 3 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 3 year stretches of 'valuestring' AND the listed years from each 3 year stretch + minutes played across the 3 seasons.\n",
        "# EX: threeyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-20', 'Kris Middleton', 'MIL' '23.32', '7120'\n",
        "def threeyearpeak_manual_data(df, valuestring):\n",
        "  three_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue and minutes\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    three_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # previous two years; e.g. 2014, 2015 before 2016. 2016, 2019 if these were the two most recent seasons for a player before 2020.\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "\n",
        "    indexlist = []\n",
        "    running_three_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_three_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+2 and len(indexlist) >=3:\n",
        "            if (prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev2year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}'.format(prev2year, prevyear, present_year)\n",
        "\n",
        "          if three_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            three_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          three_seasons_count = three_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=3:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_three_year_peak_val, running_min]], columns=cols)\n",
        "            three_year_peak = three_year_peak.append(df_temp)\n",
        "    outfile = f\"three_year_peak_{valuestring}_data.csv\"\n",
        "    three_year_peak = three_year_peak.drop_duplicates()\n",
        "    three_year_peak.to_csv(outfile, index=False)\n",
        "    player_finished.append(inner_row['Player'])\n",
        "#@title 4 year peaks (manual data) function\n",
        "\n",
        "# returns a dataframe containing 4 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 4 year stretches of 'valuestring' AND the listed years from each 4 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 4 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-19', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def fouryearpeak_manual_data(df, valuestring):\n",
        "  four_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    four_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_four_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_four_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+3 and len(indexlist) >=4:\n",
        "            if (prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev3year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}'.format(prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if four_seasons_count == original_year+4 and len(indexlist) >=4:\n",
        "            four_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          four_seasons_count = four_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=4:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_four_year_peak_val, running_min]], columns=cols)\n",
        "            four_year_peak = four_year_peak.append(df_temp)\n",
        "    outfile = f\"four_year_peak_{valuestring}_data.csv\"\n",
        "    four_year_peak = four_year_peak.drop_duplicates()\n",
        "    four_year_peak.to_csv(outfile, index=False)\n",
        "    player_finished.append(inner_row['Player'])\n",
        "#@title 5 year peaks (manual data) function\n",
        "\n",
        "# def fiveyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 5 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 5 year stretches of 'valuestring' AND the listed years from each 5 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 5 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def fiveyearpeak_manual_data(df, valuestring):\n",
        "  five_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    five_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_five_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_five_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+4 and len(indexlist) >=5:\n",
        "            if (prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev4year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}'.format(prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if five_seasons_count == original_year+5 and len(indexlist) >=5:\n",
        "            five_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          five_seasons_count = five_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=5:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_five_year_peak_val, running_min]], columns=cols)\n",
        "            five_year_peak = five_year_peak.append(df_temp)\n",
        "    outfile = f\"five_year_peak_{valuestring}_data.csv\"\n",
        "    five_year_peak = five_year_peak.drop_duplicates()\n",
        "    five_year_peak.to_csv(outfile, index=False)\n",
        "    player_finished.append(inner_row['Player'])\n",
        "#@title 6 year peaks (manual data) function\n",
        "\n",
        "# def sixyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 6 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 6 year stretches of 'valuestring' AND the listed years from each 6 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 6 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-21', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def sixyearpeak_manual_data(df, valuestring):\n",
        "  six_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    six_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_six_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_six_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+5 and len(indexlist) >=6:\n",
        "            if (prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev5year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}'.format(prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if six_seasons_count == original_year+6 and len(indexlist) >=6:\n",
        "            six_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          six_seasons_count = six_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=6:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_six_year_peak_val, running_min]], columns=cols)\n",
        "            six_year_peak = six_year_peak.append(df_temp)\n",
        "    outfile = f\"six_year_peak_{valuestring}_data.csv\"\n",
        "    six_year_peak = six_year_peak.drop_duplicates()\n",
        "    six_year_peak.to_csv(outfile, index=False)\n",
        "    player_finished.append(inner_row['Player'])\n",
        "#@title 7 year peaks (manual data) function\n",
        "\n",
        "# def sevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def sevenyearpeak_manual_data(df, valuestring):\n",
        "  seven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    seven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_seven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_seven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+6 and len(indexlist) >=7:\n",
        "            if (prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev6year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}'.format(prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if seven_seasons_count == original_year+7 and len(indexlist) >=7:\n",
        "            seven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          seven_seasons_count = seven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=7:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_seven_year_peak_val, running_min]], columns=cols)\n",
        "            seven_year_peak = seven_year_peak.append(df_temp)\n",
        "    outfile = f\"seven_year_peak_{valuestring}_data.csv\"\n",
        "    seven_year_peak = seven_year_peak.drop_duplicates()\n",
        "    seven_year_peak.to_csv(outfile, index=False)\n",
        "    player_finished.append(inner_row['Player'])\n",
        "#@title 8 year peaks (manual data) function\n",
        "\n",
        "# def eightyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def eightyearpeak_manual_data(df, valuestring):\n",
        "  eight_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eight_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_eight_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_eight_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+7 and len(indexlist) >=8:\n",
        "            if (prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev7year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}'.format(prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if eight_seasons_count == original_year+8 and len(indexlist) >=8:\n",
        "            eight_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          eight_seasons_count = eight_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=8:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_eight_year_peak_val, running_min]], columns=cols)\n",
        "            eight_year_peak = eight_year_peak.append(df_temp)\n",
        "    outfile = f\"eight_year_peak_{valuestring}_data.csv\"\n",
        "    eight_year_peak = eight_year_peak.drop_duplicates()\n",
        "    eight_year_peak.to_csv(outfile, index=False)\n",
        "    player_finished.append(inner_row['Player'])\n",
        "#@title 9 year peaks (manual data) function\n",
        "\n",
        "# def nineyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 9 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 9 year stretches of 'valuestring' AND the listed years from each 9 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 9 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def nineyearpeak_manual_data(df, valuestring):\n",
        "  nine_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    nine_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_nine_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_nine_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+8 and len(indexlist) >=9:\n",
        "            if (prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev8year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if nine_seasons_count == original_year+9 and len(indexlist) >=9:\n",
        "            nine_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          nine_seasons_count = nine_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=9:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_nine_year_peak_val, running_min]], columns=cols)\n",
        "            nine_year_peak = nine_year_peak.append(df_temp)\n",
        "    outfile = f\"nine_year_peak_{valuestring}_data.csv\"\n",
        "    nine_year_peak = nine_year_peak.drop_duplicates()\n",
        "    nine_year_peak.to_csv(outfile, index=False)\n",
        "    player_finished.append(inner_row['Player'])\n",
        "#@title 10 year peaks (manual data) function\n",
        "\n",
        "# def tenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def tenyearpeak_manual_data(df, valuestring):\n",
        "  ten_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # 9 seasons ago's peakvalue\n",
        "    prev_9back = 0\n",
        "    prev_9min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    ten_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "    prev9year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_ten_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min + prev_9min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_ten_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)) + (prev_9back * (prev_9min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev9year = 0\n",
        "            prev_9back = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            prev_9min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+9 and len(indexlist) >=10:\n",
        "            if (prev9year == (prev8year-1) and prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev9year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev9year, prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if ten_seasons_count == original_year+10 and len(indexlist) >=10:\n",
        "            ten_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          ten_seasons_count = ten_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=10:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_ten_year_peak_val, running_min]], columns=cols)\n",
        "            ten_year_peak = ten_year_peak.append(df_temp)\n",
        "    outfile = f\"ten_year_peak_{valuestring}_data.csv\"\n",
        "    ten_year_peak = ten_year_peak.drop_duplicates()\n",
        "    ten_year_peak.to_csv(outfile, index=False)\n",
        "    player_finished.append(inner_row['Player'])\n",
        "#@title 11 year peaks (manual data) function\n",
        "\n",
        "# def elevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 11 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 11 year stretches of 'valuestring' AND the listed years from each 11 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 11 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-21', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def elevenyearpeak_manual_data(df, valuestring):\n",
        "  eleven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # 9 seasons ago's peakvalue\n",
        "    prev_9back = 0\n",
        "    prev_9min = 0\n",
        "\n",
        "    prev_10back = 0\n",
        "    prev_10min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eleven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "    prev9year = 0\n",
        "    prev10year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_eleven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min + prev_9min + prev_10min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_eleven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)) + (prev_9back * (prev_9min / running_min))+ (prev_10back * (prev_10min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev9year = 0\n",
        "            prev10year = 0\n",
        "            prev_10back = 0\n",
        "            prev_9back = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            prev_9min = 0\n",
        "            prev_10min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+10 and len(indexlist) >=11:\n",
        "            if (prev10year == (prev9year-1) and prev9year == (prev8year-1) and prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev10year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev10year, prev9year, prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if eleven_seasons_count == original_year+11 and len(indexlist) >=11:\n",
        "            eleven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_10back = prev_9back\n",
        "            prev_10min = prev_9min\n",
        "            prev10year = prev9year\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_10back = prev_9back\n",
        "            prev_10min = prev_9min\n",
        "            prev10year = prev9year\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          eleven_seasons_count = eleven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=11:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_eleven_year_peak_val, running_min]], columns=cols)\n",
        "            eleven_year_peak = eleven_year_peak.append(df_temp)\n",
        "    outfile = f\"eleven_year_peak_{valuestring}_data.csv\"\n",
        "    eleven_year_peak = eleven_year_peak.drop_duplicates()\n",
        "    eleven_year_peak.to_csv(outfile, index=False)\n",
        "    player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXEdTPyqEUUH"
      },
      "source": [
        "**RUN YEAR MANUAL SUBSETS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2n5FivB9QcKn"
      },
      "outputs": [],
      "source": [
        "#@title Adjusted Playoff TS+ of Manual Subset\n",
        "def manual_adjust_scoring_efficiency(player_df, opp_ts_df, opp_defrtg_df, opp_literal_defrtg, player):\n",
        "\n",
        "      final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'PP75', 'TS+', 'NetRtg', 'rOffRtg', 'MP'])\n",
        "\n",
        "      years_list = []\n",
        "\n",
        "      player_df['PP75'] = player_df['PP75'].astype(float)\n",
        "      player_df['PP75'] = player_df['PP75'] * .75\n",
        "\n",
        "\n",
        "      player_df['TS%'] = player_df['TS%'].astype(float)\n",
        "\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(int)\n",
        "      opp_defrtg_df['Team'] = opp_defrtg_df['Team'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(int)\n",
        "      opp_literal_defrtg['Team'] = opp_literal_defrtg['Team'].astype(str)\n",
        "      opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "      player_df['Opp'] = player_df['Opp'].astype(str)\n",
        "      player_df['Year'] = player_df['Year'].astype(int)\n",
        "\n",
        "      for i, row in player_df.iterrows():\n",
        "\n",
        "        current_opp = player_df.loc[i, 'Opp']\n",
        "        current_year = player_df.loc[i, 'Year']\n",
        "\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & (opp_ts_df['Year'] == current_year)]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        opponent_literal_def = opp_literal_defrtg[(opp_literal_defrtg['Team'] == current_opp) & ((opp_literal_defrtg['Year'] == current_year))]\n",
        "        opp_def_rtg = float(opponent_literal_def['DefRtg'])\n",
        "\n",
        "        player_ts = player_df.loc[i, 'TS%']\n",
        "        tsplus = (float(player_ts) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        relOffRtg = float(row['OffRtg']) - opp_def_rtg\n",
        "\n",
        "        player_df.loc[i,'TS+'] = tsplus\n",
        "        player_df.loc[i,'PTS_coeff'] = pts_coeff\n",
        "        player_df.loc[i,'rOffRtg'] = relOffRtg\n",
        "\n",
        "\n",
        "        if player_df.loc[i, 'Year'] not in years_list:\n",
        "          years_list.append(player_df.loc[i, 'Year'])\n",
        "\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'TS%', 'PTS', 'PTS_coeff'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = player_df[(player_df['Year'] == year)]\n",
        "\n",
        "        total_pts = 0\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        total_net = 0\n",
        "        total_off = 0\n",
        "\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "         #PTS\n",
        "        iter = 0\n",
        "        for ind_pts in tmp_sub_df['PP75']:\n",
        "          ind_pts = float(ind_pts)\n",
        "          total_pts += float(ind_pts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        #coeff\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        total_pts = total_pts * total_coeff\n",
        "\n",
        "\n",
        "        # NetRtg\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['NetRtg']:\n",
        "          ind_net = float(ind_coeff)\n",
        "          total_net += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        # OffRtg\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['rOffRtg']:\n",
        "          ind_off = float(ind_coeff)\n",
        "          total_off += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        total_pts = '%.2f' % round(total_pts, 2)\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "        total_off = '%.2f' % round(total_off, 2)\n",
        "        total_net = '%.2f' % round(total_net, 2)\n",
        "\n",
        "        new_row = {'Player':player, 'Year':year,  'PP75':total_pts, 'TS+':total_ts, 'NetRtg':total_net, 'rOffRtg': total_off, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "      print(final_season_df)\n",
        "      outfile = f\"NBA_Playoff_Manual_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inflate Scoring for Manual Subset\n",
        "new_df = pd.DataFrame()\n",
        "per_75_coeff['Year'] = per_75_coeff['Year'].astype(int)\n",
        "manu_one_on['Year'] = manu_one_on['Year'].astype(float)\n",
        "manu_one_on['PP75'] = manu_one_on['PP75'].astype(float)\n",
        "for i, row in manu_one_on.iterrows():\n",
        "  sub_coeff = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PP75'] = float((row['PP75'] * sub_coeff['Coefficient']))\n",
        "  new_df = new_df.append(row)\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df['PP75'] = new_df['PP75'].astype(float)\n",
        "new_df['TS%'] = new_df['TS%'].astype(float)\n",
        "new_df['MP'] = new_df['MP'].astype(int)\n",
        "new_df['Opp'] = new_df['Opp'].astype(str)\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "team_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "team_ts_allowed_df['TS% Allowed'] = team_ts_allowed_df['TS% Allowed'].astype(float)\n",
        "team_ts_allowed_df['Year'] = team_ts_allowed_df['Year'].astype(int)\n",
        "\n",
        "opp_literal_defrtg = pd.read_csv('/content/NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "\n",
        "\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "\n",
        "manual_adjust_scoring_efficiency(new_df, team_ts_allowed_df, opponent_adj_pts_coeff, opp_literal_defrtg, 'Manu Ginbili')\n",
        "\n",
        "#Manu Ginbili"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TGTZh3uIM6lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Format Manual Subset Multi-Year Peaks\n",
        "peak_df = pd.read_csv(\"NBA_Playoff_Manual_Adjusted_TS_df.csv\", encoding='utf8')\n",
        "\n",
        "final_df = pd.DataFrame()\n",
        "\n",
        "years_list = ['two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven']\n",
        "\n",
        "twoyearpeak_manual_data(peak_df, 'PP75')\n",
        "twoyearpeak_manual_data(peak_df, 'TS+')\n",
        "twoyearpeak_manual_data(peak_df, 'NetRtg')\n",
        "twoyearpeak_manual_data(peak_df, 'rOffRtg')\n",
        "threeyearpeak_manual_data(peak_df, 'PP75')\n",
        "threeyearpeak_manual_data(peak_df, 'TS+')\n",
        "threeyearpeak_manual_data(peak_df, 'NetRtg')\n",
        "threeyearpeak_manual_data(peak_df, 'rOffRtg')\n",
        "fouryearpeak_manual_data(peak_df, 'PP75')\n",
        "fouryearpeak_manual_data(peak_df, 'TS+')\n",
        "fouryearpeak_manual_data(peak_df, 'NetRtg')\n",
        "fouryearpeak_manual_data(peak_df, 'rOffRtg')\n",
        "fiveyearpeak_manual_data(peak_df, 'PP75')\n",
        "fiveyearpeak_manual_data(peak_df, 'TS+')\n",
        "fiveyearpeak_manual_data(peak_df, 'NetRtg')\n",
        "fiveyearpeak_manual_data(peak_df, 'rOffRtg')\n",
        "sixyearpeak_manual_data(peak_df, 'PP75')\n",
        "sixyearpeak_manual_data(peak_df, 'TS+')\n",
        "sixyearpeak_manual_data(peak_df, 'NetRtg')\n",
        "sixyearpeak_manual_data(peak_df, 'rOffRtg')\n",
        "sevenyearpeak_manual_data(peak_df, 'PP75')\n",
        "sevenyearpeak_manual_data(peak_df, 'TS+')\n",
        "sevenyearpeak_manual_data(peak_df, 'NetRtg')\n",
        "sevenyearpeak_manual_data(peak_df, 'rOffRtg')\n",
        "eightyearpeak_manual_data(peak_df, 'PP75')\n",
        "eightyearpeak_manual_data(peak_df, 'TS+')\n",
        "eightyearpeak_manual_data(peak_df, 'NetRtg')\n",
        "eightyearpeak_manual_data(peak_df, 'rOffRtg')\n",
        "nineyearpeak_manual_data(peak_df, 'PP75')\n",
        "nineyearpeak_manual_data(peak_df, 'TS+')\n",
        "nineyearpeak_manual_data(peak_df, 'NetRtg')\n",
        "nineyearpeak_manual_data(peak_df, 'rOffRtg')\n",
        "tenyearpeak_manual_data(peak_df, 'PP75')\n",
        "tenyearpeak_manual_data(peak_df, 'TS+')\n",
        "tenyearpeak_manual_data(peak_df, 'NetRtg')\n",
        "tenyearpeak_manual_data(peak_df, 'rOffRtg')\n",
        "elevenyearpeak_manual_data(peak_df, 'PP75')\n",
        "elevenyearpeak_manual_data(peak_df, 'TS+')\n",
        "elevenyearpeak_manual_data(peak_df, 'NetRtg')\n",
        "elevenyearpeak_manual_data(peak_df, 'rOffRtg')\n",
        "\n",
        "for num_of_years in years_list:\n",
        "\n",
        "  import_player_pts_peaks_df = pd.read_csv(f'{num_of_years}_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_peaks_df = pd.read_csv(f'{num_of_years}_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_peaks_df = pd.read_csv(f'{num_of_years}_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_peaks_df = pd.read_csv(f'{num_of_years}_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  year_df = pd.DataFrame()\n",
        "\n",
        "  year_df['Years'] = import_player_pts_peaks_df['Years']\n",
        "  year_df['PP75'] = import_player_pts_peaks_df['PeakValue']\n",
        "  year_df['TS+'] = import_player_ts_peaks_df['PeakValue']\n",
        "  year_df['NetRtg'] = import_player_NetRtg_peaks_df['PeakValue']\n",
        "  year_df['rOffRtg'] = import_player_rOffRtg_peaks_df['PeakValue']\n",
        "  year_df['MP'] = import_player_pts_peaks_df['MP']\n",
        "  year_df['Player'] = 'Tony Parker'\n",
        "\n",
        "  \n",
        "\n",
        "  final_df = pd.concat([final_df, year_df], ignore_index=True)\n",
        "\n",
        "  year_df.to_csv(f'{num_of_years}_year_manual_peaks.csv', index=False)\n",
        "\n",
        "print(final_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "90DoiB6eC7fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN SERIES MANUAL SUBSETS**"
      ],
      "metadata": {
        "id": "X9dcEeQyVVWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu Scoring numbers with only 1 of Tim/Tony on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['18.27', '.4048', '56', 'MEM', '2004', '15.14', '106.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.17', '.7000', '66', 'LAL', '2004', '0.0', '107.50']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '76', 'DEN', '2005', '18.88', '109.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '79', 'SEA', '2005', '7.79', '119.59']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '67', 'PHO', '2005', '12.23', '110.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '86', 'DET', '2005', '11.78', '108.97']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '46', 'SAC', '2006', '1.14', '110.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '81', 'DAL', '2006', '2.70', '110.81']\n",
        "\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['32.31', '.5263', '35', 'DEN', '2007', '7.74', '110.77']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.19', '.5167', '71', 'PHO', '2007', '-7.50', '108.70']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.21', '.5370', '54', 'UTA', '2007', '9.22', '104.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.51', '.5750', '36', 'CLE', '2007', '50.79', '123.81']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['42.05', '.5606', '42', 'PHO', '2008', '-0.21', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.72', '.7333', '60', 'NOH', '2008', '28.35', '120.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.72', '.5192', '55', 'LAL', '2008', '-7.09', '100.99']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4457', '102', 'DAL', '2010', '-5.21', '98.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.49', '.4444', '49', 'PHO', '2010', '-19.89', '94.85']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['51.95', '.7800', '38', 'MEM', '2011', '31.20', '128.57']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['16.67', '.4000', '13', 'UTA', '2012', '-43.30', '95.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '10', 'LAC', '2012', '-17.73', '55.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.95', '.6071', '18', 'OKC', '2012', '-49.03', '108.11']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['45.83', '.9167', '12', 'LAL', '2013', '29.17', '137.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.79', '.5256', '83', 'GSW', '2013', '46.44', '130.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.62', '.8889', '41', 'MEM', '2013', '35.38', '117.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.91', '.4444', '75', 'MIA', '2013', '-11.91', '102.99']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['48.39', '.6471', '44', 'DAL', '2014', '26.18', '120.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.97', '.4333', '29', 'POR', '2014', '30.05', '98.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.71', '.6842', '39', 'OKC', '2014', '24.56', '110.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.38', '.5000', '20', 'MIA', '2014', '14.76', '102.56']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q4g7Q_d74lW",
        "outputId": "f698e225-a40b-4364-869e-7169e0e4e583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    PP75   TS%    MP  Opp   Year  NetRtg  OffRtg\n",
            "0   18.27  .4048   56  MEM  2004   15.14  106.73\n",
            "1   34.17  .7000   66  LAL  2004     0.0  107.50\n",
            "2   41.13  .6591   76  DEN  2005   18.88  109.22\n",
            "3   41.22  .6250   79  SEA  2005    7.79  119.59\n",
            "4   32.82  .5513   67  PHO  2005   12.23  110.69\n",
            "5   42.76  .7073   86  DET  2005   11.78  108.97\n",
            "6   12.50  .4231   46  SAC  2006    1.14  110.23\n",
            "7   41.22  .6489   81  DAL  2006    2.70  110.81\n",
            "8   32.31  .5263   35  DEN  2007    7.74  110.77\n",
            "9   23.19  .5167   71  PHO  2007   -7.50  108.70\n",
            "10  30.21  .5370   54  UTA  2007    9.22  104.17\n",
            "11  36.51  .5750   36  CLE  2007   50.79  123.81\n",
            "12  42.05  .5606   42  PHO  2008   -0.21  109.09\n",
            "13  42.72  .7333   60  NOH  2008   28.35  120.39\n",
            "14  27.72  .5192   55  LAL  2008   -7.09  100.99\n",
            "15  22.99  .4457  102  DAL  2010   -5.21   98.93\n",
            "16  16.49  .4444   49  PHO  2010  -19.89   94.85\n",
            "17  51.95  .7800   38  MEM  2011   31.20  128.57\n",
            "18  16.67  .4000   13  UTA  2012  -43.30   95.83\n",
            "19   0.00  .0000   10  LAC  2012  -17.73   55.50\n",
            "20  45.95  .6071   18  OKC  2012  -49.03  108.11\n",
            "21  45.83  .9167   12  LAL  2013   29.17  137.50\n",
            "22  25.79  .5256   83  GSW  2013   46.44  130.82\n",
            "23  21.62  .8889   41  MEM  2013   35.38  117.57\n",
            "24  17.91  .4444   75  MIA  2013  -11.91  102.99\n",
            "25  48.39  .6471   44  DAL  2014   26.18  120.43\n",
            "26  20.97  .4333   29  POR  2014   30.05   98.39\n",
            "27  31.71  .6842   39  OKC  2014   24.56  110.98\n",
            "28  15.38  .5000   20  MIA  2014   14.76  102.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Series) Adjusted Playoff TS+ of Manual Subset \n",
        "def manual_adjust_scoring_efficiency_series(player_df, opp_ts_df, opp_defrtg_df, opp_literal_defrtg, player):\n",
        "\n",
        "      final_season_df = pd.DataFrame(columns = ['Player', 'Series', 'PP75', 'TS+', 'NetRtg', 'rOffRtg', 'MP'])\n",
        "\n",
        "      series_list = []\n",
        "\n",
        "      player_df['PP75'] = player_df['PP75'].astype(float)\n",
        "      player_df['PP75'] = player_df['PP75'] * .75\n",
        "\n",
        "\n",
        "      player_df['TS%'] = player_df['TS%'].astype(float)\n",
        "\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(int)\n",
        "      opp_defrtg_df['Team'] = opp_defrtg_df['Team'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(int)\n",
        "      opp_literal_defrtg['Team'] = opp_literal_defrtg['Team'].astype(str)\n",
        "      opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "      player_df['Opp'] = player_df['Opp'].astype(str)\n",
        "      player_df['Year'] = player_df['Year'].astype(int)\n",
        "\n",
        "      for i, row in player_df.iterrows():\n",
        "\n",
        "        current_opp = player_df.loc[i, 'Opp']\n",
        "        current_year = player_df.loc[i, 'Year']\n",
        "\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & (opp_ts_df['Year'] == current_year)]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        opponent_literal_def = opp_literal_defrtg[(opp_literal_defrtg['Team'] == current_opp) & ((opp_literal_defrtg['Year'] == current_year))]\n",
        "        opp_def_rtg = float(opponent_literal_def['DefRtg'])\n",
        "\n",
        "        player_ts = player_df.loc[i, 'TS%']\n",
        "        tsplus = (float(player_ts) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        relOffRtg = float(row['OffRtg']) - opp_def_rtg\n",
        "\n",
        "        player_df.loc[i,'TS+'] = tsplus\n",
        "        player_df.loc[i,'PTS_coeff'] = pts_coeff\n",
        "        player_df.loc[i,'rOffRtg'] = relOffRtg\n",
        "\n",
        "\n",
        "      for idx, row in player_df.iterrows():\n",
        "        total_pts = 0\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        total_net = 0\n",
        "        total_off = 0\n",
        "\n",
        "        total_mp = int(row['MP'])\n",
        "        total_ts = float(row['TS+'])\n",
        "        total_pts = float(row['PP75'])\n",
        "        total_coeff = float(row['PTS_coeff'])\n",
        "        total_pts = total_pts * total_coeff\n",
        "\n",
        "\n",
        "        total_net = float(row['NetRtg'])\n",
        "        total_off = float(row['rOffRtg'])\n",
        "\n",
        "        total_pts = '%.2f' % round(total_pts, 2)\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "        total_off = '%.2f' % round(total_off, 2)\n",
        "        total_net = '%.2f' % round(total_net, 2)\n",
        "\n",
        "        series = str(row['Year'])\n",
        "        series = series + \" \"\n",
        "        series = series + str(row['Opp'])\n",
        "\n",
        "        new_row = {'Player':player, 'Series':series,  'PP75':total_pts, 'TS+':total_ts, 'NetRtg':total_net, 'rOffRtg': total_off, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "      print(final_season_df)\n",
        "      outfile = f\"NBA_Playoff_Series_Manual_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QGtEKaNlMyD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Series) Inflate Scoring for Manual Subset\n",
        "new_df = pd.DataFrame()\n",
        "per_75_coeff['Year'] = per_75_coeff['Year'].astype(int)\n",
        "manu_one_on['Year'] = manu_one_on['Year'].astype(float)\n",
        "manu_one_on['PP75'] = manu_one_on['PP75'].astype(float)\n",
        "for i, row in manu_one_on.iterrows():\n",
        "  sub_coeff = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PP75'] = float((row['PP75'] * sub_coeff['Coefficient']))\n",
        "  new_df = new_df.append(row)\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df['PP75'] = new_df['PP75'].astype(float)\n",
        "new_df['TS%'] = new_df['TS%'].astype(float)\n",
        "new_df['MP'] = new_df['MP'].astype(int)\n",
        "new_df['Opp'] = new_df['Opp'].astype(str)\n",
        "\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "team_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "team_ts_allowed_df['TS% Allowed'] = team_ts_allowed_df['TS% Allowed'].astype(float)\n",
        "team_ts_allowed_df['Year'] = team_ts_allowed_df['Year'].astype(int)\n",
        "\n",
        "opp_literal_defrtg = pd.read_csv('/content/NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "\n",
        "\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "\n",
        "print(\"   Manu Ginbili with 1 of Tim/Tony On Bench (3+ opp. starters)\\n\")\n",
        "\n",
        "manual_adjust_scoring_efficiency_series(new_df, team_ts_allowed_df, opponent_adj_pts_coeff, opp_literal_defrtg, 'Klay Thompson')\n",
        "\n",
        "#Manu Ginbili"
      ],
      "metadata": {
        "id": "H0z9UzeePrxe",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Output Manual Series Percentiles\n",
        "from scipy import stats\n",
        "graph_data =  era_opponent_adj_playoff_per_75_df.copy()\n",
        "graph_data = graph_data[(graph_data['PTS'] >= 15)]\n",
        "graph_data = graph_data[(graph_data['MP'] >= 90)]\n",
        "\n",
        "final_season_df = pd.DataFrame(columns = ['Series', 'PP75', 'TS+', 'MP'])\n",
        "\n",
        "this_df = pd.read_csv('/content/NBA_Playoff_Series_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "for idx, row in this_df.iterrows():\n",
        "  series = row['Series']\n",
        "  pts = row['PP75']\n",
        "  ts = row['TS+']\n",
        "  mp = row['MP']\n",
        "  pts_percentile = stats.percentileofscore(graph_data['PTS'], pts)\n",
        "  ts_percentile = stats.percentileofscore(graph_data['TS%+'], ts)\n",
        "\n",
        "  \n",
        "  new_row = {'Series':series,  'PP75':pts_percentile, 'TS+':ts_percentile,'MP':int(mp)}\n",
        "  final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  outfile = f\"Percentiles.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eS7gPS-sMjSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Output Manual Series Approx_Scoring_Val\n",
        "from scipy import stats\n",
        "graph_data =  era_opponent_adj_playoff_per_75_df.copy()\n",
        "graph_data = graph_data[(graph_data['PTS'] >= 15)]\n",
        "graph_data = graph_data[(graph_data['MP'] >= 90)]\n",
        "graph_data['Approx_Scoring_Val'] = 0\n",
        "\n",
        "for idx, row in graph_data.iterrows():\n",
        "  pts = row['PTS']\n",
        "  ts = row['TS%+']\n",
        "  mp = row['MP']\n",
        "  pts_percentile = stats.percentileofscore(graph_data['PTS'], pts)\n",
        "  ts_percentile = stats.percentileofscore(graph_data['TS%+'], ts)\n",
        "  approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "  graph_data.at[idx, 'Approx_Scoring_Val'] = approx_scoring_val\n",
        "\n",
        "\n",
        "final_season_df = pd.DataFrame(columns = ['Series', 'Approx_Scoring_Val', 'MP'])\n",
        "\n",
        "this_df = pd.read_csv('/content/NBA_Playoff_Series_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "for idx, row in this_df.iterrows():\n",
        "  series = row['Series']\n",
        "  pts = row['PP75']\n",
        "  ts = row['TS+']\n",
        "  mp = row['MP']\n",
        "  pts_percentile = stats.percentileofscore(graph_data['PTS'], pts)\n",
        "  ts_percentile = stats.percentileofscore(graph_data['TS%+'], ts)\n",
        "  approx_scoring_val = (0.5 * pts_percentile) + (0.5 * ts_percentile)\n",
        "  approx_scoring_val = stats.percentileofscore(graph_data['Approx_Scoring_Val'], approx_scoring_val)\n",
        "\n",
        "\n",
        "  \n",
        "  new_row = {'Series':series,  'Approx_Scoring_Val':approx_scoring_val,'MP':int(mp)}\n",
        "  final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  outfile = f\"Percentiles.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TQhwzqlCoCv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QQT2n6FFd9pf"
      },
      "outputs": [],
      "source": [
        "#@title Print Manual Peaks\n",
        "def manu_tony_compare(player, sit):\n",
        "\n",
        "  manu_only_one_adjusted = pd.read_csv('/content/NBA_Playoff_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('two_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('two_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('two_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('two_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('three_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('four_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('four_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('four_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('four_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('five_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('five_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('five_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('five_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('six_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('six_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('six_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('six_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('seven_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('seven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('eight_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('eight_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('nine_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('nine_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('ten_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('ten_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'PP75')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('eleven_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_PP75_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eleven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('eleven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eleven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  import_pts_twopeaks_df = pd.read_csv('two_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_ts_twopeaks_df = pd.read_csv('two_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_peaks_df = pd.read_csv('two_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_peaks_df = pd.read_csv('two_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_peaks_df = pd.read_csv('three_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_peaks_df = pd.read_csv('three_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg3_peaks_df = pd.read_csv('three_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg3_peaks_df = pd.read_csv('three_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_4peaks_df = pd.read_csv('four_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_4peaks_df = pd.read_csv('four_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_4peaks_df = pd.read_csv('four_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_4peaks_df = pd.read_csv('four_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_5peaks_df = pd.read_csv('five_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_5peaks_df = pd.read_csv('five_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_5peaks_df = pd.read_csv('five_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_5peaks_df = pd.read_csv('five_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_6peaks_df = pd.read_csv('six_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_6peaks_df = pd.read_csv('six_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_6peaks_df = pd.read_csv('six_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_6peaks_df = pd.read_csv('six_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_7peaks_df = pd.read_csv('seven_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_7peaks_df = pd.read_csv('seven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_7peaks_df = pd.read_csv('seven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_7peaks_df = pd.read_csv('seven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_8peaks_df = pd.read_csv('eight_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_8peaks_df = pd.read_csv('eight_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_8peaks_df = pd.read_csv('eight_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_8peaks_df = pd.read_csv('eight_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_9peaks_df = pd.read_csv('nine_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_9peaks_df = pd.read_csv('nine_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_9peaks_df = pd.read_csv('nine_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_9peaks_df = pd.read_csv('nine_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_10peaks_df = pd.read_csv('ten_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_10peaks_df = pd.read_csv('ten_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_10peaks_df = pd.read_csv('ten_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_10peaks_df = pd.read_csv('ten_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_11peaks_df = pd.read_csv('eleven_year_peak_PP75_data.csv', encoding='utf8')\n",
        "  import_player_ts_11peaks_df = pd.read_csv('eleven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_11peaks_df = pd.read_csv('eleven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_11peaks_df = pd.read_csv('eleven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #2 year playoff scoring peaks Output File\n",
        "  peaks_df = import_pts_twopeaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_ts_twopeaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Two\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_2_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #3 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg3_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg3_peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Three\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_3_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #4 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_4peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_4peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_4peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_4peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Four\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_4_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #5 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_5peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_5peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_5peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_5peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Five\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_5_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #6 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_6peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_6peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_6peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_6peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Six\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_6_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #7 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_7peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_7peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_7peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_7peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Seven\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_7_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #8 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_8peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_8peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_8peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_8peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Eight\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_8_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #9 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_9peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_9peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_9peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_9peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Nine\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_9_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #10 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_10peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_10peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_10peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_10peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Ten\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_10_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  #11 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_11peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_11peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_11peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_11peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Eleven\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_11_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "632Vlw2nH8ir"
      },
      "outputs": [],
      "source": [
        "manu_tony_compare(\"Tony\", \"Only_One\")\n",
        "# Manu Ginbili"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape NBA playoffs series possession data\n",
        "def scrape_nba_possession_97_00_data(url, player, player_ref):\n",
        "                       \n",
        "  wd.get(url)   \n",
        "  html = wd.page_source\n",
        "  soup = BeautifulSoup(html, features=\"lxml\")\n",
        "  time.sleep(10)\n",
        "\n",
        "  for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'div_other_scores'})\n",
        "          hrefs = second_div.findAll('td', attrs={'class': 'right gamelink'})\n",
        "          hrefs = str(hrefs)\n",
        "          ref_urls = re.findall(r'/\\d+\\w+\\D\\w+', hrefs)\n",
        "          urls = []\n",
        "          for ref_url in ref_urls:\n",
        "            ref_url = \"https://www.basketball-reference.com/boxscores/pbp\" + ref_url\n",
        "            urls.append(ref_url)\n",
        "  def_possessions = 0\n",
        "  missing_poss = 0\n",
        "  for game_url in urls:\n",
        "\n",
        "    wd.get(game_url)   \n",
        "    html = wd.page_source\n",
        "    soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "    for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'all_pbp'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'pbp'})\n",
        "            body = first_table.find('tbody')\n",
        "    # grab rows\n",
        "    rows = body.findAll('tr')[0:]\n",
        "\n",
        "    \n",
        "\n",
        "    total_poss = 0\n",
        "    player_out_wait = 0\n",
        "    beg_q = 0\n",
        "    extra_poss = 0\n",
        "    non_shooting = 0\n",
        "\n",
        "\n",
        "    possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "    fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "    player_out = [f'enters the game for <a href=\"{player_ref}\">{player}']\n",
        "    player_in = [f'{player}']\n",
        "\n",
        "    hes_back_but_subtly = [f'{player}</a> misses 2-pt']\n",
        "    for row in rows:\n",
        "      row = str(row)\n",
        "\n",
        "\n",
        "      if player_out_wait == 1:\n",
        "        if f'{player}</a> misses 2-pt' in row:\n",
        "          total_poss = total_poss + extra_poss\n",
        "          extra_poss = 0\n",
        "          player_out_wait = 0\n",
        "          beg_q = 0\n",
        "\n",
        "      if 'Q' in row:\n",
        "        beg_q = 1\n",
        "\n",
        "      if any(iny in row for iny in player_in):\n",
        "        player_out_wait = 0\n",
        "      if any(outy in row for outy in player_out):\n",
        "        player_out_wait = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in fts_no_shooting_foul) and player_out_wait == 0 and non_shooting == 1):\n",
        "        total_poss = total_poss + 1\n",
        "\n",
        "      if ('foul' in row and 'Shooting' not in row):\n",
        "        non_shooting = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "        total_poss = total_poss + 1\n",
        "        non_shooting = 0\n",
        "      \n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 1 and beg_q == 1):\n",
        "        extra_poss = extra_poss + 1\n",
        "        non_shooting = 0\n",
        "      \n",
        "    missing_poss = missing_poss + total_poss\n",
        "\n",
        "    #@title Default possessions\n",
        "\n",
        "    total_poss = 0\n",
        "    player_out_wait = 0\n",
        "    extra_poss = 0\n",
        "\n",
        "\n",
        "    possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "    fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "    player_out = [f'enters the game for <a href=\"{player_ref}\">{player}']\n",
        "    player_in = [f'{player}']\n",
        "\n",
        "    hes_back_but_subtly = [f'{player}</a> misses 2-pt']\n",
        "\n",
        "    for row in rows:\n",
        "      row = str(row)\n",
        "\n",
        "      if any(iny in row for iny in player_in):\n",
        "        player_out_wait = 0\n",
        "      if any(outy in row for outy in player_out):\n",
        "        player_out_wait = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "        total_poss = total_poss + 1\n",
        "    def_possessions = def_possessions + total_poss\n",
        "  print(\"Total Default:\")\n",
        "  print(def_possessions/2)\n",
        "  print(\"\\nTotal Missing:\")\n",
        "  print(missing_poss/2)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ij-9Pa2Tz-Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_nba_possession_97_00_data(\"https://www.basketball-reference.com/playoffs/2000-nba-western-conference-first-round-suns-vs-spurs.html\", 'D. Robinson', '/players/r/robinda01.html',)"
      ],
      "metadata": {
        "id": "kgQg5nhsbpPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef4719b-470f-4749-cfad-eb64710ae78b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Default:\n",
            "302.0\n",
            "\n",
            "Total Missing:\n",
            "336.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}