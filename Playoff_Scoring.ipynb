{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "KA1adZNvGkBH"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "pd.set_option('display.colheader_justify', 'center')\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import re\n",
        "\n",
        "import scipy.stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "\n",
        "from inspect import signature\n",
        "\n",
        "def someMethod(self, arg1, kwarg1=None):\n",
        "    pass\n",
        "\n",
        "possession_data_seasons = np.arange(1974, 2023, 1)\n",
        "play_by_play_data_seasons = np.arange(1997, 2023, 1)\n",
        "pre_possesson_data_seasons = np.arange(1952, 1974, 1)\n",
        "aba_seasons = np.arange(1974, 1977, 1)\n",
        "\n",
        "# plot\n",
        "import seaborn as sns\n",
        "import ast\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.pyplot import *\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as font_manager\n",
        "sns.set_style('darkgrid')        # darkgrid, white grid, dark, white and ticks\n",
        "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=14)     # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=13)    # legend fontsize\n",
        "plt.rc('font', size=13)          # controls default text sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EqvRpXTQxtV0"
      },
      "outputs": [],
      "source": [
        "#@title Import Selenium\n",
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "!pip install pyvirtualdisplay\n",
        "!apt-get install xvfb\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(800, 800))  \n",
        "display.start()\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('start-maximized')\n",
        "options.add_argument('enable-automation')\n",
        "options.add_argument('--disable-infobars')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--disable-browser-side-navigation')\n",
        "options.add_argument(\"--remote-debugging-port=9222\")\n",
        "# options.add_argument(\"--headless\")\n",
        "options.add_argument('--disable-gpu')\n",
        "options.add_argument(\"--log-level=3\")\n",
        "wd = webdriver.Chrome(chrome_options=options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NncsPba_zEg"
      },
      "source": [
        "**IMPORT RAW DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "u6CkVfCOGD-g"
      },
      "outputs": [],
      "source": [
        "#@title Manually add team abbrev, league_avg TS%, and teamcolors\n",
        "\n",
        "aba_league_avg = pd.DataFrame(columns=['Year','TS%'])\n",
        "\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1974\",\n",
        "     \"TS%\":  .509, }, ignore_index=True)\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1975\",\n",
        "     \"TS%\":  .520, }, ignore_index=True)\n",
        "aba_league_avg = aba_league_avg.append({\n",
        "     \"Year\": \"1976\",\n",
        "     \"TS%\":  .517, }, ignore_index=True)\n",
        "\n",
        "league_avg_df = pd.DataFrame(columns=['Year','TS%'])\n",
        "\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2022\",\n",
        "     \"TS%\":  .566, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2021\",\n",
        "     \"TS%\":  .572, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2020\",\n",
        "     \"TS%\":  .565, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2019\",\n",
        "     \"TS%\":  .560, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2018\",\n",
        "     \"TS%\":  .556, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2017\",\n",
        "     \"TS%\":  .552, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2016\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2015\",\n",
        "     \"TS%\":  .534, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2014\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2013\",\n",
        "     \"TS%\":  .535, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2012\",\n",
        "     \"TS%\":  .527, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2011\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2010\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2009\",\n",
        "     \"TS%\":  .544, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2008\",\n",
        "     \"TS%\":  .540, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2007\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2006\",\n",
        "     \"TS%\":  .536, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({  \n",
        "     \"Year\": \"2005\",\n",
        "     \"TS%\":  .529, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2004\",\n",
        "     \"TS%\":  .516, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2003\",\n",
        "     \"TS%\":  .519, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2002\",\n",
        "     \"TS%\":  .520, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2001\",\n",
        "     \"TS%\":  .518, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"2000\",\n",
        "     \"TS%\":  .523, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1999\",\n",
        "     \"TS%\":  .511, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1998\",\n",
        "     \"TS%\":  .524, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1997\",\n",
        "     \"TS%\":  .536, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1996\",\n",
        "     \"TS%\":  .542, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1995\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1994\",\n",
        "     \"TS%\":  .528, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "      \"Year\": \"1993\",\n",
        "     \"TS%\":  .536, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1992\",\n",
        "     \"TS%\":  .531, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1991\",\n",
        "     \"TS%\":  .534, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1990\",\n",
        "     \"TS%\":  .537, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1989\",\n",
        "     \"TS%\":  .537, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1988\",\n",
        "     \"TS%\":  .538, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1987\",\n",
        "     \"TS%\":  .538, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1986\",\n",
        "     \"TS%\":  .541, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1985\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)   \n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1984\",\n",
        "     \"TS%\":  .543, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1983\",\n",
        "     \"TS%\":  .531, }, ignore_index=True) \n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1982\",\n",
        "     \"TS%\":  .539, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1981\",\n",
        "     \"TS%\":  .534, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "    \"Year\": \"1980\",\n",
        "     \"TS%\":  .531, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1979\",\n",
        "     \"TS%\":  .530, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1978\",\n",
        "     \"TS%\":  .515, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1977\",\n",
        "     \"TS%\":  .511, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1976\",\n",
        "     \"TS%\":  .504, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1975\",\n",
        "     \"TS%\":  .502, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1974\",\n",
        "     \"TS%\":  .503, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1973\",\n",
        "     \"TS%\":  .498, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1972\",\n",
        "     \"TS%\":  .504, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1971\",\n",
        "     \"TS%\":  .500, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1970\",\n",
        "     \"TS%\":  .511, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1969\",\n",
        "     \"TS%\":  .491, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1968\",\n",
        "     \"TS%\":  .498, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1967\",\n",
        "     \"TS%\":  .493, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1966\",\n",
        "     \"TS%\":  .487, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1965\",\n",
        "     \"TS%\":  .479, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1964\",\n",
        "     \"TS%\":  .485, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1963\",\n",
        "     \"TS%\":  .493, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1962\",\n",
        "     \"TS%\":  .479, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1961\",\n",
        "     \"TS%\":  .469, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1960\",\n",
        "     \"TS%\":  .463, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1959\",\n",
        "     \"TS%\":  .457, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1958\",\n",
        "     \"TS%\":  .449, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1957\",\n",
        "     \"TS%\":  .449, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1956\",\n",
        "     \"TS%\":  .458, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1955\",\n",
        "     \"TS%\":  .455, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1954\",\n",
        "     \"TS%\":  .442, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1953\",\n",
        "     \"TS%\":  .445, }, ignore_index=True)\n",
        "league_avg_df = league_avg_df.append({\n",
        "     \"Year\": \"1952\",\n",
        "     \"TS%\":  .438, }, ignore_index=True)\n",
        "\n",
        "team_colors = {\"ATL\": \"#E03A3E\", \"BOS\": \"#007A33\", \"BRK\": \"#000000\", \"BUF\": \"#ff6314\", \"CAP\": \"#E31837\", \"CHA\": \"#00788C\", \n",
        "               \"CHI\": \"#CE1141\", \"CHO\": \"#f26631\", \"CLE\": \"#860038\", \"DAL\": \"#00538C\", \"DEN\": \"#0E2240\", \"DET\": \"#1D42BA\",\n",
        "               \"GSW\": \"#FFC72C\", \"HOU\": \"#CE1141\", \"IND\": \"#002D62\", \"KCO\": \"#5A2D81\", \"KCK\": \"#5A2D81\", \"LAC\": \"#C8102E\", \n",
        "               \"LAL\": \"#552583\", \"MEM\": \"#5D76A9\", \"MIA\": \"#98002E\", \"MIL\": \"#00471B\", \"MIN\": \"#78BE20\", \"NOH\": \"#008fc5\", \n",
        "               \"NOP\": \"#85714D\", \"NOJ\": \"#00471B\", \"NJN\": \"#00275d\", \"NYK\": \"#006BB6\", \"OKC\": \"#007AC1\", \"ORL\": \"#0077C0\", \n",
        "               \"PHI\": \"#006BB6\", \"PHO\": \"#1D1160\", \"POR\": \"#E03A3E\", \"SAC\": \"#5A2D81\", \"SAS\": \"#C4CED4\", \"SEA\": \"#00653A\", \n",
        "               \"TOR\": \"#CE1141\", \"TOT\": \"pink\", \"UTA\": \"#00471B\", \"WAS\": \"#E31837\", \"WSB\": \"#E31837\"}\n",
        "\n",
        "team_abbrev = {\"Atlanta Hawks\" : \"ATL\",       \"Boston Celtics\": \"BOS\",        \"Brooklyn Nets\": \"BRK\",         \"Charlotte Bobcats\": \"CHA\", \n",
        "               \"Chicago Bulls\": \"CHI\",      \"Charlotte Hornets\": \"CHO\",      \"Cleveland Cavaliers\": \"CLE\",     \"Dallas Mavericks\": \"DAL\",\n",
        "               \"Denver Nuggets\": \"DEN\",     \"Detroit Pistons\": \"DET\",       \"Golden State Warriors\": \"GSW\",     \"Houston Rockets\": \"HOU\",\n",
        "               \"Indiana Pacers\": \"IND\",     \"Los Angeles Clippers\": \"LAC\",  \"Los Angeles Lakers\": \"LAL\",      \"Memphis Grizzlies\": \"MEM\",\n",
        "               \"Miami Heat\": \"MIA\",         \"Milwaukee Bucks\": \"MIL\",     \"Minnesota Timberwolves\": \"MIN\",  \"New Orleans Hornets\": \"NOH\",\n",
        "               \"New Orleans Pelicans\": \"NOP\", \"New Jersey Nets\": \"NJN\",     \"New York Knicks\": \"NYK\",     \"Oklahoma City Thunder\": \"OKC\", \n",
        "               \"Orlando Magic\": \"ORL\",     \"Philadelphia 76ers\": \"PHI\",      \"Phoenix Suns\": \"PHO\",       \"Portland Trail Blazers\": \"POR\",\n",
        "               \"Sacramento Kings\": \"SAC\",    \"San Antonio Spurs\": \"SAS\",       \"Toronto Raptors\": \"TOR\",               \"Utah Jazz\": \"UTA\", \n",
        "               \"Washington Wizards\": \"WAS\", \"Capital Bullets\": \"CAP\", \"Buffalo Braves\": \"BUF\", \"Seattle SuperSonics\": \"SEA\", \"Washington Bullets\": \"WSB\",\n",
        "               \"Kansas City-Omaha Kings\": \"KCO\", \"Kansas City Kings\": \"KCK\", \"Charlotte Hornets\": \"CHH\"}\n",
        "\n",
        "\n",
        "aba_abbrev = {\"Denver Nuggets\": \"DNA\", \"Indiana Pacers\": \"INA\", \"New York Nets\": \"NYA\", \"San Antonio Spurs\": \"SAA\",\n",
        "              \"Virginia Squires\": \"VIR\", \"Carolina Cougars\": \"CAR\", \"San Diego Conquistadors\": \"SDA\", \"Kentucky Colonels\": \"KEN\",\n",
        "              \"Utah Stars\": \"UTS\", \"Carolina Cougars\": \"CAR\", \"San Diego Sails\": \"SDS\", \"Spirits of St. Louis\": \"SSL\",\n",
        "              \"Memphis Sounds\": \"MMS\", \"Denver Rockets\": \"DNR\"}\n",
        "\n",
        "team_52_73_abbrev = {\"Milwaukee Hawks\" : \"MLH\",  \"Syracuse Nationals\": \"SYR\",        \"Minneapolis Lakers\": \"MNL\",         \"Rochester Royals\": \"ROC\", \n",
        "               \"Chicago Bulls\": \"CHI\",      \"Boston Celtics\": \"BOS\",      \"Cleveland Cavaliers\": \"CLE\",     \"Fort Wayne Pistons\": \"FTW\",\n",
        "               \"Indianapolis Olympians\": \"INO\",     \"Detroit Pistons\": \"DET\",       \"Golden State Warriors\": \"GSW\",     \"Houston Rockets\": \"HOU\",\n",
        "               \"St. Louis Hawks\": \"STL\",  \"Los Angeles Lakers\": \"LAL\",      \"Philadelphia Warriors\": \"PHW\",\n",
        "               \"Cincinnati Royals\": \"CIN\",         \"Milwaukee Bucks\": \"MIL\", \"San Diego Rockets\": \"SDR\",     \n",
        "               \"New York Knicks\": \"NYK\",   \"Philadelphia 76ers\": \"PHI\",      \"Phoenix Suns\": \"PHO\",       \"Portland Trail Blazers\": \"POR\",\n",
        "               \"Baltimore Bullets\": \"BAL\", \"Buffalo Braves\": \"BUF\", \"Seattle SuperSonics\": \"SEA\", \"Washington Bullets\": \"WSB\",\n",
        "               \"Kansas City-Omaha Kings\": \"KCO\", \"Kansas City Kings\": \"KCK\", \"San Francisco Warriors\": \"SFW\", \"Atlanta Hawks\": \"ATL\",\n",
        "               \"Chicago Packers\": \"CHP\", \"Chicago Zephyrs\": \"CHZ\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "xTVOqjCkD24f"
      },
      "outputs": [],
      "source": [
        "#@title Import data and add team colors for advanced, play-by-play, per 100, and league avg data\n",
        "\n",
        "# per 100 posssessions\n",
        "#import_player_since74_per100_df = pd.read_csv('nba_player_since74_per100_data.csv')\n",
        "\n",
        "# add team color for per 100 posssessions\n",
        "#import_player_since74_per100_df['TeamColor'] = import_player_since74_per100_df['Tm'].map(team_colors)\n",
        "# per 100 playoff posssessions\n",
        "#import_player_since74playoffs_per100_df = pd.read_csv('nba_player_since74playoffs_per100_data.csv')\n",
        "# add team color for playoff per 100 posssessions\n",
        "#import_player_since74playoffs_per100_df['TeamColor'] = import_player_since74playoffs_per100_df['Tm'].map(team_colors)\n",
        "\n",
        "# advanced\n",
        "import_player_since74_advanced_df = pd.read_csv('nba_player_since74_advanced_data.csv', encoding='utf8')\n",
        "\n",
        "# advanced playoffs\n",
        "import_player_since74playoffs_advanced_df = pd.read_csv('nba_player_since74playoffs_advanced_data.csv', encoding='utf8')\n",
        "\n",
        "\n",
        "# play-by-play\n",
        "import_player_regular_playbyplay_df = pd.read_csv('nba_player_regular_playbyplay_data.csv', encoding='utf8')\n",
        "\n",
        "# add team color for play-by-play\n",
        "import_player_regular_playbyplay_df['TeamColor'] = import_player_regular_playbyplay_df['Tm'].map(team_colors)\n",
        "\n",
        "# play-by-play playoffs\n",
        "import_player_since74playoffs_playbyplay_df = pd.read_csv('nba_player_playoff_playbyplay_data.csv', encoding='utf8')\n",
        "\n",
        "# add team color for playoff play-by-play\n",
        "import_player_since74playoffs_playbyplay_df['TeamColor'] = import_player_since74playoffs_playbyplay_df['Tm'].map(team_colors)\n",
        "\n",
        "\n",
        "# import league avg data\n",
        "\n",
        "# league avg\n",
        "import_leagueavgsince74_df = pd.read_csv('nba_leaguestats_data.csv')\n",
        "\n",
        "# drop NBA seasons from inception of league until 1973 (final year without per possession data)\n",
        "import_leagueavgsince74_df.drop(import_leagueavgsince74_df.tail(26).index,inplace=True)\n",
        "\n",
        "# change from '2020-21' to '2021' and '2019-20' to '2020'... and so on\n",
        "for i, trial in import_leagueavgsince74_df.iterrows():\n",
        "   import_leagueavgsince74_df.loc[i, \"Season\"] = 2022-i\n",
        "\n",
        "league_avg_df['Year'] = league_avg_df['Year'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "b0yr4pEL4W7l"
      },
      "outputs": [],
      "source": [
        "#@title Import per 75 data (can be used in place of 'Calculate per 75' cells with necessitated imported data')\n",
        "\n",
        "# per 75 posssessions\n",
        "import_player_since74_per75_df = pd.read_csv('nba_player_since74_per75_data.csv')\n",
        "\n",
        "# add team color for per 75 posssessions\n",
        "import_player_since74_per75_df['TeamColor'] = import_player_since74_per75_df['Tm'].map(team_colors)\n",
        "\n",
        "# per 75 playoff posssessions\n",
        "import_player_since74playoffs_per75_df = pd.read_csv('nba_player_since74playoffs_per75_data.csv')\n",
        "\n",
        "# add team color for playoff per 75 posssessions\n",
        "import_player_since74playoffs_per75_df['TeamColor'] = import_player_since74playoffs_per75_df['Tm'].map(team_colors)\n",
        "\n",
        "# per 75 adjusted ts playoff posssessions\n",
        "#adjusted_playoff_per_75_df = pd.read_csv('/content/since74_adj_ts_playoffs_per75_data.csv')\n",
        "# add team color for playoff per 75 adjusted posssessions\n",
        "#adjusted_playoff_per_75_df['TeamColor'] = adjusted_playoff_per_75_df['Tm'].map(team_colors)\n",
        "\n",
        "# era/opponent adjusted scoring\n",
        "era_adj_reg_per_75_df = pd.read_csv('/content/era_adjusted_reg_per75_data.csv')\n",
        "era_opponent_adj_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "f4veohWtxhJh"
      },
      "outputs": [],
      "source": [
        "#@title Create scoring coefficients\n",
        "\n",
        "# era-adjust per game data\n",
        "per_game_coeff = pd.read_csv('/content/Avg_Reg_PTS_G.csv', index_col=False, encoding='utf8')\n",
        "per_game_coeff['Coefficient'] = per_game_coeff['Average PTS_G'].max() / per_game_coeff['Average PTS_G'] \n",
        "\n",
        "# era-adjust per 75 data\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "#aba_per75_coeff = pd.read_csv('/content/Avg_ABA_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "#aba_per75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / aba_per75_coeff['Average PP75']\n",
        "\n",
        "bpm_coeff = pd.read_csv('/content/Avg_Reg_BPM.csv', index_col=False, encoding='utf8')\n",
        "bpm_coeff['Average BPM'] = bpm_coeff['Average BPM'] +  1\n",
        "bpm_coeff['Average OBPM'] = bpm_coeff['Average OBPM'] + 1\n",
        "bpm_coeff['BPM_Coefficient'] = bpm_coeff['Average BPM'].max() / bpm_coeff['Average BPM']\n",
        "bpm_coeff['OBPM_Coefficient'] = bpm_coeff['Average OBPM'].max() / bpm_coeff['Average OBPM']\n",
        "\n",
        "try:\n",
        "  opponent_adj_pts_coeff = pd.DataFrame(columns = ['Year', 'Team', 'PTS_coeff'])\n",
        "\n",
        "  team_def_rtg = pd.read_csv('NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "  league_avg_def_rtg = pd.read_csv('/content/Avg_Def_Rtg.csv', index_col=False, encoding='utf8')\n",
        "  for idx, row in team_def_rtg.iterrows():\n",
        "          match_df = league_avg_def_rtg[(league_avg_def_rtg['Year'] == row['Year'])]\n",
        "          avg = match_df['Avg DefRtg']\n",
        "          avg = float(avg)\n",
        "          coeff = avg / row['DefRtg']\n",
        "\n",
        "          new_row = {'Year':row['Year'], 'Team':row['Team'], 'PTS_coeff':coeff}\n",
        "          opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "          opponent_adj_pts_coeff = opponent_adj_pts_coeff.append(new_row, ignore_index=True)\n",
        "\n",
        "  outfile = f\"opponent_adj_pts_coeff.csv\"\n",
        "  opponent_adj_pts_coeff.to_csv(outfile, index=False)\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outputting Cells**"
      ],
      "metadata": {
        "id": "fdjvCUzH819P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Single Playoffs Import\n",
        "#sing = pd.read_csv('/content/52-73_era_opponent_adjusted_per75_data.csv', index_col=False, encoding='utf8')\n",
        "#sing = sing.drop(['TeamColor', 'Pos', 'Age', 'GS', 'DRB', 'TRB', 'AST', 'STL', 'PF', 'FG', 'FGA', '3P', '3PA', 'TOV', '2P', '2PA', 'FG%', '3P%', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'BLK', 'Possessions','eFG%'], axis=1)\n",
        "\n",
        "#sing = era_opponent_adj_playoff_per_75_df.copy()\n",
        "#sing = sing.drop(['TeamColor', 'Pos', 'Age', 'GS', 'DRB', 'TRB', 'AST', 'STL', 'PF', 'ORtg', 'DRtg', 'FG', 'FGA', '3P', '3PA', 'TOV', '2P', '2PA', 'FG%', '3P%', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'BLK'], axis=1)\n",
        "\n",
        "sing = sing.rename(columns={\"Year\": \"Year\", \"Player\": \"Player\", \"Tm\": \"Team\", \"TS%+\": \"TS+\", \"PTS\": \"PP75\"})\n",
        "\n",
        "columns_titles = ['Year', 'Player', 'Team', 'PP75', 'TS+', 'MP', 'G']\n",
        "sing = sing.reindex(columns=columns_titles)\n",
        "\n",
        "sing['PP75'] = sing['PP75'].round(2)\n",
        "sing['TS+'] = sing['TS+'].round(2)\n",
        "sing['MP'] = sing['MP'].astype(int)\n",
        "\n",
        "sing = sing.sort_values(by = ['Player', 'Year'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "print(sing)\n",
        "sing.to_csv(\"Single_Playoffs_Adjusted_Scoring.csv\", index=False)\n",
        "\n",
        "\n",
        "#@title Single Playoffs Custom Dataframes\n",
        "#sing = era_opponent_adj_playoff_per_75_df.copy()\n",
        "sing = sing.drop(['TeamColor', 'Pos', 'Age', 'GS', 'DRB', 'TRB', 'AST', 'STL', 'PF', 'ORtg', 'DRtg', 'FG', 'FGA', '3P', '3PA', 'TOV', '2P', '2PA', 'FG%', '3P%', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'BLK'], axis=1)\n",
        "\n",
        "sing = sing.rename(columns={\"Year\": \"Year\", \"Player\": \"Player\", \"Tm\": \"Team\", \"TS%+\": \"TS+\", \"PTS\": \"PP75\"})\n",
        "\n",
        "sing = sing.sort_values(by = ['Player', 'Year'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "columns_titles = ['Year', 'Player', 'Team', 'PP75', 'TS+', 'MP', 'G']\n",
        "sing = sing.reindex(columns=columns_titles)\n",
        "\n",
        "sing['PP75'] = sing['PP75'].round(2)\n",
        "sing['TS+'] = sing['TS+'].round(2)\n",
        "\n",
        "sing['MP'] = sing['MP'].astype(int)\n",
        "sing['G'] = sing['G'].astype(int)\n",
        "\n",
        "sing = sing[(sing['MP'] >= 300)]\n",
        "sing = sing[(sing['PP75'] >= 30)]\n",
        "sing = sing[(sing['TS+'] >= 115)]\n",
        "\n",
        "sing = sing.sort_values(by = ['Year', 'Player'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "print(sing)\n",
        "sing.to_csv(\"Single_Playoffs_Adjusted_Scoring.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TeBHK4mouJzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Single Playoffs Custom Dataframes\n",
        "sing = pd.read_csv('/content/52-22_Single_Playoffs_Adjusted_Scoring.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "sing['MP'] = sing['MP'].astype(int)\n",
        "sing['G'] = sing['G'].astype(int)\n",
        "\n",
        "sing = sing[(sing['MP'] >= 300)]\n",
        "sing = sing[(sing['PP75'] >= 30)]\n",
        "sing = sing[(sing['TS+'] >= 115)]\n",
        "\n",
        "sing = sing.sort_values(by = ['Year', 'Player'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "print(sing)\n",
        "#sing.to_csv(\"Single_Playoffs_Adjusted_Scoring.csv\", index=False)"
      ],
      "metadata": {
        "id": "-FZKHrYKP9MP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Edit Text\n",
        "with open('/content/tmpurllist.txt', 'r') as f, open('better_format', 'w') as f1:\n",
        "  Lines = f.readlines()\n",
        "  \n",
        "  count = 0\n",
        "  # Strips the newline character\n",
        "  for line in Lines:\n",
        "    if \"Player\" in line:\n",
        "      continue\n",
        "    else:\n",
        "      new_line = re.sub('/pla', r',/pla', line)\n",
        "      print(new_line)\n",
        "    f1.write(new_line)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OppF_CK9sXic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_xOBKntCacv6"
      },
      "outputs": [],
      "source": [
        "#@title Scrape League Average TS% Since 1974 (not working)\n",
        "#@title Scrape NBA regular season advanced\n",
        "def scrape_nba_ts_data(years):\n",
        "\n",
        "    league_avg_ts_df = pd.DataFrame(columns = ['Year', 'TS%'])\n",
        "\n",
        "    for year in years:\n",
        "        league_stats_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\"\n",
        "        \n",
        "        wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "        wd.get(league_stats_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': '#content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': '#all_advanced_team'})\n",
        "          first_table = second_div.find('table', attrs={'id': '#advanced-team'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "        print(rows)\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        advanced_stats = [e for e in advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(advanced_stats)):\n",
        "             advanced_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        print(headers)\n",
        "\n",
        "        each_year = pd.DataFrame(advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        league_avg_ts_df = league_avg_ts_df.append(each_year)\n",
        "\n",
        "        # remove any Na\n",
        "        league_avg_ts_df = league_avg_ts_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(league_avg_ts_df.info)\n",
        "    league_avg_ts_df.to_csv(\"nba_player_since74_advanced_data.csv\", index=False)\n",
        "scrape_nba_ts_data(all_the_years)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NBA 1952-73 (estimated) DATA**"
      ],
      "metadata": {
        "id": "9DTh1HKJ2cGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scrape_team_estimated_playoff_pace_data(pre_possesson_data_seasons)\n",
        "#scrape_nba_player_pergame_data([pre_possesson_data_seasons])\n",
        "#scrape_nba_player_advanced_data([pre_possesson_data_seasons])\n",
        "#scrape_nba_player_pergame_data(pre_possesson_data_seasons)\n",
        "#scrape_nba_player_total_mp_data(pre_possesson_data_seasons)"
      ],
      "metadata": {
        "id": "XlhmwilWyuBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA 1952-73 Scrape Functions\n",
        "\n",
        "# Scrape NBA Teams' Playoff Pace (1952-73 [estimated])\n",
        "# Grab Team and Opponent Total stats to estimate pace of play for each NBA team from 1952-73\n",
        "def scrape_team_estimated_playoff_pace_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'Pace/G', 'ORtg', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/playoffs/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "\n",
        "        #Find table body of team stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-team'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year and pace column to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "             team_allowed_stats[i].insert(1, 0) \n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"Pace/G\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        each_years_teams = each_years_teams.sort_values('Team', ascending=True)\n",
        "\n",
        "        # estimate pace\n",
        "        if year >= 1971:\n",
        "          ORB_percent = 0.319\n",
        "        else:\n",
        "          ORB_percent = 0.303\n",
        "        if year >= 1971:\n",
        "          TOV_percent = 0.158\n",
        "        else:\n",
        "          TOV_percent = 0.161\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FG'] = each_years_teams['FG'].astype(float)\n",
        "        each_years_teams['G'] = each_years_teams['G'].astype(float)\n",
        "        each_years_teams['Pace/G'] = (each_years_teams['FGA'] + (0.4 * each_years_teams['FTA']) - ORB_percent * (each_years_teams['FGA'] - each_years_teams['FG']) + (-TOV_percent * (each_years_teams['FGA'] + 0.44 * each_years_teams['FTA']) / (TOV_percent - 1)))\n",
        "        each_years_teams['Ortg'] = (each_years_teams['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'], axis=1, inplace=True)\n",
        "\n",
        "        \n",
        "\n",
        "        #Find table body of opponent stats\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'switcher_per_game_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each row\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        def_rtg_df = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "        def_rtg_df = def_rtg_df.sort_values('Team', ascending=True)\n",
        "\n",
        "        def_rtg_df['PTS'] = def_rtg_df['PTS'].astype(float)\n",
        "        each_years_teams['Drtg'] = (def_rtg_df['PTS'] / each_years_teams['Pace/G']) * 100\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"NBA_Team_Estimated_Playoff_Pace_52-73_df.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season per game (1952-73)\n",
        "def scrape_nba_player_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = final_players_pergame_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"52-73_reg_pergame_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season advanced (1952-73)\n",
        "def scrape_nba_player_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        print(year)\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        time.sleep(5)\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_advanced_df = final_players_advanced_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"52-73_reg_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoff per game (1952-73)\n",
        "def scrape_nba_player_pergame_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        time.sleep(5)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = final_players_pergame_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"52-73_playoff_pergame_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoff totals (1952-73)\n",
        "def scrape_nba_player_total_mp_data(years):\n",
        "\n",
        "    final_players_pergame_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_totals.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        time.sleep(5)\n",
        "        time.sleep(5)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"PTS\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "             player_base_stats[i].insert(3, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        headers.insert(3, \"Possessions\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_pergame_df = final_players_pergame_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_pergame_df = final_players_pergame_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_pergame_df['Player'] = final_players_pergame_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_pergame_df = final_players_pergame_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_pergame_df.info)\n",
        "    final_players_pergame_df.to_csv(\"52-73_total_mp_playoff_data.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "s9oi73XB3Uru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA 1952-73 Ancillary Calculations\n",
        "\n",
        "# NBA 1952-73 Calculate reg per 75 and TS+\n",
        "pergame = pd.read_csv('52-73_reg_pergame_data.csv', encoding='utf8', index_col=False)\n",
        "pace_sup = pd.read_csv('abbrev_52-73 reg pace ortg drtg.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "pergame['PTS'] = pergame['PTS'].astype(float)\n",
        "pergame['MP'] = pergame['MP'].astype(float)\n",
        "pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "\n",
        "\n",
        "for idx, row in pergame.iterrows():\n",
        "  team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "  team_pace = team['Pace/G']\n",
        "  # changed team in middle of year. Two paces to account for.\n",
        "  if row['Tm'] == 'TOT':\n",
        "    print(row['Player'])\n",
        "    print(row['Year'])\n",
        "    continue\n",
        "  # team folded and didn't play for another team that season.\n",
        "  elif row['Tm'] == 'BLB' and row['Year'] == 1955:\n",
        "    continue\n",
        "  pergame.iat[idx, 31] = team_pace * (pergame.iat[idx, 9]/48)\n",
        "  pergame.iat[idx, 31] = pergame.iat[idx, 31].astype(float)\n",
        "  ind_poss_coeff = pergame.iat[idx, 31] / 75\n",
        "  pergame.iat[idx, 30] = pergame.iat[idx, 30]  / ind_poss_coeff\n",
        "pergame.to_csv(\"52-73_reg_per_75_data.csv\", index=False)\n",
        "\n",
        "# NBA 1952-73 Calculate playoff per 75 and TS+\n",
        "pergame = pd.read_csv('52-73_playoff_pergame_data.csv', encoding='utf8', index_col=False)\n",
        "pace_sup = pd.read_csv('Abbrev_Playoff_Pace_52-73.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "pergame['PTS'] = pergame['PTS'].astype(float)\n",
        "pergame['MP'] = pergame['MP'].astype(float)\n",
        "pace_sup['Pace/G'] = pace_sup['Pace/G'].astype(float)\n",
        "\n",
        "\n",
        "for idx, row in pergame.iterrows():\n",
        "  team = pace_sup[(pace_sup['Year'] == row['Year']) & (pace_sup['Team'] == row['Tm'])]\n",
        "  team_pace = team['Pace/G']\n",
        "  pergame.iat[idx, 31] = team_pace * (pergame.iat[idx, 9]/48)\n",
        "  pergame.iat[idx, 31] = pergame.iat[idx, 31].astype(float)\n",
        "  ind_poss_coeff = pergame.iat[idx, 31] / 75\n",
        "  pergame.iat[idx, 30] = pergame.iat[idx, 30]  / ind_poss_coeff\n",
        "pergame.to_csv(\"52-73_playoff_per_75_data.csv\", index=False)\n",
        "\n",
        "\n",
        "# Calculate average PTS per 75 (1952-73)\n",
        "# year by year find what the league average PTS per 75 possessions was. Each row (player)'s points scaled for minutes.\n",
        "avg_pts_per_75 = pd.read_csv('/content/52-73_reg_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "total_mp = 0\n",
        "running_pts_avg = []\n",
        "year_list = []\n",
        "final_df = pd.DataFrame()\n",
        "for year in pre_possesson_data_seasons:\n",
        "  year_list.append(year)\n",
        "  this_years_players = avg_pts_per_75[(avg_pts_per_75['Year']) == year]\n",
        "  this_years_players['MP'] = this_years_players['MP'].astype(float)\n",
        "  total_mp = this_years_players['MP'].sum()\n",
        "  this_years_players['AdjPts'] = (this_years_players['PTS'].astype(float)) * (this_years_players['MP'].astype(float) / total_mp)\n",
        "  running_pts_avg.append(this_years_players['AdjPts'].sum())\n",
        "\n",
        "final_df['Year'] = year_list\n",
        "final_df['Average PP75'] = running_pts_avg\n",
        "        \n",
        "final_df.to_csv(\"Avg_52-73_Reg_PP75.csv\", index=False)\n",
        "\n",
        "\n",
        "# Calculate average DefRtg (1952-73)\n",
        "# year by year find what the league average DefRtg was.\n",
        "avg_pts_per_75 = pd.read_csv('/content/abbrev_52-73 reg pace ortg drtg.csv', index_col=False, encoding='utf8')\n",
        "running_pts_avg = []\n",
        "year_list = []\n",
        "final_df = pd.DataFrame()\n",
        "for year in pre_possesson_data_seasons:\n",
        "  year_list.append(year)\n",
        "  this_years_players = avg_pts_per_75[(avg_pts_per_75['Year']) == year]\n",
        "  running_pts_avg.append(this_years_players['Drtg'].mean())\n",
        "\n",
        "final_df['Year'] = year_list\n",
        "final_df['Average DefRtg'] = running_pts_avg\n",
        "        \n",
        "final_df.to_csv(\"Avg_52-73_Reg_PP75.csv\", index=False)\n",
        "\n",
        "# Replace Per 75 'MPG' with total 'MP'\n",
        "per75 = pd.read_csv('52-73_playoff_per_75_data.csv', encoding='utf8', index_col=False)\n",
        "total_mp = pd.read_csv('52-73_total_mp_playoff_data.csv', encoding='utf8', index_col=False)\n",
        "\n",
        "\n",
        "per75['MP'] = total_mp['MP'].astype(int)\n",
        "per75.to_csv(\"52-73_playoff_per_75_data.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4KlWoPonuSwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ABA 1974-76 DATA**"
      ],
      "metadata": {
        "id": "HtCLgfbO4rpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scrape_aba_player_per100_data(aba_seasons)\n",
        "#scrape_aba_advanced_data(aba_seasons)\n",
        "#scrape_nba_player_per100_aba_data(aba_seasons)\n",
        "#scrape_team_ts_allowed_data(aba_seasons)\n",
        "#scrape_nba_player_reg_avg_per_100(aba_seasons)\n",
        "#scrape_team_defrtg_allowed_data(aba_seasons)\n",
        "#scrape_nba_player_avg_defrtg(aba_seasons)"
      ],
      "metadata": {
        "id": "YvT4wDHZ5Ihd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA 1974-76 Scrape Functions\n",
        "# Scrape ABA regular season per 100\n",
        "def scrape_aba_player_per100_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = final_players_per100_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"aba_player_since74_per100_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA regular season advanced\n",
        "def scrape_aba_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP'\n",
        "                                                        ])\n",
        "    for year in years:\n",
        "        player_advanced_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_advanced_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_advanced_stats = [e for e in player_advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_advanced_stats)):\n",
        "             player_advanced_stats[i].insert(0, year)\n",
        "             player_advanced_stats[i].insert(5, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(5, \"TeamColor\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_advanced_df = final_players_advanced_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "        #final_players_advanced_df['Player'] = final_players_advanced_df['Player'].apply(ast.literal_eval).str.decode(\"utf-8\")\n",
        "        #final_players_advanced_df['Player'] = unidecode(final_players_advanced_df['Player'])\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"aba_player_since74_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA playoffs per 100\n",
        "def scrape_nba_player_per100_aba_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = final_players_per100_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"nba_player_since74playoffs_per100_aba_data.csv\", index=False)\n",
        "\n",
        "# Scrape ABA Teams' TS% Allowed\n",
        "def scrape_team_ts_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team' 'TS% Allowed'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_totals_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'totals-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['TS% Allowed'] = each_years_teams['PTS'] / ( ( (each_years_teams['FTA'] * .44) + (each_years_teams['FGA']) ) * 2)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(aba_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"ABA_Team_TS_Percentage_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape ABA Reg Avg Per 75 Scoring\n",
        "def scrape_nba_player_reg_avg_per_100(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PP75'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = (each_year['PTS'].astype(float) * .75) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        new_row = {'Year':year, 'Average PP75':running_pts_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_ABA_Reg_PP75.csv\", index=False)\n",
        "\n",
        "# Scrape ABA Teams' DefRtg \n",
        "def scrape_team_defrtg_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(aba_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"ABA_Team_defrtg_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape ABA League Avg DefRtg\n",
        "def scrape_nba_player_avg_defrtg(years):\n",
        "\n",
        "  final_team_data_df = pd.DataFrame(columns = ['Year', 'Avg DefRtg'])\n",
        "    \n",
        "  for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/ABA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        avg_def_rtg = each_year['PTS'].mean()\n",
        "\n",
        "\n",
        "\n",
        "        new_row = {'Year':year, 'Avg DefRtg':avg_def_rtg}\n",
        "        final_team_data_df = final_team_data_df.append(new_row, ignore_index=True)\n",
        "        final_team_data_df['Year'] = final_team_data_df['Year'].astype(int)\n",
        "        print(new_row)\n",
        "        \n",
        "  # print final_df\n",
        "  final_team_data_df.to_csv(\"Avg_ABA_Def_Rtg.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0ybCHOcAfCBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ABA 1974-76 Ancillary Calculations\n",
        "\n",
        "# Calculate ABA reg per 75 points\n",
        "aba_per100_reg_df = pd.read_csv('/content/aba_player_since74_per100_data.csv')\n",
        "aba_per100_reg_df['PTS'] = aba_per100_reg_df['PTS'] * .75\n",
        "aba_advanced_reg_df = pd.read_csv('/content/aba_player_since74_advanced_data.csv')\n",
        "\n",
        "\n",
        "# Add ABA reg TS+\n",
        "# TS% from advanced dataframge (aba_advanced_reg_df.iat[j, 9]) divided by league average TS% (aba_league_avg.iat[yearloop, 1])\n",
        "i = 1976\n",
        "for yearloop in range(49):\n",
        "  for j, row in aba_per100_reg_df.iterrows():\n",
        "    if row['Year'] == i:\n",
        "      aba_per100_reg_df.iat[j, 1] = (aba_advanced_reg_df.iat[j, 9] / aba_league_avg.iat[yearloop, 1]) * 100\n",
        "  i = i - 1\n",
        "\n",
        "aba_per100_reg_df = aba_per100_reg_df[import_player_since74_per75_df['TS%+'].notna()]\n",
        "outfile = f\"aba_per75_reg_data.csv\"\n",
        "aba_per100_reg_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OIcwUzC7Swym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ylkdaUS_rxK"
      },
      "source": [
        "**NBA 1974-2022 DATA**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scrape_nba_player_reg_per100_data(possession_data_seasons)\n",
        "#scrape_nba_player_post_per100_data(possession_data_seasons)\n",
        "#scrape_nba_advanced_reg_data(possession_data_seasons)\n",
        "#scrape_nba_advanced_post_data(possession_data_seasons)\n",
        "#scrape_nba_reg_playbyplay_data(play_by_play_data_seasons)\n",
        "#scrape_nba_post_playbyplay_data(play_by_play_data_seasons)\n",
        "#scrape_nba_leaguestats_data(possession_data_seasons)\n",
        "#scrape_nba_player_reg_avg_per_75(possession_data_seasons)\n",
        "#scrape_nba_player_playoff_avg_per_75(possession_data_seasons)\n",
        "#scrape_nba_player_reg_bpm_avg(possession_data_seasons)\n",
        "#scrape_team_ts_allowed_data(all_the_years)\n",
        "#scrape_team_defrtg_allowed_data(all_the_years)\n",
        "#scrape_nba_player_avg_defrtg(all_the_years)"
      ],
      "metadata": {
        "id": "VUlmu6LP6eAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "28WIXVx2GuiM"
      },
      "outputs": [],
      "source": [
        "#@title NBA 1974-2022 Scrape Functions\n",
        "\n",
        "# Scrape NBA regular season per 100\n",
        "def scrape_nba_player_reg_per100_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = final_players_per100_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"nba_player_since74_per100_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoffs per 100\n",
        "def scrape_nba_player_post_per100_data(years):\n",
        "\n",
        "    final_players_per100_df = pd.DataFrame(columns = ['Year',  'TS%+', 'TeamColor', 'Player', 'Pos', 'Age', 'Tm', \n",
        "                                                    'G', 'GS', 'MP', 'FG', 'FGA', \n",
        "                                                    'FG%', '3P', '3PA', '3P%', '2P', \n",
        "                                                    '2PA', '2P%', 'FT', 'FTA', 'FT%', \n",
        "                                                    'ORB', 'DRB', 'TRB', 'AST', 'STL', \n",
        "                                                    'BLK', 'TOV', 'PF', 'PTS', \n",
        "                                                    'ORtg', 'DRtg']\n",
        "                                         )\n",
        "    for year in years:\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "             player_base_stats[i].insert(1, 0)\n",
        "             player_base_stats[i].insert(2, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(1, \"TS%+\")\n",
        "        headers.insert(2, \"TeamColor\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('', axis=1)\n",
        "        \n",
        "        # append to final df\n",
        "        final_players_per100_df = final_players_per100_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_per100_df = final_players_per100_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_per100_df['Player'] = final_players_per100_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_per100_df = final_players_per100_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_per100_df.info)\n",
        "    final_players_per100_df.to_csv(\"nba_player_since74playoffs_per100_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season advanced\n",
        "def scrape_nba_reg_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP'\n",
        "                                                        ])\n",
        "    for year in years:\n",
        "        player_advanced_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_advanced_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_advanced_stats = [e for e in player_advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_advanced_stats)):\n",
        "             player_advanced_stats[i].insert(0, year)\n",
        "             player_advanced_stats[i].insert(5, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(5, \"TeamColor\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_advanced_df = final_players_advanced_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "        #final_players_advanced_df['Player'] = final_players_advanced_df['Player'].apply(ast.literal_eval).str.decode(\"utf-8\")\n",
        "        #final_players_advanced_df['Player'] = unidecode(final_players_advanced_df['Player'])\n",
        "        final_players_advanced_df['Player'].apply(unidecode)\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"nba_player_since74_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoffs advanced\n",
        "def scrape_nba_post_advanced_data(years):\n",
        "\n",
        "    final_players_advanced_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age', \n",
        "                                                        'Tm', 'TeamColor', 'G', 'MP', 'PER', 'TS%', \n",
        "                                                        '3PAr', 'FTr', 'ORB%', 'DRB%', \n",
        "                                                        'TRB%', 'AST%', 'STL%', 'BLK%', \n",
        "                                                        'TOV%', 'USG%', 'OWS', 'DWS', \n",
        "                                                        'WS', 'WS/48', 'OBPM', 'DBPM', \n",
        "                                                        'BPM', 'VORP'\n",
        "                                                        ])\n",
        "    for year in years:\n",
        "        player_advanced_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_advanced_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_advanced_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_advanced_stats = [e for e in player_advanced_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_advanced_stats)):\n",
        "             player_advanced_stats[i].insert(0, year)\n",
        "             player_advanced_stats[i].insert(5, 0)\n",
        "        headers.insert(0, \"Year\")\n",
        "        headers.insert(5, \"TeamColor\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_advanced_stats, columns = headers)\n",
        "        \n",
        "        # remove blank columns\n",
        "        each_year = each_year.drop('\\xa0',axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_advanced_df = final_players_advanced_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_advanced_df = final_players_advanced_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_advanced_df['Player'] = final_players_advanced_df['Player'].str.replace(r\"[*]\", '')\n",
        "        #final_players_advanced_df['Player'] = final_players_advanced_df['Player'].apply(ast.literal_eval).str.decode(\"utf-8\")\n",
        "        #final_players_advanced_df['Player'] = unidecode(final_players_advanced_df['Player'])\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_advanced_df = final_players_advanced_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_advanced_df.info)\n",
        "    final_players_advanced_df.to_csv(\"nba_player_since74playoffs_advanced_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season play-by-play\n",
        "def scrape_nba_reg_playbyplay_data(years):\n",
        " \n",
        "    final_players_playbyplay_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age',\n",
        "                                                          'Tm', 'G', 'MP','OnCourt', 'On-Off', 'BadPass', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1'\n",
        "                                                         ])\n",
        "    \n",
        "    for year in years:\n",
        "        player_playbyplay_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        html = urlopen(player_playbyplay_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        # grab tr[1], as tr[0] is populated with categorical headers. Not headers for each columns of data (which are in tr[1])\n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"Blkd\")+1]\n",
        "\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_playbyplay_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_playbyplay_stats = [e for e in player_playbyplay_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_playbyplay_stats)):\n",
        "             player_playbyplay_stats[i].insert(0, year)   \n",
        "        headers.insert(0, \"Year\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_playbyplay_stats, columns = headers)\n",
        "\n",
        "        #rename some columns for less ambiguity\n",
        "        each_year.columns=['Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'MP','PG%', 'SG%', 'SF%', 'PF%', 'C%',\n",
        "                            'OnCourt', 'On-Off', 'BadPass', 'LostBall', 'ShootCommit', 'OffCommit', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1', 'Blkd']\n",
        "        # drop irrelevant columns\n",
        "        each_year = each_year.drop(['PG%', 'SG%', 'SF%', 'PF%', 'C%', 'LostBall', 'ShootCommit', 'OffCommit', 'Blkd'], axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_playbyplay_df['Player'] = final_players_playbyplay_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_playbyplay_df.info)\n",
        "    final_players_playbyplay_df.to_csv(\"nba_player_regular_playbyplay_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA playoffs play-by-play\n",
        "# import needed libraries\n",
        "def scrape_nba_post_playbyplay_data(years):\n",
        " \n",
        "    final_players_playbyplay_df = pd.DataFrame(columns = ['Year', 'Player', 'Pos', 'Age',\n",
        "                                                          'Tm', 'G', 'MP','OnCourt', 'On-Off', 'BadPass', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1'\n",
        "                                                         ])\n",
        "    \n",
        "    for year in years:\n",
        "        player_playbyplay_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        html = urlopen(player_playbyplay_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        # grab tr[1], as tr[0] is populated with categorical headers. Not headers for each columns of data (which are in tr[1])\n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"Blkd\")+1]\n",
        "\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_playbyplay_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_playbyplay_stats = [e for e in player_playbyplay_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_playbyplay_stats)):\n",
        "             player_playbyplay_stats[i].insert(0, year)   \n",
        "        headers.insert(0, \"Year\")\n",
        "\n",
        "        each_year = pd.DataFrame(player_playbyplay_stats, columns = headers)\n",
        "\n",
        "        #rename some columns for less ambiguity\n",
        "        each_year.columns=['Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'MP','PG%', 'SG%', 'SF%', 'PF%', 'C%',\n",
        "                            'OnCourt', 'On-Off', 'BadPass', 'LostBall', 'ShootCommit', 'OffCommit', 'ShootDrawn', 'OffDrawn', 'PGA', 'And1', 'Blkd']\n",
        "        # drop irrelevant columns\n",
        "        each_year = each_year.drop(['PG%', 'SG%', 'SF%', 'PF%', 'C%', 'LostBall', 'ShootCommit', 'OffCommit', 'Blkd'], axis=1)\n",
        "\n",
        "        # append dataframe\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.append(each_year)\n",
        "\n",
        "        # remove duplicate rows based on player being traded; first appearing row will be player's total between teams\n",
        "        # adding 'year' to subset prevents players' future seasons from being deleted.\n",
        "        # example: Avery Bradley was traded in 2019. Remove Avery Bradley rows from individual teams.\n",
        "        # Keep TOT row (total) but don't remove Avery Bradley's 2020 season as a duplicate\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.drop_duplicates(subset =['Player', 'Year'], keep=\"first\")\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        final_players_playbyplay_df['Player'] = final_players_playbyplay_df['Player'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        # remove any Na\n",
        "        final_players_playbyplay_df = final_players_playbyplay_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_players_playbyplay_df.info)\n",
        "    final_players_playbyplay_df.to_csv(\"nba_player_playoff_playbyplay_data.csv\", index=False)\n",
        "\n",
        "# Scrape NBA regular season league average\n",
        "def scrape_nba_leaguestats_data():\n",
        "\n",
        "        final_leaguestats_df = pd.DataFrame(columns = ['Year',\t'Lg',\t'Age',\t'Ht',\t'Wt',\t'G',\t'MP',\t'FG',\t'FGA',\t'3P',\n",
        "                                                      '3PA',\t'FT',\t'FTA',\t'ORB',\t'DRB',\t'TRB',\t'AST',\t'STL',\t'BLK',\t'TOV',\n",
        "                                                      'PF',\t'PTS',\t'FG%',\t'3P%',\t'FT%',\t'Pace',\t'eFG%',\t'TOV%',\t'ORB%',\n",
        "                                                      'FT/FGA',\t'ORtg', 'TS%'])\n",
        "        \n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_stats_per_game.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"ORtg\")+1]\n",
        "        headers.insert(32, \"TS%\")\n",
        "        print(headers)\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        #rows = soup.findAll('tr', class=None)[1:]\n",
        "        rows = soup.findAll('tr', class_=None)[1:]\n",
        "\n",
        "\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "          player_base_stats[i].insert(32, 0)\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        final_leaguestats_df = pd.DataFrame(player_base_stats, columns = headers)\n",
        "\n",
        "        final_leaguestats_df = final_leaguestats_df.drop(['Lg'], axis=1)\n",
        "\n",
        "        final_leaguestats_df = final_leaguestats_df.iloc[1: , :]\n",
        "\n",
        "        final_leaguestats_df.drop(final_leaguestats_df.index[20])\n",
        "        final_leaguestats_df.drop(final_leaguestats_df.index[21])\n",
        "        \n",
        "        # print final_df\n",
        "        print(final_leaguestats_df.info)\n",
        "        final_leaguestats_df.to_csv(\"nba_leaguestats_data.csv\", index=False)\n",
        "\n",
        "# Scrape Reg Avg Per 75 Scoring\n",
        "def scrape_nba_player_reg_avg_per_75(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PP75'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = (each_year['PTS'].astype(float) * .75) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        new_row = {'Year':year, 'Average PP75':running_pts_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_Reg_PP75.csv\", index=False)\n",
        "\n",
        "# Scrape Playoff Avg Per 75 Scoring\n",
        "def scrape_nba_player_playoff_avg_per_75(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average PP75'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_pts_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"DRtg\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['AdjPts'] = (each_year['PTS'].astype(float) * .75) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_pts_avg = each_year['AdjPts'].sum()\n",
        "        year = year.astype(int)\n",
        "        new_row = {'Year':year, 'Average PP75':running_pts_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_df.info)\n",
        "    final_df.to_csv(\"Avg_Playoff_PP75.csv\", index=False)\n",
        "\n",
        "# Scrape Reg Avg BPM\n",
        "def scrape_nba_player_reg_bpm_avg(years):\n",
        "\n",
        "    final_df = pd.DataFrame(columns = ['Year', 'Average BPM', 'Average OBPM'])\n",
        "    for year in years:\n",
        "        total_mp = 0\n",
        "        running_bpm_avg = 0\n",
        "        running_obpm_avg = 0\n",
        "        player_base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
        "        \n",
        "        html = urlopen(player_base_url)\n",
        "        soup = BeautifulSoup(html, features=\"lxml\")\n",
        "        \n",
        "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
        "        headers = headers[1:headers.index(\"VORP\")+1]\n",
        "\n",
        "        # grab rows (excluding first empty row 0)\n",
        "        rows = soup.findAll('tr')[1:]\n",
        "        player_base_stats = [[td.getText() for td in rows[i].findAll('td')]\n",
        "                    for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        player_base_stats = [e for e in player_base_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(player_base_stats)):\n",
        "             player_base_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(player_base_stats, columns = headers)\n",
        "        each_year = each_year[each_year['MP'] != '0']\n",
        "\n",
        "        each_year['BPM'] = each_year['BPM'].astype(float)\n",
        "        each_year['OBPM'] = each_year['OBPM'].astype(float)\n",
        "        each_year['MP'] = each_year['MP'].astype(float)\n",
        "\n",
        "        total_mp = each_year['MP'].sum()\n",
        "        each_year['adjBPM'] = each_year['BPM'].astype(float) * (each_year['MP'].astype(float) / total_mp)\n",
        "        each_year['adjOBPM'] = each_year['OBPM'].astype(float) * (each_year['MP'].astype(float) / total_mp)\n",
        "        running_bpm_avg = each_year['adjBPM'].sum()\n",
        "        running_obpm_avg = each_year['adjOBPM'].sum()\n",
        "\n",
        "        running_bpm_avg = running_bpm_avg + 1\n",
        "        running_obpm_avg = running_obpm_avg + 1\n",
        "\n",
        "\n",
        "        new_row = {'Year':year, 'Average BPM':running_bpm_avg, 'Average OBPM':running_obpm_avg}\n",
        "        final_df = final_df.append(new_row, ignore_index=True)\n",
        "        final_df['Year'] = final_df['Year'].astype(int)\n",
        "        \n",
        "    # print final_df\n",
        "    final_df.to_csv(\"Avg_Reg_BPM.csv\", index=False)\n",
        "\n",
        "# Scrape NBA Teams' TS% Allowed\n",
        "def scrape_team_ts_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team' 'TS% Allowed'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_totals_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'totals-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "        each_years_teams['FTA'] = each_years_teams['FTA'].astype(float)\n",
        "        each_years_teams['FGA'] = each_years_teams['FGA'].astype(float)\n",
        "        each_years_teams['TS% Allowed'] = each_years_teams['PTS'] / ( ( (each_years_teams['FTA'] * .44) + (each_years_teams['FGA']) ) * 2)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(team_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"NBA_Team_TS_Percentage_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape NBA Teams' DefRtg \n",
        "def scrape_team_defrtg_allowed_data(years):\n",
        " \n",
        "    final_team_data_df = pd.DataFrame(columns = ['Year', 'Team', 'DefRtg'])\n",
        "    \n",
        "    for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year) \n",
        "        headers.insert(0, \"Year\")\n",
        "        each_years_teams = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        # remove non-playoff teams\n",
        "        each_years_teams = each_years_teams[each_years_teams.Team.str.contains(\"\\*\", na=False)]\n",
        "\n",
        "        # add TS% allowed\n",
        "        each_years_teams['PTS'] = each_years_teams['PTS'].astype(float)\n",
        "\n",
        "\n",
        "        each_years_teams.drop(['G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF'], axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "\n",
        "        # remove apostrophes from name\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].str.replace(r\"[*]\", '')\n",
        "\n",
        "        each_years_teams['Team'] = each_years_teams['Team'].map(team_abbrev)\n",
        "\n",
        "        print(each_years_teams)\n",
        "\n",
        "        final_team_data_df = final_team_data_df.append(each_years_teams)\n",
        "        \n",
        "    # print final_df\n",
        "    print(final_team_data_df.info)\n",
        "    final_team_data_df.to_csv(\"NBA_Team_defrtg_Allowed_df.csv\", index=False)\n",
        "\n",
        "# Scrape League Avg DefRtg\n",
        "def scrape_nba_player_avg_defrtg(years):\n",
        "\n",
        "  final_team_data_df = pd.DataFrame(columns = ['Year', 'Avg DefRtg'])\n",
        "    \n",
        "  for year in years:\n",
        "\n",
        "        wd.get(f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\")          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        \n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_team-opponent'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss-opponent'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        # headers\n",
        "        headers = ['Team', 'G', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
        "                           '3PA',\t'3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%',\n",
        "                           'ORB',\t'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                           'PTS']\n",
        "        # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        team_allowed_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "        # remove empty rows\n",
        "        team_allowed_stats = [e for e in team_allowed_stats if e != []]\n",
        "\n",
        "        # add year to each player profile\n",
        "        for i in range(0, len(team_allowed_stats)):\n",
        "             team_allowed_stats[i].insert(0, year)\n",
        "        headers.insert(0, \"Year\")\n",
        "        \n",
        "\n",
        "        each_year = pd.DataFrame(team_allowed_stats, columns = headers)\n",
        "\n",
        "        each_year['PTS'] = each_year['PTS'].astype(float)\n",
        "        avg_def_rtg = each_year['PTS'].mean()\n",
        "\n",
        "\n",
        "\n",
        "        new_row = {'Year':year, 'Avg DefRtg':avg_def_rtg}\n",
        "        final_team_data_df = final_team_data_df.append(new_row, ignore_index=True)\n",
        "        final_team_data_df['Year'] = final_team_data_df['Year'].astype(int)\n",
        "        print(new_row)\n",
        "        \n",
        "  # print final_df\n",
        "  final_team_data_df.to_csv(\"Avg_Def_Rtg.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA 1974-2022 Ancillary Calculations\n",
        "\n",
        "# Calculate NBA reg per 75 points\n",
        "import_player_since74_per75_df = import_player_since74_per100_df.copy()\n",
        "import_player_since74_per75_df['PTS'] = import_player_since74_per75_df['PTS'] * .75\n",
        "\n",
        "# Add NBA reg TS+\n",
        "# TS% from advanced dataframge (import_player_since74_advanced_df.iat[j, 9]) divided by league average TS% (league_avg_df.iat[yearloop, 1])\n",
        "i = 2022\n",
        "for yearloop in range(49):\n",
        "  for j, row in import_player_since74_per75_df.iterrows():\n",
        "    if row['Year'] == i:\n",
        "      import_player_since74_per75_df.iat[j, 1] = (import_player_since74_advanced_df.iat[j, 9] / league_avg_df.iat[yearloop, 1]) * 100\n",
        "  i = i - 1\n",
        "\n",
        "import_player_since74_per75_df = import_player_since74_per75_df[import_player_since74_per75_df['TS%+'].notna()]\n",
        "outfile = f\"nba_player_since74_per75_data.csv\"\n",
        "import_player_since74_per75_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate Playoffs per 75\n",
        "#import_player_since74playoffs_per75_df = import_player_since74playoffs_per100_df.copy()\n",
        "#import_player_since74playoffs_per75_df['PTS'] = import_player_since74playoffs_per75_df['PTS'] * .75\n",
        "\n",
        "aba_per75_pts = pd.read_csv('/content/aba_player_since74playoffs_per100_data.csv')\n",
        "aba_per75_pts['PTS'] = aba_per75_pts['PTS'] * .75\n",
        "\n",
        "outfile = f\"aba_player_since74playoffs_per75_data.csv\"\n",
        "aba_per75_pts.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_ntucsSc6SDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPo3JH7bZmrN"
      },
      "source": [
        "**SCRAPE URL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape NBA Player URL's (1952-73)\n",
        "# import needed libraries\n",
        "def scrape_url_data_52_73(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_game.html\"\n",
        "        \n",
        "        wd.get(page_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(10)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_game_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_game_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = player_url_df.append(tmp_df)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_52-73_URL_data.csv\", index=False)\n",
        "scrape_url_data_52_73(pre_possesson_data_seasons)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Vj0vFAsXBecy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape ABA Player URL's (1974-76)\n",
        "# import needed libraries\n",
        "def scrape_url_data_aba(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/ABA_{year}_per_poss.html\"\n",
        "        \n",
        "        wd.get(page_url)       \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(15)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = player_url_df.append(tmp_df)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_aba_URL_data.csv\", index=False)\n",
        "scrape_url_data_aba([1974, 1975, 1976])"
      ],
      "metadata": {
        "id": "tl9YBqUF8T4H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gxLh3jVuAZe4"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA Player URL's (1974-2022)\n",
        "# import needed libraries\n",
        "def scrape_url_data_74(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_per_poss.html\"\n",
        "        \n",
        "        wd.get(page_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(15)\n",
        "        print(year)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_per_poss_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'per_poss_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = player_url_df.append(tmp_df)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_since_74_URL_data.csv\", index=False)\n",
        "scrape_url_data_74(all_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1BJWc9nsob9K"
      },
      "outputs": [],
      "source": [
        "#@title Scrape NBA Player URL's (1997-2022)\n",
        "# import needed libraries\n",
        "def scrape_url_data_97(years):\n",
        " \n",
        "    player_url_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "    \n",
        "    for year in years:\n",
        "        print(year)\n",
        "        page_url = f\"https://www.basketball-reference.com/playoffs/NBA_{year}_play-by-play.html\"\n",
        "        \n",
        "        wd.get(page_url)          \n",
        "        html = wd.page_source\n",
        "        soup = BeautifulSoup(html)\n",
        "        time.sleep(15)\n",
        "\n",
        "        for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'all_pbp_stats'})\n",
        "          first_table = second_div.find('table', attrs={'id': 'pbp_stats'})\n",
        "          body = first_table.find('tbody')\n",
        "\n",
        "        rows = body.find_all('tr', attrs={'class': 'full_table'})\n",
        "\n",
        "        tmp_player_name_data = [[td.getText() for td in rows[i].findAll('td', attrs={'class': 'left'})]\n",
        "                    for i in range(len(rows))]\n",
        "        player_name_data = []\n",
        "        for i in tmp_player_name_data:\n",
        "          tmp = [j for j in i if len(j) >= 4]\n",
        "          player_name_data = player_name_data + tmp\n",
        "\n",
        "        # remove empty rows\n",
        "        player_name_data = [e for e in player_name_data if e != []]\n",
        "\n",
        "        player_url_data = [link.get('href') for link in body.findAll('a')]\n",
        "\n",
        "        player_url_data = [i for i in player_url_data if not ('teams' in i)]\n",
        "\n",
        "        tmp_df = pd.DataFrame(columns = ['Player', 'URL'])\n",
        "        for i, j in zip(player_name_data, player_url_data):\n",
        "            first = pd.DataFrame([[i, j]], columns =['Player', 'URL'])\n",
        "            tmp_df = tmp_df.append(first)\n",
        "\n",
        "        # remove apostrophes from name\n",
        "        tmp_df['Player'] = tmp_df['Player'].astype(str).str.replace(r\"[*]\", '')\n",
        "\n",
        "        player_url_df = player_url_df.append(tmp_df)\n",
        "\n",
        "    # remove duplicate rows based on player being traded\n",
        "    player_url_df = player_url_df.drop_duplicates(subset = ['Player', 'URL'], keep=\"first\")\n",
        "\n",
        "    # remove any Na\n",
        "    player_url_df = player_url_df.dropna()\n",
        "        \n",
        "    # print final_df\n",
        "    print(player_url_df.info)\n",
        "    player_url_df.to_csv(\"nba_player_URL_data.csv\", index=False)\n",
        "scrape_all_distribution_data(some_of_the_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4yATMvO-BkTW"
      },
      "outputs": [],
      "source": [
        "#@title Shorten URL list to only players with >x playoff minutes\n",
        "def nba_shorten_url_list_by_x(url_df, min_requirement):\n",
        "\n",
        "    new_df = pd.DataFrame(columns = ['Player', 'URL', 'MP'])\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      og_url = url\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      \n",
        "\n",
        "      wd.get(url)          \n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "      time.sleep(5)\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_advanced-playoffs_advanced'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs_advanced'})\n",
        "        foot = first_table.find('tfoot')\n",
        "\n",
        "      rows = foot.find('tr')\n",
        "      only_for_mp = [[td.getText() for td in rows.findAll('td')]]\n",
        "\n",
        "      # remove empty rows\n",
        "      only_for_mp = [e for e in only_for_mp if e != []]\n",
        "\n",
        "      url_data = pd.DataFrame(only_for_mp)\n",
        "\n",
        "      tmp_df = pd.DataFrame(columns = ['Player', 'URL', 'MP'])\n",
        "      \n",
        "\n",
        "      # took only long mid range FGA\n",
        "      if int(url_data[5]) <= min_requirement:\n",
        "        continue\n",
        "      else:\n",
        "        mp = int(url_data[5])\n",
        "\n",
        "      tmp_df.loc[len(tmp_df)] = [player, og_url, mp]\n",
        "      new_df = new_df.append(tmp_df)\n",
        "      outfile = f\"NBA_Player_97_URL_List_{min_requirement}_Min_df.csv\"\n",
        "      new_df.to_csv(outfile, index=False)\n",
        "      print(tmp_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLzLiVsSJUU2"
      },
      "outputs": [],
      "source": [
        "player_urls = pd.read_csv('/content/donny boy.csv', index_col=False, encoding='utf8')\n",
        "nba_shorten_url_list_by_x(player_urls, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NBA 1952-73 ADJUSTED PLAYOFF TS+ (Opponent Adjustment)**"
      ],
      "metadata": {
        "id": "UGB9Dqwm8Srb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NBA 1952-73 Adjusted Playoff TS+\n",
        "def adjust_scoring_efficiency(url_df, tmp_league_avg_df, opp_defrtg_df, rr_df):\n",
        "    from itertools import chain\n",
        "\n",
        "    tmp_league_avg_df['Year'] = tmp_league_avg_df['Year'].astype(int)\n",
        "    tmp_league_avg_df['Year'] = tmp_league_avg_df['Year'].astype(str)\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'TS+', 'PTS_coeff', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      time.sleep(5)\n",
        "      print(player)\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        header = first_table.find('thead')\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      headers = [th.getText() for th in header.findAll('tr', limit=2)[1].findAll('th')]\n",
        "      try:\n",
        "        headers[32] = 'MP/G'\n",
        "        headers[33] = 'PTS/G'\n",
        "         # grab rows\n",
        "        rows = body.findAll('tr')[0:]\n",
        "        series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "        # remove empty rows\n",
        "        series_stats = [e for e in series_stats if e != []]\n",
        "        series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        missing_mp_data = series_data.copy()\n",
        "        missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      except:\n",
        "        try:\n",
        "          headers[31] = 'MP/G'\n",
        "          headers[32] = 'PTS/G'\n",
        "          # grab rows\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "          # remove empty rows\n",
        "          series_stats = [e for e in series_stats if e != []]\n",
        "          series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          missing_mp_data = series_data.copy()\n",
        "          missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "        except:\n",
        "          try:\n",
        "            headers[30] = 'MP/G'\n",
        "            headers[31] = 'PTS/G'\n",
        "            # grab rows\n",
        "            rows = body.findAll('tr')[0:]\n",
        "            series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "            # remove empty rows\n",
        "            series_stats = [e for e in series_stats if e != []]\n",
        "            series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            missing_mp_data = series_data.copy()\n",
        "            missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "          except:\n",
        "            try:\n",
        "              headers[29] = 'MP/G'\n",
        "              headers[30] = 'PTS/G'\n",
        "              # grab rows\n",
        "              rows = body.findAll('tr')[0:]\n",
        "              series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "              # remove empty rows\n",
        "              series_stats = [e for e in series_stats if e != []]\n",
        "              series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "              series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "              missing_mp_data = series_data.copy()\n",
        "              missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "            except:\n",
        "              try:\n",
        "                headers[27] = 'MP/G'\n",
        "                headers[28] = 'PTS/G'\n",
        "                # grab rows\n",
        "                rows = body.findAll('tr')[0:]\n",
        "                series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "                # remove empty rows\n",
        "                series_stats = [e for e in series_stats if e != []]\n",
        "                series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "                series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "                missing_mp_data = series_data.copy()\n",
        "                missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "              except:\n",
        "                try:\n",
        "                  headers[24] = 'MP/G'\n",
        "                  headers[25] = 'PTS/G'\n",
        "                  # grab rows\n",
        "                  rows = body.findAll('tr')[0:]\n",
        "                  series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "                  # remove empty rows\n",
        "                  series_stats = [e for e in series_stats if e != []]\n",
        "                  series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "                  series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "                  missing_mp_data = series_data.copy()\n",
        "                  missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "                except:\n",
        "                  headers[19] = 'MP/G'\n",
        "                  headers[20] = 'PTS/G'\n",
        "                  # grab rows\n",
        "                  rows = body.findAll('tr')[0:]\n",
        "                  series_stats = [[td.getText() for td in rows[i].findAll(['td','th'])] for i in range(len(rows))]\n",
        "                  # remove empty rows\n",
        "                  series_stats = [e for e in series_stats if e != []]\n",
        "                  series_stats = ([i for i in series_stats if i[0] != 'Year'])\n",
        "                  series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "                  missing_mp_data = series_data.copy()\n",
        "                  missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      \n",
        "      # drop seasons which have definite possession data (as opposed to estimated data being generated)\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1992\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1991\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1990\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1989\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1988\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1987\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1986\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1985\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1984\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1983\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1982\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1981\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1980\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1979\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1978\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1977\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1976\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1975\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1974\", float('NaN'))\n",
        "\n",
        "      # remove seasons preceding 1952\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1951\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1950\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1949\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1948\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1947\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1946\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1945\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1944\", float('NaN'))\n",
        "\n",
        "      # convert ABA seasons to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SSL\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"VIR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SAA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"INA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"UTS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"KEN\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"CAR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))    \n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "      series_data = series_data.reset_index()\n",
        "\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['G'] = series_data['G'].astype(float)\n",
        "\n",
        "      \n",
        "      # may be missing MP data.\n",
        "      # divide the missing estimated total numbers equally among games w/o MP data.\n",
        "      missing_mp_data = series_data.copy()\n",
        "      missing_mp_data = missing_mp_data[(missing_mp_data['MP'] == '')]\n",
        "      years_list = []\n",
        "      \n",
        "      remaining_mp = []\n",
        "      missing_index = 0\n",
        "      \n",
        "      \n",
        "      for mp_idx, row in missing_mp_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_mp_data.loc[mp_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which MP aren't accounted for\n",
        "          working_missing_year = missing_mp_data[(missing_mp_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # MP accounted for \n",
        "          accounted_for_mp = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_mp['MP'] = accounted_for_mp['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_mp.dropna(inplace=True)\n",
        "          accounted_for_mp = (accounted_for_mp['MP'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total MP\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x <= 1973 and x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "\n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_mp = selected_year['MP'].astype(float)\n",
        "          \n",
        "\n",
        "          # remaining MP contains estimated MP for this year's series with missing MP\n",
        "          remaining_mp.append(total_mp - accounted_for_mp)\n",
        "\n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            idx = int(idx)\n",
        "            if working_missing_year.shape[0]  == 1:\n",
        "              series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index])\n",
        "            elif working_missing_year.shape[0]  == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0]  == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"MP\"] ] = float(remaining_mp[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      # may be missing FGA data.\n",
        "      # divide the missing estimated total numbers equally among games w/o FGA data.\n",
        "      missing_fg_data = series_data.copy()\n",
        "      missing_fg_data = missing_fg_data[(missing_fg_data['FGA'] == '')]\n",
        "      years_list = []\n",
        "      remaining_fg = []\n",
        "      missing_index = 0\n",
        "\n",
        "      for fg_idx, row in missing_fg_data.iterrows():\n",
        "\n",
        "        g_list = []\n",
        "        current_year = missing_fg_data.loc[fg_idx,'Year']\n",
        "        i_list = []\n",
        "\n",
        "        lookadead_working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "        for lk_idx, row in lookadead_working_missing_year.iterrows():\n",
        "          i_list.append(lk_idx)\n",
        "        if current_year not in years_list:\n",
        "\n",
        "          # games in which FGA aren't accounted for \n",
        "          working_missing_year = missing_fg_data[(missing_fg_data['Year'] == current_year)]\n",
        "          working_missing_year = working_missing_year.reset_index()\n",
        "          if working_missing_year.shape[0] == 2:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "          if working_missing_year.shape[0]  == 3:\n",
        "            g_list.append(working_missing_year.loc[0,'G'])\n",
        "            g_list.append(working_missing_year.loc[1,'G'])\n",
        "            g_list.append(working_missing_year.loc[2,'G'])\n",
        "\n",
        "          # FGA accounted for \n",
        "          accounted_for_fg = series_data[(series_data['Year'] == current_year)]\n",
        "          accounted_for_fg['FGA'] = accounted_for_fg['FGA'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "          accounted_for_fg.dropna(inplace=True)\n",
        "          accounted_for_fg = (accounted_for_fg['FGA'].astype(float)).sum()\n",
        "\n",
        "          years_list.append(current_year)\n",
        "\n",
        "          # scrape total FGA\n",
        "          for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'switcher_totals-playoffs_totals'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'playoffs_totals'})\n",
        "            header = first_table.find('thead')\n",
        "            body = first_table.find('tbody')\n",
        "\n",
        "          headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "\n",
        "          # grab years\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_years = [[th.getText() for th in rows[i].findAll('th')] for i in range(len(rows))]\n",
        "          player_years = [e for e in player_years if e != []]\n",
        "          from itertools import chain\n",
        "          player_years = list(chain.from_iterable(player_years))\n",
        "          formatted_years = []\n",
        "          for formatted_year in player_years:\n",
        "            formatted_year = re.sub(r\"[0-9]+-\", r\"19\", formatted_year)\n",
        "            formatted_years.append(formatted_year)\n",
        "          formatted_years = [eval(i) for i in formatted_years]\n",
        "          formatted_years = [x for x in formatted_years if x <= 1973 and x >= 1952]\n",
        "\n",
        "          # grab total stats\n",
        "          rows = body.findAll('tr')[0:]\n",
        "          player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "          player_total_stats = [e for e in player_total_stats if e != []]\n",
        "          player_total_stats = ([i for i in player_total_stats if i[6] != ''])\n",
        "\n",
        "          iteration = 0\n",
        "          # add year to each player profile\n",
        "          for i in range(0, len(formatted_years)):\n",
        "              player_total_stats[i].insert(0, formatted_years[iteration])\n",
        "              iteration = iteration + 1\n",
        "          headers[0] = 'Year'\n",
        "          \n",
        "          each_year = pd.DataFrame(player_total_stats, columns = headers)\n",
        "          each_year['Year'] = each_year['Year'].astype(str)\n",
        "          selected_year = each_year[(each_year['Year'] == current_year)]\n",
        "          total_fg = selected_year['FGA'].astype(float)\n",
        "          selected_year['Tm'] = selected_year['Tm'].astype(str)\n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          # remaining FGA contains estimated FGA for this year's series with missing FGA\n",
        "          remaining_fg.append(total_fg - accounted_for_fg)\n",
        "          \n",
        "          through = 0\n",
        "          for idx in i_list:\n",
        "            if working_missing_year.shape[0] == 1:\n",
        "              series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index])\n",
        "            elif working_missing_year.shape[0] == 2:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]))\n",
        "            elif working_missing_year.shape[0] == 3:\n",
        "              if through == 0:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[0] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              elif through == 1:\n",
        "                series_data.loc[idx, [\"FGA\"] ] = float(remaining_fg[missing_index]) * (g_list[1] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "              else:\n",
        "                series_data['FGA'].iat[idx] = float(remaining_fg[missing_index]) * (g_list[2] / (g_list[0] + g_list[1]+ g_list[2]))\n",
        "                through = through + 1\n",
        "          missing_index = missing_index + 1\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      series_data['TS+'] = 0\n",
        "      years_list = []\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "\n",
        "        # get defrtg allowed by opponent\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        this_year = tmp_league_avg_df[(tmp_league_avg_df['Year'] == current_year)]\n",
        "        league_avg_ts_this_year = this_year['TS%']\n",
        "\n",
        "        league_avg_ts_this_year = float(league_avg_ts_this_year)\n",
        "\n",
        "        # estimate TS+ allowed\n",
        "        predicted_TS_plus_allowed = lr.predict([[pts_coeff]])\n",
        "\n",
        "        #find raw TS% compared to league average\n",
        "        raw_ts_allowed = league_avg_ts_this_year * predicted_TS_plus_allowed\n",
        "\n",
        "        if row['PTS'] == 0:\n",
        "          tsplus = 0\n",
        "        else:\n",
        "          tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(raw_ts_allowed)) * 100\n",
        "        series_data.loc[i,'TS+'] = tsplus\n",
        "        series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "        if series_data.loc[i,'Year'] not in years_list:\n",
        "          years_list.append(series_data.loc[i,'Year'])\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'FGA', 'FTA', 'PTS', 'MPG'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = series_data[(series_data['Year'] == year)]\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "        new_row = {'Player':player, 'Year':year, 'TS+':total_ts, 'PTS_coeff':total_coeff, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "      outfile = f\"NBA_Playoff_Estimated_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)\n",
        "    print(final_season_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Zp1fwXJViD1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Adjusted Playoff TS+ Scrape\n",
        "\n",
        "# correlation will be used to estimate TS%'s allowed by teams from 1952-1973\n",
        "rdRtg = pd.read_csv(\"/content/remove reg teams.csv\", index_col=False, encoding='utf8')\n",
        "rTS = pd.read_csv(\"/content/NBA_Team_TS_Percentage_Allowed_df.csv\", index_col=False, encoding='utf8')\n",
        "\n",
        "rTS['Year'] = rTS['Year'].astype(int)\n",
        "league_avg_df['Year'] = league_avg_df['Year'].astype(float)\n",
        "\n",
        "rTS['rTS'] = 0\n",
        "\n",
        "for idx, row in rTS.iterrows():     \n",
        "          match_df = league_avg_df[(league_avg_df['Year'] == row['Year'])]\n",
        "          rTS.iat[idx, 3] = float(rTS.iat[idx, 2] / (match_df['TS%']))\n",
        "          \n",
        "rTS = rTS.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "rdRtg = rdRtg.sort_values(by = ['Year', 'Team'], ascending = [True, True], na_position = 'first')\n",
        "\n",
        "import scipy.stats\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as r2\n",
        "x_pred = rdRtg['PTS_coeff']\n",
        "x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "y_pred = rTS['rTS']\n",
        "\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(x_pred, y_pred)\n",
        "pred = lr.predict(x_pred)\n",
        "#plt.plot(x_pred, pred, color=\"blue\", linewidth=3)\n",
        "#plt.scatter(rdRtg['PTS_coeff'], rTS['rTS'])\n",
        "\n",
        "# Run Adjusted Playoff TS+ Scrape\n",
        "url_txt_df = pd.read_csv('/content/problematic.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "rr_df = pd.read_csv('/content/RR_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "adjust_scoring_efficiency(url_txt_df, league_avg_df, opponent_adj_pts_coeff, rr_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N80qT1UsMUn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create DataFrame of Adjusted TS+ Data and Adjust for Era\n",
        "start_to_ajust_playoffs_per_75 = pd.read_csv('/content/52-73_playoff_per_75_data.csv', index_col=False, encoding='utf8')\n",
        "adj_ts_list = pd.read_csv('NBA_Playoff_Estimated_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "names = [x for x in start_to_ajust_playoffs_per_75.columns]\n",
        "adjusted_playoff_per_75_df = pd.DataFrame(columns=names)\n",
        "\n",
        "for outer_index, adj_player_season in adj_ts_list.iterrows():\n",
        "\n",
        "  adj_player_season['Player'] = str(adj_player_season['Player'])\n",
        "  adj_player_season['Year'] = str(adj_player_season['Year'])\n",
        "  start_to_ajust_playoffs_per_75['Player'] = start_to_ajust_playoffs_per_75['Player'].astype(str)\n",
        "  start_to_ajust_playoffs_per_75['Year'] = start_to_ajust_playoffs_per_75['Year'].astype(str)\n",
        "\n",
        "  current_player = adj_player_season.loc['Player']\n",
        "  current_year = adj_player_season.loc['Year']\n",
        "  smaller_start_adj_list = start_to_ajust_playoffs_per_75[(start_to_ajust_playoffs_per_75['Player'] == current_player) & ((start_to_ajust_playoffs_per_75['Year'] == current_year))]\n",
        "  smaller_start_adj_list['TS%+'] = adj_player_season['TS+']\n",
        "  smaller_start_adj_list['PTS'] = smaller_start_adj_list['PTS'] * adj_player_season['PTS_coeff']\n",
        "  adjusted_playoff_per_75_df = adjusted_playoff_per_75_df.append(smaller_start_adj_list, ignore_index=True)\n",
        "outfile = f\"since52_adj_ts_playoffs_per75_data.csv\"\n",
        "adjusted_playoff_per_75_df.to_csv(outfile, index=False)\n",
        "\n",
        "# Era Adjustment\n",
        "playoff_75_data = pd.read_csv('since52_adj_ts_playoffs_per75_data.csv')\n",
        "\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in playoff_75_data.iterrows():\n",
        "  era_adj = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PTS'] = float(row['PTS']) * float(era_adj['Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"52-73_era_opponent_adjusted_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lj225Dkh9LzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Remove round robin data\n",
        "       # remove round robin data\n",
        "          if current_year == '1954':\n",
        "            remove_rr_url = url + \"/gamelog/1954\"\n",
        "            time.sleep(5)\n",
        "            wd.get(remove_rr_url)\n",
        "            html = wd.page_source\n",
        "            soup = BeautifulSoup(html)\n",
        "            rr_df\n",
        "            selected_year = selected_year.sort_index(inplace=True)\n",
        "            rr_df = rr_df.sort_index(inplace=True)\n",
        "            print(selected_year['Tm'])\n",
        "\n",
        "            rr_df['Team'] = rr_df['Team'].astype(str)\n",
        "\n",
        "            selected_rr = rr_df[(rr_df['Team'] == selected_year['Tm'])]\n",
        "            rr_games = selected_rr['G']\n",
        "\n",
        "            # scrape Playoff shooting distribution data\n",
        "            for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "              second_div = first_div.find('div', attrs={'id': 'div_pgl_basic_playoffs'})\n",
        "              first_table = second_div.find('table', attrs={'id': 'pgl_basic_playoffs'})\n",
        "              header = first_table.find('thead')\n",
        "              body = first_table.find('tbody')\n",
        "            headers = [th.getText() for th in header.findAll('tr', limit=2)[0].findAll('th')]\n",
        "            print(headers)\n",
        "\n",
        "            # grab total stats\n",
        "            rows = body.findAll('tr')[0:]\n",
        "            player_total_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "            player_total_stats = [e for e in player_total_stats if e != []]\n",
        "            #if player_total_stats[0, ]\n",
        "            print(player_total_stats)\n",
        "            print(total_fg)\n",
        "            total_fg = total_fg - (total_fg * (selected_year['G'] - rr_games))\n",
        "            print(total_fg)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0eOsSzoYechU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhL-arWPFvb8"
      },
      "source": [
        "**NBA 1974-2022/ABA 1974-76 ADJUSTED PLAYOFF TS+ (Opponent Adjustment)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5D3qCAUcglZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title NBA 1974-2022/ABA 1974-76 Adjusted Playoff TS+\n",
        "def adjust_scoring_efficiency(url_df, opp_ts_df, opp_defrtg_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'TS+', 'PTS_coeff', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      time.sleep(15)\n",
        "      print(player)\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      # grab rows\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "\n",
        "      # post 3PA\n",
        "      try:\n",
        "        headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                  'G',\t'W', 'L',\t'MP', 'FG', 'FGA', '3P', '3PA', 'FT', \n",
        "                  'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                  'PTS', 'dum2', 'FG%', '3P%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                          'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                          'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                          'FG%', '3P%', 'FT%', 'dum3', 'PTS/G', 'TRB/G', 'AST/G'], axis=1)\n",
        "      except:\n",
        "        # post TOV pre 3PA\n",
        "        try:\n",
        "          headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                    'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                    'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                    'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                            'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                            'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                            'FG%', '3P%', 'FT%', 'dum3', 'PTS/G', 'TRB/G', 'AST/G'], axis=1)\n",
        "        # pre TOV and pre 3PA\n",
        "        except:\n",
        "          try:\n",
        "            headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                      'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                      'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'PF',\n",
        "                      'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']  \n",
        "\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                              'G',\t'W', 'L', 'FG', 'FT', 'ORB', \n",
        "                              'TRB',\t'AST', 'STL', 'BLK', 'PF', 'dum2',\n",
        "                              'FG%', 'FT%', 'dum3', 'PTS/G', 'TRB/G', 'AST/G'], axis=1)\n",
        "          # post TOV and pre 3PA \n",
        "          except:\n",
        "            headers = [th.getText() for th in first_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            headers = headers[1:]\n",
        "            headers[2] = 'Year'\n",
        "            headers[27] = 'MP/G'\n",
        "            headers[28] = 'PTS/G'\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      \n",
        "\n",
        "      # convert certain seasons and ABA teams to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1960\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1961\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1962\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1963\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1964\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1965\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1966\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1967\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1968\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1969\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1970\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1971\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1972\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1973\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data['MP'] = series_data['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "\n",
        "      # add TS% allowed\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "\n",
        "\n",
        "      years_list = []\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "\n",
        "        # get ts% allowed by opponent\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & ((opp_ts_df['Year'] == current_year))]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        # get defrtg allowed by opponent\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "        \n",
        "        if row['PTS'] == 0:\n",
        "          tsplus = 0\n",
        "        else:\n",
        "          tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        series_data.loc[i,'TS+'] = tsplus\n",
        "        series_data.loc[i, 'PTS_coeff'] = pts_coeff\n",
        "        if series_data.loc[i,'Year'] not in years_list:\n",
        "          years_list.append(series_data.loc[i,'Year'])\n",
        "      \n",
        "      #series_data['TS+'] = (float(series_data['PTS']) / ( ( (float(series_data['FTA']) * .44) + (float(series_data['FGA'])) ) * 2)) / \n",
        "\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'FGA', 'FTA', 'PTS', 'MPG'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = series_data[(series_data['Year'] == year)]\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "          \n",
        "        \n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "\n",
        "\n",
        "        new_row = {'Player':player, 'Year':year, 'TS+':total_ts, 'PTS_coeff':total_coeff, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "      outfile = f\"NBA_Playoff_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)\n",
        "    print(final_season_df)\n",
        "    #outfile = f\"NBA_Playoff_Adjusted_TS_df.csv\"\n",
        "    #final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPP2QwEUVAKq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run Adjusted Playoff TS+ Scrape\n",
        "team_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = pd.read_csv('', index_col=False, encoding='utf8')\n",
        "url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "adjust_scoring_efficiency(url_txt_df, team_ts_allowed_df, opponent_adj_pts_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uavrTm3rmdeb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Create DataFrame of Adjusted TS+ Data and Adjust for Era\n",
        "\n",
        "# NBA\n",
        "start_to_ajust_playoffs_per_75 = pd.read_csv('/content/nba_player_since74playoffs_per75_data.csv', index_col=False, encoding='utf8')\n",
        "adj_ts_list = pd.read_csv('/content/NBA_Playoff_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "# ABA\n",
        "#start_to_ajust_playoffs_per_75 = pd.read_csv('/content/aba_player_since74playoffs_per75_data.csv', index_col=False, encoding='utf8')\n",
        "#adj_ts_list = pd.read_csv('/content/ABA_Playoff_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "names = [x for x in start_to_ajust_playoffs_per_75.columns]\n",
        "adjusted_playoff_per_75_df = pd.DataFrame(columns=names)\n",
        "\n",
        "for outer_index, adj_player_season in adj_ts_list.iterrows():\n",
        "\n",
        "  adj_player_season['Player'] = str(adj_player_season['Player'])\n",
        "  adj_player_season['Year'] = str(adj_player_season['Year'])\n",
        "  start_to_ajust_playoffs_per_75['Player'] = start_to_ajust_playoffs_per_75['Player'].astype(str)\n",
        "  start_to_ajust_playoffs_per_75['Year'] = start_to_ajust_playoffs_per_75['Year'].astype(str)\n",
        "\n",
        "  current_player = adj_player_season.loc['Player']\n",
        "  current_year = adj_player_season.loc['Year']\n",
        "  smaller_start_adj_list = start_to_ajust_playoffs_per_75[(start_to_ajust_playoffs_per_75['Player'] == current_player) & ((start_to_ajust_playoffs_per_75['Year'] == current_year))]\n",
        "  smaller_start_adj_list['TS%+'] = adj_player_season['TS+']\n",
        "  smaller_start_adj_list['PTS'] = smaller_start_adj_list['PTS'] * adj_player_season['PTS_coeff']\n",
        "  adjusted_playoff_per_75_df = adjusted_playoff_per_75_df.append(smaller_start_adj_list, ignore_index=True)\n",
        "print(adjusted_playoff_per_75_df)\n",
        "outfile = f\"since74_adj_ts_playoffs_per75_data.csv\"\n",
        "adjusted_playoff_per_75_df.to_csv(outfile, index=False)\n",
        "\n",
        "# Era Adjustment\n",
        "playoff_75_data = pd.read_csv('/content/52-73_reg_per_75_data.csv')\n",
        "\n",
        "per_75_coeff = pd.read_csv('/content/Avg_Reg_PP75.csv', index_col=False, encoding='utf8')\n",
        "per_75_coeff['Coefficient'] = per_75_coeff['Average PP75'].max() / per_75_coeff['Average PP75']\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in playoff_75_data.iterrows():\n",
        "  era_adj = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PTS'] = float(row['PTS']) * float(era_adj['Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"era_opponent_adjusted_per75_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoP5OjWDf5yI"
      },
      "source": [
        "**NBA 1974-22 ADJUSTED PLAYOFF SERIES TS+ (Opponent Adjustment)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XBKkL-oJvRqw"
      },
      "outputs": [],
      "source": [
        "#@title Scrape Adjusted Playoff TS+ Series by Series (not working)\n",
        "def adjust_scoring_efficiency_series(url_df, teams_ts_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'Opp', 'PTS/G', 'TS+', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      print(player)\n",
        "      \n",
        "\n",
        "      wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "      wd.get(url)          \n",
        "      html = wd.page_source\n",
        "      soup = BeautifulSoup(html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      # grab rows\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "\n",
        "      # post 3PA\n",
        "      try:\n",
        "        headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                  'G',\t'W', 'L',\t'MP', 'FG', 'FGA', '3P', '3PA', 'FT', \n",
        "                  'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                  'PTS', 'dum2', 'FG%', '3P%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                          'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                          'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                          'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "      except:\n",
        "        # post TOV pre 3PA\n",
        "        try:\n",
        "          headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                    'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                    'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                    'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                            'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                            'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                            'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "        # pre TOV and pre 3PA\n",
        "        except:\n",
        "          try:\n",
        "            headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                      'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                      'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'PF',\n",
        "                      'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']  \n",
        "\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                              'G',\t'W', 'L', 'FG', 'FT', 'ORB', \n",
        "                              'TRB',\t'AST', 'STL', 'BLK', 'PF', 'dum2',\n",
        "                              'FG%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "          # post TOV and pre 3PA \n",
        "          except:\n",
        "            headers = [th.getText() for th in first_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            headers = headers[1:]\n",
        "            headers[2] = 'Year'\n",
        "            headers[27] = 'MP/G'\n",
        "            headers[28] = 'PTS/G'\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      \n",
        "\n",
        "      # convert ABA seasons to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SSL\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"VIR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SAA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"INA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"UTS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"KEN\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"CAR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1960\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1961\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1962\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1963\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1964\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1965\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1966\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1967\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1968\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1969\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1970\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1971\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1972\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1973\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data['MP'] = series_data['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "\n",
        "      # add TS% allowed\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['PTS/G'] = series_data['PTS/G'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      teams_ts_df['Team'] = teams_ts_df['Team'].astype(str)\n",
        "      teams_ts_df['Year'] = teams_ts_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "      opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "      series_data['opp_ts'] = opponent_ts['TS% Allowed'] np.where ( teams_ts_df['Opp'] == series_data['Opp'] & teams_ts_df['Year'] == series_data['Year'] )\n",
        "      series_data['opp_ts'] = series_data['opp_ts'].astype(float)\n",
        "        \n",
        "      if series_data['PTS/G'] == 0:\n",
        "        series_data['TS+'] = 0\n",
        "      else:\n",
        "        series_data['TS+'] = ((series_data['PTS'] / (((series_data['FTA'] * .44) + series_data['FGA']) * 2)) / series_data['opp_ts']) * 100\n",
        "        series_data['TS+'] = '%.2f' % round(series_data['TS+'], 2)\n",
        "\n",
        "      new_row = {'Player':series_data['Player'], 'Year':series_data['Player'], 'Opp':series_data['Opp'], 'PTS/G':series_data['PTS/G'], 'TS+':series_data['TS+'], 'MP':int(series_data['MP'])}\n",
        "      final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "    print(final_season_df)\n",
        "    outfile = f\"NBA_Playoff_Series_Adjusted_TS_df.csv\"\n",
        "    final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RRlU93sn61Rl"
      },
      "outputs": [],
      "source": [
        "#@title NBA 1974-2022 Adjusted Playoff TS+ Series by Series\n",
        "def adjust_scoring_efficiency_series(url_df, opp_ts_df, opp_defrtg_df):\n",
        "\n",
        "    final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'Opp', 'PTS/G', 'TS+', 'MP'])\n",
        "    percent_iteration = 1\n",
        " \n",
        "    for a, b in url_df.itertuples(index=False):\n",
        "      player = a\n",
        "      url = b\n",
        "      url = \"https://www.basketball-reference.com\" + url\n",
        "      print(player)\n",
        "      \n",
        "\n",
        "      wd.get(url)\n",
        "      html = wd.page_source\n",
        "      time.sleep(5)\n",
        "      soup = BeautifulSoup(html)\n",
        "      time.sleep(5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # scrape Playoff shooting distribution data\n",
        "      for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "        second_div = first_div.find('div', attrs={'id': 'all_playoffs-series'})\n",
        "        first_table = second_div.find('table', attrs={'id': 'playoffs-series'})\n",
        "        body = first_table.find('tbody')\n",
        "\n",
        "      # grab rows\n",
        "      rows = body.findAll('tr')[0:]\n",
        "      series_stats = [[td.getText() for td in rows[i].findAll('td')] for i in range(len(rows))]\n",
        "\n",
        "      # remove empty rows\n",
        "      series_stats = [e for e in series_stats if e != []]\n",
        "\n",
        "      # post 3PA\n",
        "      try:\n",
        "        headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                  'G',\t'W', 'L',\t'MP', 'FG', 'FGA', '3P', '3PA', 'FT', \n",
        "                  'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                  'PTS', 'dum2', 'FG%', '3P%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "        series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "        series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                          'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                          'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                          'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "      except:\n",
        "        # post TOV pre 3PA\n",
        "        try:\n",
        "          headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                    'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                    'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
        "                    'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']\n",
        "\n",
        "          series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "          series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                            'G',\t'W', 'L', 'FG', '3P', '3PA', 'FT', 'ORB', \n",
        "                            'TRB',\t'AST', 'STL', 'BLK', 'TOV', 'PF', 'dum2',\n",
        "                            'FG%', '3P%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "        # pre TOV and pre 3PA\n",
        "        except:\n",
        "          try:\n",
        "            headers = ['Age',\t'Team',\t'Year',\t'Round', 'W/L', 'Opp', 'dum1', \n",
        "                      'G',\t'W', 'L',\t'MP', 'FG', 'FGA', 'FT', \n",
        "                      'FTA', 'ORB', 'TRB',\t'AST', 'STL', 'BLK', 'PF',\n",
        "                      'PTS', 'dum2', 'FG%', 'FT%', 'dum3', 'MPG', 'PTS/G', 'TRB/G', 'AST/G']  \n",
        "\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "            series_data.drop(['Age',\t'Team',\t'Round', 'W/L', 'dum1',\n",
        "                              'G',\t'W', 'L', 'FG', 'FT', 'ORB', \n",
        "                              'TRB',\t'AST', 'STL', 'BLK', 'PF', 'dum2',\n",
        "                              'FG%', 'FT%', 'dum3', 'TRB/G', 'AST/G'], axis=1)\n",
        "          # post TOV and pre 3PA \n",
        "          except:\n",
        "            headers = [th.getText() for th in first_table.findAll('tr', limit=2)[1].findAll('th')]\n",
        "            headers = headers[1:]\n",
        "            headers[2] = 'Year'\n",
        "            headers[27] = 'MP/G'\n",
        "            headers[28] = 'PTS/G'\n",
        "            series_data = pd.DataFrame(series_stats, columns = headers)\n",
        "      \n",
        "\n",
        "      # convert ABA seasons to NaN and drop\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DNA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SSL\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"VIR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SAA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"INA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"UTS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"LAS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"KEN\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NYA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"SDA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"CAR\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMT\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"DLC\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"PTP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MNP\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"FLO\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"TEX\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"ANA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMF\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"MMS\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"NOB\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"OAK\", float('NaN'))\n",
        "      series_data['Team'] = series_data['Team'].replace(\"WSA\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1960\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1961\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1962\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1963\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1964\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1965\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1966\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1967\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1968\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1969\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1970\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1971\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1972\", float('NaN'))\n",
        "      series_data['Year'] = series_data['Year'].replace(\"1973\", float('NaN'))\n",
        "\n",
        "       # if age column is blank then replace with NaN to it's easy to drop\n",
        "      series_data['Age'] = series_data['Age'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data['MP'] = series_data['MP'].replace(r'^s*$', float('NaN'), regex = True)\n",
        "      series_data.dropna(inplace=True)\n",
        "\n",
        "      # add TS% allowed\n",
        "      series_data['PTS'] = series_data['PTS'].astype(float)\n",
        "      series_data['PTS/G'] = series_data['PTS/G'].astype(float)\n",
        "      series_data['FTA'] = series_data['FTA'].astype(float)\n",
        "      series_data['FGA'] = series_data['FGA'].astype(float)\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(str)\n",
        "      series_data['Opp'] = series_data['Opp'].astype(str)\n",
        "      series_data['Year'] = series_data['Year'].astype(str)\n",
        "      series_data['TS+'] = 0\n",
        "\n",
        "      for i, row in series_data.iterrows():\n",
        "        current_opp = series_data.loc[i, 'Opp']\n",
        "        current_year = series_data.loc[i,'Year']\n",
        "        # get ts% allowed by opponent\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & ((opp_ts_df['Year'] == current_year))]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        # get defrtg allowed by opponent\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        if row['PTS/G'] == 0:\n",
        "          tsplus = 0\n",
        "        else:\n",
        "          tsplus = ((row['PTS'] / (((row['FTA'] * .44) + row['FGA']) * 2)) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        pts = row['PTS/G']\n",
        "        tsplus = '%.2f' % round(tsplus, 2)\n",
        "        pts = pts * pts_coeff\n",
        "\n",
        "        new_row = {'Player':player, 'Year':current_year, 'Opp':current_opp, 'PTS/G':pts, 'TS+':tsplus, 'MP':int(row['MP'])}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "        \n",
        "      # print progress\n",
        "      percentage = \"{:.2%}\".format(percent_iteration/url_df.shape[0])\n",
        "      print(percentage)\n",
        "      percent_iteration = percent_iteration + 1\n",
        "    outfile = f\"NBA_Playoff_Series_Adjusted_Scoring_df.csv\"\n",
        "    final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNmY18XS86dV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run Adjusted Playoff TS+ Series by Series\n",
        "opp_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = pd.read_csv('/content/fragment97.csv', index_col=False, encoding='utf8')\n",
        "url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "adjust_scoring_efficiency_series(url_txt_df, opp_ts_allowed_df, opponent_adj_pts_coeff)\n",
        "\n",
        "spurs_guys = pd.read_csv('/content/NBA_Playoff_Series_Adjusted_Scoring_df.csv', index_col=False, encoding='utf8')\n",
        "spurs_guys = spurs_guys.sort_values('Year', ascending=True)\n",
        "\n",
        "outfile = f\"Player_Scoring_Series.csv\"\n",
        "spurs_guys.to_csv(outfile, index=False)\n",
        "\n",
        "player_df = pd.read_csv('Player_Scoring_Series.csv')\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in player_df.iterrows():\n",
        "\n",
        "  url_txt_df = pd.read_csv('/content/fragment97.csv', index_col=False, encoding='utf8')\n",
        "  url_txt_df = url_txt_df.drop('MP', axis=1)\n",
        "\n",
        "  for a, b in url_txt_df.itertuples(index=False):\n",
        "    player = a\n",
        "\n",
        "  # era adjust\n",
        "  #sub_coeff = per_game_coeff[(per_game_coeff['Year'] == row['Year'])]\n",
        "  #row['PTS/G'] = float(row['PTS/G'] * sub_coeff['Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"{player}_Inflated_Series_Stats.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df['MP'] = new_df['MP'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)\n",
        "print(new_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X7wa6qNOjrd"
      },
      "source": [
        "**REG TO PLAYOFFS SCORING CHANGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cvk_rdRbrv7P"
      },
      "outputs": [],
      "source": [
        "#@title Calculation Functions\n",
        "\n",
        "# print the change in scoring rate and effieciency for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoffs_functional_use(a, dfa, dfb):\n",
        "\n",
        "  player_reg = dfa[(dfa.Player == a)]\n",
        "  player_playoff = dfb[(dfb.Player == a)]\n",
        "\n",
        "  total_mp_reg = 0\n",
        "  pts_list_reg = []\n",
        "  ts_list_reg = []\n",
        "\n",
        "  total_mp_playoff = 0\n",
        "  pts_list_playoff = []\n",
        "  ts_list_playoff = []\n",
        "\n",
        "  mp_list_reg = []\n",
        "  mp_list_playoff = []\n",
        "\n",
        "  total_pts_change = 0\n",
        "  total_ts_change = 0\n",
        "  total_pts = 0\n",
        "  total_ts = 0\n",
        "\n",
        "  # find total reg PTS\n",
        "  i = 0\n",
        "  for row in player_reg['PTS']:\n",
        "    pts_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total reg TS+\n",
        "  i = 0\n",
        "  for row in player_reg['TS%+']:\n",
        "    ts_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff minutes\n",
        "  for row in player_playoff['MP']:\n",
        "    mp_list_playoff.append(row)\n",
        "    total_mp_playoff += row\n",
        "\n",
        "  # find total playoff PTS\n",
        "  i = 0\n",
        "  for row in player_playoff['PTS']:\n",
        "    pts_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff TS+\n",
        "  i = 0\n",
        "  for row in player_playoff['TS%+']:\n",
        "    ts_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "  if len(pts_list_reg) != len(pts_list_playoff):\n",
        "    j = j-1\n",
        "\n",
        "  i = 0\n",
        "  while i <= j-1:\n",
        "    total_pts_change += ((pts_list_playoff[i] - pts_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_ts_change += ((ts_list_playoff[i] - ts_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_pts += (pts_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_ts += (ts_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    i = i + 1\n",
        "  return (a, total_pts, total_ts, total_pts_change, total_ts_change, total_mp_playoff)\n",
        "\n",
        "\n",
        "# print the change in BPM and OBPM for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoffs_functional_use_bpm(a, dfa, dfb):\n",
        "\n",
        "  player_reg = dfa[(dfa.Player == a)]\n",
        "  player_playoff = dfb[(dfb.Player == a)]\n",
        "\n",
        "  total_mp_reg = 0\n",
        "  bpm_list_reg = []\n",
        "  obpm_list_reg = []\n",
        "\n",
        "  total_mp_playoff = 0\n",
        "  bpm_list_playoff = []\n",
        "  obpm_list_playoff = []\n",
        "\n",
        "  mp_list_reg = []\n",
        "  mp_list_playoff = []\n",
        "\n",
        "  total_bpm_change = 0\n",
        "  total_obpm_change = 0\n",
        "  total_bpm = 0\n",
        "  total_obpm = 0\n",
        "\n",
        "  # find total reg PTS\n",
        "  i = 0\n",
        "  for row in player_reg['BPM']:\n",
        "    bpm_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total reg TS+\n",
        "  i = 0\n",
        "  for row in player_reg['OBPM']:\n",
        "    obpm_list_reg.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff minutes\n",
        "  for row in player_playoff['MP']:\n",
        "    mp_list_playoff.append(row)\n",
        "    total_mp_playoff += row\n",
        "\n",
        "  # find total playoff PTS\n",
        "  i = 0\n",
        "  for row in player_playoff['BPM']:\n",
        "    bpm_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total playoff TS+\n",
        "  i = 0\n",
        "  for row in player_playoff['OBPM']:\n",
        "    obpm_list_playoff.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "  if len(bpm_list_reg) != len(bpm_list_playoff):\n",
        "    j = j-1\n",
        "\n",
        "  i = 0\n",
        "  while i <= j-1:\n",
        "    total_bpm_change += ((bpm_list_playoff[i] - bpm_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_obpm_change += ((obpm_list_playoff[i] - obpm_list_reg[i]) * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_bpm += (bpm_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    total_obpm += (obpm_list_playoff[i] * (mp_list_playoff[i] / total_mp_playoff))\n",
        "    i = i + 1\n",
        "  return (a, total_bpm, total_obpm, total_bpm_change, total_obpm_change, total_mp_playoff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "74v74ArIIZdT"
      },
      "outputs": [],
      "source": [
        "#@title Functional declaration of playoff scoring changes (x year stretches)\n",
        "\n",
        "# def twoYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every two year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def twoYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year2 = int(year2)\n",
        "        season_list = '{} - {}'.format(year1, year2)\n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = int(year2)\n",
        "        season_list = '{}, {}'.format(year1, year2)\n",
        "\n",
        "      \n",
        "\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Two_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def threeYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every three year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def threeYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-1\n",
        "        year3 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year3 = int(year3)\n",
        "        season_list = '{} - {}'.format(year1, year3)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "        year3 = years.split()[2]\n",
        "        year3 = int(year3)\n",
        "        season_list = '{}, {}, {}'.format(year1, year2, year3)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Three_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def fourYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every four year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def fourYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-2\n",
        "        year3 = int(years.split()[2])-1\n",
        "        year4 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year4)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}'.format(year1, year2, year3, year4)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Four_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def fiveYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every five year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def fiveYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-3\n",
        "        year3 = int(years.split()[2])-2\n",
        "        year4 = int(years.split()[2])-1\n",
        "        year5 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year5)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Five_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def sixYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def sixYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-4\n",
        "        year3 = int(years.split()[2])-3\n",
        "        year4 = int(years.split()[2])-2\n",
        "        year5 = int(years.split()[2])-1\n",
        "        year6 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year6)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Six_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def sevenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def sevenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-5\n",
        "        year3 = int(years.split()[2])-4\n",
        "        year4 = int(years.split()[2])-3\n",
        "        year5 = int(years.split()[2])-2\n",
        "        year6 = int(years.split()[2])-1\n",
        "        year7 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year7)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Seven_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def eightYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every eight year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def eightYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-6\n",
        "        year3 = int(years.split()[2])-5\n",
        "        year4 = int(years.split()[2])-4\n",
        "        year5 = int(years.split()[2])-3\n",
        "        year6 = int(years.split()[2])-2\n",
        "        year7 = int(years.split()[2])-1\n",
        "        year8 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year8)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Eight_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def nineYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every nine year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def nineYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year9)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8) | (adjusted_playoff_per_75_df.Year == year9))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Nine_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def tenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every ten year stretch for each player\n",
        "# and corresponding data to show change in scoring rate and effeciency from regular season to postseason\n",
        "def tenYearRegToPlayoffsProduction(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  adjusted_playoff_per_75_df = pd.read_csv('/content/era_opponent_adjusted_per75_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = int(years.split()[2])-1\n",
        "        year10 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year10)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = year9.replace(',', '')\n",
        "        year9 = int(year9)\n",
        "\n",
        "        year10 = years.split()[9]\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9, year10)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9) | (reg_df.Year == year10))]\n",
        "      player_playoff_db = adjusted_playoff_per_75_df[(adjusted_playoff_per_75_df.Player == row[\"Player\"]) & ((adjusted_playoff_per_75_df.Year == year1) | (adjusted_playoff_per_75_df.Year == year2) | (adjusted_playoff_per_75_df.Year == year3) | (adjusted_playoff_per_75_df.Year == year4) | (adjusted_playoff_per_75_df.Year == year5) | (adjusted_playoff_per_75_df.Year == year6) | (adjusted_playoff_per_75_df.Year == year7) | (adjusted_playoff_per_75_df.Year == year8) | (adjusted_playoff_per_75_df.Year == year9) | (adjusted_playoff_per_75_df.Year == year10))]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "  outfile = f\"Ten_Year_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eb96uEuGsGDN"
      },
      "outputs": [],
      "source": [
        "#@title Functional declaration of playoff scoring changes (career)  \n",
        "# output file containing change in scoring rate and efficiency from regular season to playoffs (Entire Career)\n",
        "# use only regular seasons in which a player made the playoffs\n",
        "def regToPlayoffsProductionTightScope(reg_df, playoff_db):\n",
        "\n",
        "  new_df = pd.DataFrame(columns = ['Player','PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post'])\n",
        "  headers_list = ['Player', 'PTS per 75_post', 'TS+_post', 'PTS_change', 'TS+_change', 'MP_post']\n",
        "  players_finished = []\n",
        "  used_years = []\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "    used_years = []\n",
        "    if row['Player'] not in players_finished:\n",
        "      player_playoff_db = playoff_db[(playoff_db.Player == row[\"Player\"])]\n",
        "      for use_idx, use_row in player_playoff_db.iterrows():\n",
        "        used_years.append(use_row['Year'])\n",
        "      player_reg_db = reg_df[reg_df['Year'].isin(used_years)]\n",
        "      player_reg_db = player_reg_db[(player_reg_db.Player == row[\"Player\"])]\n",
        "      (name, pts_post, ts_post, pts_change, ts_change, mp_post) = reg_playoffs_functional_use(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, pts_post, ts_post, pts_change, ts_change, mp_post]\n",
        "      players_finished.append(row['Player'])\n",
        "  outfile = f\"Career_Playoff_Scoring_Change.csv\"\n",
        "  columns_titles = ['Player', 'PTS_change', 'TS+_change', 'PTS per 75_post', 'TS+_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('PTS_change', ascending=False)\n",
        "\n",
        "  new_df['TS+_change'] = new_df['TS+_change'].round(2)\n",
        "  new_df['PTS_change'] = new_df['PTS_change'].round(2)\n",
        "  new_df['PTS per 75_post'] = new_df['PTS per 75_post'].round(2)\n",
        "  new_df['TS+_post'] = new_df['TS+_post'].round(2)\n",
        "  \n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ85A5uLjDIJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff scoring changes (x year stretches)\n",
        "import_player_pts_playoff10peaks_df = pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "tenYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff10peaks_df)\n",
        "\n",
        "import_player_pts_playoff9peaks_df = pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "nineYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff9peaks_df)\n",
        "\n",
        "import_player_pts_playoff8peaks_df = pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "eightYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff8peaks_df)\n",
        "\n",
        "import_player_pts_playoff7peaks_df = pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "sevenYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff7peaks_df)\n",
        "\n",
        "import_player_pts_playoff6peaks_df = pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "sixYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff6peaks_df)\n",
        "\n",
        "import_player_pts_playoff5peaks_df = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "fiveYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff5peaks_df)\n",
        "\n",
        "import_player_pts_playoff4peaks_df = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "fourYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff4peaks_df)\n",
        "\n",
        "import_player_pts_playoff3peaks_df = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "threeYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff3peaks_df)\n",
        "\n",
        "import_player_pts_playoff2peaks_df = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "twoYearRegToPlayoffsProduction(era_adj_reg_per_75_df, import_player_pts_playoff2peaks_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaAVm7LcZedf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff scoring changes (career)\n",
        "# CAREER\n",
        "\n",
        " \n",
        "\n",
        "regToPlayoffsProductionTightScope(era_adj_reg_per_75_df, era_opponent_adj_playoff_per_75_df)\n",
        "import_player_scoring_changes_df = pd.read_csv('Career_Playoff_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_scoring_changes_df = import_player_scoring_changes_df.dropna()\n",
        "\n",
        "\n",
        "\n",
        "one_thousand_min_filter = import_player_scoring_changes_df[(import_player_scoring_changes_df['MP_post'] >= 2000)]\n",
        "outfile_1000 = f\"Career_Playoff_Scoring_Change_2000min.csv\"\n",
        "one_thousand_min_filter.to_csv(outfile_1000, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REG TO PLAYOFFS BPM CHANGES**"
      ],
      "metadata": {
        "id": "k9F-ko-AtZj7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cXgIpAWbAXC1"
      },
      "outputs": [],
      "source": [
        "#@title Functional declaration of playoff BPM changes (x year stretches)\n",
        "\n",
        "# def twoYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every two year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def twoYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year2 = int(year2)\n",
        "        season_list = '{} - {}'.format(year1, year2)\n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = int(year2)\n",
        "        season_list = '{}, {}'.format(year1, year2)\n",
        "\n",
        "      \n",
        "\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2))]\n",
        "      player_playoff_db = playoff_bpm_data[(playoff_bpm_data.Player == row[\"Player\"]) & ((playoff_bpm_data.Year == year1) | (playoff_bpm_data.Year == year2))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Two_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def threeYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every three year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def threeYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-1\n",
        "        year3 = years.split()[2]\n",
        "        year1 = int(year1)\n",
        "        year3 = int(year3)\n",
        "        season_list = '{} - {}'.format(year1, year3)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "        year3 = years.split()[2]\n",
        "        year3 = int(year3)\n",
        "        season_list = '{}, {}, {}'.format(year1, year2, year3)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Three_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def fourYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every four year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def fourYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-2\n",
        "        year3 = int(years.split()[2])-1\n",
        "        year4 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year4)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = int(year4)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}'.format(year1, year2, year3, year4)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Four_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def fiveYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every five year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def fiveYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-3\n",
        "        year3 = int(years.split()[2])-2\n",
        "        year4 = int(years.split()[2])-1\n",
        "        year5 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year5)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = int(year5)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Five_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def sixYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def sixYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-4\n",
        "        year3 = int(years.split()[2])-3\n",
        "        year4 = int(years.split()[2])-2\n",
        "        year5 = int(years.split()[2])-1\n",
        "        year6 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year6)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = int(year6)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Six_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "# def sevenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every seven year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def sevenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-5\n",
        "        year3 = int(years.split()[2])-4\n",
        "        year4 = int(years.split()[2])-3\n",
        "        year5 = int(years.split()[2])-2\n",
        "        year6 = int(years.split()[2])-1\n",
        "        year7 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year7)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = int(year7)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Seven_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def eightYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every eight year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def eightYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-6\n",
        "        year3 = int(years.split()[2])-5\n",
        "        year4 = int(years.split()[2])-4\n",
        "        year5 = int(years.split()[2])-3\n",
        "        year6 = int(years.split()[2])-2\n",
        "        year7 = int(years.split()[2])-1\n",
        "        year8 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year8)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = int(year8)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Eight_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# def nineYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every nine year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def nineYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year9)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = int(year9)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8) | (playoff_bpm_data .Year == year9))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Nine_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# def tenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "# given regular season database and postseason database, return every ten year stretch for each player\n",
        "# and corresponding data to show change in bpm and obpm from regular season to postseason\n",
        "def tenYearRegToPlayoffsBPM(reg_df, playoff_db):\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data  = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "      years = row['Years']\n",
        "      dash_substring = '-'\n",
        "      if dash_substring in years:\n",
        "        year1 = years.split()[0]\n",
        "        year2 = int(years.split()[2])-8\n",
        "        year3 = int(years.split()[2])-7\n",
        "        year4 = int(years.split()[2])-6\n",
        "        year5 = int(years.split()[2])-5\n",
        "        year6 = int(years.split()[2])-4\n",
        "        year7 = int(years.split()[2])-3\n",
        "        year8 = int(years.split()[2])-2\n",
        "        year9 = int(years.split()[2])-1\n",
        "        year10 = years.strip().split()[2]\n",
        "\n",
        "        year1 = int(year1)\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{} - {}'.format(year1, year10)  \n",
        "      else:\n",
        "        year1 = years.split()[0]\n",
        "        year1 = year1.replace(',', '')\n",
        "        year1 = int(year1)\n",
        "\n",
        "        year2 = years.split()[1]\n",
        "        year2 = year2.replace(',', '')\n",
        "        year2 = int(year2)\n",
        "\n",
        "        year3 = years.split()[2]\n",
        "        year3 = year3.replace(',', '')\n",
        "        year3 = int(year3)\n",
        "\n",
        "        year4 = years.split()[3]\n",
        "        year4 = year4.replace(',', '')\n",
        "        year4 = int(year4)\n",
        "\n",
        "        year5 = years.split()[4]\n",
        "        year5 = year5.replace(',', '')\n",
        "        year5 = int(year5)\n",
        "\n",
        "        year6 = years.split()[5]\n",
        "        year6 = year6.replace(',', '')\n",
        "        year6 = int(year6)\n",
        "\n",
        "        year7 = years.split()[6]\n",
        "        year7 = year7.replace(',', '')\n",
        "        year7 = int(year7)\n",
        "\n",
        "        year8 = years.split()[7]\n",
        "        year8 = year8.replace(',', '')\n",
        "        year8 = int(year8)\n",
        "\n",
        "        year9 = years.split()[8]\n",
        "        year9 = year9.replace(',', '')\n",
        "        year9 = int(year9)\n",
        "\n",
        "        year10 = years.split()[9]\n",
        "        year10 = int(year10)\n",
        "\n",
        "        season_list = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(year1, year2, year3, year4, year5, year6, year7, year8, year9, year10)\n",
        "      player_reg_db = reg_df[(reg_df.Player == row[\"Player\"]) & ((reg_df.Year == year1) | (reg_df.Year == year2) | (reg_df.Year == year3) | (reg_df.Year == year4) | (reg_df.Year == year5) | (reg_df.Year == year6) | (reg_df.Year == year7) | (reg_df.Year == year8) | (reg_df.Year == year9) | (reg_df.Year == year10))]\n",
        "      player_playoff_db = playoff_bpm_data [(playoff_bpm_data .Player == row[\"Player\"]) & ((playoff_bpm_data .Year == year1) | (playoff_bpm_data .Year == year2) | (playoff_bpm_data .Year == year3) | (playoff_bpm_data .Year == year4) | (playoff_bpm_data .Year == year5) | (playoff_bpm_data .Year == year6) | (playoff_bpm_data .Year == year7) | (playoff_bpm_data .Year == year8) | (playoff_bpm_data .Year == year9) | (playoff_bpm_data .Year == year10))]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, season_list, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "  outfile = f\"Ten_Year_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'Years', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "\n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PpVhZVsYcV0E"
      },
      "outputs": [],
      "source": [
        "#@title Function declaration of playoff BPM changes (career)  \n",
        "# output file containing change in scoring rate and efficiency from regular season to playoffs (Entire Career)\n",
        "# use only regular seasons in which a player made the playoffs\n",
        "def regToPlayoffsProductionTightScopeBPM(reg_df, playoff_db):\n",
        "\n",
        "  new_df = pd.DataFrame(columns = ['Player', 'Years', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  playoff_bpm_data = pd.read_csv('/content/nba_player_since74playoffs_advanced_data.csv')\n",
        "  players_finished = []\n",
        "  used_years = []\n",
        "\n",
        "  for idx, row in playoff_db.iterrows():\n",
        "    used_years = []\n",
        "    if row['Player'] not in players_finished:\n",
        "      player_playoff_db = playoff_db[(playoff_db.Player == row[\"Player\"])]\n",
        "      for use_idx, use_row in player_playoff_db.iterrows():\n",
        "        used_years.append(use_row['Year'])\n",
        "      player_reg_db = reg_df[reg_df['Year'].isin(used_years)]\n",
        "      player_reg_db = player_reg_db[(player_reg_db.Player == row[\"Player\"])]\n",
        "      (name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post) = reg_playoffs_functional_use_bpm(row[\"Player\"], player_reg_db, player_playoff_db)\n",
        "      new_df.loc[len(new_df)] = [name, bpm_post, obpm_post, BPM_change, oBPM_change, mp_post]\n",
        "      players_finished.append(row['Player'])\n",
        "  outfile = f\"Career_Playoff_BPM_Change.csv\"\n",
        "  columns_titles = ['Player', 'BPM_change', 'OBPM_change', 'BPM_post', 'OBPM_post', 'MP_post']\n",
        "  new_df = new_df.reindex(columns=columns_titles)\n",
        "  new_df = new_df.sort_values('BPM_change', ascending=False)\n",
        "  \n",
        "  new_df['OBPM_change'] = new_df['OBPM_change'].round(2)\n",
        "  new_df['BPM_change'] = new_df['BPM_change'].round(2)\n",
        "  new_df['BPM_post'] = new_df['BPM_post'].round(2)\n",
        "  new_df['OBPM_post'] = new_df['OBPM_post'].round(2)\n",
        "  \n",
        "  new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Me79i0gHKVE3"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff bpm changes (x year stretches)\n",
        "import_player_bpm_playoff10peaks_df = pd.read_csv('/content/Ten_Year_BPM_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "tenYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff10peaks_df)\n",
        "\n",
        "import_player_bpm_playoff9peaks_df = pd.read_csv('/content/Nine_Year_BPM_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "nineYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff9peaks_df)\n",
        "\n",
        "import_player_bpm_playoff8peaks_df = pd.read_csv('/content/Eight_Year_BPM_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "eightYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff8peaks_df)\n",
        "\n",
        "import_player_bpm_playoff7peaks_df = pd.read_csv('/content/Seven_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "sevenYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff7peaks_df)\n",
        "\n",
        "import_player_bpm_playoff6peaks_df = pd.read_csv('/content/Six_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "sixYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff6peaks_df)\n",
        "\n",
        "import_player_bpm_playoff5peaks_df = pd.read_csv('/content/Five_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "fiveYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff5peaks_df)\n",
        "\n",
        "import_player_bpm_playoff4peaks_df = pd.read_csv('/content/Four_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "fourYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff4peaks_df)\n",
        "\n",
        "import_player_bpm_playoff3peaks_df = pd.read_csv('/content/Three_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "threeYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff3peaks_df)\n",
        "\n",
        "import_player_bpm_playoff2peaks_df = pd.read_csv('/content/Two_Year_BPM_Playoff_Peaks.csv', encoding='utf8')\n",
        "twoYearRegToPlayoffsBPM(new_df, import_player_bpm_playoff2peaks_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q3UBqs5tb-Ea"
      },
      "outputs": [],
      "source": [
        "#@title Run playoff BPM changes (career)\n",
        "# CAREER\n",
        "\n",
        " \n",
        "\n",
        "regToPlayoffsProductionTightScopeBPM(era_adj_reg_per_75_df, era_opponent_adj_playoff_per_75_df)\n",
        "import_player_scoring_changes_df = pd.read_csv('Career_Playoff_Scoring_Change.csv', encoding='utf8')\n",
        "import_player_scoring_changes_df = import_player_scoring_changes_df.dropna()\n",
        "\n",
        "\n",
        "\n",
        "one_thousand_min_filter = import_player_scoring_changes_df[(import_player_scoring_changes_df['MP_post'] >= 2000)]\n",
        "outfile_1000 = f\"Career_Playoff_Scoring_Change_2000min.csv\"\n",
        "one_thousand_min_filter.to_csv(outfile_1000, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu-iOQT7Rpj5"
      },
      "source": [
        "**SCORING PLOT FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-3WWnnpkhqr"
      },
      "outputs": [],
      "source": [
        "def label_point(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "      #if i % 2 == 0:\n",
        "      ax.text(point['x']+0.25, point['y'], str(point['val']))\n",
        "      #else:\n",
        "      #ax.text(point['x']+0.30, point['y'], str(point['val']))\n",
        "      #ax.text(point['x']+0.05, point['y'], str(point['val']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wJ_wS861o8eV"
      },
      "outputs": [],
      "source": [
        "#@title Single Plot Scoring Template\n",
        "def plotOneScoring(p1, c1, pts_floor, ts_floor, ts_ceiling, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Multi-Year Playoff Scoring Stretches (1952 - 2022) [min. 500 MP]', xlabel='PTS per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def plotTwoScoring(p1, p2, c1, c2,  pts_floor, ts_floor, ts_ceiling, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Multi-Year Playoff Scoring (1952 - 2022) [min 1000 MP]', xlabel='PTS per 75 (era/opponent adjusted', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def plotThreeScoring(p1, p2, p3, c1, c2, c3,  pts_floor, ts_floor, ts_ceiling, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP'] - (graph_data['MP'].min() - 150)) / (graph_data['MP'].max() - (graph_data['MP'].min() - 150)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Multi-Year Playoff Scoring (1952 - 2022)', xlabel='PTS per 75 (era/opponent adjusted', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nhc4VYkV2Zq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Multiple Plots Scoring Template\n",
        "def plotOneScoring(p1, c1, pts_floor, ts_floor, ts_ceiling):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted) (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [>500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 600)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [>600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1000)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [>1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1200)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [>1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [>1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [>1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))) / (graph_data['MP'].max() - (graph_data['MP'].min()-(graph_data['MP'].min()*.25))))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Peaks', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title 2 Guys Scoring Plot Template\n",
        "def plotTwoScoring(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling):\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(115)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [>300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [>500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 600)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [>600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1000)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [>1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1200)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [>1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [>1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [>1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[9].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Peaks', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title 3 Guys Scoring Plot Template\n",
        "def plotThreeScoring(p1, p2, p3, c1, c2, c3, pts_floor, ts_floor, ts_ceiling):\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [> 300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [> 500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 600]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [> 600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [> 1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1200]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [> 1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1400]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [> 1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [> 1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 2000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [> 2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_data = tmp_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[9].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring_Peaks', bbox_inches='tight')\n",
        "\n",
        "#@title 4 Guys Scoring Plot Template\n",
        "def plotFourScoring(p1, p2, p3, p4, c1, c2, c3, c4, pts_floor, ts_floor, ts_ceiling):\n",
        "  fig, axis = plt.subplots(10)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 300]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff Scoring (1952-2022) [> 300 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff Scoring (1952-2022) [> 500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 600]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff Scoring (1952-2022) [> 600 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff Scoring (1952-2022) [> 1000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1200]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='6 Year Playoff Scoring (1952-2022) [> 1200 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1400]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='7 Year Playoff Scoring (1952-2022) [> 1400 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 1500]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='8 Year Playoff Scoring (1952-2022) [> 1500 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='9 Year Playoff Scoring (1952-2022) [>1700 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['TS+']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+']) <= ts_ceiling]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 2000]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[8])\n",
        "  axis[8].set(title='10 Year Playoff Scoring (1952-2022) [> 2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[8].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[8].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 1 year\n",
        "  graph_data =  pd.read_csv('/content/era_opponent_adjusted_per75_data.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP']) >= 150]\n",
        "  graph_data = graph_data[(graph_data['PTS']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS%+']) >= ts_floor]\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "  no_third = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_third = no_third.append(no_second[no_second[\"Player\"] != p3])\n",
        "  tmp_data = tmp_data.append(no_third[no_third['Player'] != p4])\n",
        "  no_first = graph_data[(graph_data['Player'] == p4)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p4),c4, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(30,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS\", y=\"TS%+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[9])\n",
        "  axis[9].set(title='1 Year Playoff Scoring (1952-2022) [> 150 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (opponent adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p4, markerfacecolor=c4,  markersize=10)]\n",
        "  axis[9].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['PTS']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['TS%+']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  #axis[9].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "  plt.show()\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_{p4}_Scoring_Peaks', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Gys3Jbx0NXFW"
      },
      "outputs": [],
      "source": [
        "#@title Multiple Plots PBP Template\n",
        "def plotOnePBP(p1, c1):\n",
        "  fig, axis = plt.subplots(8)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_pbp_Peaks_NBA_Playoffs_300_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='3 Year Playoff PBP (1997-2022) [>500 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_pbp_Peaks_NBA_Playoffs_600_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='4 Year Playoff PBP (1997-2022) [>600 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_pbp_Peaks_NBA_Playoffs_1000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='5 Year Playoff PBP (1997-2022) [>1000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_pbp_Peaks_NBA_Playoffs_1400_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='6 Year Playoff PBP (1997-2022) [>1400 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_pbp_Peaks_NBA_Playoffs_2000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='7 Year Playoff PBP (1997-2022) [>2000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='8 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Nine_Year_pbp_Playoff_Peaks_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='9 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='10 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  fig.savefig(f'{p1}_PBP_Peaks', bbox_inches='tight')\n",
        "\n",
        "def plotTwoPBP(p1, p2, c1, c2):\n",
        "  fig, axis = plt.subplots(8)\n",
        "  fig.set_figheight(85)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_pbp_Peaks_NBA_Playoffs_300_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='3 Year Playoff PBP (1997-2022) [>500 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[0].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_pbp_Peaks_NBA_Playoffs_600_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='4 Year Playoff PBP (1997-2022) [>600 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[1].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_pbp_Peaks_NBA_Playoffs_1000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G']\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='5 Year Playoff PBP (1997-2022) [>1000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[2].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_pbp_Peaks_NBA_Playoffs_1400_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 1400)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='6 Year Playoff PBP (1997-2022) [>1400 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[3].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_pbp_Peaks_NBA_Playoffs_2000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP'] >= 500)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[4])\n",
        "  axis[4].set(title='7 Year Playoff PBP (1997-2022) [>2000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[4].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[4].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[5])\n",
        "  axis[5].set(title='8 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[5].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[5].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 9 year\n",
        "  graph_data =  pd.read_csv('/content/Nine_Year_pbp_Playoff_Peaks_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[6])\n",
        "  axis[6].set(title='9 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[6].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[6].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_pbp_Peaks_NBA_Playoffs_3000_min.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  graph_data['MPG'] = graph_data['MP'] / graph_data['G'] \n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP'] - graph_data['MP'].min()) / (graph_data['MP'].max() - graph_data['MP'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"OnCourt\", y=\"On-Off\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*7, 'linewidth':0.3}, ax=axis[7])\n",
        "  axis[7].set(title='10 Year Playoff PBP (1997-2022) [>3000 MP]', xlabel='OnCourt', ylabel='On-Off')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[7].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  # ridge regression\n",
        "  x_pred = graph_data['OnCourt']\n",
        "  x_pred = np.array(x_pred).reshape(-1, 1)\n",
        "  y_pred = graph_data['On-Off']\n",
        "  reg = linear_model.Ridge(alpha=10)\n",
        "  reg.fit(x_pred, y_pred)\n",
        "  pred = reg.predict(x_pred)\n",
        "  axis[7].plot(x_pred, pred, color=\"k\", linewidth=3)\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_PBP_Peaks', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sy_RXsh-Ctf"
      },
      "source": [
        "**REG->PLAYOFF SCORING CHANGE PLOTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6B5fddTe-Mbr"
      },
      "outputs": [],
      "source": [
        "#@title Single Plot Scoring Change Template\n",
        "def p_plotOneScoringChange(p1, c1, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP_post']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {pts_floor} Pts per 75 Postseason; min. {mp_floor} MP]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChange(p1, p2, c1, c2, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP_post']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {pts_floor} Pts per 75 Postseason; min. {mp_floor} MP]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChange(p1, p2, p3, c1, c2, c3, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['MP_post']) >= mp_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {pts_floor} Pts per 75 Postseason; min. {mp_floor} MP]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "  \n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title 2 Guys Scoring Change Single Plot Template (TS+ above below league avg)\n",
        "def p_plotOneScoringChange_ab(p1, c1, pts_floor, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['TS+_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PTS_change\": \"PTS_change\", \"TS+_change\": \"TS+_change\", \"PTS per 75_reg\": \"PTS per 75_reg\", \"PTS per 75_post\": \"PTS per 75_post\", \"TS+_reg\": \"TS+_reg\", \"TS+_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {threshold} TS+ postseason]\"\n",
        "  ax.set(title=title_string, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys Scoring Change Single Plot Template (TS+ above below league avg)\n",
        "def p_plotTwoScoringChange_ab(p1, p2, c1, c2, pts_floor, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['TS+_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PTS_change\": \"PTS_change\", \"TS+_change\": \"TS+_change\", \"PTS per 75_reg\": \"PTS per 75_reg\", \"PTS per 75_post\": \"PTS per 75_post\", \"TS+_reg\": \"TS+_reg\", \"TS+_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.TSpost >= threshold),c2, graph_data.color)\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.TSpost <= threshold),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS_change\", y=\"TS+_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff Scoring Changes from Reg to Post (1974 - 2022) [min. {threshold} TS+ postseason]\"\n",
        "  ax.set(title=title_string, xlabel='Change in PTS per 75', ylabel='Change in TS+')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['PTS_change'].max()\n",
        "  x_min = graph_data['PTS_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xxGUbQIlBFL6"
      },
      "outputs": [],
      "source": [
        "#@title Multiple Plots Scoring Change (with lines) Template\n",
        "def p_plotOneScoringChangeWithLines(p1, c1, pts_floor, ts_floor, ts_ceiling, label, mp_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}_Scoring_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChangeWithLines(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling, label, mp_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_Scoring_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChangeWithLines(p1, p2, p3, c1, c2, c3, pts_floor, ts_floor, ts_ceiling, label, mp_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[0])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[1])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[2])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >=  ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <=  ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff Scoring Change from Reg->Post (1974-2022) [>{mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['PTS per 75_post'], graph_data['TS+_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['PTS per 75_post'], p2_data['TS+_post'], p2_data['Years'], axis[3])\n",
        "    label_point(p3_data['PTS per 75_post'], p3_data['TS+_post'], p3_data['Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ihbDWbHaHO-S"
      },
      "outputs": [],
      "source": [
        "#@title Single Plot Career Scoring Change (with lines) Template\n",
        "def p_plotOneScoringChangeWithLinesCareer(p1, c1, pts_floor, ts_floor, ts_ceiling):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <= ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "\n",
        "def p_plotTwoScoringChangeWithLinesCareer(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling):\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <= ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "\n",
        "def p_plotThreeScoringChangeWithLinesCareer(p1, p2, p3, c1, c2, c3, pts_floor, ts_floor, ts_ceiling):\n",
        "  graph_data = pd.read_csv('/content/Career_Playoff_Scoring_Change_2000min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) >= ts_floor]\n",
        "  graph_data = graph_data[(graph_data['TS+_post']) <= ts_ceiling]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"PTS per 75_post\", y=\"TS+_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  ax.set(title='Career Playoff Scoring Change from Reg->Post (1974-2022) [>2000 MP]', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['PTS per 75_post']-graph_data['PTS_change'], graph_data['TS+_post']-graph_data['TS+_change']]\n",
        "  point2 = [graph_data['PTS per 75_post'], graph_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['PTS per 75_post']-p2_data['PTS_change'], p2_data['TS+_post']-p2_data['TS+_change']]\n",
        "  point2 = [p2_data['PTS per 75_post'], p2_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['PTS per 75_post']-p3_data['PTS_change'], p3_data['TS+_post']-p3_data['TS+_change']]\n",
        "  point2 = [p3_data['PTS per 75_post'], p3_data['TS+_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  ax.plot(x_values, y_values, c3, linestyle=\"--\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r597HycnNfI4"
      },
      "outputs": [],
      "source": [
        "# Single Plot Scoring Template\n",
        "  # plotNumScoring(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling, mp_floor)\n",
        "# Multiple Plots Scoring Template\n",
        "  # plotNumScoring(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling)\n",
        "#  Multiple Plots PBP Template\n",
        "  # plotTwoPBP(p1, p2, c1, c2)\n",
        "#  Single Plot Scoring Change Template\n",
        "  # p_plotNumScoringChange(p1, p2, c1, c2, pts_floor, mp_floor)\n",
        "#  Multiple Plots Scoring Change w Lines Template\n",
        "  # p_plotNumScoringChangeWithLines(p1, p2, c1, c2, pts_floor, ts_floor, ts_ceiling, 1or0, [mp_2year, mp_3year, mp_4year, mp_5year])\n",
        "#  Single Plot Scoring Change w Lines Template\n",
        "  # p_plotNumScoringChangeWithLinesCareer(p1, c1, pts_floor, ts_floor, ts_ceiling):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plotTwoPBP(\"Bruce Bowen\", \"Danny Green\", \"#FF8200\", \"#EF426F\")\n",
        "#plotThreeScoring(\"George Gervin\", \"Tony Parker\", \"Manu Ginbili\",  \"#EF426F\", \"#FF8200\", 15, 60, 140)\n",
        "plotTwoScoring(\"Tony Parker\", \"Manu Ginbili\", \"#EF426F\", \"#FF8200\", 15, 60, 140)"
      ],
      "metadata": {
        "id": "q_M7VGXk7lGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIWuoavMiG_r"
      },
      "source": [
        "**ERA ADJUSTED BPM CHANGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ax9wp0mPgnBr"
      },
      "outputs": [],
      "source": [
        "#@title Era Adjust BPM\n",
        "reg_playoff_per_75_df = import_player_since74_advanced_df.copy()\n",
        "new_df = pd.DataFrame()\n",
        "for i, row in reg_playoff_per_75_df.iterrows():\n",
        "  sub_mess = bpm_coeff[(bpm_coeff['Year'] == row['Year'])]\n",
        "  row['BPM'] = float(row['BPM'] * sub_mess['BPM_Coefficient'])\n",
        "  row['OBPM'] = float(row['OBPM'] * sub_mess['OBPM_Coefficient'])\n",
        "  new_df = new_df.append(row)\n",
        "outfile = f\"inflation_adjusted_reg_bpm_data.csv\"\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wlYv7A_Iexa8"
      },
      "outputs": [],
      "source": [
        "#@title (Era-Adjusted) p_plot_X_BPMChange (Single Plot)\n",
        "def p_plotOneBPMChange(p1, c1, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys BPM Change Single Plot Template (OBPM above below league avg)\n",
        "def p_plotOneBPMChange_ab(p1, c1, above_below, threshold):\n",
        "\n",
        "  graph_data = pd.read_csv('/content/All_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  \n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['OBPM_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  graph_data = graph_data.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"bpm_change\": \"bpm_change\", \"OBPM_change\": \"OBPM_change\", \"BPM_reg\": \"BPM_reg\", \"BPM_post\": \"BPM_post\", \"OBPM_reg\": \"OBPM_reg\", \"OBPM_post\": \"TSpost\", \"MP_reg\": \"MP_reg\", \"MP_post\": \"MP_post\"})\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost >= threshold), c1, \"#00B2A9\")\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.TSpost <= threshold), c1, \"#00B2A9\")\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"bpm_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  title_string = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [min. {threshold} OBPM postseason]\"\n",
        "  ax.set(title=title_string, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['bpm_change'].max()\n",
        "  x_min = graph_data['bpm_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "def p_plotTwoBPMChange(p1, p2, c1, c2, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - (graph_data['MP_post'].min()*.1))) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "#@title 2 Guys BPM Change Single Plot Template (OBPM above below league avg)\n",
        "def p_plotTwoBPMChange_ab(p1, p2, c1, c2, above_below, threshold, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data = pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  \n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data = graph_data.sort_values(['OBPM_post'], ascending=True)\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  if (above_below == 'a'):\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.BPM_post >= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.BPM_post >= threshold),c2, graph_data.color)\n",
        "  else:\n",
        "    graph_data['color'] = np.where((first_cond==True) & (graph_data.BPM_post <= threshold), c1, \"#00B2A9\")\n",
        "    graph_data['color'] = np.where((graph_data.Player == p2) & (graph_data.BPM_post <= threshold),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ( (graph_data['MP_post'] - (graph_data['MP_post'].min() - 50)) / (graph_data['MP_post'].max() - (graph_data['MP_post'].min() - 50)) )\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [min. {threshold} BPM postseason; [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_BPM_Changes', bbox_inches='tight')\n",
        "\n",
        "def p_plotThreeBPMChange(p1, p2, p3, c1, c2, c3, pts_floor, mp_floor):\n",
        "\n",
        "  graph_data =  pd.read_csv('All_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.color_palette(\"flare\", as_cmap=True)\n",
        "  ax = sns.regplot(data=graph_data, x=\"BPM_change\", y=\"OBPM_change\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3})\n",
        "  titlestring = f\"Multi-Year Playoff BPM Changes from Reg to Post (1974 - 2022) [PTS per 75 >= {pts_floor} & MP >= {mp_floor}]\"\n",
        "  ax.set(title=titlestring, xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                    Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  ax.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  x_max = graph_data['BPM_change'].max()\n",
        "  x_min = graph_data['BPM_change'].min()\n",
        "  ax.hlines(y=0, xmin=x_min, xmax=x_max, linewidth=1, color='#8A8D8F')\n",
        "  ax.axvline(x=0, linewidth=1, color='#8A8D8F')\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_BPM_Changes', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pHiJYdZueZoR"
      },
      "outputs": [],
      "source": [
        "#@title (Era-Adjusted) p_plot_X_BPMChangeWithLines (Multiple Plots)\n",
        "def p_plotOneBPMChangeWithLines(p1, c1, pts_floor, mp_floor, label):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_data = tmp_data.append(no_first)\n",
        "  graph_data = tmp_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}__BPM_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[3])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def p_plotTwoBPMChangeWithLines(p1, p2, c1, c2, pts_floor, mp_floor, label):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[0])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[0])\n",
        "  titlestring = f\"2 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[0]} MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[0])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[1])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[1])\n",
        "  titlestring = f\"3 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[1]} MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[1])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[2])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[2])\n",
        "  titlestring = f\"4 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[2]} MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[2])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor[3])]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  tmp_player_data = tmp_player_data.append(no_first[no_first[\"Player\"] != p2])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*15, 'linewidth':0.3}, ax=axis[3])\n",
        "  titlestring = f\"5 Year Playoff BPM Change from Reg->Post (1974-2022) [>= {pts_floor} PTS per 75, >= {mp_floor[3]} MP]\"\n",
        "  axis[3].set(title=titlestring, xlabel='BPM (era-adjusted)', ylabel='OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['BPM_post'], graph_data['OBPM_post'], graph_data['Years'], axis[3])\n",
        "    label_point(p2_data['BPM_post'], p2_data['OBPM_post'], p2_data['Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}__BPM_Changes_With_Lines', bbox_inches='tight')\n",
        "\n",
        "\n",
        "def p_plotThreeBPMChangeWithLines(p1, p2, p3, c1, c2, c3, pts_floor):\n",
        "\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "  axis[0].set(title='2 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  axis[1].set(title='3 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM (era-adjusted)', ylabel='Change in OBPM (era-adjusted)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "\n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "  axis[2].set(title='4 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_BPM_Changes_300min.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= mp_floor)]\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  tmp_player_data = pd.DataFrame()\n",
        "  no_first = pd.DataFrame()\n",
        "  no_second = pd.DataFrame()\n",
        "\n",
        "  no_first = no_first.append(graph_data[graph_data[\"Player\"] != p1])\n",
        "  no_second = no_second.append(no_first[no_first[\"Player\"] != p2])\n",
        "  tmp_player_data = tmp_player_data.append(no_second[no_second['Player'] != p3])\n",
        "  no_first = graph_data[(graph_data['Player'] == p2)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p1)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  no_first = graph_data[(graph_data['Player'] == p3)]\n",
        "  tmp_player_data = tmp_player_data.append(no_first)\n",
        "  graph_data = tmp_player_data\n",
        "\n",
        "  first_cond = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(first_cond==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "  graph_data['color'] = np.where((graph_data.Player == p3),c3, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['MP_post'] - graph_data['MP_post'].min()) / (graph_data['MP_post'].max() - graph_data['MP_post'].min()))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"BPM_post\", y=\"OBPM_post\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  axis[3].set(title='5 Year Playoff BPM Change from Reg->Post (1974-2022) [>300 MP]', xlabel='Change in BPM', ylabel='Change in OBPM')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p3, markerfacecolor=c3,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  \n",
        "  p3_data = graph_data[(graph_data[\"Player\"] == p3)]\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['BPM_post']-graph_data['BPM_change'], graph_data['OBPM_post']-graph_data['OBPM_change']]\n",
        "  point2 = [graph_data['BPM_post'], graph_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['BPM_post']-p2_data['BPM_change'], p2_data['OBPM_post']-p2_data['OBPM_change']]\n",
        "  point2 = [p2_data['BPM_post'], p2_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p3_data['BPM_post']-p3_data['BPM_change'], p3_data['OBPM_post']-p3_data['OBPM_change']]\n",
        "  point2 = [p3_data['BPM_post'], p3_data['OBPM_post']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c3, linestyle=\"--\")\n",
        "\n",
        "  fig.savefig(f'{p1}_{p2}_{p3}_BPM_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B-Yy-4czj7Qc"
      },
      "outputs": [],
      "source": [
        "#@title Space labels (not working)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "np.random.seed(2016)\n",
        "\n",
        "N = 20\n",
        "scatter_data = np.random.rand(N, 3)*10\n",
        "\n",
        "\n",
        "def repel_labels(ax, x, y, labels, k=0.01):\n",
        "    G = nx.DiGraph()\n",
        "    data_nodes = []\n",
        "    init_pos = {}\n",
        "    for xi, yi, label in zip(x, y, labels):\n",
        "        data_str = 'data_{0}'.format(label)\n",
        "        G.add_node(data_str)\n",
        "        G.add_node(label)\n",
        "        G.add_edge(label, data_str)\n",
        "        data_nodes.append(data_str)\n",
        "        init_pos[data_str] = (xi, yi)\n",
        "        init_pos[label] = (xi, yi)\n",
        "\n",
        "    pos = nx.spring_layout(G, pos=init_pos, fixed=data_nodes, k=k)\n",
        "\n",
        "    # undo spring_layout's rescaling\n",
        "    pos_after = np.vstack([pos[d] for d in data_nodes])\n",
        "    pos_before = np.vstack([init_pos[d] for d in data_nodes])\n",
        "    scale, shift_x = np.polyfit(pos_after[:,0], pos_before[:,0], 1)\n",
        "    scale, shift_y = np.polyfit(pos_after[:,1], pos_before[:,1], 1)\n",
        "    shift = np.array([shift_x, shift_y])\n",
        "    for key, val in pos.items():\n",
        "        pos[key] = (val*scale) + shift\n",
        "\n",
        "    for label, data_str in G.edges():\n",
        "        ax.annotate(label,\n",
        "                    xy=pos[data_str], xycoords='data',\n",
        "                    xytext=pos[label], textcoords='data',\n",
        "                    arrowprops=dict(arrowstyle=\"->\",\n",
        "                                    shrinkA=0, shrinkB=0,\n",
        "                                    connectionstyle=\"arc3\", \n",
        "                                    color='red'), )\n",
        "    # expand limits\n",
        "    all_pos = np.vstack(pos.values())\n",
        "    x_span, y_span = np.ptp(all_pos, axis=0)\n",
        "    mins = np.min(all_pos-x_span*0.15, 0)\n",
        "    maxs = np.max(all_pos+y_span*0.15, 0)\n",
        "    ax.set_xlim([mins[0], maxs[0]])\n",
        "    ax.set_ylim([mins[1], maxs[1]])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(scatter_data[:, 0], scatter_data[:, 1],\n",
        "           c=scatter_data[:, 2], s=scatter_data[:, 2] * 150)\n",
        "labels = ['ano_{}'.format(i) for i in range(N)]\n",
        "repel_labels(ax, scatter_data[:, 0], scatter_data[:, 1], labels, k=0.008)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TONY MANU MULTIPLE LINE DRAWN SITUATIONAL CHANGES**"
      ],
      "metadata": {
        "id": "A1FZBFWLaGXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-Bgnirj0wYoA"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu Many changes from Big 3 -> 2/3 (2/3/4/5)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_2_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_3_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='3 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data = pd.read_csv('/content/Combined_4_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='4 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_5_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 300)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*1, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='5 Year Playoff Scoring Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['1_Years'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['1_Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5oM4_4esYh2N"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu Many changes from Big 3 -> 2/3  +/- (2/3/4/5)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_2_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[0])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_3_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "  axis[1].set(title='3 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[1])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[1])\n",
        "\n",
        "\n",
        "\n",
        "  # 4 year\n",
        "  graph_data = pd.read_csv('/content/Combined_4_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='4 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[2])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_5_Year_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_NET\", y=\"1_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='5 Year +/- Change; Big 3 -> 2/3 of Big 3 (2014-2022)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_NET'], graph_data['3_OFF']]\n",
        "  point2 = [graph_data['1_NET'], graph_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_NET'], p2_data['3_OFF']]\n",
        "  point2 = [p2_data['1_NET'], p2_data['1_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_NET'], graph_data['1_OFF'], graph_data['1_Years'], axis[3])\n",
        "    label_point(p2_data['1_NET'], p2_data['1_OFF'], p2_data['1_Years'], axis[3])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_Scoring_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zgZ3-e7EQzRl"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu First to Later Rounds (+/-)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_NET\", y=\"Later_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Playoff +/- Change from First Round to Later Rounds (2004-14)', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_NET'], graph_data['First_OFF']]\n",
        "  point2 = [graph_data['Later_NET'], graph_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_NET'], p2_data['First_OFF']]\n",
        "  point2 = [p2_data['Later_NET'], p2_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_NET'], graph_data['Later_OFF'], graph_data['Later_Years'], axis[0])\n",
        "    label_point(p2_data['Later_NET'], p2_data['Later_OFF'], p2_data['Later_Years'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_NET\", y=\"Later_OFF\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':size*11, 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Playoff +/- Change from First Round to Later Rounds (2004-14) [3+ opposing starters]', xlabel='NetRtg', ylabel='OffRtg')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_NET'], graph_data['First_OFF']]\n",
        "  point2 = [graph_data['Later_NET'], graph_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_NET'], p2_data['First_OFF']]\n",
        "  point2 = [p2_data['Later_NET'], p2_data['Later_OFF']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_NET'], graph_data['Later_OFF'], graph_data['Later_Years'], axis[1])\n",
        "    label_point(p2_data['Later_NET'], p2_data['Later_OFF'], p2_data['Later_Years'], axis[1])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_Situational_NET_Changes_With_Lines', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loBdpFyEEaxA"
      },
      "source": [
        "**TONY MANU SITUATIONAL CHANGES FROM BIG 3 TO 2/3 BIG 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qw6gPZ85jYOp"
      },
      "outputs": [],
      "source": [
        "#@title Big 3 to Two Thirds\\2004-14\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O8X_Qca_iBDF"
      },
      "outputs": [],
      "source": [
        "#@title Big 3 to Two Thirds\\5 Year\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (5 Year Peaks) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_5_Year_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Edki8wjYbKWz"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu 2004-14 change from Big 3 -> 2/3 (Tony Only 3 Opposing starters)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # NET\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  axis[0].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [Manu 3+ opposing starters; Tony max 3 opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Scoring Change from Big 3 On -> 2/3 Big 3 On (2004-14) [Manu 3+ opposing starters; Tony max 3 opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_Big3_to_Two_Thirds.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0q8D6_zN2C5"
      },
      "source": [
        "**FROM FIRST TO LATER ROUNDS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xZ2si_VlN5mM"
      },
      "outputs": [],
      "source": [
        "#@title First Round to Later Rounds\\2004-14\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EP83nxE0UKmh"
      },
      "outputs": [],
      "source": [
        "#@title First Round to Later Rounds\\5 Year Later Peaks\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) [3+ opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_NET'] - (graph_data['Later_NET'].min() - 50)) / (graph_data['Later_NET'].max() - (graph_data['Later_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (5 Year Peaks) [3+ opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_5_Year_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UGlPvsNNcac7"
      },
      "outputs": [],
      "source": [
        "#@title Tony/Manu 2004-14 change from first to later rounds (Tony Only 3 Opposing starters)\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(45)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus_Round.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 15)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['First_MP'] - (graph_data['First_MP'].min() - 15)) / (graph_data['First_MP'].max() - (graph_data['First_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"First_PTS\", y=\"First_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['First_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [Manu 3+ opposing starters; Tony max 3 opposing starters] {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['Later_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['Later_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus_Round.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['Later_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['Later_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['Later_MP'] - (graph_data['Later_MP'].min() - 50)) / (graph_data['Later_MP'].max() - (graph_data['Later_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"Later_PTS\", y=\"Later_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['Later_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='2/3 of Big 3 On; Scoring Change from First Round to Later Rounds (2004-14) [Manu 3+ opposing starters; Tony max 3 opposing starters] {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['First_PTS'], graph_data['First_TS+']]\n",
        "  point2 = [graph_data['Later_PTS'], graph_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['First_PTS'], p2_data['First_TS+']]\n",
        "  point2 = [p2_data['Later_PTS'], p2_data['Later_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['Later_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['Later_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['Later_PTS'], graph_data['Later_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['Later_PTS'], p2_data['Later_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Tony_Manu_2004-2014_First_Later.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYaoLW0ASXvx"
      },
      "outputs": [],
      "source": [
        "plotTonyManuSituationalChange(\"Manu Ginbili\", \"Tony Parker\", \"#FF8200\", \"#EF426F\", 5, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KLAY/MANU GRAPHS"
      ],
      "metadata": {
        "id": "rxviYp2iQyeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Klay/Manu 5 Year Change\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (5 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (5 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Klay_Manu_5_Year_Change.png', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XisSl6juQ0fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Klay/Manu 3 Year Change\n",
        "def plotTonyManuSituationalChange(p1, p2, c1, c2, pts_floor, label):\n",
        "\n",
        "  fig, axis = plt.subplots(4)\n",
        "  fig.set_figheight(65)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "  \n",
        "\n",
        "\n",
        "  # 0+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 15)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 15)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #size = 100 * ((graph_data['3_MP'] - (graph_data['3_MP'].min() - 15)) / (graph_data['3_MP'].max() - (graph_data['3_MP'].min() - 15)))\n",
        "  #plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  #sns.regplot(data=graph_data, x=\"3_PTS\", y=\"3_TS+\", fit_reg=False, scatter_kws={'marker':\"D\", 'facecolors':graph_data['color'], 'alpha':0.7,  's':graph_data['3_MP'], 'linewidth':0.3}, ax=axis[0])\n",
        "\n",
        "  axis[0].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (3 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[0].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[0].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[0])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[1])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_MP'] - (graph_data['1_MP'].min() - 50)) / (graph_data['1_MP'].max() - (graph_data['1_MP'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[1])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[1].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On (3 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[1].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[1].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  axis[1].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[1])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[1])\n",
        "\n",
        "\n",
        "  \n",
        "  # 3+\n",
        "  graph_data = pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 20)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[2])\n",
        "\n",
        "  \n",
        "\n",
        "  axis[2].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (3 Year Peaks) {NetRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[2].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[2].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['NET_n'] = graph_data['1_NET'].round(2)\n",
        "  p2_data['NET_n'] = p2_data['1_NET'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['NET_n'], axis[2])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['NET_n'], axis[2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  graph_data =  pd.read_csv('/content/Combined_Comparison_3_Plus.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['1_MP'] >= 80)]\n",
        "  graph_data = graph_data[(graph_data['1_PTS']) >= pts_floor]\n",
        "  graph_data = graph_data.dropna()\n",
        "\n",
        "  Manu = (graph_data['Player']== p1)\n",
        "  graph_data['color'] = np.where(Manu==True, c1, \"#00B2A9\")\n",
        "  graph_data['color'] = np.where((graph_data.Player == p2),c2, graph_data.color)\n",
        "\n",
        "  league_graph_data = pd.read_csv('/content/All_Scoring_Stretches_500min.csv', encoding='utf8')\n",
        "  league_graph_data = league_graph_data[(league_graph_data['MP'] >= 500)]\n",
        "  size = 100 * ((league_graph_data['MP'] - (league_graph_data['MP'].min() - 15)) / (league_graph_data['MP'].max() - (league_graph_data['MP'].min() - 15)))\n",
        "  sns.regplot(data=league_graph_data, x=\"PTS\", y=\"TS+\", fit_reg=False, scatter_kws={'facecolors':'c', 'alpha':0.7, 's':size*3, 'linewidth':0.3}, ax=axis[3])\n",
        "\n",
        "\n",
        "  size = 100 * ((graph_data['1_NET'] - (graph_data['1_NET'].min() - 50)) / (graph_data['1_NET'].max() - (graph_data['1_NET'].min() - 50)))\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "  sns.regplot(data=graph_data, x=\"1_PTS\", y=\"1_TS+\", fit_reg=False, scatter_kws={'facecolors':graph_data['color'], 'alpha':0.7, 's':graph_data['1_MP'], 'linewidth':0.3}, ax=axis[3])\n",
        "  \n",
        "  \n",
        "\n",
        "  axis[3].set(title='Klay Scoring Change from Steph On->Off. Manu Scoring Change from Big 3 On->2/3 Big 3 On [3+ opposing starters] (3 Year Peaks) {rOffRtg annotated}', xlabel='Pts per 75 (era/opponent adjusted)', ylabel='TS+ (adjusted for opponent)')\n",
        "\n",
        "  legend_elements = [Line2D([0], [0], marker='o', color='#EAEAF2', label=p1, markerfacecolor=c1,  markersize=10),\n",
        "                     Line2D([0], [0], marker='o', color='#EAEAF2', label=p2, markerfacecolor=c2,  markersize=10)]\n",
        "  axis[3].legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "  p2_data = graph_data[(graph_data[\"Player\"] == p2)]\n",
        "  graph_data = graph_data[(graph_data[\"Player\"] == p1)]\n",
        "\n",
        "  point1 = [graph_data['3_PTS'], graph_data['3_TS+']]\n",
        "  point2 = [graph_data['1_PTS'], graph_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c1, linestyle=\"--\")\n",
        "\n",
        "  point1 = [p2_data['3_PTS'], p2_data['3_TS+']]\n",
        "  point2 = [p2_data['1_PTS'], p2_data['1_TS+']]\n",
        "  x_values = [point1[0], point2[0]]\n",
        "  y_values = [point1[1], point2[1]]\n",
        "  axis[3].plot(x_values, y_values, c2, linestyle=\"--\")\n",
        "\n",
        "  graph_data['OFF_n'] = graph_data['1_OFF'].round(2)\n",
        "  p2_data['OFF_n'] = p2_data['1_OFF'].round(2)\n",
        "\n",
        "  if label == 1:\n",
        "    label_point(graph_data['1_PTS'], graph_data['1_TS+'], graph_data['OFF_n'], axis[3])\n",
        "    label_point(p2_data['1_PTS'], p2_data['1_TS+'], p2_data['OFF_n'], axis[3])\n",
        "\n",
        "\n",
        "  fig.savefig(f'Klay_Manu_3_Year_Change.png', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "br-VNioYT6LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotTonyManuSituationalChange(\"Manu Ginbili\", \"Klay Thompson\", \"k\", \"y\", 5, 1)"
      ],
      "metadata": {
        "id": "Wj6lgLfbRRG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MISC**"
      ],
      "metadata": {
        "id": "1BUC_calmAZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-AWQpDM9zWF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Append into one\n",
        "two = pd.read_csv('/content/Ten_Year_scoring_Playoff_Peaks_2000min.csv', encoding='utf8')\n",
        "three = pd.read_csv('/content/Nine_Year_scoring_Playoff_Peaks_1700min.csv', index_col=False, encoding='utf8')\n",
        "four = pd.read_csv('/content/Eight_Year_scoring_Playoff_Peaks_1500min.csv', index_col=False, encoding='utf8')\n",
        "five = pd.read_csv('/content/Seven_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "six = pd.read_csv('/content/Six_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "seven = pd.read_csv('/content/Five_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "eight = pd.read_csv('/content/Four_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "nine = pd.read_csv('/content/Three_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "ten = pd.read_csv('/content/Two_Year_scoring_Playoff_Peaks.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "two = two.append(three)\n",
        "two = two.append(four)\n",
        "two = two.append(five)\n",
        "two = two.append(six)\n",
        "two = two.append(seven)\n",
        "two = two.append(eight)\n",
        "two = two.append(nine)\n",
        "two = two.append(ten)\n",
        "two = two[(two['MP'] >= 500)]\n",
        "two = two.sort_values(by = ['PTS', 'MP'], ascending = [False, False], na_position = 'first')\n",
        "print(two)\n",
        "\n",
        "outfile = f\"All_Scoring_Stretches_500min.csv\"\n",
        "two.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3bBmu92gXOiE"
      },
      "outputs": [],
      "source": [
        "#@title 'Combine x year scoring and bpm changes' Function\n",
        "def combine_scoring_bpm_changes(scoring_df, bpm_df, year):\n",
        "  final_season_df = pd.DataFrame(columns = ['Player', 'Years', 'PTS per 75_post', 'TS+_post', 'PTS_Change', 'TS+_Change', 'BPM_post', 'OBPM_post', 'BPM_change', 'OBPM_change', 'MP_post'])\n",
        "  for idx, row in scoring_df.iterrows():\n",
        "    sub_second_df = bpm_df[(bpm_df['Player'] == row['Player'])]\n",
        "    for jdx, inner_row in sub_second_df.iterrows():\n",
        "      if inner_row['Player'] == row['Player'] and inner_row['Years'] == row['Years']:\n",
        "        new_row = {'Player':inner_row['Player'], 'Years':inner_row['Years'], 'PTS per 75_post':row['PTS per 75_post'], 'TS+_post':row['TS+_post'], 'PTS_Change':row['PTS_change'], 'TS+_Change':row['TS+_change'], 'BPM_post':inner_row['BPM_post'], 'OBPM_post':inner_row['OBPM_post'], 'BPM_change':inner_row['BPM_change'], 'OBPM_change':inner_row['OBPM_change'], 'MP_post':int(inner_row['MP_post'])}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  final_season_df = final_season_df[(final_season_df['MP_post'] >= 300)]\n",
        "  outfile = f\"{year}_Year_Scoring_BPM_Changes_300min.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3VNf4cGdXn40"
      },
      "outputs": [],
      "source": [
        "#@title Run 'Combine x year scoring and bpm changes'\n",
        "scoring = pd.read_csv('/content/Two_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Two_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Two\")\n",
        "\n",
        "scoring = pd.read_csv('/content/Three_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Three_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Three\")\n",
        "\n",
        "\n",
        "scoring = pd.read_csv('/content/Four_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Four_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Four\")\n",
        "\n",
        "\n",
        "scoring = pd.read_csv('/content/Five_Year_Scoring_Change.csv', index_col=False, encoding='utf8')\n",
        "scoring = scoring.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "bpm = pd.read_csv('/content/Five_Year_BPM_Change.csv', index_col=False, encoding='utf8')\n",
        "bpm = bpm.sort_values(['Player', 'Years'], ascending=[True, True])\n",
        "\n",
        "combine_scoring_bpm_changes(scoring, bpm, \"Five\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HISTORICAL PERCENTILES**"
      ],
      "metadata": {
        "id": "Ti-kIv9qTcdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Year Percentiles\n",
        "def Spurs_Playoff_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu PP75', 'Tony PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu PP75', 'Tony PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu TS+', 'Tony TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu TS+', 'Tony TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Year', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title Spurs '2/3' Percentiles\n",
        "def Spurs_Playoff_2_3_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_2-3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu PP75', 'Tony PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu PP75', 'Tony PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 70 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_2-3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Year', 'Manu TS+', 'Tony TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu TS+', 'Tony TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 70 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_2-3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Year', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 70 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title Spurs '2/3' Percentiles\n",
        "def Spurs_Playoff_4_Plus_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_4plus_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)', 'Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)'])\n",
        "  columns_titles = ['Year', 'Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_4plus_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)', 'Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)'])\n",
        "  columns_titles = ['Year', 'Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_4plus_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75 (4+ opp. starters)', 'Tony PP75 (4+ opp. starters)', 'Manu TS+ (4+ opp. starters)', 'Tony TS+ (4+ opp. starters)'])\n",
        "  columns_titles = ['Year', 'Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP (4+ opp. starters)', 'Tony MP (4+ opp. starters)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "BcoxF8ymi6Pf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Series Percentiles\n",
        "def Spurs_Playoff_Series_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      righat=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu PP75', 'Tony PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu PP75', 'Tony PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu TS+', 'Tony TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu TS+', 'Tony TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "\n",
        "#@title Spurs Series Percentiles\n",
        "def Spurs_Playoff_Series_Percentile_Approx():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_series_percentile.csv', encoding='utf8')\n",
        "  graph_data['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Manu PP75']) + (0.5 * graph_data['Manu TS+'])\n",
        "  graph_data['Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tony PP75']) + (0.5 * graph_data['Tony TS+'])\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_Manu_Tony_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "#@title Spurs Series Percentiles\n",
        "def Spurs_Playoff_Series_Percentile_No_First():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_No_First_Manu_Tony_series_percentile.csv', encoding='utf8')\n",
        "  graph_data['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Manu PP75']) + (0.5 * graph_data['Manu TS+'])\n",
        "  graph_data['Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tony PP75']) + (0.5 * graph_data['Tony TS+'])\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+', 'Manu MP', 'Tony MP'])\n",
        "  columns_titles = ['Series', 'Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Melt_No_First_Manu_Tony_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Manu TS+', 'Tony TS+'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "C7xD2Y3KU0Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Big 3 Year Percentiles\n",
        "def Big_3_Playoff_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(25)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Tim TS+', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Year', 'Manu PP75', 'Tony PP75', 'Tim PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = graph_data.sort_values('Year', ascending=True)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu PP75', 'Tony PP75', 'Tim PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Year', 'Manu TS+', 'Tony TS+', 'Tim TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = graph_data.sort_values('Year', ascending=True)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu TS+', 'Tony TS+', 'Tim TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+'])\n",
        "  columns_titles = ['Year', 'Manu MP', 'Tony MP', 'Tim MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = graph_data.sort_values('Year', ascending=True)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP', 'Tony MP', 'Tim MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 100 MP]\"\n",
        "  axis[2].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "def Big_3_Playoff_Percentile_Approx():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(35)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_percentile.csv', encoding='utf8')\n",
        "  graph_data['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Manu PP75']) + (0.5 * graph_data['Manu TS+'])\n",
        "  graph_data['Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tony PP75']) + (0.5 * graph_data['Tony TS+'])\n",
        "  graph_data['Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tim PP75']) + (0.5 * graph_data['Tim TS+'])\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Year', 'Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = graph_data.sort_values('Year', ascending=True)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)',], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Year', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+'])\n",
        "  columns_titles = ['Year', 'Manu MP', 'Tony MP', 'Tim MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = graph_data.sort_values('Year', ascending=True)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Year\", value_vars=['Manu MP', 'Tony MP', 'Tim MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Year', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Year', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gZNoLOZqE4Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Big 3 Series Percentiles\n",
        "def Big_3_Playoff_Series_Percentile():\n",
        "\n",
        "  fig, axis = plt.subplots(3)\n",
        "  fig.set_figheight(25)\n",
        "  fig.set_figwidth(45)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu TS+', 'Tony TS+', 'Tim TS+', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Series', 'Manu PP75', 'Tony PP75', 'Tim PP75']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu PP75', 'Tony PP75', 'Tim PP75'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Rate (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Series', 'Manu TS+', 'Tony TS+', 'Tim TS+']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu TS+', 'Tony TS+', 'Tim TS+'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring Efficiency (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP', 'Tim MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP', 'Tim MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[2])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[2].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')\n",
        "\n",
        "def Big_3_Playoff_Series_Percentile_Approx():\n",
        "\n",
        "  fig, axis = plt.subplots(2)\n",
        "  fig.set_figheight(30)\n",
        "  fig.set_figwidth(45)\n",
        "\n",
        "  plt.subplots_adjust(left=0.1,\n",
        "                      bottom=0.1, \n",
        "                      right=0.9, \n",
        "                      top=0.9, \n",
        "                      wspace=0.4, \n",
        "                      hspace=0.4)\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_series_percentile.csv', encoding='utf8')\n",
        "  graph_data['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Manu PP75']) + (0.5 * graph_data['Manu TS+'])\n",
        "  graph_data['Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tony PP75']) + (0.5 * graph_data['Tony TS+'])\n",
        "  graph_data['Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)'] = (0.5 * graph_data['Tim PP75']) + (0.5 * graph_data['Tim TS+'])\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+', 'Manu MP', 'Tony MP', 'Tim MP'])\n",
        "  columns_titles = ['Series', 'Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tony Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)', 'Tim Approx_Scoring_Val (1/2 PP75) + (1/2 TS+)',], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[0])\n",
        "\n",
        "  titlestring = f\"Playoff Scoring (1952 - 2022) *1954 not included* [min. 15 PP75; 90 MP]\"\n",
        "  axis[0].set(title=titlestring, xlabel='Series', ylabel='Historical Percentile')\n",
        "\n",
        "  graph_data = pd.read_csv('/content/Big3_series_percentile.csv', encoding='utf8')\n",
        "  graph_data = graph_data.drop(columns=['Manu PP75', 'Tony PP75', 'Tim PP75', 'Manu TS+', 'Tony TS+', 'Tim TS+'])\n",
        "  columns_titles = ['Series', 'Manu MP', 'Tony MP', 'Tim MP']\n",
        "  graph_data = graph_data.reindex(columns=columns_titles)\n",
        "  graph_data = pd.melt(graph_data, id_vars=\"Series\", value_vars=['Manu MP', 'Tony MP', 'Tim MP'], value_name=\"Percentile\", var_name ='Player Key')\n",
        "\n",
        "  sns.barplot(data=graph_data, x='Series', y='Percentile', hue=\"Player Key\", palette=[\"#FF8200\", \"#00B2A9\", \"k\"], ax=axis[1])\n",
        "\n",
        "  titlestring = f\"Playoff MP\"\n",
        "  axis[1].set(title=titlestring, xlabel='Series', ylabel='MP')\n",
        "\n",
        "  fig.savefig(f'Spurs_Percentiles', bbox_inches='tight')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UBPGkgOEsTJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spurs_Playoff_4_Plus_Percentile()\n",
        "#Spurs_Playoff_Series_Percentile()\n",
        "#Spurs_Playoff_Series_Percentile_Approx()\n",
        "#Spurs_Playoff_Series_Percentile_No_First()\n",
        "Big_3_Playoff_Series_Percentile_Approx()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ziavXuWMjzgk",
        "outputId": "e858a80e-5c43-4d66-8a74-9bc74939b450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3240x2160 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0unXklbF571"
      },
      "source": [
        "**PLOT SHOOTING DISTRIBUTION DATA/PRINT MANUAL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FIVy6IDJYfP2"
      },
      "outputs": [],
      "source": [
        "#@title Print Medians\n",
        "def printmedians(pts_floor):\n",
        "  # 2 year\n",
        "  graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 300)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"2 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"2 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 3 year\n",
        "  graph_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"3 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"3 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 4 year\n",
        "  graph_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 800)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"4 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"4 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 5 year\n",
        "  graph_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1000)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"5 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"5 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 6 year\n",
        "  graph_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1200)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"6 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"6 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 7 year\n",
        "  graph_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1400)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"7 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"7 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 8 year\n",
        "  graph_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 1500)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"8 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"8 Year Median TS+ decline\")\n",
        "  print(med_ts)\n",
        "  # 10 year\n",
        "  graph_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "  graph_data = graph_data[(graph_data['PTS per 75_post'] >= pts_floor)]\n",
        "  graph_data = graph_data[(graph_data['MP_post'] >= 2000)]\n",
        "  med_pts = graph_data['PTS_change'].median()\n",
        "  med_ts = graph_data['TS+_change'].median()\n",
        "  print(\"10 Year Median PTS per 75 decline\")\n",
        "  print(med_pts)\n",
        "  print(\"10 Year Median TS+ decline\")\n",
        "  print(med_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-xXRuU0mbJ-g"
      },
      "outputs": [],
      "source": [
        "#@title Print Distribution of Scoring Changes\n",
        "def printTSdistribution(all_some, pts_floor):\n",
        "  if all_some == 0:\n",
        "    # 2 year\n",
        "    graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "\n",
        "    # 3 year\n",
        "    tmp_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 4 year\n",
        "    tmp_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 5 year\n",
        "    tmp_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 6 year\n",
        "    tmp_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 7 year\n",
        "    tmp_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 8 year\n",
        "    tmp_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 10 year\n",
        "    tmp_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "  else:\n",
        "    graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data['PTS_change'] = graph_data['PTS_change'].round(1)\n",
        "  graph_data['TS+_change'] = graph_data['TS+_change'].round(1)\n",
        "\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "\n",
        "  pd.cut(graph_data['TS+_change'], \n",
        "       bins=[-17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8], \n",
        "       labels = ['-17% or worse', '-16%', '-15%', '-14%', '-13%', '-12%', '-11%', '-10%', '-9%', '-8%', '-7%', '-6%', '-5%', '-4%',\n",
        "                 '-3%', '-2%', '-1%', '0%', '+1%', '+2%', '+3%', '+4%', '+5%', '+6%',\n",
        "                 '+7% or better'])\\\n",
        "  .value_counts(sort=False).plot.bar()\n",
        "  title_string = f\"Reg->Post Scoring Change; Multi Year Playoff Stretches; >= {pts_floor} PP75 Post (1974-2022)\"\n",
        "  plt.title(title_string)\n",
        "  plt.xlabel('Change in TS+')\n",
        "  plt.ylabel('Count')\n",
        "  plt.show()\n",
        "  print(graph_data['TS+_change'].quantile(0.98))\n",
        "\n",
        "def printPTSdistribution(all_some, pts_floor):\n",
        "  if all_some == 0:\n",
        "    # 2 year\n",
        "    graph_data = pd.read_csv('/content/Two_Year_Scoring_Change.csv', encoding='utf8')\n",
        "\n",
        "    # 3 year\n",
        "    tmp_data =  pd.read_csv('/content/Three_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 4 year\n",
        "    tmp_data =  pd.read_csv('/content/Four_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 5 year\n",
        "    tmp_data =  pd.read_csv('/content/Five_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 6 year\n",
        "    tmp_data =  pd.read_csv('/content/Six_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 7 year\n",
        "    tmp_data =  pd.read_csv('/content/Seven_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 8 year\n",
        "    tmp_data =  pd.read_csv('/content/Eight_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "\n",
        "    # 10 year\n",
        "    tmp_data =  pd.read_csv('/content/Ten_Year_Scoring_Change.csv', encoding='utf8')\n",
        "    graph_data = graph_data.append(tmp_data)\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "  else:\n",
        "    graph_data =  pd.read_csv('/content/All_Scoring_Changes_300min.csv', encoding='utf8')\n",
        "    graph_data = graph_data[(graph_data['MP_post'] >= 500)]\n",
        "    graph_data = graph_data[(graph_data['PTS per 75_post']) >= pts_floor]\n",
        "    graph_data = graph_data.dropna()\n",
        "\n",
        "  graph_data['PTS_change'] = graph_data['PTS_change'].round(1)\n",
        "  graph_data['TS+_change'] = graph_data['TS+_change'].round(1)\n",
        "\n",
        "  plt.figure(figsize=(20,12), tight_layout=True)\n",
        "\n",
        "  pd.cut(graph_data['PTS_change'], \n",
        "       bins=[-6, -5.5, -5, -4.5, -4, -3.5, -3, -2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5], \n",
        "       labels = ['-6 PTS or worse', '-5.5', '-5', '-4.5', '-4', '-3.5', '-3', '-2.5', '-2', '-1.5', '-1', '-0.5', '0', '+0.5', '+1', '+1.5', '+2', '+2.5', '+3', '+3.5', '+4', '+4.5% or better'])\\\n",
        "  .value_counts(sort=False).plot.bar()\n",
        "  title_string = f\"Reg->Post Scoring Change; Multi Year Playoff Stretches; >= {pts_floor} PP75 Post (1974-2022)\"\n",
        "  plt.title(title_string)\n",
        "  plt.xlabel('Change in PTS per 75')\n",
        "  plt.ylabel('Count')\n",
        "  plt.show()\n",
        "  print(graph_data['PTS_change'].quantile(0.8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CnygkJdO3VSy"
      },
      "outputs": [],
      "source": [
        "#@title Round Format\n",
        "player_change_file['TS+_change'] = player_change_file['TS+_change'].round(2)\n",
        "player_change_file['PTS_change'] = player_change_file['PTS_change'].round(2)\n",
        "player_change_file['PTS per 75_post'] = player_change_file['PTS per 75_post'].round(2)\n",
        "player_change_file['TS+_post'] = player_change_file['TS+_post'].round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1KNOV-aK5JdN"
      },
      "outputs": [],
      "source": [
        "#@title Manual comparisons function\n",
        "sorted_playoffs_pts = era_opponent_adj_playoff_per_75_df.copy()\n",
        "sorted_reg_pts = import_player_since74_per75_df.copy()\n",
        "\n",
        "player_a = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Kawhi Leonard\") & ((sorted_playoffs_pts.Year == 2017) | (sorted_playoffs_pts.Year == 2019)  | (sorted_playoffs_pts.Year == 2021))]\n",
        "player_b = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Kevin Durant\") & ((sorted_playoffs_pts.Year == 2012) | (sorted_playoffs_pts.Year == 2017)  | (sorted_playoffs_pts.Year == 2018) | (sorted_playoffs_pts.Year == 2019) | (sorted_playoffs_pts.Year == 2021))]\n",
        "\n",
        "#player_b = sorted_reg_pts[(sorted_reg_pts.Player == \"Damian Lillard\") & ((sorted_reg_pts.Year == 2014) | (sorted_reg_pts.Year == 2015)  | (sorted_reg_pts.Year == 2016) | (sorted_reg_pts.Year == 2016) | (sorted_reg_pts.Year == 2017) | (sorted_reg_pts.Year == 2019) | (sorted_reg_pts.Year == 2020) | (sorted_reg_pts.Year == 2021))]\n",
        "\n",
        "#player_a = sorted_pts[(sorted_pts.Player == \"Kawhi Leonard\") & ((sorted_pts.Year == 2012) | (sorted_pts.Year == 2014)  | (sorted_pts.Year == 2019) | (sorted_pts.Year == 2016) | (sorted_pts.Year == 2015) | (sorted_pts.Year == 2017) | (sorted_pts.Year == 2020) | (sorted_pts.Year == 2021))]\n",
        "\n",
        "#player_a = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Klay Thompson\") & ((sorted_playoffs_pts.Year == 2013) | (sorted_playoffs_pts.Year == 2014)  | (sorted_playoffs_pts.Year == 2015) | (sorted_playoffs_pts.Year == 2016) | (sorted_playoffs_pts.Year == 2017) | (sorted_playoffs_pts.Year == 2018) | (sorted_playoffs_pts.Year == 2019))]\n",
        "#player_b = sorted_playoffs_pts[(sorted_playoffs_pts.Player == \"Kobe Bryant\")]\n",
        "#player_a = df[(df.Player == a)]\n",
        "#player_b = df[(df.Player == b)]\n",
        "total_mp_a = 0\n",
        "total_pts_a = 0\n",
        "total_ts_a = 0\n",
        "\n",
        "total_mp_b = 0\n",
        "total_pts_b = 0\n",
        "total_ts_b = 0\n",
        "mp_list_a = []\n",
        "mp_list_b = []\n",
        "\n",
        "# find total minutes a\n",
        "for row in player_a['MP']:\n",
        "  mp_list_a.append(row)\n",
        "  total_mp_a += row\n",
        "print(player_a.iat[0, 3], \"\\nminutes: \", total_mp_a)\n",
        "\n",
        "# find total PTS a\n",
        "i = 0\n",
        "for row in player_a['PTS']:\n",
        "  total_pts_a += row * (mp_list_a[i] / total_mp_a)\n",
        "  i = i + 1\n",
        "\n",
        "# find total TS+ a\n",
        "i = 0\n",
        "for row in player_a['TS%+']:\n",
        "  total_ts_a += row * (mp_list_a[i] / total_mp_a)\n",
        "  i = i + 1\n",
        "\n",
        "print(\"PTS per 75: \", total_pts_a)\n",
        "print(\"TS+: \",total_ts_a)\n",
        "\n",
        "# find total minutes\n",
        "for row in player_b['MP']:\n",
        "  mp_list_b.append(row)\n",
        "  total_mp_b += row\n",
        "print(\"\\n\")\n",
        "print(player_b.iat[0, 3], \"\\nminutes: \", total_mp_b)\n",
        "\n",
        "# find total PTS\n",
        "i = 0\n",
        "for row in player_b['PTS']:\n",
        "  total_pts_b += row * (mp_list_b[i] / total_mp_b)\n",
        "  i = i + 1\n",
        "\n",
        "# find total TS+\n",
        "i = 0\n",
        "for row in player_b['TS%+']:\n",
        "  total_ts_b += row * (mp_list_b[i] / total_mp_b)\n",
        "  i = i + 1\n",
        "\n",
        "print(\"PTS per 75: \", total_pts_b)\n",
        "print(\"TS+: \",total_ts_b)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M8yAW7WASwDX"
      },
      "outputs": [],
      "source": [
        "#@title def reg_playoff_comp(a, dfa, dfb) \n",
        "# def reg_playoff_comp(a, dfa, dfb) \n",
        "# print the change in scoring rate and effieciency for player from regular season, dfa, to postseason, dfb\n",
        "def reg_playoff_comp(a, dfa, dfb):\n",
        "\n",
        "  player_a = dfa[(dfa.Player == a)]\n",
        "  player_b = dfb[(dfb.Player == a)]\n",
        "  total_mp_a = 0\n",
        "  pts_list_a = []\n",
        "  ts_list_a = []\n",
        "\n",
        "  total_mp_b = 0\n",
        "  pts_list_b = []\n",
        "  ts_list_b = []\n",
        "\n",
        "  mp_list_a = []\n",
        "  mp_list_b = []\n",
        "\n",
        "\n",
        "  # find total PTS a\n",
        "  i = 0\n",
        "  for row in player_a['PTS']:\n",
        "    pts_list_a.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+ a\n",
        "  i = 0\n",
        "  for row in player_a['TS%+']:\n",
        "    ts_list_a.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total minutes\n",
        "  for row in player_b['MP']:\n",
        "    mp_list_b.append(row)\n",
        "    total_mp_b += row\n",
        "  print(\"\\n\")\n",
        "  print(player_b.iat[0, 3], \"\\nPlayoffs\\n\\nminutes: \", total_mp_b)\n",
        "\n",
        "  # find total PTS\n",
        "  i = 0\n",
        "  for row in player_b['PTS']:\n",
        "    pts_list_b.append(row)\n",
        "    i = i + 1\n",
        "\n",
        "  # find total TS+\n",
        "  i = 0\n",
        "  for row in player_b['TS%+']:\n",
        "    ts_list_b.append(row)\n",
        "    i = i + 1\n",
        "    j = i\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  total_pts = 0\n",
        "  total_ts = 0\n",
        "  while i <= j-1:\n",
        "    total_pts += ((pts_list_b[i] - pts_list_a[i]) * (mp_list_b[i] / total_mp_b))\n",
        "    print(pts_list_b[i] - pts_list_a[i])\n",
        "    print(((pts_list_b[i] - pts_list_a[i]) * (mp_list_b[i] / total_mp_b)))\n",
        "    total_ts += ((ts_list_b[i] - ts_list_a[i]) * (mp_list_b[i] / total_mp_b))\n",
        "    i = i + 1\n",
        "\n",
        "  print(\"\\n\\nRegular Season to Playoffs Change\\n\")\n",
        "  if total_pts > 0:\n",
        "    form_string = \"PTS per 75: +{}\".format(total_pts)\n",
        "    print(form_string)\n",
        "  else: \n",
        "    print(\"PTS per 75: \", total_pts)\n",
        "  if total_ts > 0:\n",
        "    form_string = \"TS+ {}\".format(total_ts)\n",
        "    print(form_string)\n",
        "  else:\n",
        "    print(\"TS+: \",total_ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ1Q1Vf25HB8"
      },
      "source": [
        "**SCORING PEAK FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NXifsLAWa2m_"
      },
      "outputs": [],
      "source": [
        "#@title Run Scoring Peaks\n",
        "\n",
        "# 2\n",
        "twoyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "twoyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('two_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 3 \n",
        "threeyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "threeyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('three_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 4 \n",
        "fouryearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "fouryearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('four_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 5 \n",
        "fiveyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "fiveyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('five_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 6 \n",
        "sixyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "sixyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('six_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 7 \n",
        "sevenyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "sevenyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('seven_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 8 \n",
        "eightyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "eightyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('eight_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 9 \n",
        "nineyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "nineyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('nine_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "# 10 \n",
        "tenyearpeak(era_opponent_adj_playoff_per_75_df, 'PTS')\n",
        "import_player_PTS_peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_player_PTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_PTS_data.csv\"\n",
        "import_player_PTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "tenyearpeak(era_opponent_adj_playoff_per_75_df, 'TS%+')\n",
        "import_player_TS_peaks_df = pd.read_csv('ten_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_player_TS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_TS%+_data.csv\"\n",
        "import_player_TS_peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "18EL_SvjcEnR"
      },
      "outputs": [],
      "source": [
        "#@title Import Scoring Peaks\n",
        "\n",
        "# 2\n",
        "import_adjpts_twopeaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_twopeaks_df = import_adjpts_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_twopeaks_df = pd.read_csv('two_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_twopeaks_df = import_adjts_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_twopeaks_df['TeamColor'] = import_adjpts_twopeaks_df['Team'].map(team_colors)\n",
        "import_adjts_twopeaks_df['TeamColor'] = import_adjts_twopeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_threepeaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_threepeaks_df = import_adjpts_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_threepeaks_df = pd.read_csv('three_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_threepeaks_df = import_adjts_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_threepeaks_df['TeamColor'] = import_adjpts_threepeaks_df['Team'].map(team_colors)\n",
        "import_adjts_threepeaks_df['TeamColor'] = import_adjts_threepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_4peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_4peaks_df = import_adjpts_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_4peaks_df = pd.read_csv('four_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_4peaks_df = import_adjts_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_4peaks_df['TeamColor'] = import_adjpts_4peaks_df['Team'].map(team_colors)\n",
        "import_adjts_4peaks_df['TeamColor'] = import_adjts_4peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_fivepeaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_fivepeaks_df = import_adjpts_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_fivepeaks_df = pd.read_csv('five_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_fivepeaks_df = import_adjts_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_fivepeaks_df['TeamColor'] = import_adjpts_fivepeaks_df['Team'].map(team_colors)\n",
        "import_adjts_fivepeaks_df['TeamColor'] = import_adjts_fivepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_6peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_6peaks_df = import_adjpts_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_6peaks_df = pd.read_csv('six_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_6peaks_df = import_adjts_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjts_6peaks_df['TeamColor'] = import_adjts_6peaks_df['Team'].map(team_colors)\n",
        "import_adjpts_6peaks_df['TeamColor'] = import_adjpts_6peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_7peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_7peaks_df = import_adjpts_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_7peaks_df = pd.read_csv('seven_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_7peaks_df = import_adjts_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjts_7peaks_df['TeamColor'] = import_adjts_7peaks_df['Team'].map(team_colors)\n",
        "import_adjpts_7peaks_df['TeamColor'] = import_adjpts_7peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_eightpeaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_eightpeaks_df = import_adjpts_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_eightpeaks_df = pd.read_csv('eight_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_eightpeaks_df = import_adjts_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_eightpeaks_df['TeamColor'] = import_adjpts_eightpeaks_df['Team'].map(team_colors)\n",
        "import_adjts_eightpeaks_df['TeamColor'] = import_adjts_eightpeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_9peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_9peaks_df = import_adjpts_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_9peaks_df = pd.read_csv('nine_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_9peaks_df = import_adjts_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_9peaks_df['TeamColor'] = import_adjpts_9peaks_df['Team'].map(team_colors)\n",
        "import_adjts_9peaks_df['TeamColor'] = import_adjts_9peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_adjpts_10peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "import_adjpts_10peaks_df = import_adjpts_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_adjts_10peaks_df = pd.read_csv('ten_year_peak_TS%+_data.csv', encoding='utf8')\n",
        "import_adjts_10peaks_df = import_adjts_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_adjpts_10peaks_df['TeamColor'] = import_adjpts_10peaks_df['Team'].map(team_colors)\n",
        "import_adjts_10peaks_df['TeamColor'] = import_adjts_10peaks_df['Team'].map(team_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Fo8KJtggdtZC"
      },
      "outputs": [],
      "source": [
        "#@title Output Scoring Peaks\n",
        "\n",
        "# 2\n",
        "at_least_400_min_2pts = import_adjpts_twopeaks_df[(import_adjpts_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2pts = at_least_400_min_2pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_2ts = import_adjts_twopeaks_df[(import_adjts_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2ts = at_least_400_min_2ts.reset_index(drop=True)\n",
        "\n",
        "sorted_2pts = at_least_400_min_2pts.copy()\n",
        "sorted_2pts.insert(6, \"TS+\", at_least_400_min_2ts['PeakValue'])\n",
        "sorted_2pts = sorted_2pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_2pts = sorted_2pts.sort_values('PTS', ascending=False)\n",
        "sorted_2pts = sorted_2pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_2pts = sorted_2pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_2pts['PTS'] = sorted_2pts['PTS'].round(2)\n",
        "sorted_2pts['TS+'] = sorted_2pts['TS+'].round(2)\n",
        "\n",
        "sorted_2pts = sorted_2pts.dropna()\n",
        "\n",
        "print(sorted_2pts)\n",
        "\n",
        "sorted_2pts.to_csv(\"Two_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 3\n",
        "at_least_400_min_pts = import_adjpts_threepeaks_df[(import_adjpts_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_pts = at_least_400_min_pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_ts = import_adjts_threepeaks_df[(import_adjts_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_ts = at_least_400_min_ts.reset_index(drop=True)\n",
        "\n",
        "sorted_3pts = at_least_400_min_pts.copy()\n",
        "sorted_3pts.insert(6, \"TS+\", at_least_400_min_ts['PeakValue'])\n",
        "sorted_3pts = sorted_3pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3pts = sorted_3pts.sort_values('PTS', ascending=False)\n",
        "sorted_3pts = sorted_3pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_3pts = sorted_3pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3pts['PTS'] = sorted_3pts['PTS'].round(2)\n",
        "sorted_3pts['TS+'] = sorted_3pts['TS+'].round(2)\n",
        "\n",
        "sorted_3pts = sorted_3pts.dropna()\n",
        "\n",
        "print(sorted_3pts)\n",
        "\n",
        "sorted_3pts.to_csv(\"Three_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 4\n",
        "at_least_400_min_pts = import_adjpts_4peaks_df[(import_adjpts_4peaks_df['MP'] >= 600)]\n",
        "at_least_400_min_pts = at_least_400_min_pts.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_ts = import_adjts_4peaks_df[(import_adjts_4peaks_df['MP'] >= 600)]\n",
        "at_least_400_min_ts = at_least_400_min_ts.reset_index(drop=True)\n",
        "\n",
        "sorted_3pts = at_least_400_min_pts.copy()\n",
        "sorted_3pts.insert(6, \"TS+\", at_least_400_min_ts['PeakValue'])\n",
        "sorted_3pts = sorted_3pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3pts = sorted_3pts.sort_values('PTS', ascending=False)\n",
        "sorted_3pts = sorted_3pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_3pts = sorted_3pts.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3pts['PTS'] = sorted_3pts['PTS'].round(2)\n",
        "sorted_3pts['TS+'] = sorted_3pts['TS+'].round(2)\n",
        "\n",
        "sorted_3pts = sorted_3pts.dropna()\n",
        "\n",
        "print(sorted_3pts)\n",
        "\n",
        "sorted_3pts.to_csv(\"Four_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 5\n",
        "at_least_800_min_pts = import_adjpts_fivepeaks_df[(import_adjpts_fivepeaks_df['MP'] >= 1000)]\n",
        "at_least_800_min_ts = import_adjts_fivepeaks_df[(import_adjts_fivepeaks_df['MP'] >= 1000)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Five_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 6\n",
        "at_least_800_min_pts = import_adjpts_6peaks_df[(import_adjpts_6peaks_df['MP'] >= 1200)]\n",
        "at_least_800_min_ts = import_adjts_6peaks_df[(import_adjts_6peaks_df['MP'] >= 1200)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Six_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 7\n",
        "at_least_800_min_pts = import_adjpts_7peaks_df[(import_adjpts_7peaks_df['MP'] >= 1400)]\n",
        "at_least_800_min_ts = import_adjts_7peaks_df[(import_adjts_7peaks_df['MP'] >= 1400)]\n",
        "\n",
        "\n",
        "sorted_5pts = at_least_800_min_pts.copy()\n",
        "sorted_5pts.insert(6, \"TS+\", at_least_800_min_ts['PeakValue'])\n",
        "sorted_5pts = sorted_5pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5pts = sorted_5pts.sort_values('PTS', ascending=False)\n",
        "sorted_5pts = sorted_5pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_5pts = sorted_5pts.reindex(columns=columns_titles)\n",
        "sorted_5pts = sorted_5pts.reset_index(drop=True)\n",
        "\n",
        "sorted_5pts['PTS'] = sorted_5pts['PTS'].round(2)\n",
        "sorted_5pts['TS+'] = sorted_5pts['TS+'].round(2)\n",
        "\n",
        "sorted_5pts = sorted_5pts.dropna()\n",
        "\n",
        "print(sorted_5pts)\n",
        "\n",
        "sorted_5pts.to_csv(\"Seven_Year_scoring_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 8\n",
        "at_least_1500_min_pts = import_adjpts_eightpeaks_df[(import_adjpts_eightpeaks_df['MP'] >= 1500)]\n",
        "at_least_1500_min_ts = import_adjts_eightpeaks_df[(import_adjts_eightpeaks_df['MP'] >= 1500)]\n",
        "\n",
        "\n",
        "sorted_8pts = at_least_1500_min_pts.copy()\n",
        "sorted_8pts.insert(6, \"TS+\", at_least_1500_min_ts['PeakValue'])\n",
        "sorted_8pts = sorted_8pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_8pts = sorted_8pts.sort_values('PTS', ascending=False)\n",
        "sorted_8pts = sorted_8pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_8pts = sorted_8pts.reindex(columns=columns_titles)\n",
        "sorted_8pts = sorted_8pts.reset_index(drop=True)\n",
        "\n",
        "sorted_8pts['PTS'] = sorted_8pts['PTS'].round(2)\n",
        "sorted_8pts['TS+'] = sorted_8pts['TS+'].round(2)\n",
        "\n",
        "sorted_8pts = sorted_8pts.dropna()\n",
        "\n",
        "\n",
        "print(sorted_8pts)\n",
        "\n",
        "sorted_8pts.to_csv(\"Eight_Year_scoring_Playoff_Peaks_1500min.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 9\n",
        "at_least_1500_min_pts = import_adjpts_9peaks_df[(import_adjpts_9peaks_df['MP'] >= 1700)]\n",
        "at_least_1500_min_ts = import_adjts_9peaks_df[(import_adjts_9peaks_df['MP'] >= 1700)]\n",
        "\n",
        "\n",
        "sorted_9pts = at_least_1500_min_pts.copy()\n",
        "sorted_9pts.insert(6, \"TS+\", at_least_1500_min_ts['PeakValue'])\n",
        "sorted_9pts = sorted_9pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_9pts = sorted_9pts.sort_values('PTS', ascending=False)\n",
        "sorted_9pts = sorted_9pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_9pts = sorted_9pts.reindex(columns=columns_titles)\n",
        "sorted_9pts = sorted_9pts.reset_index(drop=True)\n",
        "\n",
        "sorted_9pts['PTS'] = sorted_9pts['PTS'].round(2)\n",
        "sorted_9pts['TS+'] = sorted_9pts['TS+'].round(2)\n",
        "\n",
        "sorted_9pts = sorted_9pts.dropna()\n",
        "\n",
        "\n",
        "print(sorted_9pts)\n",
        "\n",
        "sorted_9pts.to_csv(\"Nine_Year_scoring_Playoff_Peaks_1700min.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "# 10\n",
        "at_least_2000_min_pts = import_adjpts_10peaks_df[(import_adjpts_10peaks_df['MP'] >= 2000)]\n",
        "at_least_2000_min_ts = import_adjts_10peaks_df[(import_adjts_10peaks_df['MP'] >= 2000)]\n",
        "\n",
        "\n",
        "sorted_10pts = at_least_2000_min_pts.copy()\n",
        "sorted_10pts.insert(6, \"TS+\", at_least_2000_min_ts['PeakValue'])\n",
        "sorted_10pts = sorted_10pts.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"TS+\": \"TS+\", \"G\": \"G\"})\n",
        "\n",
        "sorted_10pts = sorted_10pts.sort_values('PTS', ascending=False)\n",
        "sorted_10pts = sorted_10pts.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'PTS', 'TS+', 'MP', 'G']\n",
        "sorted_10pts = sorted_10pts.reindex(columns=columns_titles)\n",
        "sorted_10pts = sorted_10pts.reset_index(drop=True)\n",
        "sorted_10pts['PTS'] = sorted_10pts['PTS'].round(2)\n",
        "sorted_10pts['TS+'] = sorted_10pts['TS+'].round(2)\n",
        "\n",
        "sorted_10pts = sorted_10pts.dropna()\n",
        "\n",
        "print(sorted_10pts)\n",
        "\n",
        "sorted_10pts.to_csv(\"Ten_Year_scoring_Playoff_Peaks_2000min.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9leRo7p78g-t"
      },
      "source": [
        "**BPM PEAK FILES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w_maV6Oy-7B1"
      },
      "outputs": [],
      "source": [
        "#@title Run BPM Peaks\n",
        "twoyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('two_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "twoyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('two_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"two_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "# 3\n",
        "threeyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('three_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "threeyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('three_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"three_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#4\n",
        "fouryearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('four_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "fouryearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('four_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"four_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#5\n",
        "fiveyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('five_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "fiveyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('five_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"five_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#6\n",
        "sixyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('six_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "sixyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('six_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"six_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#7\n",
        "sevenyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('seven_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "sevenyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"seven_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#\n",
        "eightyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('eight_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "eightyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"eight_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#9\n",
        "nineyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('nine_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "nineyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "#10\n",
        "tenyearpeak(new_df, 'BPM')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('ten_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_BPM_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "tenyearpeak(new_df, 'OBPM')\n",
        "import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"ten_year_peak_OBPM_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XMGgOIAq70p1"
      },
      "outputs": [],
      "source": [
        "#@title Import BPM Peaks\n",
        "import_bpm_twopeaks_df = pd.read_csv('two_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_twopeaks_df = import_bpm_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_twopeaks_df = pd.read_csv('two_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_twopeaks_df = import_obpm_twopeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_twopeaks_df['TeamColor'] = import_bpm_twopeaks_df['Team'].map(team_colors)\n",
        "import_obpm_twopeaks_df['TeamColor'] = import_obpm_twopeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_threepeaks_df = pd.read_csv('three_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_threepeaks_df = import_bpm_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_threepeaks_df = pd.read_csv('three_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_threepeaks_df = import_obpm_threepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_threepeaks_df['TeamColor'] = import_bpm_threepeaks_df['Team'].map(team_colors)\n",
        "import_obpm_threepeaks_df['TeamColor'] = import_obpm_threepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_4peaks_df = pd.read_csv('four_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_4peaks_df = import_bpm_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_4peaks_df = pd.read_csv('four_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_4peaks_df = import_obpm_4peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_4peaks_df['TeamColor'] = import_bpm_4peaks_df['Team'].map(team_colors)\n",
        "import_obpm_4peaks_df['TeamColor'] = import_obpm_4peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_fivepeaks_df = pd.read_csv('five_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_fivepeaks_df = import_bpm_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_fivepeaks_df = pd.read_csv('five_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_fivepeaks_df = import_obpm_fivepeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_fivepeaks_df['TeamColor'] = import_bpm_fivepeaks_df['Team'].map(team_colors)\n",
        "import_obpm_fivepeaks_df['TeamColor'] = import_obpm_fivepeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_6peaks_df = pd.read_csv('six_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_6peaks_df = import_bpm_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_6peaks_df = pd.read_csv('six_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_6peaks_df = import_obpm_6peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_obpm_6peaks_df['TeamColor'] = import_obpm_6peaks_df['Team'].map(team_colors)\n",
        "import_bpm_6peaks_df['TeamColor'] = import_bpm_6peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_7peaks_df = pd.read_csv('seven_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_7peaks_df = import_bpm_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_7peaks_df = pd.read_csv('seven_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_7peaks_df = import_obpm_7peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_obpm_7peaks_df['TeamColor'] = import_obpm_7peaks_df['Team'].map(team_colors)\n",
        "import_bpm_7peaks_df['TeamColor'] = import_bpm_7peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_eightpeaks_df = pd.read_csv('eight_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_eightpeaks_df = import_bpm_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_eightpeaks_df = pd.read_csv('eight_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_eightpeaks_df = import_obpm_eightpeaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_eightpeaks_df['TeamColor'] = import_bpm_eightpeaks_df['Team'].map(team_colors)\n",
        "import_obpm_eightpeaks_df['TeamColor'] = import_obpm_eightpeaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_9peaks_df = pd.read_csv('nine_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_9peaks_df = import_bpm_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_9peaks_df = pd.read_csv('nine_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_9peaks_df = import_obpm_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_9peaks_df['TeamColor'] = import_bpm_9peaks_df['Team'].map(team_colors)\n",
        "import_obpm_9peaks_df['TeamColor'] = import_obpm_9peaks_df['Team'].map(team_colors)\n",
        "\n",
        "import_bpm_10peaks_df = pd.read_csv('ten_year_peak_BPM_data.csv', encoding='utf8')\n",
        "import_bpm_10peaks_df = import_bpm_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_obpm_10peaks_df = pd.read_csv('ten_year_peak_OBPM_data.csv', encoding='utf8')\n",
        "import_obpm_10peaks_df = import_obpm_10peaks_df.assign(TeamColor=0)\n",
        "\n",
        "# add team color for plotting\n",
        "import_bpm_10peaks_df['TeamColor'] = import_bpm_10peaks_df['Team'].map(team_colors)\n",
        "import_obpm_10peaks_df['TeamColor'] = import_obpm_10peaks_df['Team'].map(team_colors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7g56Mu1U8gL7"
      },
      "outputs": [],
      "source": [
        "#@title Output BPM Peaks\n",
        "\n",
        "at_least_400_min_2bpm = import_bpm_twopeaks_df[(import_bpm_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2bpm = at_least_400_min_2bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_2obpm = import_obpm_twopeaks_df[(import_obpm_twopeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_2obpm = at_least_400_min_2obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_2bpm = at_least_400_min_2bpm.copy()\n",
        "sorted_2bpm.insert(6, \"OBPM\", at_least_400_min_2obpm['PeakValue'])\n",
        "sorted_2bpm = sorted_2bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_2bpm = sorted_2bpm.sort_values('BPM', ascending=False)\n",
        "sorted_2bpm = sorted_2bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_2bpm = sorted_2bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_2bpm['BPM'] = sorted_2bpm['BPM'].round(2)\n",
        "sorted_2bpm['OBPM'] = sorted_2bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_2bpm = sorted_2bpm.dropna()\n",
        "\n",
        "print(sorted_2bpm)\n",
        "\n",
        "sorted_2bpm.to_csv(\"Two_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 3 year adjusted playoff scoring peaks (>= 400 min) Output File\n",
        "\n",
        "# 400 minutes filter\n",
        "at_least_400_min_bpm = import_bpm_threepeaks_df[(import_bpm_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_bpm = at_least_400_min_bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_obpm = import_obpm_threepeaks_df[(import_obpm_threepeaks_df['MP'] >= 300)]\n",
        "at_least_400_min_obpm = at_least_400_min_obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_3bpm = at_least_400_min_bpm.copy()\n",
        "sorted_3bpm.insert(6, \"OBPM\", at_least_400_min_obpm['PeakValue'])\n",
        "sorted_3bpm = sorted_3bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.sort_values('BPM', ascending=False)\n",
        "sorted_3bpm = sorted_3bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_3bpm = sorted_3bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3bpm['BPM'] = sorted_3bpm['BPM'].round(2)\n",
        "sorted_3bpm['OBPM'] = sorted_3bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.dropna()\n",
        "\n",
        "print(sorted_3bpm)\n",
        "\n",
        "sorted_3bpm.to_csv(\"Three_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 4 year adjusted playoff scoring peaks (>= 600 min) Output File\n",
        "\n",
        "# 400 minutes filter\n",
        "at_least_400_min_bpm = import_bpm_4peaks_df[(import_bpm_4peaks_df['MP'] >= 300)]\n",
        "at_least_400_min_bpm = at_least_400_min_bpm.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_obpm = import_obpm_4peaks_df[(import_obpm_4peaks_df['MP'] >= 300)]\n",
        "at_least_400_min_obpm = at_least_400_min_obpm.reset_index(drop=True)\n",
        "\n",
        "sorted_3bpm = at_least_400_min_bpm.copy()\n",
        "sorted_3bpm.insert(6, \"OBPM\", at_least_400_min_obpm['PeakValue'])\n",
        "sorted_3bpm = sorted_3bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.sort_values('BPM', ascending=False)\n",
        "sorted_3bpm = sorted_3bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_3bpm = sorted_3bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3bpm['BPM'] = sorted_3bpm['BPM'].round(2)\n",
        "sorted_3bpm['OBPM'] = sorted_3bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.dropna()\n",
        "\n",
        "print(sorted_3bpm)\n",
        "\n",
        "sorted_3bpm.to_csv(\"Four_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 5 year adjusted playoff scoring peaks (>=800 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_fivepeaks_df[(import_bpm_fivepeaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_fivepeaks_df[(import_obpm_fivepeaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Five_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 6 year adjusted playoff scoring peaks (>=1000 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_6peaks_df[(import_bpm_6peaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_6peaks_df[(import_obpm_6peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Six_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 7 year adjusted playoff scoring peaks (>=1200 min) Output File\n",
        "\n",
        "at_least_800_min_bpm = import_bpm_7peaks_df[(import_bpm_7peaks_df['MP'] >= 300)]\n",
        "at_least_800_min_obpm = import_obpm_7peaks_df[(import_obpm_7peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_5bpm = at_least_800_min_bpm.copy()\n",
        "sorted_5bpm.insert(6, \"OBPM\", at_least_800_min_obpm['PeakValue'])\n",
        "sorted_5bpm = sorted_5bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.sort_values('BPM', ascending=False)\n",
        "sorted_5bpm = sorted_5bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_5bpm = sorted_5bpm.reindex(columns=columns_titles)\n",
        "sorted_5bpm = sorted_5bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_5bpm['BPM'] = sorted_5bpm['BPM'].round(2)\n",
        "sorted_5bpm['OBPM'] = sorted_5bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_5bpm = sorted_5bpm.dropna()\n",
        "\n",
        "print(sorted_5bpm)\n",
        "\n",
        "sorted_5bpm.to_csv(\"Seven_Year_BPM_Playoff_Peaks.csv\", index=False)\n",
        "\n",
        "#@title 8 year adjusted playoff scoring peaks (>=1500 min) Output File\n",
        "\n",
        "at_least_1500_min_bpm = import_bpm_eightpeaks_df[(import_bpm_eightpeaks_df['MP'] >= 300)]\n",
        "at_least_1500_min_obpm = import_obpm_eightpeaks_df[(import_obpm_eightpeaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_8bpm = at_least_1500_min_bpm.copy()\n",
        "sorted_8bpm.insert(6, \"OBPM\", at_least_1500_min_obpm['PeakValue'])\n",
        "sorted_8bpm = sorted_8bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_8bpm = sorted_8bpm.sort_values('BPM', ascending=False)\n",
        "sorted_8bpm = sorted_8bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_8bpm = sorted_8bpm.reindex(columns=columns_titles)\n",
        "sorted_8bpm = sorted_8bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_8bpm['BPM'] = sorted_8bpm['BPM'].round(2)\n",
        "sorted_8bpm['OBPM'] = sorted_8bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_8bpm = sorted_8bpm.dropna()\n",
        "\n",
        "\n",
        "print(sorted_8bpm)\n",
        "\n",
        "sorted_8bpm.to_csv(\"Eight_Year_BPM_Playoff_Peaks_1500min.csv\", index=False)\n",
        "\n",
        "#@title 9 year adjusted playoff scoring peaks (>=1700 min) Output File\n",
        "\n",
        "at_least_1500_min_bpm = import_bpm_9peaks_df[(import_bpm_9peaks_df['MP'] >= 300)]\n",
        "at_least_1500_min_obpm = import_obpm_9peaks_df[(import_obpm_9peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_9bpm = at_least_1500_min_bpm.copy()\n",
        "sorted_9bpm.insert(6, \"OBPM\", at_least_1500_min_obpm['PeakValue'])\n",
        "sorted_9bpm = sorted_9bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_9bpm = sorted_9bpm.sort_values('BPM', ascending=False)\n",
        "sorted_9bpm = sorted_9bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_9bpm = sorted_9bpm.reindex(columns=columns_titles)\n",
        "sorted_9bpm = sorted_9bpm.reset_index(drop=True)\n",
        "\n",
        "sorted_9bpm['BPM'] = sorted_9bpm['BPM'].round(2)\n",
        "sorted_9bpm['OBPM'] = sorted_9bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_9bpm = sorted_9bpm.dropna()\n",
        "\n",
        "\n",
        "print(sorted_9bpm)\n",
        "\n",
        "sorted_9bpm.to_csv(\"Nine_Year_BPM_Playoff_Peaks_1700min.csv\", index=False)\n",
        "\n",
        "#@title 10 year adjusted playoff scoring peaks (>=2000 min) Output File\n",
        "\n",
        "at_least_2000_min_bpm = import_bpm_10peaks_df[(import_bpm_10peaks_df['MP'] >= 300)]\n",
        "at_least_2000_min_obpm = import_obpm_10peaks_df[(import_obpm_10peaks_df['MP'] >= 300)]\n",
        "\n",
        "\n",
        "sorted_10bpm = at_least_2000_min_bpm.copy()\n",
        "sorted_10bpm.insert(6, \"OBPM\", at_least_2000_min_obpm['PeakValue'])\n",
        "sorted_10bpm = sorted_10bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"BPM\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"OBPM\": \"OBPM\", \"G\": \"G\"})\n",
        "\n",
        "sorted_10bpm = sorted_10bpm.sort_values('BPM', ascending=False)\n",
        "sorted_10bpm = sorted_10bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'BPM', 'OBPM', 'MP', 'G']\n",
        "sorted_10bpm = sorted_10bpm.reindex(columns=columns_titles)\n",
        "sorted_10bpm = sorted_10bpm.reset_index(drop=True)\n",
        "sorted_10bpm['BPM'] = sorted_10bpm['BPM'].round(2)\n",
        "sorted_10bpm['OBPM'] = sorted_10bpm['OBPM'].round(2)\n",
        "\n",
        "sorted_10bpm = sorted_10bpm.dropna()\n",
        "\n",
        "print(sorted_10bpm)\n",
        "\n",
        "sorted_10bpm.to_csv(\"Ten_Year_BPM_Playoff_Peaks_2000min.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PBP PEAK FILES**"
      ],
      "metadata": {
        "id": "s1nOyA7_9oGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run PBP Peaks\n",
        "nineyearpeak(import_player_since74playoffs_playbyplay_df, 'OnCourt')\n",
        "import_player_longPTS_peaks_df = pd.read_csv('nine_year_peak_OnCourt_data.csv', encoding='utf8')\n",
        "import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_OnCourt_data.csv\"\n",
        "import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "nineyearpeak(import_player_since74playoffs_playbyplay_df, 'On-Off')\n",
        "import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_On-Off_data.csv', encoding='utf8')\n",
        "import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "outfile = f\"nine_year_peak_On-Off_data.csv\"\n",
        "import_player_longTS_peaks_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "id": "vdNvzeQ39nct",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import PBP Peaks\n",
        "import_oncourt_9peaks_df = pd.read_csv('nine_year_peak_OnCourt_data.csv', encoding='utf8')\n",
        "import_oncourt_9peaks_df = import_oncourt_9peaks_df.assign(TeamColor=0)\n",
        "\n",
        "import_onoff_9peaks_df = pd.read_csv('nine_year_peak_On-Off_data.csv', encoding='utf8')\n",
        "import_onoff_9peaks_df = import_onoff_9peaks_df.assign(TeamColor=0)"
      ],
      "metadata": {
        "id": "KrW6tABC98im",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Output PBP Peaks\n",
        "\n",
        "at_least_400_min_oncourt = import_oncourt_9peaks_df[(import_oncourt_9peaks_df['MP'] >= 3000)]\n",
        "at_least_400_min_oncourt = at_least_400_min_oncourt.reset_index(drop=True)\n",
        "\n",
        "at_least_400_min_onoff = import_onoff_9peaks_df[(import_onoff_9peaks_df['MP'] >= 3000)]\n",
        "at_least_400_min_onoff = at_least_400_min_onoff.reset_index(drop=True)\n",
        "\n",
        "sorted_3bpm = at_least_400_min_oncourt.copy()\n",
        "sorted_3bpm.insert(6, \"On-Off\", at_least_400_min_onoff['PeakValue'])\n",
        "sorted_3bpm = sorted_3bpm.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"Team\": \"Team\", \"PeakValue\": \"OnCourt\", \"MP\": \"MP\", \"TeamColor\": \"TeamColor\", \"On-Off\": \"On-Off\", \"G\": \"G\"})\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.sort_values('On-Off', ascending=False)\n",
        "sorted_3bpm = sorted_3bpm.drop(columns=['TeamColor'])\n",
        "\n",
        "columns_titles = ['Player', 'Years', 'Team', 'On-Off', 'OnCourt', 'MP', 'G']\n",
        "sorted_3bpm = sorted_3bpm.reindex(columns=columns_titles)\n",
        "\n",
        "sorted_3bpm['On-Off'] = sorted_3bpm['On-Off'].round(2)\n",
        "sorted_3bpm['OnCourt'] = sorted_3bpm['OnCourt'].round(2)\n",
        "\n",
        "sorted_3bpm = sorted_3bpm.dropna()\n",
        "\n",
        "print(sorted_3bpm)\n",
        "\n",
        "sorted_3bpm.to_csv(\"Nine_Year_pbp_Playoff_Peaks_3000_min.csv\", index=False)"
      ],
      "metadata": {
        "id": "qa_aFfXc-Ts6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape NBA playoffs series possession data\n",
        "def scrape_nba_player_series_data(url, player, player_ref):\n",
        "                       \n",
        "  wd.get(url)   \n",
        "  html = wd.page_source\n",
        "  soup = BeautifulSoup(html, features=\"lxml\")\n",
        "  time.sleep(10)\n",
        "\n",
        "  for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "          second_div = first_div.find('div', attrs={'id': 'div_other_scores'})\n",
        "          hrefs = second_div.findAll('td', attrs={'class': 'right gamelink'})\n",
        "          hrefs = str(hrefs)\n",
        "          ref_urls = re.findall(r'/\\d+\\w+\\D\\w+', hrefs)\n",
        "          urls = []\n",
        "          for ref_url in ref_urls:\n",
        "            ref_url = \"https://www.basketball-reference.com/boxscores/pbp\" + ref_url\n",
        "            urls.append(ref_url)\n",
        "  def_possessions = 0\n",
        "  missing_poss = 0\n",
        "  for game_url in urls:\n",
        "\n",
        "    wd.get(game_url)   \n",
        "    html = wd.page_source\n",
        "    soup = BeautifulSoup(html, features=\"lxml\")\n",
        "\n",
        "    for first_div in soup.find_all('div', attrs={'id': 'content'}):\n",
        "            second_div = first_div.find('div', attrs={'id': 'all_pbp'})\n",
        "            first_table = second_div.find('table', attrs={'id': 'pbp'})\n",
        "            body = first_table.find('tbody')\n",
        "    # grab rows\n",
        "    rows = body.findAll('tr')[0:]\n",
        "\n",
        "    \n",
        "\n",
        "    total_poss = 0\n",
        "    player_out_wait = 0\n",
        "    beg_q = 0\n",
        "    extra_poss = 0\n",
        "    non_shooting = 0\n",
        "\n",
        "\n",
        "    possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "    fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "    player_out = [f'enters the game for <a href=\"{player_ref}\">{player}']\n",
        "    player_in = [f'{player}']\n",
        "\n",
        "    hes_back_but_subtly = [f'{player}</a> misses 2-pt']\n",
        "    for row in rows:\n",
        "      row = str(row)\n",
        "\n",
        "\n",
        "      if player_out_wait == 1:\n",
        "        if f'{player}</a> misses 2-pt' in row:\n",
        "          total_poss = total_poss + extra_poss\n",
        "          extra_poss = 0\n",
        "          player_out_wait = 0\n",
        "          beg_q = 0\n",
        "\n",
        "      if 'Q' in row:\n",
        "        beg_q = 1\n",
        "\n",
        "      if any(iny in row for iny in player_in):\n",
        "        player_out_wait = 0\n",
        "      if any(outy in row for outy in player_out):\n",
        "        player_out_wait = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in fts_no_shooting_foul) and player_out_wait == 0 and non_shooting == 1):\n",
        "        total_poss = total_poss + 1\n",
        "\n",
        "      if ('foul' in row and 'Shooting' not in row):\n",
        "        non_shooting = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "        total_poss = total_poss + 1\n",
        "        non_shooting = 0\n",
        "      \n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 1 and beg_q == 1):\n",
        "        extra_poss = extra_poss + 1\n",
        "        non_shooting = 0\n",
        "      \n",
        "    missing_poss = missing_poss + total_poss\n",
        "\n",
        "    #@title Default possessions\n",
        "\n",
        "    total_poss = 0\n",
        "    player_out_wait = 0\n",
        "    extra_poss = 0\n",
        "\n",
        "\n",
        "    possession_enders = ['Defensive rebound', 'makes 2-pt', 'makes 3-pt', 'Turnover', 'Shooting foul']\n",
        "    fts_no_shooting_foul = ['free throw 1 of 2']\n",
        "\n",
        "    player_out = [f'enters the game for <a href=\"{player_ref}\">{player}']\n",
        "    player_in = [f'{player}']\n",
        "\n",
        "    hes_back_but_subtly = [f'{player}</a> misses 2-pt']\n",
        "\n",
        "    for row in rows:\n",
        "      row = str(row)\n",
        "\n",
        "      if any(iny in row for iny in player_in):\n",
        "        player_out_wait = 0\n",
        "      if any(outy in row for outy in player_out):\n",
        "        player_out_wait = 1\n",
        "\n",
        "      if (any(end_poss in row for end_poss in possession_enders) and player_out_wait == 0):\n",
        "        total_poss = total_poss + 1\n",
        "    def_possessions = def_possessions + total_poss\n",
        "  print(\"Total Default:\")\n",
        "  print(def_possessions/2)\n",
        "  print(\"\\nTotal Missing:\")\n",
        "  print(missing_poss/2)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ij-9Pa2Tz-Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_nba_player_series_data(\"https://www.basketball-reference.com/playoffs/1998-nba-western-conference-semifinals-spurs-vs-jazz.html\", 'T. Duncan', '/players/d/duncati01.html')"
      ],
      "metadata": {
        "id": "kgQg5nhsbpPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0608b5-eefe-405a-fbb9-ce553cec1598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Default:\n",
            "354.5\n",
            "\n",
            "Total Missing:\n",
            "371.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "five = pd.read_csv('/content/Single_Playoffs_Adjusted_Scoring.csv')\n",
        "five['MP'] = five['MP'].astype(int)\n",
        "five['PTS per 75'] = five['PTS per 75'].round(2)\n",
        "five = five.sort_values('Year', ascending=True)\n",
        "\n",
        "five = five[(five['Player'] == 'Lou Williams')]\n",
        "print(five)\n",
        "\n",
        "outfile = f\"top_scorers.csv\"\n",
        "five.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "id": "sTiMB6Xt1iB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xD45xeb_1zE"
      },
      "source": [
        "**PEAK FUNCTION DEFINITIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WKanZbn6ABM9"
      },
      "outputs": [],
      "source": [
        "#@title 2 year peaks function\n",
        "\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '777' '15'\n",
        "def twoyearpeak(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = 0\n",
        "    prev_min = 0\n",
        "    prev_g = 0\n",
        "    prevYearTeam = 0\n",
        "    prevyear = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + prev_g\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back * (prev_min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prev_back = 0\n",
        "            prev_min = 0\n",
        "            prev_g = 0\n",
        "            prevYearTeam = 0\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 2 consecutive seasons\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear , present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+2 and len(indexlist) >=2:\n",
        "            two_seasons_count = player['Year']\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back = inner_row[valuestring]\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prev_min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "            prev_g = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            prev_back = inner_row[valuestring]\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prev_min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "            prev_g = inner_row['G']\n",
        "\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 2:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and prevYearTeam == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_two_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_two_year_peak_val, running_min, games]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "            outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "            two_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XTmZzNX7_UBG"
      },
      "outputs": [],
      "source": [
        "#@title 3 year peaks function\n",
        "\n",
        "# def threeyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 3 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 3 year stretches of 'valuestring' AND the listed years from each 3 year stretch + minutes played across the 3 seasons.\n",
        "# EX: threeyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-20', 'Kris Middleton', 'MIL' '23.32', '712' '22'\n",
        "def threeyearpeak(df, valuestring):\n",
        "  three_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 3 year peaks); begin as 0's\n",
        "    for i in range(0, 2):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    three_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_three_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_three_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[1]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 2):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons\n",
        "          if present_year >= original_year+2 and len(indexlist) >=3:\n",
        "            if (prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[1] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}'.format(prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if three_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            three_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 1\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 1\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          three_seasons_count = three_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 3:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_three_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_three_year_peak_val, running_min, games]], columns=cols)\n",
        "            three_year_peak = three_year_peak.append(df_temp)\n",
        "            outfile = f\"three_year_peak_{valuestring}_data.csv\"\n",
        "            three_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5Syc_qCO-cpI"
      },
      "outputs": [],
      "source": [
        "#@title 4 year peaks function\n",
        "\n",
        "# def fouryearpeak(df, valuestring):\n",
        "# returns a dataframe containing 4 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 4 year stretches of 'valuestring' AND the listed years from each 4 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fouryearpeak(import_player_since74_per100_df, 'PTS') returns 4 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-19', 'Kris Middleton', 'MIL' '22.11', '1213' '28'\n",
        "def fouryearpeak(df, valuestring):\n",
        "  four_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 4 year peaks); begin as 0's\n",
        "    for i in range(0, 3):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    four_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_four_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_four_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[2]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 3):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 4 consecutive seasons\n",
        "          if present_year >= original_year+3 and len(indexlist) >=4:\n",
        "            if (prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[2] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}'.format(prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if four_seasons_count == original_year+4 and len(indexlist) >=4:\n",
        "            four_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 2\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 2\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          four_seasons_count = four_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 4:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_four_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_four_year_peak_val, running_min, games]], columns=cols)\n",
        "            four_year_peak = four_year_peak.append(df_temp)\n",
        "            outfile = f\"four_year_peak_{valuestring}_data.csv\"\n",
        "            four_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iAmiC4OO9Ypf"
      },
      "outputs": [],
      "source": [
        "#@title 5 year peaks function\n",
        "\n",
        "# def fiveyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 5 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 5 year stretches of 'valuestring' AND the listed years from each 5 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 5 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-20', 'Kris Middleton', 'MIL' '22.11', '1639 '34'\n",
        "def fiveyearpeak(df, valuestring):\n",
        "  five_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 5 year peaks); begin as 0's\n",
        "    for i in range(0, 4):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    five_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_five_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_five_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[3]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 4):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 5 consecutive seasons\n",
        "          if present_year >= original_year+4 and len(indexlist) >=5:\n",
        "            if (prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[3] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}'.format(prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if five_seasons_count == original_year+5 and len(indexlist) >=5:\n",
        "            five_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 3\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 3\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          five_seasons_count = five_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 5:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_five_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_five_year_peak_val, running_min, games]], columns=cols)\n",
        "            five_year_peak = five_year_peak.append(df_temp)\n",
        "            outfile = f\"five_year_peak_{valuestring}_data.csv\"\n",
        "            five_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OdOIKhKi8z_t"
      },
      "outputs": [],
      "source": [
        "#@title 6 year peaks function\n",
        "\n",
        "# def sixyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 6 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 6 year stretches of 'valuestring' AND the listed years from each 6 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 6 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-21', 'Kris Middleton', 'MIL' '22.11', '1119' '46'\n",
        "def sixyearpeak(df, valuestring):\n",
        "  six_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 6 year peaks); begin as 0's\n",
        "    for i in range(0, 5):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    six_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_six_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_six_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[4]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 5):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 6 consecutive seasons\n",
        "          if present_year >= original_year+5 and len(indexlist) >=6:\n",
        "            if (prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[4] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}'.format(prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if six_seasons_count == original_year+6 and len(indexlist) >=6:\n",
        "            six_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 4\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 4\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          six_seasons_count = six_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 6:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_six_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_six_year_peak_val, running_min, games]], columns=cols)\n",
        "            six_year_peak = six_year_peak.append(df_temp)\n",
        "            outfile = f\"six_year_peak_{valuestring}_data.csv\"\n",
        "            six_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4rrbqSWm8Mvn"
      },
      "outputs": [],
      "source": [
        "#@title 7 year peaks function\n",
        "\n",
        "# def sevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 7 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 7 year stretches of 'valuestring' AND the listed years from each 7 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 7 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-22', 'Kris Middleton', 'MIL' '22.11', '1467' '66'\n",
        "def sevenyearpeak(df, valuestring):\n",
        "  seven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 7 year peaks); begin as 0's\n",
        "    for i in range(0, 6):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    seven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_seven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_seven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[5]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 6):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 7 consecutive seasons\n",
        "          if present_year >= original_year+6 and len(indexlist) >=7:\n",
        "            if (prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[5] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}'.format(prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if seven_seasons_count == original_year+7 and len(indexlist) >=7:\n",
        "            seven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 5\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 5\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          seven_seasons_count = seven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 7:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_seven_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_seven_year_peak_val, running_min, games]], columns=cols)\n",
        "            seven_year_peak = seven_year_peak.append(df_temp)\n",
        "            outfile = f\"seven_year_peak_{valuestring}_data.csv\"\n",
        "            seven_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A4a_yTqH7Z8f"
      },
      "outputs": [],
      "source": [
        "#@title 8 year peaks function\n",
        "\n",
        "# def eightyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 8 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 8 year stretches of 'valuestring' AND the listed years from each 8 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 8 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2013-20', 'Kris Middleton', 'MIL' '22.11', '2139' '66'\n",
        "def eightyearpeak(df, valuestring):\n",
        "  eight_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 8 year peaks); begin as 0's\n",
        "    for i in range(0, 7):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eight_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_eight_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_eight_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[6]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 7):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 8 consecutive seasons\n",
        "          if present_year >= original_year+7 and len(indexlist) >=8:\n",
        "            if (prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[6] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if eight_seasons_count == original_year+8 and len(indexlist) >=8:\n",
        "            eight_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 6\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 6\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          eight_seasons_count = eight_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 8:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_eight_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_eight_year_peak_val, running_min, games]], columns=cols)\n",
        "            eight_year_peak = eight_year_peak.append(df_temp)\n",
        "            outfile = f\"eight_year_peak_{valuestring}_data.csv\"\n",
        "            eight_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CTS30J-_32LS"
      },
      "outputs": [],
      "source": [
        "#@title 9 year peaks function\n",
        "\n",
        "# def nineyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 9 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 9 year stretches of 'valuestring' AND the listed years from each 9 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 9 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2012-20', 'Kris Middleton', 'MIL' '22.11', '2585' '66'\n",
        "def nineyearpeak(df, valuestring):\n",
        "  nine_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 9 year peaks); begin as 0's\n",
        "    for i in range(0, 8):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    nine_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_nine_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_nine_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)) + (prev_back[7] * (prev_min[7] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[7]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 8):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 9 consecutive seasons\n",
        "          if present_year >= original_year+8 and len(indexlist) >=9:\n",
        "            if (prevyear[7]  == (prevyear[6] - 1) and prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[7] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[7] , prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if nine_seasons_count == original_year+9 and len(indexlist) >=9:\n",
        "            nine_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 7\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 7\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          nine_seasons_count = nine_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 9:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[7] and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_nine_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_nine_year_peak_val, running_min, games]], columns=cols)\n",
        "            nine_year_peak = nine_year_peak.append(df_temp)\n",
        "            outfile = f\"nine_year_peak_{valuestring}_data.csv\"\n",
        "            nine_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wJUmrKQyZ7yv"
      },
      "outputs": [],
      "source": [
        "#@title 10 year peaks function\n",
        "\n",
        "# def tenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '2976', '76'\n",
        "def tenyearpeak(df, valuestring):\n",
        "  ten_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous seasons' values\n",
        "    prev_back = []\n",
        "    prev_min = []\n",
        "    prev_g = []\n",
        "    prevYearTeam = []\n",
        "    prevyear = []\n",
        "\n",
        "    # store values from previous seasons (relevant in formulating 10 year peaks); begin as 0's\n",
        "    for i in range(0, 9):\n",
        "      prev_back.append(0)\n",
        "      prev_min.append(0)\n",
        "      prev_g.append(0)\n",
        "      prevYearTeam.append(0)\n",
        "      prevyear.append(0)\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    ten_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    indexlist = []\n",
        "    running_ten_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + sum(prev_min))\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          games = inner_row['G'] + sum(prev_g)\n",
        "          running_ten_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_back[0] * (prev_min[0] / running_min)) + (prev_back[1] * (prev_min[1] / running_min)) + (prev_back[2] * (prev_min[2] / running_min)) + (prev_back[3] * (prev_min[3] / running_min)) + (prev_back[4] * (prev_min[4] / running_min)) + (prev_back[5] * (prev_min[5] / running_min)) + (prev_back[6] * (prev_min[6] / running_min)) + (prev_back[7] * (prev_min[7] / running_min)) + (prev_back[8] * (prev_min[8] / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam[8]\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            for i in range(0, 9):\n",
        "              prev_back.append(0)\n",
        "              prev_min.append(0)\n",
        "              prev_g.append(0)\n",
        "              prevYearTeam.append(0)\n",
        "            indexlist = []\n",
        "\n",
        "          # can finally store years as this player has had 10 consecutive seasons\n",
        "          if present_year >= original_year+9 and len(indexlist) >=10:\n",
        "            if (prevyear[8] == (prevyear[7] - 1) and prevyear[7]  == (prevyear[6] - 1) and prevyear[6]  == (prevyear[5] - 1) and prevyear[5]  == (prevyear[4] - 1) and prevyear[4]  == (prevyear[3] - 1) and prevyear[3]  == (prevyear[2] - 1) and prevyear[2]  == (prevyear[1] - 1) and prevyear[1]  == (prevyear[0] - 1) and prevyear[0]  == (present_year - 1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear[8] , present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prevyear[8] , prevyear[7] , prevyear[6] , prevyear[5] , prevyear[4] , prevyear[3] , prevyear[2] , prevyear[1] , prevyear[0] , present_year)\n",
        "\n",
        "          if ten_seasons_count == original_year+10 and len(indexlist) >=10:\n",
        "            ten_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            i = 8\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "\n",
        "          if present_year == original_year:\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "          if present_year > original_year:\n",
        "            i = 8\n",
        "            while i >= 1:\n",
        "              prev_back[i] = prev_back[i-1]\n",
        "              prevYearTeam[i] = prevYearTeam[i-1]\n",
        "              prev_min[i] = prev_min[i-1]\n",
        "              prevyear[i] = prevyear[i-1]\n",
        "              prev_g[i] = prev_g[i-1]\n",
        "              i = i - 1\n",
        "            prev_back[0] = inner_row[valuestring]\n",
        "            prevYearTeam[0] = inner_row['Tm']\n",
        "            prev_min[0] = inner_row['MP']\n",
        "            prevyear[0] = inner_row['Year']\n",
        "            prev_g[0] = inner_row['G']\n",
        "\n",
        "          ten_seasons_count = ten_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >= 10:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP', 'G']\n",
        "            running_min = int(running_min)\n",
        "            games = int(games)\n",
        "            if (inner_row['Tm'] == old_team and inner_row['Tm'] == prevYearTeam[7] and inner_row['Tm'] == prevYearTeam[6] and inner_row['Tm'] == prevYearTeam[5] and inner_row['Tm'] == prevYearTeam[4] and inner_row['Tm'] == prevYearTeam[3] and inner_row['Tm'] == prevYearTeam[2] and inner_row['Tm'] == prevYearTeam[1] and prevYearTeam[0] == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_ten_year_peak_val, running_min, games]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_ten_year_peak_val, running_min, games]], columns=cols)\n",
        "            ten_year_peak = ten_year_peak.append(df_temp)\n",
        "            outfile = f\"ten_year_peak_{valuestring}_data.csv\"\n",
        "            ten_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjnG8CpstskX"
      },
      "source": [
        "**SMALL USE CASE PEAK FUNCTION DEFINITIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oAcCFD7_sNPw"
      },
      "outputs": [],
      "source": [
        "#@title 2 year fragmented peaks function\n",
        "\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '4231'\n",
        "def fragtwoyearpeak(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'Team', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes played\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = [0, 0]\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # store team player played on a season and 2 seasons ago in case they change teams during peak 3 years.\n",
        "    prevyear = 0\n",
        "    prevYearTeam = 0\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "          old_team = prevYearTeam\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevYearTeam = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prevyear = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 2 consecutive seasons (not reached after 2 rows of a player is found)\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear, present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+2 and len(indexlist) >=2:\n",
        "            two_seasons_count = player['Year']\n",
        "\n",
        "          # move present value to previous year's value\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevYearTeam = inner_row['Tm']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=2:\n",
        "            cols = ['Years', 'Player', 'Team', 'PeakValue', 'MP']\n",
        "            if (old_team == inner_row['Tm']):\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], inner_row['Tm'], running_two_year_peak_val, running_min]], columns=cols)\n",
        "            else:\n",
        "                df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], 'TOT', running_two_year_peak_val, running_min]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "            outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "            two_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jTUzLULMfPWF"
      },
      "outputs": [],
      "source": [
        "#@title Manual Data Peak Functions\n",
        "\n",
        "# def twoyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 2 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 2 year stretches of 'valuestring' AND the listed years from each 2 year stretch + minutes played across the 2 seasons.\n",
        "# EX: twoyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-19', 'Kris Middleton', 'MIL' '23.32', '4231'\n",
        "def twoyearpeak_manual_data(df, valuestring):\n",
        "  two_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    two_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # store the team a player played with 1 season and 2 seasons ago in case they change teams during peak 3 years.\n",
        "\n",
        "    prevyear = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_two_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    old_team = 0\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_two_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+1 and len(indexlist) >=2:\n",
        "            if (prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prevyear, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}'.format(prevyear, present_year)\n",
        "\n",
        "          if two_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            two_seasons_count = player['Year']\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          two_seasons_count = two_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=2:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_two_year_peak_val, running_min]], columns=cols)\n",
        "            two_year_peak = two_year_peak.append(df_temp)\n",
        "            outfile = f\"two_year_peak_{valuestring}_data.csv\"\n",
        "            two_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 3 year peaks (manual data) function\n",
        "\n",
        "# def threeyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 3 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 3 year stretches of 'valuestring' AND the listed years from each 3 year stretch + minutes played across the 3 seasons.\n",
        "# EX: threeyearpeak(import_player_since74_per100_df, 'PTS') returns 3 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2018-20', 'Kris Middleton', 'MIL' '23.32', '7120'\n",
        "def threeyearpeak_manual_data(df, valuestring):\n",
        "  three_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue and minutes\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue and minutes\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    three_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    # previous two years; e.g. 2014, 2015 before 2016. 2016, 2019 if these were the two most recent seasons for a player before 2020.\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "\n",
        "    indexlist = []\n",
        "    running_three_year_peak_val = 0\n",
        "    running_min = 0\n",
        "    games = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_three_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+2 and len(indexlist) >=3:\n",
        "            if (prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev2year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}'.format(prev2year, prevyear, present_year)\n",
        "\n",
        "          if three_seasons_count == original_year+3 and len(indexlist) >=3:\n",
        "            three_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          three_seasons_count = three_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=3:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_three_year_peak_val, running_min]], columns=cols)\n",
        "            three_year_peak = three_year_peak.append(df_temp)\n",
        "            outfile = f\"three_year_peak_{valuestring}_data.csv\"\n",
        "            three_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 4 year peaks (manual data) function\n",
        "\n",
        "# returns a dataframe containing 4 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 4 year stretches of 'valuestring' AND the listed years from each 4 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 4 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-19', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def fouryearpeak_manual_data(df, valuestring):\n",
        "  four_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    four_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_four_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_four_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+3 and len(indexlist) >=4:\n",
        "            if (prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev3year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}'.format(prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if four_seasons_count == original_year+4 and len(indexlist) >=4:\n",
        "            four_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          four_seasons_count = four_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=4:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_four_year_peak_val, running_min]], columns=cols)\n",
        "            four_year_peak = four_year_peak.append(df_temp)\n",
        "            outfile = f\"four_year_peak_{valuestring}_data.csv\"\n",
        "            four_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 5 year peaks (manual data) function\n",
        "\n",
        "# def fiveyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 5 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 5 year stretches of 'valuestring' AND the listed years from each 5 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 5 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def fiveyearpeak_manual_data(df, valuestring):\n",
        "  five_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    five_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_five_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_five_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+4 and len(indexlist) >=5:\n",
        "            if (prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev4year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}'.format(prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if five_seasons_count == original_year+5 and len(indexlist) >=5:\n",
        "            five_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          five_seasons_count = five_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=5:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_five_year_peak_val, running_min]], columns=cols)\n",
        "            five_year_peak = five_year_peak.append(df_temp)\n",
        "            outfile = f\"five_year_peak_{valuestring}_data.csv\"\n",
        "            five_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 6 year peaks (manual data) function\n",
        "\n",
        "# def sixyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 6 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 6 year stretches of 'valuestring' AND the listed years from each 6 year stretch + minutes played across the 5 seasons.\n",
        "# EX: sixyearpeak(import_player_since74_per100_df, 'PTS') returns 6 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2016-21', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def sixyearpeak_manual_data(df, valuestring):\n",
        "  six_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    six_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_six_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_six_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+5 and len(indexlist) >=6:\n",
        "            if (prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev5year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}'.format(prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if six_seasons_count == original_year+6 and len(indexlist) >=6:\n",
        "            six_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          six_seasons_count = six_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=6:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_six_year_peak_val, running_min]], columns=cols)\n",
        "            six_year_peak = six_year_peak.append(df_temp)\n",
        "            outfile = f\"six_year_peak_{valuestring}_data.csv\"\n",
        "            six_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 7 year peaks (manual data) function\n",
        "\n",
        "# def sevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def sevenyearpeak_manual_data(df, valuestring):\n",
        "  seven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    seven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_seven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_seven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+6 and len(indexlist) >=7:\n",
        "            if (prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev6year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}'.format(prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if seven_seasons_count == original_year+7 and len(indexlist) >=7:\n",
        "            seven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          seven_seasons_count = seven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=7:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_seven_year_peak_val, running_min]], columns=cols)\n",
        "            seven_year_peak = seven_year_peak.append(df_temp)\n",
        "            outfile = f\"seven_year_peak_{valuestring}_data.csv\"\n",
        "            seven_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 8 year peaks (manual data) function\n",
        "\n",
        "# def eightyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def eightyearpeak_manual_data(df, valuestring):\n",
        "  eight_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eight_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_eight_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_eight_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+7 and len(indexlist) >=8:\n",
        "            if (prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev7year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}'.format(prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if eight_seasons_count == original_year+8 and len(indexlist) >=8:\n",
        "            eight_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          eight_seasons_count = eight_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=8:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_eight_year_peak_val, running_min]], columns=cols)\n",
        "            eight_year_peak = eight_year_peak.append(df_temp)\n",
        "            outfile = f\"eight_year_peak_{valuestring}_data.csv\"\n",
        "            eight_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 9 year peaks (manual data) function\n",
        "\n",
        "# def nineyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 9 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 9 year stretches of 'valuestring' AND the listed years from each 9 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 9 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def nineyearpeak_manual_data(df, valuestring):\n",
        "  nine_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    nine_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_nine_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_nine_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+8 and len(indexlist) >=9:\n",
        "            if (prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev8year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if nine_seasons_count == original_year+9 and len(indexlist) >=9:\n",
        "            nine_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          nine_seasons_count = nine_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=9:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_nine_year_peak_val, running_min]], columns=cols)\n",
        "            nine_year_peak = nine_year_peak.append(df_temp)\n",
        "            outfile = f\"nine_year_peak_{valuestring}_data.csv\"\n",
        "            nine_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 10 year peaks (manual data) function\n",
        "\n",
        "# def tenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 10 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 10 year stretches of 'valuestring' AND the listed years from each 10 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 10 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-20', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def tenyearpeak_manual_data(df, valuestring):\n",
        "  ten_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # 9 seasons ago's peakvalue\n",
        "    prev_9back = 0\n",
        "    prev_9min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    ten_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "    prev9year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_ten_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min + prev_9min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_ten_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)) + (prev_9back * (prev_9min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev9year = 0\n",
        "            prev_9back = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            prev_9min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+9 and len(indexlist) >=10:\n",
        "            if (prev9year == (prev8year-1) and prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev9year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev9year, prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if ten_seasons_count == original_year+10 and len(indexlist) >=10:\n",
        "            ten_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          ten_seasons_count = ten_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=10:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_ten_year_peak_val, running_min]], columns=cols)\n",
        "            ten_year_peak = ten_year_peak.append(df_temp)\n",
        "            outfile = f\"ten_year_peak_{valuestring}_data.csv\"\n",
        "            ten_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])\n",
        "#@title 11 year peaks (manual data) function\n",
        "\n",
        "# def elevenyearpeak(df, valuestring):\n",
        "# returns a dataframe containing 11 year stretches of 'valuestring' contained within pandas dataframe, 'df'.\n",
        "# returned dataframe containts 11 year stretches of 'valuestring' AND the listed years from each 11 year stretch + minutes played across the 5 seasons.\n",
        "# EX: fiveyearpeak(import_player_since74_per100_df, 'PTS') returns 11 year PTS peaks from all players in 'import_player_since74_per100_df' DataFrame as well as the listed years.\n",
        "# EX returned row: '2011-21', 'Kris Middleton', 'MIL' '22.11', '12139'\n",
        "def elevenyearpeak_manual_data(df, valuestring):\n",
        "  eleven_year_peak = pd.DataFrame(columns = ['Years', 'Player', 'PeakValue', 'MP'])\n",
        "  \n",
        "   # for each player (starting with players as early as possible)\n",
        "  for idx, player in df.iterrows():\n",
        "\n",
        "    outer_player = player['Player']\n",
        "\n",
        "    # previous season's peakvalue\n",
        "    prev_1back = 0\n",
        "    prev_1min = 0\n",
        "\n",
        "    # 2 seasons ago's peakvalue\n",
        "    prev_2back = 0\n",
        "    prev_2min = 0\n",
        "\n",
        "    # 3 seasons ago's peakvalue\n",
        "    prev_3back = 0\n",
        "    prev_3min = 0\n",
        "\n",
        "    # 4 seasons ago's peakvalue\n",
        "    prev_4back = 0\n",
        "    prev_4min = 0\n",
        "\n",
        "    # 5 seasons ago's peakvalue\n",
        "    prev_5back = 0\n",
        "    prev_5min = 0\n",
        "\n",
        "    # 6 seasons ago's peakvalue\n",
        "    prev_6back = 0\n",
        "    prev_6min = 0\n",
        "\n",
        "    # 7 seasons ago's peakvalue\n",
        "    prev_7back = 0\n",
        "    prev_7min = 0\n",
        "\n",
        "    # 8 seasons ago's peakvalue\n",
        "    prev_8back = 0\n",
        "    prev_8min = 0\n",
        "\n",
        "    # 9 seasons ago's peakvalue\n",
        "    prev_9back = 0\n",
        "    prev_9min = 0\n",
        "\n",
        "    prev_10back = 0\n",
        "    prev_10min = 0\n",
        "\n",
        "    # peak start and end season\n",
        "    present_peak_years = ''\n",
        "\n",
        "    # starting season original value\n",
        "    present_year = player['Year']\n",
        "    eleven_seasons_count = player['Year']\n",
        "\n",
        "    # starting season original value\n",
        "    original_year = player['Year']\n",
        "\n",
        "    prevyear = 0\n",
        "    prev2year = 0\n",
        "    prev3year = 0\n",
        "    prev4year = 0\n",
        "    prev5year = 0\n",
        "    prev6year = 0\n",
        "    prev7year = 0\n",
        "    prev8year = 0\n",
        "    prev9year = 0\n",
        "    prev10year = 0\n",
        "\n",
        "\n",
        "    indexlist = []\n",
        "    running_eleven_year_peak_val = 0\n",
        "    running_min = 0\n",
        "\n",
        "    numSeasons = df[(df['Player'] == player['Player'])]\n",
        "\n",
        "    player_finished = []\n",
        "\n",
        "\n",
        "    \n",
        "    # each season from the SAME player as outer for-loop\n",
        "    if player['Player'] not in player_finished:\n",
        "      # trim newdf to only contain player from outerrow so it is less expensive a search to find all their other seasons\n",
        "      newdf = df[(df['Player'] == player['Player'])]\n",
        "      for inner_idx, inner_row in newdf.iterrows():\n",
        "        if inner_row['Player'] == outer_player and inner_row['Year'] >= original_year:\n",
        "          running_min = (inner_row['MP'] + prev_1min + prev_2min + prev_3min + prev_4min + prev_5min + prev_6min + prev_7min + prev_8min + prev_9min + prev_10min)\n",
        "          if running_min == 0:\n",
        "            running_min = 1\n",
        "          running_eleven_year_peak_val = ((inner_row[valuestring] * (inner_row['MP'] / running_min)) + (prev_1back * (prev_1min / running_min)) + (prev_2back * (prev_2min / running_min)) + (prev_3back * (prev_3min / running_min)) + (prev_4back * (prev_4min / running_min)) + (prev_5back * (prev_5min / running_min)) + (prev_6back * (prev_6min / running_min)) + (prev_7back * (prev_7min / running_min)) + (prev_8back * (prev_8min / running_min)) + (prev_9back * (prev_9min / running_min))+ (prev_10back * (prev_10min / running_min)))\n",
        "          indexlist.append(present_year)\n",
        "          present_year = inner_row['Year']\n",
        "\n",
        "          if inner_row['Year'] != present_year:\n",
        "            prevyear = 0\n",
        "            prev2year = 0\n",
        "            prev3year = 0\n",
        "            prev4year = 0\n",
        "            prev5year = 0\n",
        "            prev6year = 0\n",
        "            prev7year = 0\n",
        "            prev8year = 0\n",
        "            prev9year = 0\n",
        "            prev10year = 0\n",
        "            prev_10back = 0\n",
        "            prev_9back = 0\n",
        "            prev_8back = 0\n",
        "            prev_7back = 0\n",
        "            prev_6back = 0\n",
        "            prev_5back = 0\n",
        "            prev_4back = 0\n",
        "            prev_3back = 0\n",
        "            prev_2back = 0\n",
        "            prev_1back = 0\n",
        "            prev_1min = 0\n",
        "            prev_2min = 0\n",
        "            prev_3min = 0\n",
        "            prev_4min = 0\n",
        "            prev_5min = 0\n",
        "            prev_6min = 0\n",
        "            prev_7min = 0\n",
        "            prev_8min = 0\n",
        "            prev_9min = 0\n",
        "            prev_10min = 0\n",
        "            indexlist = []\n",
        "\n",
        "\n",
        "          # can finally store years as this player has had 3 consecutive seasons (not reached after 3 rows of a player is found)\n",
        "          if present_year >= original_year+10 and len(indexlist) >=11:\n",
        "            if (prev10year == (prev9year-1) and prev9year == (prev8year-1) and prev8year == (prev7year-1) and prev7year == (prev6year-1) and prev6year == (prev5year-1) and prev5year == (prev4year-1) and prev4year == (prev3year-1) and prev3year == (prev2year-1) and prev2year == (prevyear-1) and prevyear == (present_year-1)):\n",
        "              present_peak_years = '{} - {}'.format(prev10year, present_year)\n",
        "            else:\n",
        "              present_peak_years = '{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}'.format(prev10year, prev9year, prev8year, prev7year, prev6year, prev5year, prev4year, prev3year, prev2year, prevyear, present_year)\n",
        "\n",
        "          if eleven_seasons_count == original_year+11 and len(indexlist) >=11:\n",
        "            eleven_seasons_count = player['Year']\n",
        "          if present_year == original_year+1:\n",
        "\n",
        "            prev_10back = prev_9back\n",
        "            prev_10min = prev_9min\n",
        "            prev10year = prev9year\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "          if present_year == original_year:\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "          if present_year > original_year:\n",
        "\n",
        "            prev_10back = prev_9back\n",
        "            prev_10min = prev_9min\n",
        "            prev10year = prev9year\n",
        "\n",
        "            prev_9back = prev_8back\n",
        "            prev_9min = prev_8min\n",
        "            prev9year = prev8year\n",
        "\n",
        "            prev_8back = prev_7back\n",
        "            prev_8min = prev_7min\n",
        "            prev8year = prev7year\n",
        "\n",
        "            prev_7back = prev_6back\n",
        "            prev_7min = prev_6min\n",
        "            prev7year = prev6year\n",
        "\n",
        "            prev_6back = prev_5back\n",
        "            prev_6min = prev_5min\n",
        "            prev6year = prev5year\n",
        "\n",
        "            prev_5back = prev_4back\n",
        "            prev_5min = prev_4min\n",
        "            prev5year = prev4year\n",
        "            \n",
        "            prev_4back = prev_3back\n",
        "            prev_4min = prev_3min\n",
        "            prev4year = prev3year\n",
        "\n",
        "            prev_3back = prev_2back\n",
        "            prev_3min = prev_2min\n",
        "            prev3year = prev2year\n",
        "\n",
        "            prev_2back = prev_1back\n",
        "            prev_2min = prev_1min\n",
        "            prev2year = prevyear\n",
        "\n",
        "            prev_1back = inner_row[valuestring]\n",
        "            prev_1min = inner_row['MP']\n",
        "            prevyear = inner_row['Year']\n",
        "\n",
        "          eleven_seasons_count = eleven_seasons_count + 1\n",
        "\n",
        "          if len(indexlist) >=11:\n",
        "            cols = ['Years', 'Player', 'PeakValue', 'MP']\n",
        "            df_temp = pd.DataFrame([[present_peak_years, inner_row['Player'], running_eleven_year_peak_val, running_min]], columns=cols)\n",
        "            eleven_year_peak = eleven_year_peak.append(df_temp)\n",
        "            outfile = f\"eleven_year_peak_{valuestring}_data.csv\"\n",
        "            eleven_year_peak.to_csv(outfile, index=False)\n",
        "            player_finished.append(inner_row['Player'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXEdTPyqEUUH"
      },
      "source": [
        "**RUN YEAR MANUAL SUBSETS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2n5FivB9QcKn"
      },
      "outputs": [],
      "source": [
        "#@title Adjusted Playoff TS+ of Manual Subset\n",
        "def manual_adjust_scoring_efficiency(player_df, opp_ts_df, opp_defrtg_df, opp_literal_defrtg, player):\n",
        "\n",
        "      final_season_df = pd.DataFrame(columns = ['Player', 'Year', 'PP75', 'TS+', 'NetRtg', 'rOffRtg', 'MP'])\n",
        "\n",
        "      years_list = []\n",
        "\n",
        "      player_df['PP75'] = player_df['PP75'].astype(float)\n",
        "      player_df['PP75'] = player_df['PP75'] * .75\n",
        "\n",
        "\n",
        "      player_df['TS%'] = player_df['TS%'].astype(float)\n",
        "\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(int)\n",
        "      opp_defrtg_df['Team'] = opp_defrtg_df['Team'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(int)\n",
        "      opp_literal_defrtg['Team'] = opp_literal_defrtg['Team'].astype(str)\n",
        "      opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "      player_df['Opp'] = player_df['Opp'].astype(str)\n",
        "      player_df['Year'] = player_df['Year'].astype(int)\n",
        "\n",
        "      for i, row in player_df.iterrows():\n",
        "\n",
        "        current_opp = player_df.loc[i, 'Opp']\n",
        "        current_year = player_df.loc[i, 'Year']\n",
        "\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & (opp_ts_df['Year'] == current_year)]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        opponent_literal_def = opp_literal_defrtg[(opp_literal_defrtg['Team'] == current_opp) & ((opp_literal_defrtg['Year'] == current_year))]\n",
        "        opp_def_rtg = float(opponent_literal_def['DefRtg'])\n",
        "\n",
        "        player_ts = player_df.loc[i, 'TS%']\n",
        "        tsplus = (float(player_ts) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        relOffRtg = float(row['OffRtg']) - opp_def_rtg\n",
        "\n",
        "        player_df.loc[i,'TS+'] = tsplus\n",
        "        player_df.loc[i,'PTS_coeff'] = pts_coeff\n",
        "        player_df.loc[i,'rOffRtg'] = relOffRtg\n",
        "\n",
        "\n",
        "        if player_df.loc[i, 'Year'] not in years_list:\n",
        "          years_list.append(player_df.loc[i, 'Year'])\n",
        "\n",
        "      tmp_series_df = pd.DataFrame(columns = ['Year', 'OPP', 'MP', 'TS%', 'PTS', 'PTS_coeff'])\n",
        "      for year in years_list:\n",
        "        tmp_sub_df = player_df[(player_df['Year'] == year)]\n",
        "\n",
        "        total_pts = 0\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        total_net = 0\n",
        "        total_off = 0\n",
        "\n",
        "        mp_list = []\n",
        "        #MP\n",
        "        for ind_mp in tmp_sub_df['MP']:\n",
        "          ind_mp = float(ind_mp)\n",
        "          mp_list.append(ind_mp)\n",
        "          total_mp += ind_mp\n",
        "          if total_mp == 0:\n",
        "            total_mp = 1\n",
        "        #TS\n",
        "        iter = 0\n",
        "        for ind_ts in tmp_sub_df['TS+']:\n",
        "          ind_ts = float(ind_ts)\n",
        "          total_ts += float(ind_ts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "         #PTS\n",
        "        iter = 0\n",
        "        for ind_pts in tmp_sub_df['PP75']:\n",
        "          ind_pts = float(ind_pts)\n",
        "          total_pts += float(ind_pts) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        iter = 0\n",
        "        #coeff\n",
        "        for ind_coeff in tmp_sub_df['PTS_coeff']:\n",
        "          ind_coeff = float(ind_coeff)\n",
        "          total_coeff += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "        total_pts = total_pts * total_coeff\n",
        "\n",
        "\n",
        "        # NetRtg\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['NetRtg']:\n",
        "          ind_net = float(ind_coeff)\n",
        "          total_net += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        # OffRtg\n",
        "        iter = 0\n",
        "        for ind_coeff in tmp_sub_df['rOffRtg']:\n",
        "          ind_off = float(ind_coeff)\n",
        "          total_off += float(ind_coeff) * (float(mp_list[iter])) / float(total_mp)\n",
        "          iter = iter + 1\n",
        "\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "        total_off = '%.2f' % round(total_off, 2)\n",
        "        total_net = '%.2f' % round(total_net, 2)\n",
        "\n",
        "        new_row = {'Player':player, 'Year':year,  'PP75':total_pts, 'TS+':total_ts, 'NetRtg':total_net, 'rOffRtg': total_off, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "      print(final_season_df)\n",
        "      outfile = f\"NBA_Playoff_Manual_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QQT2n6FFd9pf"
      },
      "outputs": [],
      "source": [
        "#@title Print Manual Peaks\n",
        "def manu_tony_compare(player, sit):\n",
        "\n",
        "  manu_only_one_adjusted = pd.read_csv('/content/NBA_Playoff_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('two_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('two_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  twoyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('two_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"two_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  threeyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('three_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"three_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('four_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('four_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  fouryearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('four_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"four_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('five_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('five_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  fiveyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('five_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"five_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('six_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('six_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  sixyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('six_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"six_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('seven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  sevenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('seven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"seven_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('eight_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  eightyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eight_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eight_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('nine_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  nineyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('nine_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"nine_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('ten_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  tenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('ten_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"ten_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'PTS')\n",
        "  import_player_longPTS_peaks_df = pd.read_csv('eleven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_longPTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_PTS_data.csv\"\n",
        "  import_player_longPTS_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'TS+')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eleven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_TS+_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'NetRtg')\n",
        "  import_player_longNetRtg_peaks_df = pd.read_csv('eleven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_longNetRtg_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_NetRtg_data.csv\"\n",
        "  import_player_longNetRtg_peaks_df.to_csv(outfile, index=False)\n",
        "  elevenyearpeak_manual_data(manu_only_one_adjusted, 'rOffRtg')\n",
        "  import_player_longTS_peaks_df = pd.read_csv('eleven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "  import_player_longTS_peaks_df.drop_duplicates(keep='first', inplace=True)\n",
        "  outfile = f\"eleven_year_peak_rOffRtg_data.csv\"\n",
        "  import_player_longTS_peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  import_pts_twopeaks_df = pd.read_csv('two_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_ts_twopeaks_df = pd.read_csv('two_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_peaks_df = pd.read_csv('two_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_peaks_df = pd.read_csv('two_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_peaks_df = pd.read_csv('three_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_peaks_df = pd.read_csv('three_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg3_peaks_df = pd.read_csv('three_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg3_peaks_df = pd.read_csv('three_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_4peaks_df = pd.read_csv('four_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_4peaks_df = pd.read_csv('four_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_4peaks_df = pd.read_csv('four_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_4peaks_df = pd.read_csv('four_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_5peaks_df = pd.read_csv('five_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_5peaks_df = pd.read_csv('five_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_5peaks_df = pd.read_csv('five_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_5peaks_df = pd.read_csv('five_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_6peaks_df = pd.read_csv('six_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_6peaks_df = pd.read_csv('six_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_6peaks_df = pd.read_csv('six_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_6peaks_df = pd.read_csv('six_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_7peaks_df = pd.read_csv('seven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_7peaks_df = pd.read_csv('seven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_7peaks_df = pd.read_csv('seven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_7peaks_df = pd.read_csv('seven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_8peaks_df = pd.read_csv('eight_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_8peaks_df = pd.read_csv('eight_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_8peaks_df = pd.read_csv('eight_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_8peaks_df = pd.read_csv('eight_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_9peaks_df = pd.read_csv('nine_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_9peaks_df = pd.read_csv('nine_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_9peaks_df = pd.read_csv('nine_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_9peaks_df = pd.read_csv('nine_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_10peaks_df = pd.read_csv('ten_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_10peaks_df = pd.read_csv('ten_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_10peaks_df = pd.read_csv('ten_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_10peaks_df = pd.read_csv('ten_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "  import_player_pts_11peaks_df = pd.read_csv('eleven_year_peak_PTS_data.csv', encoding='utf8')\n",
        "  import_player_ts_11peaks_df = pd.read_csv('eleven_year_peak_TS+_data.csv', encoding='utf8')\n",
        "  import_player_NetRtg_11peaks_df = pd.read_csv('eleven_year_peak_NetRtg_data.csv', encoding='utf8')\n",
        "  import_player_rOffRtg_11peaks_df = pd.read_csv('eleven_year_peak_rOffRtg_data.csv', encoding='utf8')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #2 year playoff scoring peaks Output File\n",
        "  peaks_df = import_pts_twopeaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_ts_twopeaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Two\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_2_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #3 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg3_peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg3_peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Three\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_3_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #4 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_4peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_4peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_4peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_4peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Four\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_4_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #5 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_5peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_5peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_5peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_5peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Five\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_5_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #6 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_6peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_6peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_6peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_6peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Six\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_6_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #7 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_7peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_7peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_7peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_7peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Seven\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_7_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "  #8 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_8peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_8peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_8peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_8peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Eight\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_8_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #9 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_9peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_9peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_9peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_9peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Nine\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_9_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "  #10 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_10peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_10peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_10peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_10peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Ten\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_10_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)\n",
        "\n",
        "\n",
        "\n",
        "  #11 year playoff scoring peaks Output File\n",
        "  peaks_df = import_player_pts_11peaks_df.copy()\n",
        "  peaks_df.insert(4, \"TS+\", import_player_ts_11peaks_df['PeakValue'])\n",
        "  peaks_df.insert(5, \"NetRtg\", import_player_NetRtg_11peaks_df['PeakValue'])\n",
        "  peaks_df.insert(6, \"rOffRtg\", import_player_rOffRtg_11peaks_df['PeakValue'])\n",
        "\n",
        "  peaks_df = peaks_df.rename(columns={\"Years\": \"Years\", \"Player\": \"Player\", \"PeakValue\": \"PTS\", \"MP\": \"MP\", \"TS+\": \"TS+\", \"NetRtg\": \"NetRtg\", \"rOffRtg\": \"rOffRtg\"})\n",
        "\n",
        "  peaks_df = peaks_df.sort_values('PTS', ascending=False)\n",
        "  columns_titles = ['Player', 'Years', 'PTS', 'TS+', \"NetRtg\", \"rOffRtg\", 'MP']\n",
        "  peaks_df = peaks_df.reindex(columns=columns_titles)\n",
        "\n",
        "  print(\"Eleven\")\n",
        "  print(peaks_df)\n",
        "\n",
        "  outfile = f\"{player}_11_{sit}_scoring_Playoff_Peaks.csv\"\n",
        "  peaks_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inflate Scoring for Manual Subset\n",
        "new_df = pd.DataFrame()\n",
        "per_75_coeff['Year'] = per_75_coeff['Year'].astype(int)\n",
        "manu_one_on['Year'] = manu_one_on['Year'].astype(float)\n",
        "manu_one_on['PP75'] = manu_one_on['PP75'].astype(float)\n",
        "for i, row in manu_one_on.iterrows():\n",
        "  sub_coeff = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PP75'] = float((row['PP75'] * sub_coeff['Coefficient']))\n",
        "  new_df = new_df.append(row)\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df['PP75'] = new_df['PP75'].astype(float)\n",
        "new_df['TS%'] = new_df['TS%'].astype(float)\n",
        "new_df['MP'] = new_df['MP'].astype(int)\n",
        "new_df['Opp'] = new_df['Opp'].astype(str)\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "team_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "team_ts_allowed_df['TS% Allowed'] = team_ts_allowed_df['TS% Allowed'].astype(float)\n",
        "team_ts_allowed_df['Year'] = team_ts_allowed_df['Year'].astype(int)\n",
        "\n",
        "opp_literal_defrtg = pd.read_csv('/content/NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "\n",
        "\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "\n",
        "manual_adjust_scoring_efficiency(new_df, team_ts_allowed_df, opponent_adj_pts_coeff, opp_literal_defrtg, 'Tim Duncan')\n",
        "\n",
        "#Manu Ginbili"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TGTZh3uIM6lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrnCdHn6Z4hM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Output Year Percentiles\n",
        "from scipy import stats\n",
        "graph_data =  era_opponent_adj_playoff_per_75_df.copy()\n",
        "graph_data = graph_data[(graph_data['PTS'] >= 15)]\n",
        "graph_data = graph_data[(graph_data['MP'] >= 90)]\n",
        "\n",
        "final_season_df = pd.DataFrame(columns = ['Year', 'PP75', 'TS+', 'MP'])\n",
        "\n",
        "this_df = pd.read_csv('/content/NBA_Playoff_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "for idx, row in this_df.iterrows():\n",
        "  year = int(row['Year'])\n",
        "  pts = row['PP75']\n",
        "  ts = row['TS+']\n",
        "  mp = row['MP']\n",
        "  pts_percentile = stats.percentileofscore(graph_data['PTS'], pts)\n",
        "  ts_percentile = stats.percentileofscore(graph_data['TS%+'], ts)\n",
        "\n",
        "  \n",
        "  new_row = {'Year':year,  'PP75':pts_percentile, 'TS+':ts_percentile,'MP':int(mp)}\n",
        "  final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  outfile = f\"Percentiles.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "632Vlw2nH8ir"
      },
      "outputs": [],
      "source": [
        "manu_tony_compare(\"Tony\", \"Only_One\")\n",
        "# Manu Ginbili"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN SERIES MANUAL SUBSETS**"
      ],
      "metadata": {
        "id": "X9dcEeQyVVWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Adjusted Playoff TS+ of Manual Subset (Series)\n",
        "def manual_adjust_scoring_efficiency_series(player_df, opp_ts_df, opp_defrtg_df, opp_literal_defrtg, player):\n",
        "\n",
        "      final_season_df = pd.DataFrame(columns = ['Player', 'Series', 'PP75', 'TS+', 'NetRtg', 'rOffRtg', 'MP'])\n",
        "\n",
        "      series_list = []\n",
        "\n",
        "      player_df['PP75'] = player_df['PP75'].astype(float)\n",
        "      player_df['PP75'] = player_df['PP75'] * .75\n",
        "\n",
        "\n",
        "      player_df['TS%'] = player_df['TS%'].astype(float)\n",
        "\n",
        "      opp_ts_df['Team'] = opp_ts_df['Team'].astype(str)\n",
        "      opp_ts_df['Year'] = opp_ts_df['Year'].astype(int)\n",
        "      opp_defrtg_df['Team'] = opp_defrtg_df['Team'].astype(str)\n",
        "      opp_defrtg_df['Year'] = opp_defrtg_df['Year'].astype(int)\n",
        "      opp_literal_defrtg['Team'] = opp_literal_defrtg['Team'].astype(str)\n",
        "      opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "      player_df['Opp'] = player_df['Opp'].astype(str)\n",
        "      player_df['Year'] = player_df['Year'].astype(int)\n",
        "\n",
        "      for i, row in player_df.iterrows():\n",
        "\n",
        "        current_opp = player_df.loc[i, 'Opp']\n",
        "        current_year = player_df.loc[i, 'Year']\n",
        "\n",
        "        opponent_ts = opp_ts_df[(opp_ts_df['Team'] == current_opp) & (opp_ts_df['Year'] == current_year)]\n",
        "        opponent_ts['TS% Allowed'] = opponent_ts['TS% Allowed'].astype(float)\n",
        "\n",
        "        opponent_def = opp_defrtg_df[(opp_defrtg_df['Team'] == current_opp) & ((opp_defrtg_df['Year'] == current_year))]\n",
        "        pts_coeff = float(opponent_def['PTS_coeff'])\n",
        "\n",
        "        opponent_literal_def = opp_literal_defrtg[(opp_literal_defrtg['Team'] == current_opp) & ((opp_literal_defrtg['Year'] == current_year))]\n",
        "        opp_def_rtg = float(opponent_literal_def['DefRtg'])\n",
        "\n",
        "        player_ts = player_df.loc[i, 'TS%']\n",
        "        tsplus = (float(player_ts) / float(opponent_ts['TS% Allowed'])) * 100\n",
        "        relOffRtg = float(row['OffRtg']) - opp_def_rtg\n",
        "\n",
        "        player_df.loc[i,'TS+'] = tsplus\n",
        "        player_df.loc[i,'PTS_coeff'] = pts_coeff\n",
        "        player_df.loc[i,'rOffRtg'] = relOffRtg\n",
        "\n",
        "\n",
        "      for idx, row in player_df.iterrows():\n",
        "        total_pts = 0\n",
        "        total_ts = 0\n",
        "        total_mp = 0\n",
        "        total_coeff = 0\n",
        "        total_net = 0\n",
        "        total_off = 0\n",
        "\n",
        "        total_mp = int(row['MP'])\n",
        "        total_ts = float(row['TS+'])\n",
        "        total_pts = float(row['PP75'])\n",
        "        total_coeff = float(row['PTS_coeff'])\n",
        "        total_pts = total_pts * total_coeff\n",
        "\n",
        "\n",
        "        total_net = float(row['NetRtg'])\n",
        "        total_off = float(row['rOffRtg'])\n",
        "\n",
        "        total_pts = '%.2f' % round(total_pts, 2)\n",
        "        total_ts = '%.2f' % round(total_ts, 2)\n",
        "        total_off = '%.2f' % round(total_off, 2)\n",
        "        total_net = '%.2f' % round(total_net, 2)\n",
        "\n",
        "        series = str(row['Year'])\n",
        "        series = series + \" \"\n",
        "        series = series + str(row['Opp'])\n",
        "\n",
        "        new_row = {'Player':player, 'Series':series,  'PP75':total_pts, 'TS+':total_ts, 'NetRtg':total_net, 'rOffRtg': total_off, 'MP':int(total_mp)}\n",
        "        final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "      print(final_season_df)\n",
        "      outfile = f\"NBA_Playoff_Series_Manual_Adjusted_TS_df.csv\"\n",
        "      final_season_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QGtEKaNlMyD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inflate Scoring for Manual Subset (Series)\n",
        "new_df = pd.DataFrame()\n",
        "per_75_coeff['Year'] = per_75_coeff['Year'].astype(int)\n",
        "manu_one_on['Year'] = manu_one_on['Year'].astype(float)\n",
        "manu_one_on['PP75'] = manu_one_on['PP75'].astype(float)\n",
        "for i, row in manu_one_on.iterrows():\n",
        "  sub_coeff = per_75_coeff[(per_75_coeff['Year'] == row['Year'])]\n",
        "  row['PP75'] = float((row['PP75'] * sub_coeff['Coefficient']))\n",
        "  new_df = new_df.append(row)\n",
        "new_df['Year'] = new_df['Year'].astype(int)\n",
        "new_df['PP75'] = new_df['PP75'].astype(float)\n",
        "new_df['TS%'] = new_df['TS%'].astype(float)\n",
        "new_df['MP'] = new_df['MP'].astype(int)\n",
        "new_df['Opp'] = new_df['Opp'].astype(str)\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "team_ts_allowed_df = pd.read_csv('/content/NBA_Team_TS_Percentage_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "team_ts_allowed_df['TS% Allowed'] = team_ts_allowed_df['TS% Allowed'].astype(float)\n",
        "team_ts_allowed_df['Year'] = team_ts_allowed_df['Year'].astype(int)\n",
        "\n",
        "opp_literal_defrtg = pd.read_csv('/content/NBA_Team_defrtg_Allowed_df.csv', index_col=False, encoding='utf8')\n",
        "opp_literal_defrtg['Year'] = opp_literal_defrtg['Year'].astype(int)\n",
        "\n",
        "\n",
        "opponent_adj_pts_coeff = pd.read_csv('/content/opponent_adj_pts_coeff.csv', index_col=False, encoding='utf8')\n",
        "opponent_adj_pts_coeff['Year'] = opponent_adj_pts_coeff['Year'].astype(int)\n",
        "\n",
        "manual_adjust_scoring_efficiency_series(new_df, team_ts_allowed_df, opponent_adj_pts_coeff, opp_literal_defrtg, 'Tim Duncan')\n",
        "\n",
        "#Manu Ginbili"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H0z9UzeePrxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Output Series Percentiles\n",
        "from scipy import stats\n",
        "graph_data =  era_opponent_adj_playoff_per_75_df.copy()\n",
        "graph_data = graph_data[(graph_data['PTS'] >= 15)]\n",
        "graph_data = graph_data[(graph_data['MP'] >= 90)]\n",
        "\n",
        "final_season_df = pd.DataFrame(columns = ['Series', 'PP75', 'TS+', 'MP'])\n",
        "\n",
        "this_df = pd.read_csv('/content/NBA_Playoff_Series_Manual_Adjusted_TS_df.csv', index_col=False, encoding='utf8')\n",
        "for idx, row in this_df.iterrows():\n",
        "  series = row['Series']\n",
        "  pts = row['PP75']\n",
        "  ts = row['TS+']\n",
        "  mp = row['MP']\n",
        "  pts_percentile = stats.percentileofscore(graph_data['PTS'], pts)\n",
        "  ts_percentile = stats.percentileofscore(graph_data['TS%+'], ts)\n",
        "\n",
        "  \n",
        "  new_row = {'Series':series,  'PP75':pts_percentile, 'TS+':ts_percentile,'MP':int(mp)}\n",
        "  final_season_df = final_season_df.append(new_row, ignore_index=True)\n",
        "  outfile = f\"Percentiles.csv\"\n",
        "  final_season_df.to_csv(outfile, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eS7gPS-sMjSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBcJHTYvdqJ9"
      },
      "source": [
        "**MANUAL SUBSETS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzgUworfEJgE"
      },
      "source": [
        "MANU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MS29cIwYJqdM"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with both of Tim and Tony on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['23.08', '.5938', '50', 'MEM', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.38', '.6081', '106', 'LAL', '2004', '6.16', '96.52']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['33.08', '.6719', '66', 'DEN', '2005', '13.0', '121.8']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.29', '.6705', '106', 'SEA', '2005', '21.34', '122.92']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.43', '.6327', '112', 'PHO', '2005', '2.40', '121.68']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.82', '.5593', '161', 'DET', '2005', '-0.93', '103.60']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['30.66', '.6154', '112', 'SAC', '2006', '20.24', '125.00']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.95', '.5859', '154', 'DAL', '2006', '7.45', '115.96']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['17.65', '.4194', '78', 'DEN', '2007', '-3.83', '108.50']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.76', '.5784', '114', 'PHO', '2007', '1.48', '108.30']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.58', '.6667', '79', 'UTA', '2007', '7.58', '122.15']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.61', '.6613', '65', 'CLE', '2007', '14.18', '108.20']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['19.51', '.5128', '105', 'PHO', '2008', '3.80', '109.27']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.31', '.5655', '169', 'NOH', '2008', '-10.07', '100.94']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.59', '.5484', '102', 'LAL', '2008', '-3.62', '98.99']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['43.83', '.6481', '91', 'DAL', '2010', '11.94', '123.46']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.02', '.7368', '89', 'PHO', '2010', '5.88', '119.10']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['26.70', '.5795', '102', 'MEM', '2011', '-1.04', '97.91']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.4375', '50', 'UTA', '2012', '-0.19', '109.18']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.20', '.7083', '67', 'LAC', '2012', '30.88', '116.0']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.79', '.6591', '117', 'OKC', '2012', '8.79', '110.08']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['14.47', '.6111', '41', 'LAL', '2013', '19.74', '119.74']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.95', '.3103', '73', 'GSW', '2013', '-13.80', '90.65']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.47', '.5500', '41', 'MEM', '2013', '-17.26', '101.32']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.93', '.6622', '98', 'MIA', '2013', '-1.84', '111.64']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['24.19', '.5375', '97', 'DAL', '2014', '12.92', '116.67']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.81', '.4483', '57', 'POR', '2014', '-2.40', '110.53']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.06', '.7321', '66', 'OKC', '2014', '6.0', '120.61']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.78', '.5469', '87', 'MIA', '2014', '27.22', '128.48']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "manu_one_on = manu_one_on.reset_index(drop=True)\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8IJyDJSH0uKl"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with both of Tim/Tony on (5+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['5.26', '.5000', '9', 'MEM', '2004']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.86', '.6667', '64', 'LAL', '2004']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['39.73', '.7250', '38', 'DEN', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['56.45', '1.1000', '38', 'SEA', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.6892', '79', 'PHO', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.14', '.6023', '116', 'DET', '2005']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['27.73', '.5333', '67', 'SAC', '2006']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['13.51', '.3462', '42', 'DAL', '2006']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['19.44', '.4762', '56', 'DEN', '2007']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.92', '.5500', '35', 'PHO', '2007']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.65', '.7083', '31', 'UTA', '2007']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.53', '.7727', '22', 'CLE', '2007']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['14.71', '.5000', '34', 'PHO', '2008']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.35', '.6048', '131', 'NOH', '2008']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.31', '.3889', '51', 'LAL', '2008']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['21.90', '.4792', '58', 'DAL', '2010']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.67', '.6500', '31', 'PHO', '2010']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['22.52', '.5435', '60', 'MEM', '2011']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['28.21', '.5500', '19', 'UTA', '2012']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.81', '.5000', '16', 'LAC', '2012']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['8.62', '.5000', '32', 'OKC', '2012']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '3', 'LAL', '2013']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['13.61', '.5000', '18', 'GSW', '2013']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '5', 'MEM', '2013']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.85', '.7333', '41', 'MIA', '2013']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['40.63', '1.0833', '16', 'DAL', '2014']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.00', '.5192', '46', 'POR', '2014']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.00', '.7500', '20', 'OKC', '2014']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['46.15', '.7500', '14', 'MIA', '2014']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "497kM8cObznH"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with only 1 of Tim/Tony on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['18.27', '.4048', '56', 'MEM', '2004', '15.14', '106.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.17', '.7000', '66', 'LAL', '2004', '0.0', '107.50']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '76', 'DEN', '2005', '18.88', '109.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '79', 'SEA', '2005', '7.79', '119.59']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '67', 'PHO', '2005', '12.23', '110.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '86', 'DET', '2005', '11.78', '108.97']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '46', 'SAC', '2006', '1.14', '110.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '81', 'DAL', '2006', '2.70', '110.81']\n",
        "\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['32.31', '.5263', '35', 'DEN', '2007', '7.74', '110.77']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.19', '.5167', '71', 'PHO', '2007', '-7.50', '108.70']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.21', '.5370', '54', 'UTA', '2007', '9.22', '104.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.51', '.5750', '36', 'CLE', '2007', '50.79', '123.81']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['42.05', '.5606', '42', 'PHO', '2008', '-0.21', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.72', '.7333', '60', 'NOH', '2008', '28.35', '120.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.72', '.5192', '55', 'LAL', '2008', '-7.09', '100.99']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4457', '102', 'DAL', '2010', '-5.21', '98.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.49', '.4444', '49', 'PHO', '2010', '-19.89', '94.85']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['51.95', '.7800', '38', 'MEM', '2011', '31.20', '128.57']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['16.67', '.4000', '13', 'UTA', '2012', '-43.30', '95.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '10', 'LAC', '2012', '-17.73', '55.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.95', '.6071', '18', 'OKC', '2012', '-49.03', '108.11']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['45.83', '.9167', '12', 'LAL', '2013', '29.17', '137.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.79', '.5256', '83', 'GSW', '2013', '46.44', '130.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.62', '.8889', '41', 'MEM', '2013', '35.38', '117.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.91', '.4444', '75', 'MIA', '2013', '-11.91', '102.99']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['48.39', '.6471', '44', 'DAL', '2014', '26.18', '120.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.97', '.4333', '29', 'POR', '2014', '30.05', '98.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.71', '.6842', '39', 'OKC', '2014', '24.56', '110.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.38', '.5000', '20', 'MIA', '2014', '14.76', '102.56']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SU6mtICYuRvm"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with only 1 of Tim/Tony on (3+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['17.65', '.4000', '29', 'MEM', '2004', '0.0', '90.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.4750', '42', 'LAL', '2004', '-2.26', '105.33']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['47.19', '.7000', '47', 'DEN', '2005', '26.97', '112.36']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['55.56', '.8125', '40', 'SEA', '2005', '14.38', '131.94']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '67', 'PHO', '2005', '12.23', '110.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.97', '.7250', '84', 'DET', '2005', '11.39', '109.22']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['8.70', '.3000', '36', 'SAC', '2006', '-21.74', '102.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.17', '.6528', '63', 'DAL', '2006', '3.42', '108.55']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['30.36', '.5333', '30', 'DEN', '2007', '-1.60', '108.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16', '.4167', '52', 'PHO', '2007', '-9.67', '107.0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.21', '.6667', '24', 'UTA', '2007', '16.59', '123.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.48', '.5000', '17', 'CLE', '2007', '72.41', '124.14']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['28.07', '.5000', '26', 'PHO', '2008', '-16.43', '101.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['44.00', '.7500', '42', 'NOH', '2008', '18.33', '113.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.55', '.5000', '25', 'LAL', '2008', '-21.28', '100.00']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['23.53', '.4872', '93', 'DAL', '2010', '-6.47', '98.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['10.53', '.3333', '28', 'PHO', '2010', '-34.31', '87.72']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['55.77', '.7250', '26', 'MEM', '2011', '17.31', '117.31']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.5000', '9', 'UTA', '2012', '-46.27', '106.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '6', 'LAC', '2012', '-24.18', '61.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['55.56', '.4545', '8', 'OKC', '2012', '-30.72', '122.22']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['60.00', '1.1250', '7', 'LAL', '2013', '40.00', '133.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.76', '.4444', '54', 'GSW', '2013', '44.55', '124.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['11.63', '.8333', '23', 'MEM', '2013', '61.60', '137.21']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['7.46', '.2083', '39', 'MIA', '2013', '-24.64', '94.03']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['62.22', '.6750', '21', 'DAL', '2014', '28.89', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.91', '.3889', '22', 'POR', '2014', '20.98', '97.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.89', '.7000', '26', 'OKC', '2014', '30.34', '111.11']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.05', '.6667', '12', 'MIA', '2014', '41.67', '100.00']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZMIRy4nnvI8E"
      },
      "outputs": [],
      "source": [
        "#@title Manu Scoring numbers with only 1 of Tim/Tony on (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.000', '4', 'MEM', '2004', '6.94', '44.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.58', '.5667', '25', 'LAL', '2004', '8.67', '116.67']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['55.81', '.7059', '26', 'DEN', '2005', '16.90', '104.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['73.33', '1.2222', '16', 'SEA', '2005', '66.25', '160.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.47', '.5000', '44', 'PHO', '2005', '11.87', '114.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['49.25', '.8056', '42', 'DET', '2005', '28.14', '120.90']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['16.67', '.3333', '13', 'SAC', '2006', '-52.88', '62.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.7857', '11', 'DAL', '2006', '-9.09', '90.91']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.3889', '13', 'DEN', '2007', '-41.50', '96.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.25', '.5000', '27', 'PHO', '2007', '-30.22', '101.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '7', 'UTA', '2007', '33.33', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.2500', '6', 'CLE', '2007', '92.42', '109.09']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['22.71', '.5000', '10', 'PHO', '2008', '-19.26', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.46', '.7143', '29', 'NOH', '2008', '20.94', '117.31']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['13.33', '.2500', '8', 'LAL', '2008', '-37.92', '93.33']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['17.27', '.3800', '61', 'DAL', '2010', '-41.56', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['4.76', '.2500', '20', 'PHO', '2010', '-6.40', '91.82']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['56.25', '.7500', '14', 'MEM', '2011', '20.00', '100.00']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5000', '6', 'UTA', '2012', '-97.73', '75.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '3', 'LAC', '2012', '-66.67', '66.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.50', '.3750', '4', 'OKC', '2012', '-100.00', '100.00']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['75.00', '1.500', '4', 'LAL', '2013', '62.50', '162.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.4286', '16', 'GSW', '2013', '41.94', '106.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '14', 'MEM', '2013', '42.63', '138.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0000', '19', 'MIA', '2013', '-49.88', '75.76']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['68.42', '.8571', '8', 'DAL', '2014', '2.79', '126.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.58', '.5000', '16', 'POR', '2014', '9.68', '90.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.43', '.6000', '18', 'OKC', '2014', '11.58', '97.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.6667', '8', 'MIA', '2014', '50.89', '107.14']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu Scoring numbers (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['18.75', '.5000', '16', 'MEM', '2004', '6.94', '44.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.6146', '121', 'LAL', '2004', '8.67', '116.67']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['35.62', '.6500', '77', 'DEN', '2005', '16.90', '104.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['46.72', '.9483', '69', 'SEA', '2005', '66.25', '160.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.28', '.5600', '149', 'PHO', '2005', '11.87', '114.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.03', '.6250', '171', 'DET', '2005', '28.14', '120.90']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['25.76', '.5435', '107', 'SAC', '2006', '-52.88', '62.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.03', '.5833', '102', 'DAL', '2006', '-9.09', '90.91']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['19.63', '.4306', '82', 'DEN', '2007', '-41.50', '96.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.42', '.5909', '112', 'PHO', '2007', '-30.22', '101.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.00', '.5893', '71', 'UTA', '2007', '33.33', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.5833', '42', 'CLE', '2007', '92.42', '109.09']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['13.10', '.4074', '85', 'PHO', '2008', '-19.26', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.23', '.6146', '180', 'NOH', '2008', '20.94', '117.31']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.86', '.4310', '89', 'LAL', '2008', '-37.92', '93.33']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['28.42', '.5098', '102', 'DAL', '2010', '-41.56', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.06', '.6618', '84', 'PHO', '2010', '-6.40', '91.82']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['32.11', '.6224', '98', 'MEM', '2011', '20.00', '100.00']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['21.88', '.5000', '49', 'UTA', '2012', '-97.73', '75.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.06', '.5909', '38', 'LAC', '2012', '-66.67', '66.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.25', '.5893', '80', 'OKC', '2012', '-100.00', '100.00']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['22.92', '.7857', '26', 'LAL', '2013', '62.50', '162.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.67', '.3913', '58', 'GSW', '2013', '41.94', '106.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['10.29', '.5000', '37', 'MEM', '2013', '42.63', '138.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.23', '.6857', '96', 'MIA', '2013', '-49.88', '75.76']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['35.54', '.6833', '63', 'DAL', '2014', '2.79', '126.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.68', '.4306', '70', 'POR', '2014', '9.68', '90.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.38', '.5893', '49', 'OKC', '2014', '11.58', '97.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.78', '.7273', '51', 'MIA', '2014', '50.89', '107.14']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H6Z3FD97Q_oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu Scoring numbers\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['12.96', '.4107', '182', 'PHO', '2003', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.31', '.6364', '149', 'LAL', '2003', '-24.93', '86.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.77', '.5472', '158', 'DAL', '2003', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.05', '.4643', '171', 'NJN', '2003', '-24.93', '86.63']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['21.32', '.5000', '106', 'MEM', '2004', '6.94', '44.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.24', '.5833', '173', 'LAL', '2004', '8.67', '116.67']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['38.13', '.6420', '154', 'DEN', '2005', '16.90', '104.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.76', '.7000', '187', 'SEA', '2005', '66.25', '160.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.41', '.6033', '183', 'PHO', '2005', '11.87', '114.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.39', '.6139', '252', 'DET', '2005', '28.14', '120.90']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['26.09', '.5779', '184', 'SAC', '2006', '-52.88', '62.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.48', '.6271', '243', 'DAL', '2006', '-9.09', '90.91']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['25.19', '.4710', '138', 'DEN', '2007', '-41.50', '96.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.37', '.5464', '197', 'PHO', '2007', '-30.22', '101.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.56', '.6143', '150', 'UTA', '2007', '33.33', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.81', '.5635', '117', 'CLE', '2007', '92.42', '109.09']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['29.35', '.5617', '155', 'PHO', '2008', '-19.26', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.04', '.6025', '244', 'NOH', '2008', '20.94', '117.31']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.72', '.5259', '160', 'LAL', '2008', '-37.92', '93.33']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['31.75', '.5550', '199', 'DAL', '2010', '-41.56', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.5735', '153', 'PHO', '2010', '-6.40', '91.82']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['31.21', '.5795', '174', 'MEM', '2011', '20.00', '100.00']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['17.71', '.4583', '99', 'UTA', '2012', '-97.73', '75.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.69', '.5490', '112', 'LAC', '2012', '-66.67', '66.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.25', '.6667', '180', 'OKC', '2012', '-100.00', '100.00']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.6250', '78', 'LAL', '2013', '62.50', '162.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.29', '.4471', '178', 'GSW', '2013', '41.94', '106.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.30', '.5714', '105', 'MEM', '2013', '42.63', '138.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.66', '.5548', '199', 'MIA', '2013', '-49.88', '75.76']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['32.89', '.6050', '192', 'DAL', '2014', '2.79', '126.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.38', '.3893', '113', 'POR', '2014', '9.68', '90.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.73', '.6567', '137', 'OKC', '2014', '11.58', '97.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.53', '.6574', '143', 'MIA', '2014', '50.89', '107.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.88', '.5283', '131', 'LAC', '2015', '-24.93', '86.63']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uJrNIC7PWILu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pIVKP6D6QBbO"
      },
      "outputs": [],
      "source": [
        "#@title Manu MISC numbers\n",
        "\n",
        "\n",
        "#@title Manu Finals Scoring numbers with only 1 of Tim/Tony on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.27', '.4750', '58', 'NJN', '2003', '31.94', '110.58']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '86', 'DET', '2005', '11.78', '108.97']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.51', '.5750', '36', 'CLE', '2007', '50.79', '123.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.91', '.4444', '75', 'MIA', '2013', '-11.91', '102.99']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.38', '.5000', '20', 'MIA', '2014', '14.76', '102.56']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "#@title Manu Scoring numbers when he starts (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['19.51', '.5714', '20', 'DEN', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['52.38', '.9118', '35', 'SEA', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.28', '.5600', '149', 'PHO', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.03', '.6250', '171', 'DET', '2005']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['25.76', '.5435', '107', 'SAC', '2006']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25', '.5758', '86', 'DAL', '2006']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5959', '143', 'NOH', '2008']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['4.35', '.1429', '23', 'LAL', '2008']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['28.42', '.5098', '102', 'DAL', '2010']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.06', '.6618', '84', 'PHO', '2010']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['32.11', '.6224', '98', 'MEM', '2011']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['40.26', '.6200', '39', 'OKC', '2012']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['26.72', '.7381', '60', 'MIA', '2013']\n",
        "\n",
        "# 2017\n",
        "tmp_df.loc[len(tmp_df)] = ['5.56', '.2000', '16', 'GSW', '2017']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu Finals Scoring numbers with only 1 of Tim/Tony on games 1 and 2\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['53.85', '.8750', '8', 'DET', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['83.33', '1.1667', '11', 'DET', '2005']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.9231', '32', 'DET', '2005']\n",
        "\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu Finals Scoring numbers with only 1 of Tim/Tony on (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['31.43', '.7857', '19', 'NJN', '2003']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['49.25', '.8056', '42', 'DET', '2005']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.2500', '6', 'CLE', '2007']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['0', '.0', '19', 'MIA', '2013']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.6667', '8', 'MIA', '2014']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu 07 numbers\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['25.19', '.4710', '138', 'DEN', '2007', '2.84', '107.89']\n",
        "\n",
        "#g1-4\n",
        "tmp_df.loc[len(tmp_df)] = ['19.67', '.4123', '123', 'PHO', '2007', '-7.02', '105.33']\n",
        "\n",
        "#g5 1Q\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '6', 'PHO', '2007', '-100.00', '33.33']\n",
        "\n",
        "#g5 2Q\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.5000', '9', 'PHO', '2007', '0.00', '106.67']\n",
        "\n",
        "#g5 3Q\n",
        "tmp_df.loc[len(tmp_df)] = ['35.00', '.7000', '10', 'PHO', '2007', '25.00', '115.00']\n",
        "\n",
        "#g5 4Q\n",
        "tmp_df.loc[len(tmp_df)] = ['62.50', '1.0714', '12', 'PHO', '2007', '37.50', '133.33']\n",
        "\n",
        "#g6\n",
        "tmp_df.loc[len(tmp_df)] = ['43.42', '.7857', '36', 'PHO', '2007', '14.42', '118.42']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.56', '.6143', '150', 'UTA', '2007', '8.27', '112.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.81', '.5635', '117', 'CLE', '2007', '20.62', '110.48']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu 05 numbers\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['38.13', '.6420', '154', 'DEN', '2005', '15.39', '114.05']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.76', '.7000', '187', 'SEA', '2005', '13.25', '120.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.41', '.6033', '183', 'PHO', '2005', '9.20', '120.0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.39', '.6139', '252', 'DET', '2005', '2.71', '104.64']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu 07 numbers (3+ starters)\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "#g5 3Q\n",
        "tmp_df.loc[len(tmp_df)] = ['35.00', '.7000', '10', 'PHO', '2007', '25.00', '115.00']\n",
        "\n",
        "#g5 4Q\n",
        "tmp_df.loc[len(tmp_df)] = ['62.50', '1.0714', '12', 'PHO', '2007', '37.50', '133.33']\n",
        "\n",
        "#g6\n",
        "tmp_df.loc[len(tmp_df)] = ['37.93', '.7333', '27', 'PHO', '2007', '13.73', '117.24']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.05', '.6860', '106', 'UTA', '2007', '8.08', '123.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.00', '.5882', '68', 'CLE', '2007', '31.20', '111.20']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Manu 07 numbers (0-2 starters)\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "\n",
        "#g6\n",
        "tmp_df.loc[len(tmp_df)] = ['61.11', '.9167', '9', 'PHO', '2007', '16.67', '122.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.76', '.5000', '44', 'UTA', '2007', '8.50', '85.88']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.47', '.5345', '49', 'CLE', '2007', '5.96', '109.41']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "#@title Manu alone\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "#tmp_df.loc[len(tmp_df)] = ['17.74', '.4024', '105', 'NJN', '2003', '-14.96', '90.86']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['100.00', '1.000', '1', 'MEM', '2004', '-100.00', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['00.00', '.0000', '1', 'LAL', '2004', '00.00', '0.0']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['48.00', '.5000', '12', 'DEN', '2005', '3.70', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.0000', '2', 'SEA', '2005', '-175.00', '0.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['75.00', '.7500', '3', 'PHO', '2005', '150.00', '225.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['00.00', '.00', '5', 'DET', '2005', '-37.50', '62.50']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['31.11', '.5833', '25', 'SAC', '2006', '30.17', '108.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['80.00', '.8571', '8', 'DAL', '2006', '-28.72', '86.67']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['39.58', '.5000', '26', 'DEN', '2007', '17.64', '102.08']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['66.67', '.5000', '12', 'PHO', '2007', '11.11', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.6538', '17', 'UTA', '2007', '6.42', '88.24']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.00', '.2971', '16', 'CLE', '2007', '-23.11', '88.00']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['82.35', '.7778', '8', 'PHO', '2008', '-11.76', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.5000', '15', 'NOH', '2008', '26.29', '114.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.000', '3', 'LAL', '2008', '-87.50', '0.00']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '.000', '6', 'DAL', '2010', '-40.00', '60.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.14', '.2500', '15', 'PHO', '2010', '-44.83', '68.97']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.3158', '31', 'MEM', '2011', '-8.06', '103.23']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['22.86', '.5000', '36', 'UTA', '2012', '47.14', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.14', '.4783', '35', 'LAC', '2012', '-36.99', '97.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.04', '.7147', '45', 'OKC', '2012', '-21.09', '108.70']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['43.50', '.5476', '25', 'LAL', '2013', '50.94', '126.42']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.53', '.5000', '22', 'GSW', '2013', '-0.05', '113.95']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.66', '.4063', '23', 'MEM', '2013', '8.51', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.69', '.4444', '27', 'MIA', '2013', '-38.22', '86.27']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['34.69', '.6538', '52', 'DAL', '2014', '-10.62', '109.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['6.90', '.1667', '28', 'POR', '2014', '31.88', '148.28']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.38', '.5250', '33', 'OKC', '2014', '-0.29', '118.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['46.88', '.9375', '36', 'MIA', '2014', '56.45', '143.75']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SQe3mtTEK-Y"
      },
      "source": [
        "Tony"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wzdz_hyZHVns"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with both of Tim and Manu on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.6190', '50', 'MEM', '2004', '36.35', '128.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.88', '.4211', '106', 'LAL', '2004', '6.16', '96.52']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['24.06', '.4706', '66', 'DEN', '2005', '13.0', '121.8']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.34', '.4667', '106', 'SEA', '2005', '21.34', '122.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.43', '.4844', '112', 'PHO', '2005', '2.40', '121.68']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.82', '.5476', '161', 'DET', '2005', '-0.93', '103.60']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['25.94', '.5288', '112', 'SAC', '2006', '20.24', '125.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.47', '.5149', '154', 'DAL', '2006', '7.45', '115.96']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.5233', '78', 'DEN', '2007', '-3.83', '108.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.90', '.3942', '114', 'PHO', '2007', '1.48', '108.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.18', '.6136', '79', 'UTA', '2007', '7.58', '122.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.97', '.5735', '65', 'CLE', '2007', '14.18', '108.20']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['32.20', '.6000', '105', 'PHO', '2008', '3.80', '109.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.06', '.5746', '169', 'NOH', '2008', '-10.07', '100.94']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.03', '.5556', '102', 'LAL', '2008', '-3.62', '98.99']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['25.31', '.5125', '91', 'DAL', '2010', '11.94', '123.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.65', '.5930', '89', 'PHO', '2010', '5.88', '119.10']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['30.37', '.6042', '102', 'MEM', '2011', '-1.04', '97.91']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['43.88', '.6719', '50', 'UTA', '2012', '-0.19', '109.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.40', '.4583', '67', 'LAC', '2012', '30.88', '116.0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.09', '.5362', '117', 'OKC', '2012', '8.79', '110.08']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['44.74', '.5690', '41', 'LAL', '2013', '19.74', '119.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.90', '.4500', '73', 'GSW', '2013', '-13.80', '90.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.21', '.5652', '41', 'MEM', '2013', '-17.26', '101.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.93', '.5698', '98', 'MIA', '2013', '-1.84', '111.64']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.18', '.5179', '97', 'DAL', '2014', '12.92', '116.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.19', '.5741', '57', 'POR', '2014', '-2.40', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.95', '.6296', '66', 'OKC', '2014', '6.0', '120.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.28', '.6375', '87', 'MIA', '2014', '27.22', '128.48']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RYGsEEHwBoxW"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "#tmp_df.loc[len(tmp_df)] = ['17.74', '.4024', '105', 'NJN', '2003', '-14.96', '90.86']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['31.98', '.6875', '94', 'MEM', '2004', '15.11', '114.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.94', '.4310', '125', 'LAL', '2004', '-16.40', '89.91']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['28.65', '.5000', '105', 'DEN', '2005', '7.27', '105.21']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.31', '.5536', '108', 'SEA', '2005', '-0.51', '114.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '71', 'PHO', '2005', '-3.88', '106.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.97', '.3235', '95', 'DET', '2005', '-4.0', '113.61']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['48.18', '.6226', '73', 'SAC', '2006', '-3.09', '117.52']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.67', '.4648', '105', 'DAL', '2006', '-7.77', '109.41']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['23.08', '.4773', '102', 'DEN', '2007', '18.46', '110.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.63', '.5714', '121', 'PHO', '2007', '4.79', '108.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.65', '.4700', '94', 'UTA', '2007', '7.65', '107.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.67', '.6395', '80', 'CLE', '2007', '-3.12', '103.03']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['45.88', '.5821', '92', 'PHO', '2008', '1.69', '107.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.58', '.5000', '93', 'NOH', '2008', '12.40', '119.11']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.74', '.4674', '83', 'LAL', '2008', '-3.81', '101.29']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['42.32', '.5825', '149', 'DAL', '2009', '-0.65', '111.99']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['24.81', '.4714', '73', 'DAL', '2010', '-1.73', '108.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.55', '.4107', '53', 'PHO', '2010', '-24.51', '101.96']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['26.23', '.4898', '97', 'MEM', '2011', '-9.11', '107.65']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '73', 'UTA', '2012', '33.82', '116.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '73', 'LAC', '2012', '24.51', '119.40']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '92', 'OKC', '2012', '1.43', '111.83']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '82', 'LAL', '2013', '19.43', '111.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '141', 'GSW', '2013', '10.50', '111.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '97', 'MEM', '2013', '28.25', '112.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '135', 'MIA', '2013', '1.02', '107.11']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '126', 'DAL', '2014', '0.70', '111.21']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '81', 'POR', '2014', '15.54', '107.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '91', 'OKC', '2014', '2.39', '107.47']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '64', 'MIA', '2014', '4.57', '114.05']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Z9hQvfBWDyBp"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (3+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '63', 'MEM', '2004', '14.55', '114.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '121', 'LAL', '2004', '-20.18', '86.79']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '91', 'DEN', '2005', '11.90', '105.36']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '82', 'SEA', '2005', '-1.77', '116.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '71', 'PHO', '2005', '-3.88', '106.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '92', 'DET', '2005', '-0.56', '116.43']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '66', 'SAC', '2006', '-4.97', '115.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '93', 'DAL', '2006', '-10.43', '107.39']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '98', 'DEN', '2007', '18.18', '110.92']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '106', 'PHO', '2007', '7.08', '108.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '75', 'UTA', '2007', '8.45', '114.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '66', 'CLE', '2007', '7.62', '105.71']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '82', 'PHO', '2008', '1.31', '105.88']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.46', '.5313', '73', 'NOH', '2008', '14.04', '117.07']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.4848', '55', 'LAL', '2008', '-8.43', '107.92']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['33.60', '.5667', '139', 'DAL', '2009', '-1.93', '110.28']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['19.44', '.3889', '59', 'DAL', '2010', '0.0', '110.19']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.63', '.4063', '33', 'PHO', '2010', '-40.39', '98.41']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['28.29', '.5000', '79', 'MEM', '2011', '-19.63', '101.32']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['27.93', '.4844', '58', 'UTA', '2012', '42.16', '121.62']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.00', '.5000', '59', 'LAC', '2012', '23.17', '124.07']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.39', '.5750', '78', 'OKC', '2012', '2.34', '110.56']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['29.71', '.4750', '75', 'LAL', '2013', '22.39', '112.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.5462', '114', 'GSW', '2013', '0.0', '106.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.56', '.5875', '77', 'MEM', '2013', '26.94', '108.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.33', '.3700', '103', 'MIA', '2013', '-5.12', '103.30']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['30.81', '.4692', '108', 'DAL', '2014', '-0.25', '108.08']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.69', '.5000', '78', 'POR', '2014', '13.61', '106.80']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.94', '.4722', '74', 'OKC', '2014', '4.96', '107.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.02', '.4286', '60', 'MIA', '2014', '-4.70', '107.34']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PjFAAd14T4Pn"
      },
      "outputs": [],
      "source": [
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['34.74', '.8684', '55', 'MEM', '2004', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.93', '.4186', '97', 'LAL', '2004', '-24.93', '86.63']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4714', '70', 'DEN', '2005', '1.50', '99.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.56', '.5893', '62', 'SEA', '2005', '6.83', '119.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4630', '59', 'PHO', '2005', '-2.49', '104.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.94', '.2895', '57', 'DET', '2005', '-5.75', '116.47']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['37.84', '.5385', '42', 'SAC', '2006', '5.06', '113.51']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25', '.4138', '49', 'DAL', '2006', '-3.75', '108.33']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['19.29', '.4091', '79', 'DEN', '2007', '13.25', '102.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.77', '.5938', '84', 'PHO', '2007', '4.01', '107.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.55', '.4107', '58', 'UTA', '2007', '11.88', '114.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['44.19', '.6129', '53', 'CLE', '2007', '12.67', '102.33']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['46.28', '.5600', '65', 'PHO', '2008', '4.92', '107.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.60', '.5128', '61', 'NOH', '2008', '0', '115.84']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.63', '.4800', '44', 'LAL', '2008', '-10.95', '102.47']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['46.03', '.6397', '103', 'DAL', '2009', '-0.84', '112.70']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['21.05', '.4444', '20', 'DAL', '2010', '21.34', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['10.34', '.2143', '14', 'PHO', '2010', '-68.86', '65.52']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['23.76', '.4286', '51', 'MEM', '2011', '-19.55', '99.01']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['28.44', '.4844', '56', 'UTA', '2012', '42.63', '119.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.73', '.5000', '51', 'LAC', '2012', '19.45', '127.96']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.06', '.5694', '68', 'OKC', '2012', '0', '108.87']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['23.14', '.3939', '66', 'LAL', '2013', '18.93', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.4286', '77', 'GSW', '2013', '-18.87', '95.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.02', '.5645', '60', 'MEM', '2013', '14.05', '102.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.44', '.3889', '77', 'MIA', '2013', '5.19', '107.30']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.61', '.4900', '84', 'DAL', '2014', '5.18', '107.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.45', '.4881', '65', 'POR', '2014', '8.36', '105.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.81', '.4848', '64', 'OKC', '2014', '2.47', '108.87']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.57', '.3600', '51', 'MIA', '2014', '-9.96', '106.52']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tony Scoring numbers (4+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['32.20', '.8261', '66', 'MEM', '2004', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.25', '.3906', '195', 'LAL', '2004', '-24.93', '86.63']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['23.25', '.4141', '123', 'DEN', '2005', '1.50', '99.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.79', '.5213', '118', 'SEA', '2005', '6.83', '119.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.40', '.5000', '169', 'PHO', '2005', '-2.49', '104.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.89', '.4394', '185', 'DET', '2005', '-5.75', '116.47']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['27.78', '.5282', '148', 'SAC', '2006', '5.06', '113.51']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.71', '.4516', '140', 'DAL', '2006', '-3.75', '108.33']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['24.30', '.4539', '152', 'DEN', '2007', '13.25', '102.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.48', '.5000', '169', 'PHO', '2007', '4.01', '107.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.33', '.5690', '120', 'UTA', '2007', '11.88', '114.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.40', '.5909', '92', 'CLE', '2007', '12.67', '102.33']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['38.15', '.5787', '141', 'PHO', '2008', '4.92', '107.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.51', '.5200', '208', 'NOH', '2008', '0', '115.84']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.97', '.5242', '124', 'LAL', '2008', '-10.95', '102.47']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['46.03', '.6397', '103', 'DAL', '2009', '-0.84', '112.70']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['19.66', '.4600', '64', 'DAL', '2010', '21.34', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.62', '.5395', '76', 'PHO', '2010', '-68.86', '65.52']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['29.43', '.5417', '139', 'MEM', '2011', '-19.55', '99.01']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.73', '.5636', '94', 'UTA', '2012', '42.63', '119.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.85', '.5000', '85', 'LAC', '2012', '19.45', '127.96']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.96', '.5333', '140', 'OKC', '2012', '0', '108.87']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.4327', '91', 'LAL', '2013', '18.93', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.20', '.4706', '127', 'GSW', '2013', '-18.87', '95.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.89', '.5000', '82', 'MEM', '2013', '14.05', '102.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.94', '.4603', '149', 'MIA', '2013', '5.19', '107.30']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['30.20', '.4744', '132', 'DAL', '2014', '5.18', '107.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.28', '.5379', '117', 'POR', '2014', '8.36', '105.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.86', '.5366', '92', 'OKC', '2014', '2.47', '108.87']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.00', '.3804', '95', 'MIA', '2014', '-9.96', '106.52']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JBiDmpuqYGEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tony Scoring numbers\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['32.21', '.5733', '147', 'SEA', '2002', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.77', '.4792', '194', 'LAL', '2002', '-24.93', '86.63']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['22.44', '.4355', '193', 'PHO', '2003', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.65', '.4731', '210', 'LAL', '2003', '-24.93', '86.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.31', '.4850', '199', 'DAL', '2003', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.43', '.4468', '212', 'NJN', '2003', '-24.93', '86.63']\n",
        "\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['31.00', '.6364', '148', 'MEM', '2004', '10.53', '112.63']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.09', '.4202', '238', 'LAL', '2004', '-24.93', '86.63']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['26.69', '.4840', '180', 'DEN', '2005', '1.50', '99.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.43', '.5096', '221', 'SEA', '2005', '6.83', '119.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.64', '.4904', '190', 'PHO', '2005', '-2.49', '104.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.95', '.4907', '265', 'DET', '2005', '-5.75', '116.47']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['34.28', '.5833', '207', 'SAC', '2006', '5.06', '113.51']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.03', '.4732', '268', 'DAL', '2006', '-3.75', '108.33']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['26.30', '.4892', '187', 'DEN', '2007', '13.25', '102.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.77', '.4921', '238', 'PHO', '2007', '4.01', '107.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.61', '.5372', '174', 'UTA', '2007', '11.88', '114.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.84', '.6049', '151', 'CLE', '2007', '12.67', '102.33']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['38.84', '.5781', '202', 'PHO', '2008', '4.92', '107.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.45', '.5397', '262', 'NOH', '2008', '0', '115.84']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.87', '.5160', '190', 'LAL', '2008', '-10.95', '102.47']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['43.07', '.5813', '181', 'DAL', '2009', '-0.84', '112.70']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['27.38', '.4948', '189', 'DAL', '2010', '21.34', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.99', '.5065', '147', 'PHO', '2010', '-68.86', '65.52']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['28.43', '.5221', '221', 'MEM', '2011', '-19.55', '99.01']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['33.07', '.5753', '131', 'UTA', '2012', '42.63', '119.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.09', '.4595', '149', 'LAC', '2012', '19.45', '127.96']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.45', '.5466', '226', 'OKC', '2012', '0', '108.87']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['37.55', '.5380', '127', 'LAL', '2013', '18.93', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.41', '.4963', '233', 'GSW', '2013', '-18.87', '95.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.22', '.5741', '153', 'MEM', '2013', '14.05', '102.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.02', '.4701', '246', 'MIA', '2013', '5.19', '107.30']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.81', '.5148', '231', 'DAL', '2014', '5.18', '107.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.17', '.5476', '145', 'POR', '2014', '8.36', '105.04']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.31', '.5197', '167', 'OKC', '2014', '2.47', '108.87']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.52', '.5422', '176', 'MIA', '2014', '-9.96', '106.52']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.00', '.3838', '210', 'LAC', '2015', '-9.96', '106.52']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IgddRQCebcJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tony MISC numbers\n",
        "\n",
        "\n",
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (At most 2 starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.5238', '40', 'MEM', '2004', '20.68', '116.88']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.43', '.4667', '28', 'LAL', '2004', '14.42', '102.17']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['30.99', '.5500', '36', 'DEN', '2005', '17.03', '115.49']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.22', '.5179', '47', 'SEA', '2005', '-9.46', '107.78']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.78', '.6667', '12', 'PHO', '2005', '-15.94', '117.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.74', '.3667', '38', 'DET', '2005', '-0.32', '109.68']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['60.32', '.7037', '31', 'SAC', '2006', '-12.78', '122.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.62', '.5000', '56', 'DAL', '2006', '-11.12', '110.38']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['35.77', '.6818', '24', 'DEN', '2007', '35.77', '138.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.26', '.5227', '37', 'PHO', '2007', '6.30', '110.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '.5455', '36', 'UTA', '2007', '1.54', '97.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.96', '.7083', '28', 'CLE', '2007', '-35.19', '104.35']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['44.90', '.6471', '27', 'PHO', '2008', '-6.12', '108.16']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.93', '.4750', '32', 'NOH', '2008', '21.43', '125.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.68', '.4524', '40', 'LAL', '2008', '4.00', '100.00']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.4483', '46', 'DAL', '2009', '-0.13', '110.26']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4808', '53', 'DAL', '2010', '-10.91', '107.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.40', '.4762', '38', 'PHO', '2010', '-6.42', '116.44']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['29.27', '.5714', '46', 'MEM', '2011', '-3.66', '118.29']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['16.13', '.4167', '17', 'UTA', '2012', '3.23', '106.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.83', '.4583', '22', 'LAC', '2012', '34.88', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.5714', '24', 'OKC', '2012', '-0.97', '118.18']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['69.70', '.7857', '17', 'LAL', '2013', '21.21', '118.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.45', '.6923', '63', 'GSW', '2013', '46.15', '130.58']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['39.68', '.6250', '37', 'MEM', '2013', '51.43', '128.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.47', '.4091', '58', 'MIA', '2013', '-4.68', '106.86']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['32.47', '.5435', '42', 'DAL', '2014', '-7.43', '118.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.89', '.6364', '16', 'POR', '2014', '40.36', '113.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.00', '.3636', '27', 'OKC', '2014', '2.08', '104.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['51.72', '.8333', '14', 'MIA', '2014', '53.93', '137.93']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Tony Scoring numbers with only 1 of Tim/Manu on (Exactly 3 starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.3333', '8', 'MEM', '2004', '38.43', '126.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.00', '.5000', '23', 'LAL', '2004', '-0.60', '87.50']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['29.79', '.5833', '22', 'DEN', '2005', '41.79', '121.28']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.50', '.4231', '20', 'SEA', '2005', '-25.00', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.78', '.6667', '12', 'PHO', '2005', '-15.94', '117.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['16.36', '.3462', '35', 'DET', '2005', '8.96', '116.36']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['60.78', '.7750', '24', 'SAC', '2006', '-19.85', '117.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.00', '.5000', '44', 'DAL', '2006', '-17.85', '106.25']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['32.35', '.6875', '19', 'DEN', '2007', '38.49', '147.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.82', '.5833', '22', 'PHO', '2007', '18.29', '113.64']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.71', '.6667', '18', 'UTA', '2007', '-3.23', '112.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['52.63', '.6250', '13', 'CLE', '2007', '-17.84', '121.05']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['31.25', '.5000', '18', 'PHO', '2008', '-11.76', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.6111', '12', 'NOH', '2008', '43.56', '122.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.00', '.5000', '12', 'LAL', '2008', '-8.43', '130.00']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['28.13', '.4091', '36', 'DAL', '2009', '-4.94', '103.13']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['18.57', '.3611', '39', 'DAL', '2010', '-20.30', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.5556', '19', 'PHO', '2010', '-16.39', '126.47']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['37.25', '.6333', '28', 'MEM', '2011', '-19.61', '250.00']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['0.0', '.00', '2', 'UTA', '2012', '110.00', '121.62']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.67', '.5000', '9', 'LAC', '2012', '41.18', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.78', '.6250', '10', 'OKC', '2012', '7.22', '122.22']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['76.47', '.8571', '9', 'LAL', '2013', '47.06', '135.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.59', '.7308', '37', 'GSW', '2013', '45.59', '129.41']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.00', '.6667', '17', 'MEM', '2013', '71.94', '130.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.00', '.3214', '26', 'MIA', '2013', '-35.97', '91.11']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['27.91', '.4000', '24', 'DAL', '2014', '-17.78', '109.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.71', '.5556', '13', 'POR', '2014', '36.51', '114.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['11.11', '.3333', '10', 'OKC', '2014', '20.76', '94.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '1.000', '9', 'MIA', '2014', '23.53', '111.76']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Tony Finals Scoring numbers with only 1 of Tim/Manu on (3+ starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['15.20', '.3714', '96', 'NJN', '2003']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '92', 'DET', '2005']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '66', 'CLE', '2007']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['20.33', '.3700', '103', 'MIA', '2013']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['22.02', '.4286', '60', 'MIA', '2014']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "#@title Tony 07 numbers\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2007\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.30', '.4892', '187', 'DEN', '2007', '6.35', '108.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.77', '.4921', '238', 'PHO', '2007', '1.63', '107.49']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.61', '.5372', '174', 'UTA', '2007', '7.49', '114.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.84', '.6049', '151', 'CLE', '2007', '3.73', '104.89']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title Tony alone\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "#tmp_df.loc[len(tmp_df)] = ['17.74', '.4024', '105', 'NJN', '2003', '-14.96', '90.86']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['36.50', '.3000', '4', 'MEM', '2004', '33.93', '62.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.2500', '7', 'LAL', '2004', '-21.43', '85.71']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['25.00', '.4000', '8', 'DEN', '2005', '18.75', '27.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['18.18', '.3333', '7', 'SEA', '2005', '-99.39', '114.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['50.00', '.5000', '7', 'PHO', '2005', '-13.33', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '.5000', '9', 'DET', '2005', '22.88', '111.76']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['30.77', '.6667', '21', 'SAC', '2006', '-17.95', '102.56']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.58', '.2727', '9', 'DAL', '2006', '-90.16', '31.58']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '0.00', '7', 'DEN', '2007', '-63.64', '63.64']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['57.14', '.4000', '4', 'PHO', '2007', '-100.00', '57.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['0.00', '0.000', '1', 'UTA', '2007', '-50.00', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5000', '6', 'CLE', '2007', '-23.72', '91.67']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['36.36', '.3333', '5', 'PHO', '2008', '11.69', '72.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['57.14', '.6667', '4', 'LAL', '2008', '-22.22', '100.00']\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['46.15', '.5769', '32', 'DAL', '2009', '-25.06', '84.62']\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['40.38', '.5000', '25', 'DAL', '2010', '-12.02', '94.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['44.44', '.3333', '5', 'PHO', '2010', '-31.31', '122.22']\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['29.27', '.3750', '22', 'MEM', '2011', '-8.31', '78.05']\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['31.25', '.8333', '8', 'UTA', '2012', '-37.50', '87.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.2500', '9', 'LAC', '2012', '-6.25', '93.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.35', '.5000', '17', 'OKC', '2012', '-49.68', '90.32']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['57.14', '.6667', '4', 'LAL', '2013', '10.71', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.3125', '20', 'GSW', '2013', '-15.52', '94.74']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.92', '.5000', '15', 'MEM', '2013', '-39.56', '96.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.00', '.6000', '14', 'MIA', '2013', '-4.07', '103.33']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['36.84', '.5833', '9', 'DAL', '2014', '15.17', '121.05']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.29', '.7500', '8', 'POR', '2014', '17.65', '117.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.00', '.5000', '10', 'OKC', '2014', '20.00', '125.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.3333', '24', 'MIA', '2014', '-25.00', '97.92']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qEBKucfP2uUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TIM**"
      ],
      "metadata": {
        "id": "IuUt6BM79PS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tim\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "# 1998\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['26.6', '.5730', '163', 'PHO', '1998', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['29.6', '.5485', '210', 'UTA', '1998', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "\n",
        "# 1999\n",
        "tmp_df.loc[len(tmp_df)] = ['24.67', '.516', '171', 'MIN', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.2688331', '.600', '177', 'LAL', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.47', '.547', '157', 'POR', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.349469', '.5999', '228', 'NYK', '1999', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.47', '.512', '154', 'MIN', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['35.6', '.5400', '202', 'DAL', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.3', '.547', '169', 'LAL', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['37.73', '.5988', '156', 'SEA', '2002', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.07', '.486', '224', 'LAL', '2002', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['22.95', '.5773', '257', 'PHO', '2003', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "            \n",
        "tmp_df.loc[len(tmp_df)] = ['37', '.575', '241', 'LAL', '2003', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['33.4', '.5957', '260', 'DAL', '2003', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.71', '.5410', '264', 'NJN', '2003', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['35.66', '.5988', '153', 'MEM', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "            \n",
        "tmp_df.loc[len(tmp_df)] = ['27.25', '.534', '251', 'LAL', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['35.83', '.5140', '165', 'DEN', '2005', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['38.52', '.5393', '218', 'SEA', '2005', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['36.44', '.5855', '198', 'PHO', '2005', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.81', '.471', '285', 'DET', '2005', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "#easy\n",
        "tmp_df.loc[len(tmp_df)] = ['29.57', '.6471', '202', 'SAC', '2006', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.7221172', '.5938', '291', 'DAL', '2006', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['29.19', '.4856', '188', 'DEN', '2007', '13.25', '102.14']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.14', '.5919', '229', 'PHO', '2007', '4.01', '107.10']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.94', '.6193', '170', 'UTA', '2007', '11.88', '114.71']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.97', '.4803', '149', 'CLE', '2007', '12.67', '102.33']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['32.55', '.5167', '199', 'PHO', '2008', '4.92', '107.44']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.20', '.4820', '266', 'NOH', '2008', '0', '115.84']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.55', '.4628', '124', 'LAL', '2008', '-10.95', '102.47']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2009\n",
        "tmp_df.loc[len(tmp_df)] = ['33.79', '.5562', '164', 'DAL', '2009', '-0.84', '112.70']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2010\n",
        "tmp_df.loc[len(tmp_df)] = ['27.25', '.5142', '223', 'DAL', '2010', '21.34', '110.53']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.5473', '150', 'PHO', '2010', '-68.86', '65.52']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2011\n",
        "tmp_df.loc[len(tmp_df)] = ['19.05', '.4935', '212', 'MEM', '2011', '-19.55', '99.01']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['24.46', '.5278', '121', 'UTA', '2012', '42.63', '119.27']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.47', '.6176', '136', 'LAC', '2012', '19.45', '127.96']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.25', '.4766', '207', 'OKC', '2012', '0', '108.87']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['29.29', '.5556', '129', 'LAL', '2013', '18.93', '109.09']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.96', '.4916', '214', 'GSW', '2013', '-18.87', '95.89']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.90', '.4921', '138', 'MEM', '2013', '14.05', '102.83']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.03', '.5500', '254', 'MIA', '2013', '5.19', '107.30']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['25.80', '.6050', '244', 'DAL', '2014', '5.18', '107.74']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.90', '.4929', '162', 'POR', '2014', '8.36', '105.04']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.89', '.5515', '181', 'OKC', '2014', '2.47', '108.87']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.67', '.6111', '165', 'MIA', '2014', '-9.96', '106.52']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.88', '.5952', '250', 'LAC', '2015', '-9.96', '106.52']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "manu_one_on = manu_one_on.reset_index(drop=True)\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "b68i0m747x5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Kobe/Shaq series\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "\n",
        "# Shaq\n",
        "tmp_df.loc[len(tmp_df)] = ['44.7497547', '.5938', '1', 'IND', '2000', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.67', '.5885', '163', 'SAC', '2001', '7.35', '105.81']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.24', '.5455', '156', 'SAS', '2001', '22.70', '114.48']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "#Kobe\n",
        "tmp_df.loc[len(tmp_df)] = ['40.00', '.588', '173', 'SAC', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.36', '.571', '168', 'SAS', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.83', '.501', '234', 'PHI', '2001', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.42', '.486', '218', 'SAS', '2002', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.89', '.491', '308', 'SAC', '2002', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "            \n",
        "tmp_df.loc[len(tmp_df)] = ['31.85', '.623', '174', 'NJN', '2002', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "            \n",
        "tmp_df.loc[len(tmp_df)] = ['39.27', '.533', '261', 'SAS', '2003', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "            \n",
        "tmp_df.loc[len(tmp_df)] = ['30.05', '.507', '233', 'HOU', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.64', '.534', '264', 'SAS', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.81', '.519', '255', 'MIN', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.49', '.456', '231', 'DET', '2004', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "            \n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.585', '201', 'SAS', '2008', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.56', '.505', '258', 'BOS', '2008', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '219', 'ORL', '2009', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.31', '.528', '288', 'BOS', '2010', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "# Kobe rOffRtg\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.585', '157', 'DEN', '2008', '36.35', '118.75']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.585', '247', 'UTA', '2008', '36.35', '118.40']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.585', '201', 'SAS', '2008', '36.35', '106.05']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.56', '.505', '258', 'BOS', '2008', '36.35', '103.89']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '203', 'UTA', '2009', '36.35', '113.28']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '266', 'HOU', '2009', '36.35', '111.65']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '252', 'DEN', '2009', '36.35', '116.39']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '219', 'ORL', '2009', '36.35', '112.28']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '2221', 'OKC', '2010', '36.35', '107.66']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '164', 'UTA', '2010', '36.35', '118.87']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['40.60', '.525', '249', 'PHO', '2010', '36.35', '127.41']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.31', '.528', '288', 'BOS', '2010', '36.35', '104.02']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# LeBron\n",
        "tmp_df.loc[len(tmp_df)] = ['40.75', '.528', '288', 'SAS', '2014', '36.35', '128.57']\n",
        "manu_one_on = manu_one_on.append(tmp_df)\n",
        "tmp_df.drop(tmp_df.index,inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "manu_one_on = manu_one_on.reset_index(drop=True)\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a8EsRGnBMhuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tony/Manu On/Off numbers"
      ],
      "metadata": {
        "id": "HIYHokiV2-3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Peak rOffRtg On/Off\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# everything besides OffRtg and MP dummy values\n",
        "\n",
        "# Manu On\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '154', 'DEN', '2005', '18.88', '114.05']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '187', 'SEA', '2005', '7.79', '120.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '183', 'PHO', '2005', '12.23', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '252', 'DET', '2005', '11.78', '104.64']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '184', 'SAC', '2006', '1.14', '119.13']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '243', 'DAL', '2006', '2.70', '113.26']\n",
        "\n",
        "\n",
        "\n",
        "# Manu Off\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '91', 'DEN', '2005', '18.88', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '101', 'SEA', '2005', '7.79', '99.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '57', 'PHO', '2005', '12.23', '105.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '89', 'DET', '2005', '11.78', '98.62']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '109', 'SAC', '2006', '1.14', '114.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '103', 'DAL', '2006', '2.70', '98.98']\n",
        "\n",
        "\n",
        "\n",
        "# Manu On (no Bruce!)\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '57', 'DEN', '2005', '18.88', '108.70']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '61', 'SEA', '2005', '7.79', '124.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '69', 'PHO', '2005', '12.23', '128.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '59', 'DET', '2005', '11.78', '99.04']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '80', 'SAC', '2006', '1.14', '120.13']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '60', 'DAL', '2006', '2.70', '126.50']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tony On\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '131', 'UTA', '2012', '33.82', '111.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '149', 'LAC', '2012', '24.51', '116.36']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '226', 'OKC', '2012', '1.43', '109.36']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '127', 'LAL', '2013', '19.43', '113.08']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '233', 'GSW', '2013', '10.50', '103.60']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '153', 'MEM', '2013', '28.25', '107.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '246', 'MIA', '2013', '1.02', '108.73']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '231', 'DAL', '2014', '0.70', '113.96']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '145', 'POR', '2014', '15.54', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '167', 'OKC', '2014', '2.39', '113.85']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '176', 'MIA', '2014', '4.57', '118.65']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tony Off\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '61', 'UTA', '2012', '33.82', '107.86']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '43', 'LAC', '2012', '24.51', '101.11']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '62', 'OKC', '2012', '1.43', '102.38']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '65', 'LAL', '2013', '19.43', '114.73']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '70', 'GSW', '2013', '10.50', '112.59']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '49', 'MEM', '2013', '28.25', '107.29']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '95', 'MIA', '2013', '1.02', '106.29']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '105', 'DAL', '2014', '0.70', '107.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '95', 'POR', '2014', '15.54', '120.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '126', 'OKC', '2014', '2.39', '111.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '64', 'MIA', '2014', '4.57', '123.89']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Im8HJgCBZ-88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manu/Tony Peak rOffRtg On/Off 4+ starters\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# everything besides OffRtg dummy values\n",
        "\n",
        "# Manu On\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '77', 'DEN', '2005', '18.88', '110.27']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '69', 'SEA', '2005', '7.79', '140.16']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '149', 'PHO', '2005', '12.23', '120.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '171', 'DET', '2005', '11.78', '104.15']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '107', 'SAC', '2006', '1.14', '118.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '102', 'DAL', '2006', '2.70', '108.65']\n",
        "\n",
        "\n",
        "\n",
        "# Manu Off\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['41.13', '.6591', '56', 'DEN', '2005', '18.88', '91.75']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6250', '56', 'SEA', '2005', '7.79', '94.85']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['32.82', '.5513', '42', 'PHO', '2005', '12.23', '102.78']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.76', '.7073', '53', 'DET', '2005', '11.78', '98.75']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['12.50', '.4231', '61', 'SAC', '2006', '1.14', '114.41']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.22', '.6489', '54', 'DAL', '2006', '2.70', '108.57']\n",
        "\n",
        "\n",
        "\n",
        "# Tony On\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '94', 'UTA', '2012', '33.82', '114.13']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '85', 'LAC', '2012', '24.51', '123.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '140', 'OKC', '2012', '1.43', '110.49']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '91', 'LAL', '2013', '19.43', '113.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '127', 'GSW', '2013', '10.50', '96.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '82', 'MEM', '2013', '28.25', '100.68']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '149', 'MIA', '2013', '1.02', '110.47']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '132', 'DAL', '2014', '0.70', '113.47']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '117', 'POR', '2014', '15.54', '109.25']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '92', 'OKC', '2014', '2.39', '112.99']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '95', 'MIA', '2014', '4.57', '112.57']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tony Off\n",
        "\n",
        "# 2012\n",
        "tmp_df.loc[len(tmp_df)] = ['25.71', '.4737', '15', 'UTA', '2012', '33.82', '103.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.37', '.4853', '2', 'LAC', '2012', '24.51', '0']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.99', '.5698', '8', 'OKC', '2012', '1.43', '61.11']\n",
        "\n",
        "# 2013\n",
        "tmp_df.loc[len(tmp_df)] = ['33.12', '.5106', '13', 'LAL', '2013', '19.43', '88.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['33.33', '.5577', '18', 'GSW', '2013', '10.50', '111.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.50', '.5882', '14', 'MEM', '2013', '28.25', '115.38']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.01', '.3986', '28', 'MIA', '2013', '1.02', '94.12']\n",
        "\n",
        "# 2014\n",
        "tmp_df.loc[len(tmp_df)] = ['31.90', '.5068', '14', 'DAL', '2014', '0.70', '143.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.48', '.5189', '47', 'POR', '2014', '15.54', '122.34']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.99', '.4545', '32', 'OKC', '2014', '2.39', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.27', '.4853', '14', 'MIA', '2014', '4.57', '150.00']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c85_peEvlzaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title rOffRtg Tim/Tony On; Manu Off\n",
        "\n",
        "# PTS TS+ dummy values\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['31.98', '.6875', '68', 'MEM', '2004', '10.83', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.94', '.4310', '102', 'LAL', '2004', '-19.82', '86.36']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['24.06', '.4706', '56', 'DEN', '2005', '-3.99', '97.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.34', '.4667', '60', 'SEA', '2005', '-6.59', '105.56']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['27.43', '.4844', '40', 'PHO', '2005', '-13.28', '112.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.82', '.5476', '62', 'DET', '2005', '-11.47', '111.83']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['25.94', '.5288', '53', 'SAC', '2006', '-3.29', '114.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.47', '.5149', '71', 'DAL', '2006', '-9.72', '112.59']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.5233', '87', 'DEN', '2007', '18.27', '107.95']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['17.90', '.3942', '82', 'PHO', '2007', '5.23', '105.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.18', '.6136', '60', 'UTA', '2007', '10.51', '112.38']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.97', '.5735', '61', 'CLE', '2007', '-14.29', '97.96']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['32.20', '.6000', '72', 'PHO', '2008', '-3.80', '106.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['24.06', '.5746', '65', 'NOH', '2008', '7.53', '120.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.03', '.5556', '64', 'LAL', '2008', '2.59', '103.42']\n",
        "\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jUzUW7YluP6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sHrWJxvESTy"
      },
      "source": [
        "Klay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2NZwjbmh3GYh"
      },
      "outputs": [],
      "source": [
        "#@title Kobe Scoring numbers vs Spurs (Tim On)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2001\n",
        "tmp_df.loc[len(tmp_df)] = ['40.69', '.5673', '157', 'SAS', '2001', '15', '15']\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['32.80', '.4766', '209', 'SAS', '2002', '15', '15']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['38.90', '.5185', '232', 'SAS', '2003', '15', '15']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['32.30', '.5271', '232', 'SAS', '2004', '15', '15']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['38.42', '.5862', '188', 'SAS', '2008', '15', '15']\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NWwiLOog3IMM"
      },
      "outputs": [],
      "source": [
        "#@title Kobe Scoring numbers vs Spurs (Tim Off)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2001\n",
        "tmp_df.loc[len(tmp_df)] = ['62.5', '.5833', '11', 'SAS', '2001', '15', '15']\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['47.06', '.6667', '9', 'SAS', '2002', '15', '15']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['42.11', '.6000', '29', 'SAS', '2003', '15', '15']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['34.92', '.5526', '31', 'SAS', '2004', '15', '15']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['38.46', '.6250', '13', 'SAS', '2008', '15', '15']\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Klay Scoring numbers with Curry off\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2015\n",
        "tmp_df.loc[len(tmp_df)] = ['18.87', '.3571', '28', 'NOP', '2015', '-37.74', '90.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.43', '.7000', '41', 'MEM', '2015', '-1.62', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.90', '.6364', '32', 'HOU', '2015', '29.46', '126.23']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.86', '.5833', '27', 'CLE', '2015', '-24.29', '87.76']\n",
        "\n",
        "# 2016\n",
        "tmp_df.loc[len(tmp_df)] = ['34.26', '.5774', '141', 'HOU', '2016', '20.08', '115.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.32', '.5707', '133', 'POR', '2016', '4.83', '112.41']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.65', '.4524', '35', 'OKC', '2016', '-24.19', '90.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.8000', '56', 'CLE', '2016', '-4.22', '104.95']\n",
        "\n",
        "# 2017\n",
        "tmp_df.loc[len(tmp_df)] = ['29.41', '.4762', '37', 'POR', '2017', '4.14', '113.24']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['15.00', '.3333', '43', 'UTA', '2017', '-2.59', '90.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.05', '.5000', '37', 'SAS', '2017', '9.03', '115.79']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.69', '.3750', '44', 'CLE', '2017', '5.51', '95.40']\n",
        "\n",
        "# 2018\n",
        "tmp_df.loc[len(tmp_df)] = ['30.21', '.6348', '196', 'SAS', '2018', '8.54', '113.10']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['30.86', '.4821', '83', 'NOP', '2018', '-8.48', '99.43']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['42.62', '.5909', '32', 'HOU', '2018', '-17.20', '108.20']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['37.84', '.7000', '21', 'CLE', '2018', '44.93', '132.43']\n",
        "\n",
        "# 2019\n",
        "tmp_df.loc[len(tmp_df)] = ['30.22', '.7000', '68', 'LAC', '2019', '0.31', '121.58']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.71', '.6250', '53', 'HOU', '2019', '-7.48', '109.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.98', '.3542', '36', 'POR', '2019', '-12.55', '96.83']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.42', '.5769', '31', 'TOR', '2019', '-16.95', '106.78']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hOP-kp58D25z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Klay Scoring numbers with Curry on\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2015\n",
        "tmp_df.loc[len(tmp_df)] = ['37.04', '.618', '124', 'NOP', '2015', '23.46', '123.46']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.42', '.5519', '183', 'MEM', '2015', '10.26', '101.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.02', '.4692', '126', 'HOU', '2015', '0', '106.79']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['19.22', '.4933', '200', 'CLE', '2015', '10.40', '109.61']\n",
        "\n",
        "# 2016\n",
        "tmp_df.loc[len(tmp_df)] = ['28.57', '.8182', '28', 'HOU', '2016', '35.81', '107.94']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['38.46', '.9259', '58', 'POR', '2016', '17.18', '133.85']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.90', '.5540', '207', 'OKC', '2016', '0.21', '110.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['28.07', '.5198', '191', 'CLE', '2016', '-9.82', '102.41']\n",
        "\n",
        "# 2017\n",
        "tmp_df.loc[len(tmp_df)] = ['24.09', '.4796', '101', 'POR', '2017', '33.15', '125.45']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['21.78', '.6111', '95', 'UTA', '2017', '18.23', '120.79']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['12.84', '.3889', '101', 'SAS', '2017', '20.22', '128.44']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['22.38', '.6413', '139', 'CLE', '2017', '6.64', '126.92']\n",
        "\n",
        "# 2018\n",
        "tmp_df.loc[len(tmp_df)] = ['30.40', '.4787', '100', 'NOP', '2018', '17.16', '111.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.71', '.6250', '234', 'HOU', '2018', '10.54', '112.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.75', '.5952', '127', 'CLE', '2018', '15.26', '126.56']\n",
        "\n",
        "# 2019\n",
        "tmp_df.loc[len(tmp_df)] = ['19.20', '.5083', '148', 'LAC', '2019', '0.38', '113.31']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['20.20', '.5263', '196', 'HOU', '2019', '5.11', '117.68']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.65', '.5074', '129', 'POR', '2019', '5.77', '117.84']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['36.16', '.7278', '157', 'TOR', '2019', '-0.31', '113.21']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JTLfqjB6MFIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce Off/Manu On (3+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '114', 'PHO', '2003', '23.51', '110.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '37', 'LAL', '2003', '-30.56', '84.51']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '77', 'DAL', '2003', '27.20', '115.79']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '75', 'NJN', '2003', '11.74', '102.01']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '27', 'MEM', '2004', '5.37', '84.62']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '74', 'LAL', '2004', '10.27', '103.42']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '23', 'DEN', '2005', '23.57', '104.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '31', 'SEA', '2005', '34.12', '144.64']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '69', 'PHO', '2005', '25.18', '128.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '57', 'DET', '2005', '8.70', '100.00']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '66', 'SAC', '2006', '3.59', '117.19']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '40', 'DAL', '2006', '12.58', '118.99']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '53', 'DEN', '2007', '3.05', '114.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '45', 'PHO', '2007', '2.04', '120.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '46', 'UTA', '2007', '17.44', '129.07']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '9', 'CLE', '2007', '27.78', '94.44']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '84', 'PHO', '2008', '2.56', '112.87']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '52', 'NOH', '2008', '10.62', '117.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '22', 'LAL', '2008', '-32.00', '102.04']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LmU_yGiEgfLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce On/Manu On (3+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '44', 'PHO', '2003', '-4.40', '85.71']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '65', 'LAL', '2003', '19.53', '119.53']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '68', 'DAL', '2003', '0.15', '104.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '52', 'NJN', '2003', '13.38', '97.92']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '28', 'MEM', '2004', '34.69', '132.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '69', 'LAL', '2004', '-12.46', '90.00']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '86', 'DEN', '2005', '11.03', '117.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '95', 'SEA', '2005', '14.20', '120.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '114', 'PHO', '2005', '-0.17', '114.98']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '192', 'DET', '2005', '0.47', '106.13']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '97', 'SAC', '2006', '14.59', '117.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '92', 'DAL', '2006', '1.35', '109.64']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '66', 'DEN', '2007', '-10.57', '98.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '123', 'PHO', '2007', '-4.87', '101.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '59', 'UTA', '2007', '1.10', '118.80']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '59', 'CLE', '2007', '32.54', '114.02']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '43', 'PHO', '2008', '-16.51', '95.12']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.46', '.5313', '162', 'NOH', '2008', '-9.33', '99.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.4848', '98', 'LAL', '2008', '-3.86', '95.58']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3I39N3jAghOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce Off/Manu On (4+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '78', 'PHO', '2003', '24.00', '106.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '12', 'LAL', '2003', '0.38', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '42', 'DAL', '2003', '44.06', '114.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '49', 'NJN', '2003', '16.00', '112.87']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '11', 'MEM', '2004', '35.00', '95.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '61', 'LAL', '2004', '6.77', '105.04']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '12', 'DEN', '2005', '4.00', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '13', 'SEA', '2005', '60.87', '173.91']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '46', 'PHO', '2005', '20.56', '126.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '14', 'DET', '2005', '-32.39', '82.61']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '26', 'SAC', '2006', '9.80', '131.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '9', 'DAL', '2006', '0.0', '100.00']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '29', 'DEN', '2007', '-8.53', '112.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '19', 'PHO', '2007', '5.07', '137.50']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '29', 'UTA', '2007', '30.22', '133.93']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '6', 'CLE', '2007', '3.33', '83.33']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '56', 'PHO', '2008', '5.19', '111.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '35', 'NOH', '2008', '-14.50', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '10', 'LAL', '2008', '27.30', '136.00']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JxTKtAAdMxB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce On/Manu On (4+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '16', 'PHO', '2003', '-3.12', '81.25']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '40', 'LAL', '2003', '19.33', '123.08']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '21', 'DAL', '2003', '-8.93', '88.57']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '36', 'NJN', '2003', '-0.09', '93.85']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '5', 'MEM', '2004', '-1.28', '83.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '60', 'LAL', '2004', '-4.72', '95.28']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '65', 'DEN', '2005', '7.69', '112.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '55', 'SEA', '2005', '41.41', '132.32']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '102', 'PHO', '2005', '-3.00', '117.48']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '157', 'DET', '2005', '4.51', '106.02']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '81', 'SAC', '2006', '15.18', '113.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '92', 'DAL', '2006', '1.35', '109.64']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '53', 'DEN', '2007', '-17.15', '99.01']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '92', 'PHO', '2007', '-10.11', '100.56']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '42', 'UTA', '2007', '-1.60', '115.48']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '36', 'CLE', '2007', '62.97', '130.16']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '29', 'PHO', '2008', '-38.91', '82.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.46', '.5313', '145', 'NOH', '2008', '-8.64', '101.85']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.4848', '79', 'LAL', '2008', '-8.67', '91.33']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ni8QrCQ5MvTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce Off (4+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '20', 'SEA', '2002', '63.89', '152.78']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '15', 'LAL', '2002', '4.28', '93.94']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '80', 'PHO', '2003', '20.05', '104.03']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '12', 'LAL', '2003', '0.38', '104.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '42', 'DAL', '2003', '44.66', '113.41']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '52', 'NJN', '2003', '11.16', '112.15']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '11', 'MEM', '2004', '30.48', '90.48']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '70', 'LAL', '2004', '2.23', '102.99']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '14', 'DEN', '2005', '4.29', '90.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '19', 'SEA', '2005', '45.36', '151.61']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '46', 'PHO', '2005', '20.56', '126.37']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '18', 'DET', '2005', '-48.89', '68.97']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '45', 'SAC', '2006', '0', '124.72']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '11', 'DAL', '2006', '3.70', '108.70']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '29', 'DEN', '2007', '-8.53', '112.90']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '21', 'PHO', '2007', '2.72', '129.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '34', 'UTA', '2007', '30.39', '136.36']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '11', 'CLE', '2007', '4.74', '110.00']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '68', 'PHO', '2008', '6.39', '117.16']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '43', 'NOH', '2008', '-19.05', '102.47']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '10', 'LAL', '2008', '27.30', '136.00']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4hutnyOS2ZpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce On (4+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '112', 'SEA', '2002', '10.78', '112.31']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '132', 'LAL', '2002', '0.01', '100.43']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '97', 'PHO', '2003', '-19.25', '84.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '148', 'LAL', '2003', '13.92', '112.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '106', 'DAL', '2003', '0', '103.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '122', 'NJN', '2003', '-4.59', '94.04']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '62', 'MEM', '2004', '8.21', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '131', 'LAL', '2004', '-22.28', '86.27']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '118', 'DEN', '2005', '-1.21', '104.69']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '106', 'SEA', '2005', '9.01', '114.89']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '144', 'PHO', '2005', '-5.13', '113.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '206', 'DET', '2005', '-1.85', '105.88']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '123', 'SAC', '2006', '13.19', '113.64']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '145', 'DAL', '2006', '-2.66', '108.61']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '136', 'DEN', '2007', '0.01', '100.81']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '163', 'PHO', '2007', '-6.44', '102.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '93', 'UTA', '2007', '1.75', '112.28']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '57', 'CLE', '2007', '24.78', '115.31']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '78', 'PHO', '2008', '-6.84', '95.86']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.46', '.5313', '184', 'NOH', '2008', '-5.69', '104.22']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.4848', '121', 'LAL', '2008', '-8.81', '95.57']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WZutUNEs2Xoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce Off (5+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '2', 'SEA', '2002', '140.00', '180.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '4', 'LAL', '2002', '-77.50', '60.00']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '10', 'PHO', '2003', '30.26', '125.00']\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '6', 'LAL', '2003', '-23.08', '100.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '9', 'DAL', '2003', '66.11', '105.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '13', 'NJN', '2003', '16.67', '91.67']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '4', 'MEM', '2004', '96.43', '125.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '27', 'LAL', '2004', '39.87', '115.38']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '6', 'DEN', '2005', '55.24', '146.15']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '11', 'SEA', '2005', '64.74', '170.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '6', 'PHO', '2005', '39.39', '166.67']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '4', 'DET', '2005', '-114.29', '42.86']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '15', 'SAC', '2006', '-24.01', '124.14']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '2', 'DAL', '2006', '0', '75.00']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '16', 'DEN', '2007', '14.96', '121.21']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '10', 'PHO', '2007', '4.21', '120.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '18', 'UTA', '2007', '38.05', '146.88']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '1', 'CLE', '2007', '-100.00', '0']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '21', 'PHO', '2008', '-4.29', '110.00']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '18', 'NOH', '2008', '-39.78', '93.55']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '5', 'LAL', '2008', '55.56', '133.33']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1eRNPEgcyxM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bruce On (5+ opp. starters)\n",
        "\n",
        "tmp_df = pd.DataFrame(columns = ['PP75', 'TS%', 'MP', 'Opp', 'Year', 'NetRtg', 'OffRtg'])\n",
        "tmp_df = tmp_df.iloc[0:0]\n",
        "\n",
        "# 2002\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '73', 'SEA', '2002', '24.83', '114.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '83', 'LAL', '2002', '-7.02', '93.66']\n",
        "\n",
        "# 2003\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '51', 'PHO', '2003', '-9.48', '86.17']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '127', 'LAL', '2003', '14.10', '112.82']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '44', 'DAL', '2003', '9.30', '110.47']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '84', 'NJN', '2003', '-8.01', '87.42']\n",
        "\n",
        "# 2004\n",
        "tmp_df.loc[len(tmp_df)] = ['33.64', '.7400', '59', 'MEM', '2004', '10.63', '112.26']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['23.58', '.4386', '104', 'LAL', '2004', '-26.55', '87.98']\n",
        "\n",
        "# 2005\n",
        "tmp_df.loc[len(tmp_df)] = ['27.98', '.5000', '70', 'DEN', '2005', '-3.81', '104.65']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['29.73', '.5366', '54', 'SEA', '2005', '19.57', '117.39']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['25.58', '.5000', '85', 'PHO', '2005', '7.76', '130.30']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['14.29', '.3125', '137', 'DET', '2005', '-5.99', '100.88']\n",
        "\n",
        "# 2006\n",
        "tmp_df.loc[len(tmp_df)] = ['47.20', '.6413', '75', 'SAC', '2006', '27.96', '118.18']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['34.09', '.4615', '60', 'DAL', '2006', '0', '102.75']\n",
        "\n",
        "# 2007\n",
        "tmp_df.loc[len(tmp_df)] = ['21.84', '.4634', '103', 'DEN', '2007', '4.26', '100.54']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['35.68', '.5917', '72', 'PHO', '2007', '5.31', '106.06']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['26.32', '.4730', '60', 'UTA', '2007', '6.31', '109.09']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['45.71', '.6154', '57', 'CLE', '2007', '24.78', '115.31']\n",
        "\n",
        "# 2008\n",
        "tmp_df.loc[len(tmp_df)] = ['43.14', '.5500', '49', 'PHO', '2008', '-17.23', '84.95']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['41.46', '.5313', '133', 'NOH', '2008', '-16.19', '98.33']\n",
        "\n",
        "tmp_df.loc[len(tmp_df)] = ['31.68', '.4848', '84', 'LAL', '2008', '-5.73', '95.57']\n",
        "\n",
        "manu_one_on = tmp_df.copy()\n",
        "\n",
        "print(manu_one_on)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LeivjhypuOx1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}